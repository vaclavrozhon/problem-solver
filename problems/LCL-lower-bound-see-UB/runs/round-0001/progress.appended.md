## Round 0001 — 2025-08-28T11:38:00.688946Z

Headlines
- Goal: Prove NEXPTIME-hardness for classifying β-normalized, radius-1 LCLs on globally oriented paths into O(1) vs. Ω(log* n) vs. Ω(n).
- Status: The attached draft gives an NEXPTIME upper bound for feasible-function existence (FFE) and sketches NEXPTIME-hardness via a reduction from Succinct-3SAT. I identified a subtlety in the hardness appendix: “activity” of a context must be type-invariant, since f is defined on context types, not on concrete words. I propose a corrected construction that makes the relevant property depend only on the boundary-extendibility behavior (hence on the type), and I outline the checks that keep everything radius-1 and β-normalized.

Gaps / issues spotted in the attached draft (Appendix B)
- Context activity vs. type invariance. Appendix B uses “active contexts” that contain a well-formed header+indices+RUN somewhere “inside w1/w2.” As written, the property “this concrete context contains a valid block” may not be constant within a type: two words of the same type (agreeing on D1∪D2 extendibility) can differ arbitrarily in the interior. Since f is defined on types, we must ensure that for any type τ we use as a variable or clause type, every representative of τ is active in exactly the same way (otherwise (F1) could fail on some representative).
- Where the exponential blow-up resides. The draft claims there are 2^B variable and 2^B clause context types present in C. This is plausible only if “RID/GID” information is encoded into the boundary-extendibility function of the whole context (thus affecting the type). It is not enough to place RID/GID far in the interior, as that would not be reflected in the type (which only depends on boundary inputs and the extendibility table for the 4 boundary outputs). A clean way is to make “RID/GID” selection manifest at the context’s boundaries, via boundary key states whose permitted continuations encode the 2^B possibilities.
- Uniform extendibility vs. S-only forcing. In the (F1) verification, only the two S nodes are forced; the verifier chooses all other outputs (including the 4 boundary nodes). Hence, any variable/clause identity must be “selected” by the existence of some consistent completion, not by externally fixing boundary outputs. The construction must ensure: for each variable-type τi, some (and in fact many) boundary assignments lead to a completion that realizes RID = i and no assignment leads to RID ≠ i; analogously for clause types. Otherwise two different RIDs could collapse to the same type.

Key idea: boundary-keyed types and seam-certified witnesses
- Boundary-keyed types. For each variable index i∈{0,1}^B, define a distinct boundary behavior at the right end of a variable-context (the last two nodes of wa S1 wb), witnessed by a “key” pair (kv,i, rv,i) of output symbols. Dually, for each clause index j define a distinct boundary behavior at the left end (first two nodes of wc S2 wd), with a key pair (kc,j, lc,j). The adjacency table is set so that:
  - A variable-context of type Vari is characterized by: there exists a completion consistent with S free such that the last-two-boundary symbols are exactly (kv,i, rv,i), and conversely, no completion exists that realizes the last-two-boundary symbols from any other key (kv,i′, rv,i′) with i′≠i. The same for clause-context types Clj at their first two boundary nodes.
  - This makes RID/GID selection a property of the context’s type (since the type is precisely the yes/no table of extendibility for all 4-boundary assignments). Because the type equivalence class records, for each of β^4 boundary assignments, whether a completion exists, we have more than enough capacity to separate 2^B different behaviors when β = poly(s) and B = s^{c0} with a larger constant in β.
- Witness chains initiated at S. Upon placing a non-⊥ color at S (RED/GRN/BLU), the out–out rules enable a local “witness chain” that walks from S to (i) the right boundary of the left context and (ii) the left boundary of the right context. At those boundaries, it must latch onto the proper keys (kv,i, rv,i) and (kc,j, lc,j). From the keys, the chain enters the corresponding interior block modules that encode, via a row-by-row 1D tableau, the vectors HotRID (one-hot) and the three clause-indicator vectors V(+),V(−),V(⊥) computed by a fixed universal TM U on input (C, RID, GID). The chain succeeds iff for the chosen color, there exists a bit position p such that HotRID[p]=1 and V(±/⊥)[p]=1 as appropriate. If any subcheck fails, the chain cannot be completed (no completion exists, hence the DP rejects). All of this is radius-1: pointer segments are finite-state “pipes” checked by Cout–out, and each tape row transition in RUN is enforced by nearest-neighbor constraints, exactly as in §3 of the reference.
- Uniformity within types. Because keys reside at the 4 boundary nodes and the admissible continuations for a given key are baked into the out–out table, the existence/non-existence of a successful witness is purely a type property. That is, any two representatives of the same type have identical extendibility tables for all 4-boundary assignments; hence for a fixed color at S, either both admit some completion (with the appropriate key) or neither do.

Why exponentially many (context) types are available
- Type count. For r=1, types are determined by: (i) 2^4 choices of boundary inputs and (ii) a β^4-bit truth table indicating which 4-boundary output assignments are extendible. Hence |Types| ≤ 2^4 · 2^{β^4} = 2^{Θ(β^4)}. With β = s^{c1}, pick c1≫c0 so that 2^{β^4} ≫ 2^B. Thus we can assign pairwise distinct truth tables to the 2^B desired variable keys and to the 2^B clause keys, leaving plenty of slack for all other contexts.
- Realization by radius-1 rules. Each distinct truth table is realized by tailoring the local “plumbing” around the 4 boundary nodes: for each of the β^4 boundary assignments, either permit at least one outgoing legal extension (by supplying a small admissible gadget that grows into the variable/clause block and RUN) or forbid any extension (by forcing dead ends unless an error-chain is emitted, which we disallow when S carries a non-⊥ color). This is purely in Cout–out and Cin–out and does not depend on interior inputs.

Soundness and completeness of the reduction (cleaned)
- Source: Succinct-3SAT instance C of size s. We set β = s^{c1} and work in the explicit β-normalized, radius-1 model.
- Target: PC = (Σin={0,1}, Σout of size β, Cin–out, Cout–out). The alphabet has fixed tracks: role/phase, ⊥, 3 colors {RED,GRN,BLU}, finitely many error symbols, and the work alphabet for U (all independent of B), as in §3.
- Variable and clause types. We reserve 2^B variable types {Vari} and 2^B clause types {Clj} by their boundary keys, as above. All other types are “inactive” and accept ⊥ at S unconditionally.
- (⇒) If ΦC is satisfiable, define f on types by: f(Vari)=RED if α(xi)=1 else GRN; f(Clj) is set to a color that corresponds to some true literal in clause(j) (RED for positive, GRN for negative; BLU is unused/dummy); f(τ)=⊥ for all inactive types. For any ordered pair of contexts, if both are active and in roles (variable,clause), the witness chain succeeds by picking the unique hot position for RID (enforced by the variable block) and the matching 1 in V(±) (enforced by the clause block). All other ordered pairs are trivialized (either inactive or the grammar ignores colors in those role combinations), hence all (F1) DP checks pass.
- (⇐) If there exists f satisfying (F1), read an assignment α from the variable types: α(xi)=1 iff f(Vari)=RED, α(xi)=0 iff f(Vari)=GRN (BLU impossible for variable types by construction; if allowed, fix it arbitrarily). Fix any clause j. Since (F1) must hold for the ordered pair (Vari, Clj) for the i appearing in clause(j), the only way the DP can succeed (given the grammar) is that f(Clj) picks a color that matches a true literal under α (the witness chain cannot otherwise be completed). Hence every clause has a true literal and α satisfies ΦC.
- Inactive contexts never constrain f: for any type without the proper boundary keys and RUN plumbing, any non-⊥ color at S leads to a dead-end (no completion), whereas ⊥ always admits a completion via the neutral plumbing and/or the standard error-chain (per §3). Thus assigning f(τ)=⊥ for all such τ ensures all mixed-type (F1) checks pass.

From FFE(F1) to the tri-class classification
- As in the draft: (F1) characterizes O(log* n) vs. Θ(n) (Theorem 8 machinery), and adding a neutral ⊥ that freely fills repetitions makes (F2) vacuous, whence (F1)+(F2) yields O(1) (Theorem 9 machinery). Therefore:
  - Distinguishing Θ(n) vs. sublinear (i.e., the existence of a feasible f) is NEXPTIME-hard.
  - Distinguishing O(1) vs. Ω(log* n) (by toggling (F2) via ⊥-filling) is also NEXPTIME-hard.
  - Hence the full three-way classification is NEXPTIME-hard under the explicit β-normalized encoding.

Checkability and complexity bookkeeping
- Radius 1: All constraints (role placement, boundary keys, pointer pipes, RUN row-to-row evolution, and error-chains) involve each node and its predecessor only, i.e., exactly Cin–out and Cout–out.
- Alphabet size: Σout is of size β = poly(s); the number of “states” required for roles, phases, pipes, and U is constant. The heavy lifting (2^B distinct behaviors) is encoded not in new symbols but in the accept/reject decisions for the β^4 boundary assignments (the type truth tables), which are programmed into Cout–out.
- Lengths: Contexts have length ≈ℓpump (double-exponential in s), so there is ample room to host the O(poly(s))-size headers/indices and RUNs needed to compute clause(j) from C.

Examples / sanity checks
- Toy instance: Fix B=2, so there are 4 variable and 4 clause types. Assign four disjoint pairs of boundary keys for the variables on the right and four for the clauses on the left. The seam witness for RED requires a position p with HotRID[p]=1 and V(+)[p]=1; the grammar enforces that exactly one p has HotRID[p]=1, and RUN computes V(+) correctly from C and GID. Testing all 16 ordered pairs (Vari, Clj) by hand recovers the truth table of satisfaction.

Next steps (concrete, verifiable)
1) Formalize the boundary-keyed type lemma: Given β, construct Cout–out so that for any prescribed subset S⊆[β]^4 (boundary assignments) of size ≤2^B we can realize a type whose extendibility table equals the indicator of S. This pins down the “truth table capacity” rigorously.
2) Write the exact local transition rules for the pointer pipes and RUN rows, following §3 of the reference, and count the number of symbols added (to check β=poly(s) suffices).
3) Prove the uniformity lemma: For any two words of the same type, the success/failure of the (F1) DP for a fixed pair of types and a fixed color at S is identical. This uses Lemma 11 (replacement) to justify that only the boundary truth tables matter.
4) Integrate the ⊥-filling trick to make (F2) vacuous and connect the hardness to the O(1) vs. Ω(log* n) gap explicitly.

Why useful here
- The boundary-keyed construction eliminates the “activity” non-invariance and anchors the reduction in the type semantics used by the NEXPTIME verifier. Establishing this rigorously will convert the hardness sketch into a clean, auditable proof.

