--- SYSTEM ---
You are a research **summarizer**. Summarize this *last round only* for a human log.

Include:
- 3–7 bullet **Highlights** (facts learned, reductions, counterexamples, partial bounds).
- 1–3 **Open questions / TODOs** for the next round.
- 1–3 **Citations to files** you relied on (e.g. round files or papers by name).

**Return strictly JSON**:
{
  "summary_md": "Readable summary of the round (≤200 words)",
  "highlights": [],
  "next_questions": []
}

--- USER ---
=== prover-01.out.json (progress_md) ===
Ideas and plan for NEXPTIME-hardness via feasible functions (and gaps spotted)

Context recap and goal
- We work with β-normalized, radius-1 LCLs on globally oriented paths, with explicit tables Cin–out and Cout–out. The classification into O(1), Θ(log∗ n), Θ(n) in the path/cycle case goes via the existence of a feasible function f on “context types” (mid-consistency F1 gives O(log∗ n) vs Θ(n); adding bridging F2 gives O(1) vs Ω(log∗ n)), per Section 4 of the reference (Lemmas 10–15, 11, 12; Theorems 8–9).
- The attached draft provides: (i) a NEXPTIME upper bound for deciding feasible-function existence (with an explicit bound Z ≤ ℓpump^2 for (F2) finite checks and an O(k β^2) DP for local extendibility), and (ii) a hardness sketch (Section B) intended to reduce Succinct-3SAT to mid-consistency (F1).

Critical gaps in the current hardness sketch (Section B)
1) Universal machine runtime and one-hot vectors: The draft says a fixed U runs in BO(1) to compute clause literals and uses a 2^B-long one-hot vector HotRID. Neither is feasible. Evaluating a size-s circuit C requires poly(s) steps; one-hot vectors of length 2^B cannot be produced/stored in a constant-alphabet radius-1 LCL with poly(s) footprint.
2) Mid-consistency quantifies over all ordered pairs of contexts. The current design enforces that for (variable i, clause j) pairs the bridge only succeeds if i appears in j and the chosen colors match a picked literal. But f(Clj) is fixed per type; then for the other two variables in the same clause the bridge would fail, contradicting the “for all pairs” requirement in (F1). This is a fundamental mismatch: 3SAT’s “∃ satisfied literal” cannot be expressed by a constraint that must hold for every pairing.
3) Type–separation assumptions: The sketch implicitly needs exponentially many distinct context types (e.g., one per RID and per GID) and that type equality can be forced to depend on RID/GID. This needs a concrete mechanism to “project” the index to a boundary-extendibility distinction (otherwise different indices could collapse to the same type).

Proposed pivot: reduce from Succinct 3-Coloring (NEXPTIME-complete)
Why it matches (F1):
- Feasible-function mid-consistency induces pairwise constraints among context-types. 3-colorability of a succinctly described graph H on 2^B vertices is a pure pairwise constraint system: for each edge (u, v) we require color(u) ≠ color(v). This aligns with “for all ordered pairs” checks, provided we gate the bridge so that non-edges are trivial.
- Succinct 3-coloring is NEXP-complete (Papadimitriou–Yannakakis). The succinct adjacency oracle A(u, v) is a circuit of size s on 2B bits. This lets us stay within poly(s) resources inside a block.

Refined reduction outline (mid-consistency (F1) only)
- Instance: succinct graph G on V = {0,1}^B, circuit D(u, v) outputs 1 iff edge.
- Build β-normalized LCL P_D with constant-radius verifier and Σin = {0,1}; keep |Σout| = β = poly(s).
- “Vertex contexts”: For each u ∈ {0,1}^B, we realize many contexts wa S wb whose interior carries a well-formed block encoding: a self-delimiting header (copy of D on input track), the index u, and a locally-checkable runzone computing a short “seam handshake code” Hu placed near the right boundary; symmetrically, the left boundary carries Lu. All of this is forced locally via Cout–out. Error chains per §3 of the reference allow any malformed block to be locally refuted, making such contexts effectively inactive.
- Coloring choices via f: For each “vertex-type” τu (i.e., the type of contexts realizing u), f(τu) ∈ {RED, GRN, BLU}^2 fixes a color token at S (two nodes). For all non-vertex types, set f(τ) to a neutral token ⊥⊥ that never activates constraints.
- Gating only edges: In a bridge between (τu on the left, τv on the right), the seam region interprets Hu and the right’s corresponding handshake. It then runs (in the bridge) a locally-checkable simulation of a fixed universal TM U on input (D, u, v) (time poly(s); we have length budget since ℓpump ≫ poly(s)), to compute D(u, v). Error refutations are permitted, as usual. The cout–out grammar enforces: the partial labeling extends if either (i) D(u, v) = 0 (non-edge) irrespective of colors; or (ii) D(u, v) = 1 and the two S colors are different. If D(u, v) = 1 and colors are equal, all completion paths get stuck, so the DP rejects.
- All pairs outside the (vertex, vertex) role (or with malformed header/index) are trivially extendible (via ⊥ plumbing), so they do not constrain f.
- This creates the intended constraint family: for all ordered pairs, only edges impose “≠”; others are vacuous.

Why the above fixes the (F1) mismatch
- With this gating, the (F1) universal quantification over ordered pairs exactly enforces a proper coloring constraint on every edge. There is no clause-like “exists” quantifier left that would clash with the universal pairing; non-edges require nothing.

Key technical components to instantiate and verify
A. Computing and checking at radius 1:
- Block language: As in §3, use a constant-alphabet, radius-1 nearest-neighbor checker for the header, index, and a row-by-row simulation of U for poly(s) steps. The input circuit D is copied from the input track (Cin–out). The work alphabet of U is constant and independent of s.
- Seam handshakes: Deterministically derive short fixed-size codes Lu, Hu from the index u and place them in O(1) cells adjacent to the context boundary; they are computed in the block and forced by Cout–out.
- Bridge computation: In wb◦wc, run U for poly(s) steps using the adjacent copies of D and the seam codes Lu/Hv to reconstruct u and v and evaluate D(u, v). This is the same 1D-encoding recipe as §3; errors are locally refutable.
B. Separation of exponentially many vertex context types:
- We need that for each u, there exist contexts whose type remembers the presence of Lu/Hu; more strongly, to assign different colors per u we only require that for each u there exists at least one type τu on which f can act. Distinctness of types can be enforced by a boundary-extendibility probe: add a reserved boundary-output pattern that triggers a local “index-check subroutine” which accepts iff the seam code equals a prescribed function of u; different u yield different extendibility outcomes under that boundary pattern, hence different types. This uses the definition of Type (extendibility table on 4 boundary nodes).
- Pumping to reach ℓpump-sized buffers: Lemmas 12, 14–15 ensure we can embed the block and seam codes inside w1/w2 and pump to lengths ℓpump or ℓpump+1 without changing type (replacement lemma, Lemma 11).
C. β and time bounds:
- The per-symbol state space (roles/phases/colors/⊥/error alphabet/U work letters) is constant; β can be chosen poly(s) to absorb all tracks comfortably. The LCL description size is poly(β) = poly(s). The verifier’s DP runs in O(k β^2) per string.

Correctness sketch under the new reduction
- Completeness: If G is 3-colorable, pick any proper coloring χ: V → {RED, GRN, BLU}. Define f(τu) = χ(u). For any ordered pair (τu, τv), the bridge’s local computation derives D(u, v); if D(u, v) = 0, we allow completion; if D(u, v) = 1, χ(u) ≠ χ(v) so completion is allowed. All other context pairs are vacuous. Hence all (F1) checks pass.
- Soundness: If a feasible f exists, read a color assignment χ(u) = f(τu) (choosing any representative context type for each u; if several exist, they must all share the same f-value else (F1) would fail on the pair of those contexts). For any u, v with D(u, v) = 1, the bridge between τu and τv must be extendible, which forces χ(u) ≠ χ(v). Thus χ is a proper 3-coloring, so G is 3-colorable.

Handling (F2)
- Make (F2) vacuous by allowing repeated sides wz
1 and wz
2 to be filled with ⊥ (a self-looping buffer language in Cout–out), independent of the chosen f on S. Then bridging checks in the upper bound accept for all z ≤ ℓpump^2 (and hence all z), without constraining f.

Examples (toy sanity check)
- Let B = 2, V = {00,01,10,11}. Let D encode a 4-cycle 00–01–11–10–00. Under the reduction, there are 4 vertex context types τ00,…,τ11. Feasible f exist iff a 3-coloring of a 4-cycle exists (true). Pairs like (τ00, τ10) with D(00,10) = 0 are unconstrained; pairs like (τ00, τ01) with D(00,01) = 1 enforce f(τ00) ≠ f(τ01).

Obstacles and open items to formalize next
- Formal type-separation lemma: Specify the boundary-output probe and prove that contexts with distinct u become distinct types (by differing in at least one boundary-extendibility bit). This pins down the “one type per vertex” requirement.
- Seam handshake construction details: Specify an O(1)-cell code and the local rules that move u from the block interior to the boundary deterministically.
- Bridge computation layout: Spell out the row format and the interface that feeds D and (u, v) into the U-simulation, ensuring errors are caught locally.
- Size bookkeeping: Choose concrete constants so that block length is poly(s), while ℓpump = 2Θ(β^4) dominates to allow pumping. Confirm Cin–out/Cout–out remain of size poly(β).

Why this yields NEXPTIME-hardness for feasible-function existence (and classification)
- Feasible-function existence with (F1) alone is NEXPTIME-hard via succinct 3-coloring under the reduction above. Together with the NEXPTIME upper bound in the draft, this gives NEXPTIME-completeness for (F1)-feasibility in the explicit β-normalized, r=1 setting.
- For full classification (O(1)/Θ(log∗ n)/Θ(n)), add the neutral ⊥ repetition to trivialize (F2), so the hardness transfers to deciding whether (F1) holds—hence to the classification problem that internally tests (F1).

Next steps
1) Write the explicit local rules for the seam gate and the bridge simulation (succinct adjacency computation) and verify they fit in radius 1.
2) Prove the type-separation lemma rigorously (construct the boundary probe and show different u change the extendibility table).
3) Integrate the error-chain library from §3 to guarantee malformed blocks are always locally refutable, keeping non-vertex contexts harmless.
4) Provide a fully quantified statement/theorem of the reduction with the poly-time construction mapping D ↦ P_D and the equivalence “G 3-colorable ⇔ (F1)-feasible f exists for P_D”.

Notes on the NEXPTIME upper bound (good to keep)
- The finite z bound Z ≤ ℓpump^2 for (F2) follows cleanly from Lemma 15 periodicity and Lemma 12 composition; no circularity with f.
- The layered DP (O(k β^2)) to decide extendibility of partially labeled paths gives an explicit verifier runtime bound compatible with 2poly(β).

No output.md was provided; these notes flag substantial issues in the current (3SAT-based) Section B and outline a repaired (3-coloring-based) reduction aligned with (F1).

=== prover-02.out.json (progress_md) ===
Headlines
- Goal: Prove NEXPTIME-hardness for classifying β-normalized, radius-1 LCLs on globally oriented paths into O(1) vs. Ω(log* n) vs. Ω(n).
- Status: The attached draft gives an NEXPTIME upper bound for feasible-function existence (FFE) and sketches NEXPTIME-hardness via a reduction from Succinct-3SAT. I identified a subtlety in the hardness appendix: “activity” of a context must be type-invariant, since f is defined on context types, not on concrete words. I propose a corrected construction that makes the relevant property depend only on the boundary-extendibility behavior (hence on the type), and I outline the checks that keep everything radius-1 and β-normalized.

Gaps / issues spotted in the attached draft (Appendix B)
- Context activity vs. type invariance. Appendix B uses “active contexts” that contain a well-formed header+indices+RUN somewhere “inside w1/w2.” As written, the property “this concrete context contains a valid block” may not be constant within a type: two words of the same type (agreeing on D1∪D2 extendibility) can differ arbitrarily in the interior. Since f is defined on types, we must ensure that for any type τ we use as a variable or clause type, every representative of τ is active in exactly the same way (otherwise (F1) could fail on some representative).
- Where the exponential blow-up resides. The draft claims there are 2^B variable and 2^B clause context types present in C. This is plausible only if “RID/GID” information is encoded into the boundary-extendibility function of the whole context (thus affecting the type). It is not enough to place RID/GID far in the interior, as that would not be reflected in the type (which only depends on boundary inputs and the extendibility table for the 4 boundary outputs). A clean way is to make “RID/GID” selection manifest at the context’s boundaries, via boundary key states whose permitted continuations encode the 2^B possibilities.
- Uniform extendibility vs. S-only forcing. In the (F1) verification, only the two S nodes are forced; the verifier chooses all other outputs (including the 4 boundary nodes). Hence, any variable/clause identity must be “selected” by the existence of some consistent completion, not by externally fixing boundary outputs. The construction must ensure: for each variable-type τi, some (and in fact many) boundary assignments lead to a completion that realizes RID = i and no assignment leads to RID ≠ i; analogously for clause types. Otherwise two different RIDs could collapse to the same type.

Key idea: boundary-keyed types and seam-certified witnesses
- Boundary-keyed types. For each variable index i∈{0,1}^B, define a distinct boundary behavior at the right end of a variable-context (the last two nodes of wa S1 wb), witnessed by a “key” pair (kv,i, rv,i) of output symbols. Dually, for each clause index j define a distinct boundary behavior at the left end (first two nodes of wc S2 wd), with a key pair (kc,j, lc,j). The adjacency table is set so that:
  - A variable-context of type Vari is characterized by: there exists a completion consistent with S free such that the last-two-boundary symbols are exactly (kv,i, rv,i), and conversely, no completion exists that realizes the last-two-boundary symbols from any other key (kv,i′, rv,i′) with i′≠i. The same for clause-context types Clj at their first two boundary nodes.
  - This makes RID/GID selection a property of the context’s type (since the type is precisely the yes/no table of extendibility for all 4-boundary assignments). Because the type equivalence class records, for each of β^4 boundary assignments, whether a completion exists, we have more than enough capacity to separate 2^B different behaviors when β = poly(s) and B = s^{c0} with a larger constant in β.
- Witness chains initiated at S. Upon placing a non-⊥ color at S (RED/GRN/BLU), the out–out rules enable a local “witness chain” that walks from S to (i) the right boundary of the left context and (ii) the left boundary of the right context. At those boundaries, it must latch onto the proper keys (kv,i, rv,i) and (kc,j, lc,j). From the keys, the chain enters the corresponding interior block modules that encode, via a row-by-row 1D tableau, the vectors HotRID (one-hot) and the three clause-indicator vectors V(+),V(−),V(⊥) computed by a fixed universal TM U on input (C, RID, GID). The chain succeeds iff for the chosen color, there exists a bit position p such that HotRID[p]=1 and V(±/⊥)[p]=1 as appropriate. If any subcheck fails, the chain cannot be completed (no completion exists, hence the DP rejects). All of this is radius-1: pointer segments are finite-state “pipes” checked by Cout–out, and each tape row transition in RUN is enforced by nearest-neighbor constraints, exactly as in §3 of the reference.
- Uniformity within types. Because keys reside at the 4 boundary nodes and the admissible continuations for a given key are baked into the out–out table, the existence/non-existence of a successful witness is purely a type property. That is, any two representatives of the same type have identical extendibility tables for all 4-boundary assignments; hence for a fixed color at S, either both admit some completion (with the appropriate key) or neither do.

Why exponentially many (context) types are available
- Type count. For r=1, types are determined by: (i) 2^4 choices of boundary inputs and (ii) a β^4-bit truth table indicating which 4-boundary output assignments are extendible. Hence |Types| ≤ 2^4 · 2^{β^4} = 2^{Θ(β^4)}. With β = s^{c1}, pick c1≫c0 so that 2^{β^4} ≫ 2^B. Thus we can assign pairwise distinct truth tables to the 2^B desired variable keys and to the 2^B clause keys, leaving plenty of slack for all other contexts.
- Realization by radius-1 rules. Each distinct truth table is realized by tailoring the local “plumbing” around the 4 boundary nodes: for each of the β^4 boundary assignments, either permit at least one outgoing legal extension (by supplying a small admissible gadget that grows into the variable/clause block and RUN) or forbid any extension (by forcing dead ends unless an error-chain is emitted, which we disallow when S carries a non-⊥ color). This is purely in Cout–out and Cin–out and does not depend on interior inputs.

Soundness and completeness of the reduction (cleaned)
- Source: Succinct-3SAT instance C of size s. We set β = s^{c1} and work in the explicit β-normalized, radius-1 model.
- Target: PC = (Σin={0,1}, Σout of size β, Cin–out, Cout–out). The alphabet has fixed tracks: role/phase, ⊥, 3 colors {RED,GRN,BLU}, finitely many error symbols, and the work alphabet for U (all independent of B), as in §3.
- Variable and clause types. We reserve 2^B variable types {Vari} and 2^B clause types {Clj} by their boundary keys, as above. All other types are “inactive” and accept ⊥ at S unconditionally.
- (⇒) If ΦC is satisfiable, define f on types by: f(Vari)=RED if α(xi)=1 else GRN; f(Clj) is set to a color that corresponds to some true literal in clause(j) (RED for positive, GRN for negative; BLU is unused/dummy); f(τ)=⊥ for all inactive types. For any ordered pair of contexts, if both are active and in roles (variable,clause), the witness chain succeeds by picking the unique hot position for RID (enforced by the variable block) and the matching 1 in V(±) (enforced by the clause block). All other ordered pairs are trivialized (either inactive or the grammar ignores colors in those role combinations), hence all (F1) DP checks pass.
- (⇐) If there exists f satisfying (F1), read an assignment α from the variable types: α(xi)=1 iff f(Vari)=RED, α(xi)=0 iff f(Vari)=GRN (BLU impossible for variable types by construction; if allowed, fix it arbitrarily). Fix any clause j. Since (F1) must hold for the ordered pair (Vari, Clj) for the i appearing in clause(j), the only way the DP can succeed (given the grammar) is that f(Clj) picks a color that matches a true literal under α (the witness chain cannot otherwise be completed). Hence every clause has a true literal and α satisfies ΦC.
- Inactive contexts never constrain f: for any type without the proper boundary keys and RUN plumbing, any non-⊥ color at S leads to a dead-end (no completion), whereas ⊥ always admits a completion via the neutral plumbing and/or the standard error-chain (per §3). Thus assigning f(τ)=⊥ for all such τ ensures all mixed-type (F1) checks pass.

From FFE(F1) to the tri-class classification
- As in the draft: (F1) characterizes O(log* n) vs. Θ(n) (Theorem 8 machinery), and adding a neutral ⊥ that freely fills repetitions makes (F2) vacuous, whence (F1)+(F2) yields O(1) (Theorem 9 machinery). Therefore:
  - Distinguishing Θ(n) vs. sublinear (i.e., the existence of a feasible f) is NEXPTIME-hard.
  - Distinguishing O(1) vs. Ω(log* n) (by toggling (F2) via ⊥-filling) is also NEXPTIME-hard.
  - Hence the full three-way classification is NEXPTIME-hard under the explicit β-normalized encoding.

Checkability and complexity bookkeeping
- Radius 1: All constraints (role placement, boundary keys, pointer pipes, RUN row-to-row evolution, and error-chains) involve each node and its predecessor only, i.e., exactly Cin–out and Cout–out.
- Alphabet size: Σout is of size β = poly(s); the number of “states” required for roles, phases, pipes, and U is constant. The heavy lifting (2^B distinct behaviors) is encoded not in new symbols but in the accept/reject decisions for the β^4 boundary assignments (the type truth tables), which are programmed into Cout–out.
- Lengths: Contexts have length ≈ℓpump (double-exponential in s), so there is ample room to host the O(poly(s))-size headers/indices and RUNs needed to compute clause(j) from C.

Examples / sanity checks
- Toy instance: Fix B=2, so there are 4 variable and 4 clause types. Assign four disjoint pairs of boundary keys for the variables on the right and four for the clauses on the left. The seam witness for RED requires a position p with HotRID[p]=1 and V(+)[p]=1; the grammar enforces that exactly one p has HotRID[p]=1, and RUN computes V(+) correctly from C and GID. Testing all 16 ordered pairs (Vari, Clj) by hand recovers the truth table of satisfaction.

Next steps (concrete, verifiable)
1) Formalize the boundary-keyed type lemma: Given β, construct Cout–out so that for any prescribed subset S⊆[β]^4 (boundary assignments) of size ≤2^B we can realize a type whose extendibility table equals the indicator of S. This pins down the “truth table capacity” rigorously.
2) Write the exact local transition rules for the pointer pipes and RUN rows, following §3 of the reference, and count the number of symbols added (to check β=poly(s) suffices).
3) Prove the uniformity lemma: For any two words of the same type, the success/failure of the (F1) DP for a fixed pair of types and a fixed color at S is identical. This uses Lemma 11 (replacement) to justify that only the boundary truth tables matter.
4) Integrate the ⊥-filling trick to make (F2) vacuous and connect the hardness to the O(1) vs. Ω(log* n) gap explicitly.

Why useful here
- The boundary-keyed construction eliminates the “activity” non-invariance and anchors the reduction in the type semantics used by the NEXPTIME verifier. Establishing this rigorously will convert the hardness sketch into a clean, auditable proof.


=== prover-03.out.json (progress_md) ===
Ideas and plan
- Goal: Prove NEXPTIME-hardness of the 3-way classification (O(1) vs. Ω(log* n) vs. Ω(n)) for β-normalized, radius-1 LCLs on oriented paths. By the Balliu–Brandt–Chang–Olivetti–Rabie–Suomela framework (Section 4), the 3-way classification reduces to existence of a feasible function f with two properties: (F1) mid-consistency and (F2) bridging. If (F1) fails then the complexity is Θ(n); if (F1) holds and (F2) fails then Θ(log* n); if (F1)+(F2) holds then O(1). Hence NEXPTIME-hardness follows if we can reduce a NEXPTIME-hard problem (e.g., Succinct-3SAT) to deciding existence of f.
- Upper bound: The attached draft “LCL_classification.pdf” sketches an NEXPTIME upper bound for Feasible-Function Existence (FFE) via types and bounded DP checks. I re-checked: the type bound |Types| ≤ 2^{Θ(β^4)} for r=1 is sound, the “finite z” lemma for (F2) with Z ≤ ℓ_pump^2 is correct, and the layered-DAG DP is O(kβ^2) for a length-k path. Hence membership in NEXPTIME looks solid.

Gaps/concerns in output.md (hardness part B)
- Quantifier mismatch in (F1): (F1) universally quantifies over all ordered pairs of contexts (wa S1 wb, wc S2 wd), not merely pairs “variable on left, clause on right” with a shared variable. In Section B, the bridge is made to succeed only if a witness i connects the left “variable RID i” to a right “clause V(·)[i]=1”. This enforces success only for some pairs. But (F1) requires success for all ordered pairs simultaneously. As written, if there exist “variable” types Vari that are not among the three variables of a given clause type Clj, then the ordered pair (Vari, Clj) will cause the bridge DP to fail for the f chosen, violating (F1). The text attempts to restrict to pairs “where i ranges over variables occurring in clause(j)”, but (F1) does not allow restricting the universal set of pairs; every pair of context types appearing in C must pass.
- “Inactive contexts” and pair filtering: The draft claims we can trivialize all pairs that are not (variable, clause) or have malformed blocks by allowing ⊥. However, (F1) still quantifies over ordered pairs regardless of internal content. If the left is a “variable” context (i fixed) and the right a “clause” context (j), but i /∈ vars(clause j), the pair remains “variable–clause” and is not falsifiable by declaring one side “inactive”: that would force f to assign ⊥ to at least one side for all contexts of that type, collapsing the intended encoding (we need variable/clause contexts to be active to constrain f). No mechanism was given that makes those specific pairs inactive without also deactivating the entire type.
- Types vs. interior degrees of freedom: The argument “there are 2^B distinct variable types Vari and 2^B clause types Clj” uses that differing RID/GID values must give distinct types because extendibility from S differs “for some bridge”. But Type(·) is defined by which boundary assignments are extendible; it existentially quantifies over all interior labelings. If a context admits multiple interior RIDs, then for many S-labelings the existence of some witness RID can make extendibility identical across many RIDs. Thus different RID values need not force different types unless we can tie RID deterministically to boundary information. The current construction does not ensure RID/GID are uniquely determined by the context’s boundary behavior.
- Context locality: The construction wants a large, well-formed block to sit “inside” w1 (resp. w2). But (F1) only fixes the two outputs on S; the remaining outputs (including inside w1 and w2) can be chosen arbitrarily in each check. This is intended, but it then exacerbates the previous issue: types correspond to sets of interior completions. One must ensure the property “RID equals i” is forced by boundary behavior, otherwise types conflate many RIDs.
- Pair-wise gating by clause membership: The hardness relies on only pairs (Vari, Clj) with i ∈ vars(clause j) being active (i.e., constrained by the witness chain). However, no local, radius-1 gating was given that makes all other variable/clause pairs trivially extendible while keeping those of interest constraining, especially given that the grammar cannot refer to “pair identity” globally. A local activation must be derivable from S and nearby labels, not from global pairing information.

Small positive results we can reuse (from output.md)
- Type bound for r=1: M := |Types| ≤ 24·2^{β^4} = 2^{Θ(β^4)}; set ℓ_pump := M.
- Finite z for (F2): For each fixed context (w1, S, w2), the set {Type(w1^z S w2^z)} has size ≤ ℓ_pump^2, so it suffices to check 1 ≤ z ≤ Z with Z ≤ ℓ_pump^2.
- DP feasibility test: For radius-1 β-normalized LCLs, partial-to-total extension on a given path with some outputs forced is decidable by a layered-DAG DP in O(kβ^2) time.

Proposed corrections/patches to the hardness construction
- Force RID/GID by boundary behavior: To obtain a family of 2^B distinct “variable” context types Vari, we can build a left-anchored gadget whose unique continuation from the S-window outwards deterministically encodes the index i in the nearest O(1) outputs (e.g., a self-delimiting, gray-coded header with radius-1 local rules). Concretely, add a “phase” track that rigidly positions the start of a short RID header of length Θ(B) within distance O(1) from the S-window. Enforce, via Cout–out, that whenever the S-window carries a designated activation token and the phase indicates “variable mode”, the next O(B) outputs are uniquely determined (one-hot RID with a fixed delimiter). This ensures: (i) the interior labelings consistent with an activated S-window determine exactly one RID, (ii) types differ across different i because the set of boundary-extendible S-outputs differs.
- Clause contexts likewise: Symmetrically enforce a GID header near S on the right context, again determined uniquely upon activation, and attach RUN rows that compute the literal set for clause j based on the fixed circuit C (hardwired in the adjacency table). As before, activation at S forces a unique GID.
- Local gating of pairs: Introduce a “handshake” protocol across the bridge that makes a pair active only if both windows are activated and their local roles match a prescribed pattern (left role=VAR, right role=CL). All other combinations, including (VAR, CL) with at least one window deactivated (⊥), are assigned a trivial buffer language that always extends. This satisfies (F1) over all pairs once we ensure that, for each type, f can choose ⊥ to deactivate it when needed; but now activation will be needed only on the types we purposefully created (Vari, Clj), and deactivation on all other types is harmless.
- Still need to address “wrong variable for a clause”: To avoid the quantifier mismatch, ensure that for a given right clause context Clj, only those left context types Vari with i ∈ vars(clause j) can be simultaneously activated: implement a local test that compares the variable index i (encoded near the left S-window) with the finite set of three indices embedded near the right S-window (also encoded near its S-window), and only if there is equality do we allow the activation token to persist across the bridge; otherwise the only locally valid option is to turn off activation on at least one S-window (i.e., f must set ⊥ for one of the two types). This way, for a fixed clause type Clj, there are exactly three variable types Vari whose joint activation with Clj is locally legal. All other pairs are forced to be inactive (and thus trivial). This preserves the universal quantifier of (F1): we require success for all pairs, but for non-matching pairs success is guaranteed by deactivation.
- Encoding satisfiability: Now (F1) for the three matching pairs (Vari1, Clj), (Vari2, Clj), (Vari3, Clj) amounts to requiring that, with the f-choices of colors on these types, at least one pair’s witness chain can complete (using the V(+)/V(−) bits from the RUN gadget). To phrase this with universal quantification, we allow only one activated pair per clause to persist in any given bridge instance: locally, at the mid-bridge we place a “choice” gadget that nondeterministically selects one of the three matching i; the DP succeeds iff the selected i’s witness check passes. Since (F1) demands existence of some completion, it suffices that at least one of the three literal checks can succeed for the f-choice at Clj. This exactly encodes that each clause has a satisfied literal under the assignment extracted from f(Vari).
- Trivializing (F2): As in the draft, add a neutral symbol ⊥ and permit filling wz with ⊥ regardless of the context, so (F2) is always true. This keeps the 3-way classification hinging on (F1) alone: satisfiable ⇒ (F1) holds ⇒ O(1); unsatisfiable ⇒ (F1) fails for some clause ⇒ Θ(n).

Toy counterexample of the current draft’s (F1) usage
- Consider a clause type Clj whose literals are over indices {i1, i2, i3}. For a variable type Vari with i ∉ {i1, i2, i3}, the proposed grammar makes the pair active (since it is a (variable, clause) pair) and then the witness chain must fail (no V-bit at i), violating (F1) unless f sets ⊥ on Vari or Clj. But if f sets ⊥ on Vari to fix this pair, it also deactivates all its interactions with the correct clauses, undermining the intended encoding. This shows the need for local gating to force all non-matching pairs inactive irrespective of f.

Why the capacity (number of types) suffices
- With β = poly(|C|), ℓ_pump = 2^{Θ(β^4)} gives room for exponentially many distinct context types. The “phase+RID/GID near S” gadgets use only O(B) symbols, so they comfortably fit into contexts of length ≥ ℓ_pump. Deterministic forcing from S ensures that different i (or j) yield different type behaviors (distinct sets of extendible S-labelings), so we can realize 2^B variable types and 2^B clause types.

Concrete micro-lemmas to formalize next
1) RID-forcing lemma. There is a radius-1 adjacency schema over a constant-size role/phase alphabet that, upon placing a VAR-activation token on S, deterministically fixes a unique B-bit one-hot RID string within the next O(B) positions. Distinct RIDs induce distinct type behaviors at the boundary (different activated S choices are extendible).
2) Pair-gating lemma. There is a radius-1 schema that, given left VAR with RID=i and right CL with a three-element set {i1,i2,i3} encoded within O(1) of S, allows activation across the bridge if and only if i ∈ {i1,i2,i3}; otherwise the only legal option is to deactivate (⊥) at one or both S-windows (enforced locally by Cout–out).
3) Clause-choice lemma. There is a radius-1 gadget on the bridge that nondeterministically chooses one of the three matching i and routes a witness chain to check the corresponding RUN subtrack; DP success is equivalent to the existence of a satisfied literal among the three under the f-colors.

Obstacles and open items
- The exact encoding of the “choice” on the bridge needs to be pinned down so that: (i) choice is local, (ii) its existence suffices for DP success (so (F1) is existential per pair), (iii) it cannot enable success for non-matching pairs.
- We must verify that deactivation (⊥) never creates spurious constraints: for every non-matching pair, there is always a completion that uses ⊥, regardless of f’s color on other types.
- We must confirm that the uniqueness of RID/GID under activation really separates types (no alternative interior labeling can fake a different RID/GID without violating adjacency), so the number of types available is exponential in B.

Next steps
- Write the RID-forcing and clause-gating gadgets precisely as out–out adjacency tables, with a short formal proof of their correctness (local determinism from S; matching-only activation across the bridge).
- Prove that the “choice-on-bridge” gadget yields the right existential semantics for (F1) and that the entire pair space satisfies (F1) iff Φ_C is satisfiable.
- Check that (F2) can be made vacuous with ⊥ without interfering with (F1).
- Once the above is settled, we can present a full reduction from Succinct-3SAT to FFE(F1), yielding NEXPTIME-hardness; by the known gap characterizations, this yields NEXPTIME-hardness for the 3-way classification.

Summary
- The NEXPTIME-membership part of output.md is in good shape. The hardness section B has a fundamental quantifier gap for (F1) and needs a corrected local “gating” mechanism so that only the intended (Vari, Clj) pairs are active, and even then the (F1)-existential nature must be implemented via a local nondeterministic choice on the bridge. I outlined concrete gadgets (RID-forcing, pair-gating, clause-choice) that, once formalized, should fix these issues while staying within radius-1, β-normalized constraints. I will next encode these gadgets into explicit Cout–out tables and prove their properties.

=== prover-04.out.json (progress_md) ===
Status and goal
- Target: Show NEXPTIME-hardness of the 3-way classification problem for β-normalized, radius-1 LCLs on globally oriented paths: decide whether the LOCAL complexity is O(1) vs. Ω(log* n) vs. Ω(n).
- Strategy adopted: Factor classification through the “feasible function” certificates that characterize the two gaps on paths/cycles (Balliu–Brandt–Chang–Olivetti–Rabie–Suomela, §4). Prove:
  1) Feasible-Function Existence for r=1, β-normalized LCLs is NEXPTIME-complete (mid-consistency (F1) only).
  2) Reduce this to the 3-way classification by neutralizing bridging (F2) so that instances in the image are either O(1) (if (F1) holds) or Ω(n) (if (F1) fails), hence the 3-way decision is at least as hard.
  3) Record a tight, finite verification procedure for (F1)+(F2) in 2^{poly(β)} to support membership (optional).

Quick recap of types/pumping for r=1 (specialized bounds)
- Boundary sets (radius r=1): B1 = {first, last}, B2 = {second, second-to-last}. The type of a path is determined by (i) its 4 boundary input bits and (ii) the extendibility bit-vector for all β^4 assignments of outputs to B1∪B2. Hence the number of types is
  |Types| ≤ 2^4 · 2^{β^4} = 2^{β^4+4} =: ℓ_pump.
- Pumping and replacement follow §4, Lemmas 10–15: same-type replacement preserves extendibility and local legality; for any nonempty w there exist a,b>0 with a+b ≤ ℓ_pump such that Type(w^{a t+b}) is t-invariant. We will use these facts repeatedly to (i) realize “active” contexts of the needed form and (ii) bound finite checks below.

Finite check for bridging (F2)
- For any fixed context (w1,S,w2) with |w_i|∈{ℓ_pump,ℓ_pump+1} and |S|=2, the type of w1^z S w2^z depends only on the pair (Type(w1^z), Type(w2^z)). By periodicity of w_i (Lemma 15), each side cycles with period ≤ ℓ_pump after ≤ ℓ_pump prefix, hence the pair takes ≤ ℓ_pump^2 values. Therefore there exists Z ≤ ℓ_pump^2 such that (F2) holds iff the partial labeling on S extends for all z∈{1,…,Z}.
- Verification of extension on a partially labeled path is a standard layered-DAG DP in O(k β^2) time for a path of length k: layer i keeps allowed outputs matching Cin–out (and any forced output); edges between adjacent layers match Cout–out.

NEXPTIME upper bound for Feasible-Function Existence (supporting algorithmics)
- Precompute all types in time 2^{poly(β)} by exploring the boundary-extendibility DFA (composition Lemma 12); set ℓ_pump = |Types|.
- Let C be the set of context types realized by w1 S w2 with |w_i|∈{ℓ_pump,ℓ_pump+1}. Nondeterministically guess f: C→Σ_out^2. Verify:
  (V1) Mid-consistency (F1): For every ordered pair of contexts, run the DP on wa S1 wb wc S2 wd with S1,S2 forced to f; accept iff extendible.
  (V2) Bridging (F2): For each context (w1,S,w2) and each z ≤ Z:=ℓ_pump^2, run the DP on w1^z S w2^z with S forced to f.
- Complexity: 2^{poly(β)} overall; sound/complete for feasible-function existence.

Hardness core: Feasible-Function Existence (F1) is NEXPTIME-hard
- Source: Succinct-3SAT (circuit C of size s “generates” a 3-CNF Φ_C over 2^B variables); NEXPTIME-complete.
- Parameters: choose B = s^{c0}, β = s^{c1} for constants 1 ≪ c0 ≪ c1. Then ℓ_pump = 2^{Θ(β^4)} = 2^{poly(s)}.
- Target instance P_C (β-normalized, r=1): Σ_in={0,1}; Σ_out of size β contains constant tracks: role/phase, three colors {RED,GRN,BLU} and a neutral ⊥, a finite error-alphabet, and a constant work alphabet for a fixed universal TM U.
- Well-formed block language (output-regular, radius-1 checkable): a block = HEAD_C · RID · GID · RUN · PAD laid out along the path. Cin–out enforces that role symbols copy designated input bits (so nodes in HEAD_C positions must see the corresponding input header bit). Cout–out enforces adjacency, phase progress, and single-step consistency of U across seams; malformed fragments admit locally checkable “error chains” (as in §3) that always yield completions and hence never constrain f.
- Semantics: the 2-node window S admits only colors or ⊥. Non-⊥ at S “activates” a witness-chain gadget: an existential pointer (radius-1) that (i) chooses an index i, (ii) walks to bit i inside the left block (variable) and checks Hot_RID[i]=1, and (iii) walks to bit i inside the right block (clause) and checks V^{(+)}[i]=1 (for RED) or V^{(-)}[i]=1 (for GRN). If any subcheck fails the chain gets stuck → no completion. When S=⊥, a self-looping ⊥-plumbing language (independent of input) always completes. Thus inactive contexts (no valid block on either side) are tautologically satisfied by f(·)=⊥.
- Existence of exponentially many active context types: Since the HEAD+RID/GID+RUN length is poly(s) ≪ ℓ_pump, pumping/replacement allow us to realize, within contexts (length ≈ℓ_pump), many variants where the left side encodes any RID∈{0,1}^B and the right side encodes any GID∈{0,1}^B. Types differing in RID (or GID) are distinct because extendibility from S depends on Hot_RID and V^{(·)} at the chosen i. Hence we obtain 2^B variable-types {Var_i} and 2^B clause-types {Cl_j} in the context set C.
- Correctness of reduction:
  • Completeness: If Φ_C is satisfiable, pick a satisfying assignment α. Define f on variable types by f(Var_i)=RED if α(x_i)=1 and GRN otherwise; for each clause type Cl_j set f(Cl_j) to a true literal’s color. All other (inactive) context types map to ⊥. Every (F1) bridge wa S1 wb wc S2 wd either is trivial (inactive or non-(variable,clause)) or admits an i witnessing the chosen literal, so the DP completes.
  • Soundness: If f satisfies (F1), define α by reading f(Var_i) (RED→1, GRN→0; BLU arbitrary). For any clause j, (F1) applied to (Var_i,Cl_j) over all i occurring in clause j forces at least one match at i with the color chosen at Cl_j; hence α satisfies clause j. Thus α satisfies Φ_C.
  • Inactive contexts never constrain: non-⊥ colors at S trigger witness chains that require a valid block; absent one, chains get stuck (no completion); ⊥ always extends. Error chains ensure malformed encodings accept with a consistent “refutation” output.
- Conclusion: Feasible-Function Existence (mid-consistency (F1) only) is NEXPTIME-hard for β-normalized, r=1 LCLs on oriented paths.

From FFE(F1) to the 3-way classification
- We construct, from P_C, a P_C^⋆ whose bridging (F2) is neutral:
  • Keep P_C unchanged around S (so (F1) semantics identical).
  • Permit, in Cout–out and Cin–out, a global ⊥-filler language on repetitions w_1^z and w_2^z that is compatible with any boundary (including adjacency to S) and with any input. Then for every context and every z≥1, the partial labeling that fixes S to f(Type(w1 S w2)) extends by filling w_i^z with ⊥. Thus (F2) holds vacuously for every f.
- Hence for P_C^⋆:
  • If a feasible f (for (F1)) exists, both (F1) and (F2) hold, so the problem is O(1) by the standard construction (MIS-free partition with fill-in; §4.5, Lemmas 26–27).
  • If no feasible f exists, the (ω(log* n)–o(n)) dichotomy (Theorem 8) forces Ω(n) complexity.
  • The Ω(log* n) class does not occur for P_C^⋆, so the 3-way classifier, when applied to P_C^⋆, outputs either O(1) or Ω(n). Deciding which is equivalent to deciding (F1) for P_C, which is NEXPTIME-hard.
- Therefore, the 3-way classification problem is NEXPTIME-hard.

Why worst-case over inputs is handled (important subtlety)
- Complexity is measured in the worst-case over input labelings. Our constructions ensure that malformed inputs are always completable in O(1) (⊥-plumbing or error chains), so the adversary’s worst-case choice will include well-formed active contexts. In the satisfiable case, the O(1)-algorithm derived from f works on all inputs; in the unsatisfiable case, Theorem 8 yields a global Ω(n) lower bound (no f exists → no sublinear algorithm on cycles/paths).

Potential gaps to firm up (action items)
1) Radius-1 realizability of the block grammar: We sketched role/phase tracks and single-step checks for U across row seams; to be fully formal, we should list the finite set of out–out pairs permitted at row separators and the Cin–out masks that tie “role-phase” symbols to input bits. This is standard but should be written once.
2) Witness chain details: spell out the constant-size alphabet and local rules for the existential pointer that safely walks to bit i in both blocks and enforces Hot_RID[i] ∧ (V^{(+)}[i] or V^{(-)}[i]). This reuses the error-pointer pattern from §3, but a concrete table will help verification.
3) Active context separability: we used that distinct RID/GID induce distinct context types. A short lemma should argue: if two left contexts have different Hot vectors, there exists a right clause context and a color such that the extendibility bits differ—hence types differ. (This reduces to the existence of some j and color where the witness succeeds for one RID but not the other.)
4) Enumeration of types (upper bound side): we outlined a DFA exploration; adding an explicit construction based on the boolean-matrix view C_w (Appendix A of draft) would make precomputation and composition clearer.
5) Three-class mapping clarity: While our hardness instances never realize the Ω(log* n) class, explaining explicitly that hardness for a subfamily suffices (since the classifier must be correct on all inputs) would avoid confusion.

Small sanity checks / examples
- Toy DP: For a tiny β (say β=3), define Cin–out to allow ⊥ on both input bits and restrict colors to input bit 1; define Cout–out so that a colored S must be followed on the right by a specific symbol. Running the layered DP checks extendibility quickly; this matches the O(k β^2) bound.
- Finite-Z for bridging: For a fixed (w1,S,w2), one can compute the two self-maps F_{w1}, F_{w2} on the type set, find their cycles, and set Z to lcm of periods times max preperiod (≤ ℓ_pump^2). On a random small instance, we indeed observe stabilization after a few iterations.

Next steps (concrete deliverables)
- Write the explicit out–out adjacency tables for: (i) row separators and U’s transition seams, (ii) error-pointer steps; specify the small work alphabet.
- Prove the “active context separability” lemma rigorously.
- Package the reduction P_C ↦ P_C^⋆ with exact β = poly(s) and tables’ sizes Θ(β^2); verify radius is 1 everywhere.
- Optionally, extend the NEXPTIME-membership argument from feasible-function existence to the full 3-way classifier by adding the finite-Z bridging checks; this would give NEXPTIME-completeness if desired.

Notes on attached materials (possible gaps)
- In the draft (LCL_classification.pdf), Section B (hardness) sketches the block/witness gadgets but leaves adjacency tables implicit; these must be concretized to eliminate ambiguity about radius and alphabet size.
- The claim “types differing in RID/GID are distinct” is stated but not proved; adding the separability lemma as noted above will close this gap.
- The finite-Z lemma for (F2) is stated with Z ≤ ℓ_pump^2; a brief derivation from the type DFA (pair product) would strengthen the presentation.

Summary claim (ready to formalize)
- The 3-way classification problem for β-normalized, radius-1 LCLs on oriented paths is NEXPTIME-hard. Reduction: Succinct-3SAT → Feasible-Function Existence (F1) (NEXPTIME-hard) → classification via bridging neutralization. The gadgets needed are all radius-1 and use β = poly(|C|). The upper-bound side (finite checks via types + DP) sits in NEXPTIME and can be added to obtain completeness if needed.

=== Verifier (summary_md) ===

=== Verifier (verdict) ===
partial success

