--- SYSTEM ---
You are a strict mathematical verifier & research manager.

You are being run in a loop with provers. Your tasks:
- Audit their ideas for correctness and rigor.
- Curate files (notes.md and outputs.md).
- Suggest the next steps.

Inputs: 
- task statement
- outputs of provers
- notes.md (summary so far)
- outputs.md (rigorously proven results so far)

Guidelines:
- notes.md: should be a readable running log of interesting work. Prefer appending. Replace only if old notes are clearly misleading.
- outputs.md: should be concise and rigorous. Keep only proven theorems with clear proofs. If a statement is flawed and you cannot fix it, remove it from outputs.md and instead add it to notes.md with explanation.
- Be careful with the booleans `new_notes_append` and `new_outputs_append`: default is True (append). Use False only when deliberately rewriting everything.

Tasks:
1) Audit rigor: identify unjustified steps, false statements, missing lemmas; produce minimal counterexamples.
2) Triage value: separate genuine progress from noise.
3) Guide next steps: propose what provers should try next.

**Return strictly JSON**:
{
  "feedback_md": "Detailed critique of prover outputs (â‰¥200 words). Include concrete next-step suggestions. The next round of provers may not see last round outputs; ensure all valuable info is stored in notes.",
  "new_notes_md": "Markdown (KaTeX allowed). Usually appended to notes.",
  "new_notes_append": "True|False",
  "new_outputs_md": "Markdown (KaTeX allowed). Usually appended to outputs.",
  "new_outputs_append": "True|False",
  "verdict": "success|uncertain|nothing so far"
}


--- USER ---
You receive multiple prover reports. Evaluate correctness, value, and pick promising directions. Update notes.md (append/replace) with useful ideas and update output.md (append/replace) ONLY with rigorously verified results.

Prover reports (JSON):
[{"prover_id": "01", "markdown_md": "# Incremental Progress on NEXPTIME-hardness Proof for LCL on Globally Oriented Paths\n\n## Ideas\nTo prove the NEXPTIME-hardness of the problem regarding the local complexity of $\beta$-normalized, radius-1 LCLs on globally oriented paths, we can build upon the existing PSPACE-hardness results. The key is to explore modifications to the automata used in the encoding and to analyze how these modifications can lead to an increase in complexity. \n\n### Lemmas from Literature\n1. **Pumping Lemma for Regular Languages**: This lemma states that for sufficiently long strings in a regular language, we can find substrings that can be "}, {"prover_id": "02", "markdown_md": "# Incremental Progress on NEXPTIME-hardness of LCL Problems on Paths\n\n## Ideas\nThe task is to prove NEXPTIME-hardness for the classification of the local complexity of $\beta$-normalized, radius-1 locally checkable labeling (LCL) problems on globally oriented paths. Given the PSPACE-hardness established in the previous paper, we can explore the following ideas:\n1. **Encoding Complexity**: Investigate how to encode the execution of a Turing machine in a way that allows for a classification of complexity beyond PSPACE. This could involve using larger tape sizes or different representations that do not restrict to polynomial bounds.\n2. **Modified Automata**: Consider modifications to the Linear Bounded Automata (LBA) model, such as allowing for exponential growth in the number of states or transitions, which may lead to NEXPTIME hardness.\n3. **Hierarchical Structures**: Explore hierarchical structures in the input that could lead to a more complex classification of outputs, possibly by introducing layers of encoding that leverage the properties of LCLs.\n\n## Examples\nTo test the robustness of our claims, we can consider small examples of LCL problems and their classifications:\n- **Example 1**: A simple LCL problem with a known constant-time solution should be analyzed to ensure it does not exhibit unexpected complexity when the input size increases.\n- **Example 2**: Construct a series of LCL problems that incrementally increase in complexity, checking if the classification remains consistent with the expected bounds (e.g., $O(1)$, $\theta(\text{log}^* n)$).\n\n## Obstacles\n1. **Technical Limitations**: The previous proof's reliance on bounded tape limits the generalization to NEXPTIME. We need to find a way to bypass this limitation, perhaps by considering unbounded tape or different computational models.\n2. **Complexity Collapse**: Establishing NEXPTIME-hardness would imply a collapse in complexity classes, which is a significant hurdle. We must ensure our approach does not inadvertently suggest such collapses.\n\n## Next Steps\n1. **Formal Error Chain**: Develop a formal error chain that illustrates how varying $\beta$ impacts the complexity classification, particularly focusing on $\beta = \theta(B)$.\n2. **Pump-Length Bound**: Precisely define the pump-length bound and explore how it can be computed in the context of our LCL problems.\n3. **Automated Checker Prototype**: Implement a prototype that can automatically check small $\beta$ values against our claims to ensure the robustness of our findings.\n\n## Gaps in Output.md\n- The output.md lacks a clear explanation of how the transition from PSPACE-hardness to NEXPTIME-hardness can be justified technically. This gap needs to be addressed to strengthen the argument.\n- There is no mention of specific examples or counterexamples that could provide insight into the potential complexity classifications. Including these would enhance the rigor of the claims.\n- The previous work's assumptions about the tape size and its implications for complexity need further exploration to clarify how they affect our current task."}]

Current notes.md:


Current output.md (if any):

