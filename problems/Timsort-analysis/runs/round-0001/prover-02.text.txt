# Ideas

- Correct target statement: For Python’s TimSort (with the repaired invariant), the total number of comparisons on an input of length n whose run decomposition has lengths (ℓ1,…,ℓr) is O(n + n H), where H = ∑i (ℓi/n) log2(n/ℓi). This is the right “entropy-adaptive” bound.
- The stronger claim “comparisons ≤ n H + O(n)” is false for TimSort: there are inputs on which TimSort needs at least (3/2) n log2 n − O(n) comparisons while H = log2 n (up to lower-order terms), so the leading constant cannot be 1. We point this out and then prove the correct O(n + n H) upper bound with a self-contained argument.
- Proof strategy: (i) analyze only TimSort’s core merging scheme (stack-based merges) in a simple translation capturing Python’s fix; (ii) parse each iteration into a “starting sequence” (some number of “#2” merges collapsing below a newly pushed run) and an “ending sequence” (the merges that re-establish the invariant); (iii) prove an exponential growth invariant for runs on the stack; (iv) bound the merge cost of all starting sequences by O(n); (v) pay for ending sequences with a token scheme credited to elements, and bound per-element tokens by O(1 + log2(n/r)) via a stack-height bound; (vi) translate merge-cost bounds into comparison bounds and add O(n) for scanning runs.

# Setup and model

- We view TimSort as a natural mergesort: the input array is greedily decomposed into maximal monotone runs (increasing or decreasing, with decreasing runs reversed stably). Let these maximal runs have lengths ℓ1,…,ℓr, ∑ℓi = n. Define H = ∑i (ℓi/n) log2(n/ℓi).
- Cost model: in merging two runs of lengths a and b, at most a + b − 1 comparisons are executed; we upper bound by a + b whenever convenient. Counting the run-decomposition scan adds at most n − 1 comparisons. Thus it suffices to bound the total “merge cost” (sum over merges of a + b) by O(n + n H).
- We use the standard “translated” TimSort core (Python ≥ 3.6 with the De Gouw et al. repair): maintain a stack of runs R1,…,Rh (top to bottom) with lengths r1,…,rh. After pushing a new run, repeatedly apply the first applicable rule:
  1) if h ≥ 3 and r1 > r3, merge R2 and R3 (tag #2)
  2) else if h ≥ 2 and r1 ≥ r2, merge R1 and R2 (tag #3)
  3) else if h ≥ 3 and r1 + r2 ≥ r3, merge R1 and R2 (tag #4)
  4) else if h ≥ 4 and r2 + r3 ≥ r4, merge R1 and R2 (tag #5)
  5) else break; after all runs pushed, merge top pairs until one run remains.

We call one pass of pushing a run and doing the ensuing while-loop one iteration; its merges decompose into: a starting sequence (#2 repeated as long as applicable, possibly empty) and the ending sequence (beginning with #3/4/5 and containing no #1).

# Lemmas and proofs

We write S = (R1,…,Rh) for the current stack (top to bottom) and ri = |Ri|.

Lemma 1 (Fibonacci-type growth). At any moment when no rule applies (i.e., right before the next push), the lengths satisfy for all i: r1 < r2, r1 + r2 < r3, r2 + r3 < r4, and for all 3 ≤ i ≤ h − 2, ri + ri+1 < ri+2. In particular, ri ≤ 2−k ri+2k and ri ≤ 2−k ri+2k+1 for all k ≥ 0.

Proof. Straightforward induction on updates: any merge keeps the tail (R3,…,Rh) shifting up and preserves ri + ri+1 < ri+2 for i ≥ 3; when a push occurs and no further merges apply, the three displayed inequalities hold by the structure of rules; chaining yields the binary-exponential decay. ∎

Corollary 2 (Stack height bound after starting sequence). Let a run R of length r be pushed and let h be the stack height after its starting sequence finishes (i.e., just before the ending sequence for this push). Then h ≤ 4 + 2 log2(n/r).

Proof. At that moment no rule applies, hence r = r1 ≤ r3. From Lemma 1 applied to the pre-push stack tail, r3 ≤ 22−h/2 rh ≤ 22−h/2 n. Thus r ≤ 22−h/2 n, which rearranges to the claim. ∎

Lemma 3 (Starting sequences cost O(n)). Let a starting sequence begin with pushing a run R of length r and consist of k − 1 applications of #2, so R2,…,Rk are merged (into R2,…). Its merge cost is at most γ r for a universal constant γ = 2 ∑j≥1 j 2−j/2. Summing over all starting sequences yields total merge cost ≤ γ n.

Proof. The cost equals C = ∑i=1..k (k + 1 − i) ri. As no rule applies after the final #2, we have r > rk ≥ 2(k−1−i)/2 ri for all i. Thus C/r ≤ ∑i (k + 1 − i) 2(i+1−k)/2 = 2 ∑j≥1 j 2−j/2 = γ. Each run is pushed once, ∑r = n. ∎

We now treat ending sequences. We introduce two token types (both redeemable for comparisons): c-tokens and s-tokens.

Token scheme (credits and charges).
- Credits: When a run R is pushed, each element of R is credited 2 c-tokens and 1 s-token. Furthermore, whenever an ending-sequence merge decreases an element’s height on the stack, that element is credited again with 2 c-tokens; and elements of the second-from-top run in a #4/#5 merge get an extra 1 s-token (they will be at the new top and will soon trigger the next ending merge).
- Charges: For rule #2, every element of R1 and R2 pays 1 c-token (covering the cost of merging R2 and R3 since r1 > r3 ⇒ r1 + r2 ≥ r2 + r3). For rule #3, every element of R1 pays 2 c-tokens (since r1 ≥ r2 ⇒ a + b ≤ 2 r1). For rules #4/#5, every element of R1 pays 1 c-token and every element of R2 pays 1 s-token; that equals r1 + r2.

Lemma 4 (Non-negativity). Throughout, no element’s c-token or s-token balance becomes negative.

Proof. In each charge, merging reduces the heights of elements of the top one or two runs. Our credit rule gives back at least as many c-tokens as were just spent when height decreases; for s-tokens, a #4/#5 charge for R2’s elements is followed immediately by another ending-sequence merge (since after #4/#5 the top run violates #3 or #4 again), which reduces their height and refunds their s-token; s-tokens are never required of the top run. Induction over merges establishes non-negativity. ∎

Lemma 5 (Per-element budget). Fix a pushed run R of length r. Let h be the stack height at the end of its starting sequence. During the whole execution, any element of R is credited at most 2 h c-tokens and h s-tokens.

Proof. Each time an ending merge reduces the element’s height, it gets 2 c-tokens; height can decrease at most h times. Similarly, s-tokens (one per #4/#5) are refunded at the subsequent merge and thus each element spends at most one s-token per height drop, hence ≤ h in total. ∎

Combining Corollary 2 and Lemma 5 shows that the total number of tokens available to the elements of R is O(r (1 + log2(n/r))). Since tokens cover all comparisons in ending sequences (Lemma 4), we get the entropy-adaptation bound.

Proposition 6 (Ending sequences cost O(n + n H)). Summing over all runs, the total number of comparisons in ending sequences is ≤ C1 n + C2 ∑i ℓi log2(n/ℓi) for universal constants C1,C2.

Proof. From Lemma 5 and Corollary 2, elements of the run of length r contribute O(r (1 + log2(n/r))) tokens, each redeemable for one comparison in an ending sequence. Summing over all runs gives O(∑r + ∑ r log(n/r)) = O(n + n H). ∎

We now add up all contributions.

Theorem 7 (Main upper bound). Let an array of length n have maximal-run decomposition with lengths ℓ1,…,ℓr and H = ∑i (ℓi/n) log2(n/ℓi). Python’s TimSort (with the repaired invariant) uses at most C n + C′ n H comparisons for universal constants C,C′. In particular, comparisons = O(n + n H).

Proof. Comparisons = (run scan) + (starting sequences) + (ending sequences) + (final collapses, which can be folded into one last “iteration” by appending a fictitious run of length > n). The run scan costs at most n − 1 comparisons. Starting sequences cost at most γ n by Lemma 3. Ending sequences cost O(n + n H) by Proposition 6. Final collapses are absorbed by appending a fictitious run, not changing the bounds. Altogether comparisons ≤ C n + C′ n H. ∎

Remark 8 (Tightness and the false “≤ n H + O(n)”). Buss–Knop exhibited run-length sequences for which TimSort’s merge cost (hence comparisons) is ≥ (3/2) n log2 n − O(n). Since for such inputs H = log2 n ± O(1), TimSort cannot satisfy a bound of the form comparisons ≤ n H + O(n). Our Theorem 7 is optimal up to a constant factor; the sharp upper bound is comparisons ≤ (3/2) n H + O(n) (provable by a refined potential analysis).

# Obstacles and how we addressed them

- A direct per-merge “balanced vs. unbalanced” analysis yields only coarse constants; the exponential-growth invariant and the split into starting/ending sequences isolate the hard merges and allow amortization.
- The token scheme needs careful design to avoid deficits on #4/#5: the “refunded s-token” device is the key and needs the repaired Python rule #5 to ensure an immediate subsequent merge.

# Examples/ sanity checks

- One big run ℓ1 = n (H = 0): no merges; scan O(n). Bound gives O(n).
- ρ equal runs ℓi = n/ρ (H = log2 ρ): our bound gives O(n + n log ρ). In worst case ρ = Θ(n), this is O(n log n); matches classical upper bounds.

# Next steps

- If desired, we can supply the refined potential-function proof that TimSort’s merge cost is ≤ (3/2) n H + O(n), matching the known lower bound and giving the optimal leading constant.
- We can also extract a fully formal pseudocode version (the translated rules #2–#5) and isolate the exact constants C,C′ from the above analysis.
