{
  "content": "## Clarifying the target and the model\n- We analyze Python\u2019s TimSort (with the de Gouw\u2013et al. fix), under the standard comparison model. The input is greedily decomposed into maximal monotone runs of lengths \u21131,\u2026,\u2113r, with \u03a3\u2113i=n.\n- We write H = \u03a3 (\u2113i/n) log2(n/\u2113i).\n- Important: the statement \u201cTimSort uses \u2264 n H + O(n) comparisons\u201d with leading constant 1 is false for TimSort in general; there are inputs with cost \u2265 (3/2 \u2212 o(1)) n log2 n when H\u2248log2 n. What we prove here is the entropy-adaptive upper bound O(n + nH), which is tight up to a constant factor, and is the strongest true statement with constant-independent big-Oh. A refined tight upper bound (3/2) nH + O(n) is cited and sketched at the end.\n\nWe give a self-contained proof that the number of comparisons is O(n + nH).\n\n## Algorithmic core (abstracted TimSort rule)\nMaintain a stack of run lengths (top to bottom) r1,\u2026,rh. When a new run r is pushed, repeatedly apply the first applicable rule among:\n- (#2) if h\u22653 and r1>r3: merge runs R2 and R3;\n- (#3) else if h\u22652 and r1\u2265r2: merge R1 and R2;\n- (#4) else if h\u22653 and r1+r2\u2265r3: merge R1 and R2;\n- (#5) else if h\u22654 and r2+r3\u2265r4: merge R1 and R2;\notherwise stop. After all pushes, force-collapse until one run remains.\n\nMerge cost model: merging lengths a,b costs a+b. Each merge uses at most a+b\u22121 comparisons; detecting runs and control overhead is O(n). Hence total comparisons \u2264 total merge cost + O(n).\n\n## Stack-growth invariant\nLemma 1 (quiescent invariant). Just before a new push (i.e., after the while-loop stabilizes), the stack satisfies\n- r1<r2, r1+r2<r3, r2+r3<r4, and for all i\u22653: ri+ri+1<ri+2.\nProof. By induction over updates. If a push just ended, none of (#2\u2013#5) holds, yielding the first three inequalities. A merge shifts indices and preserves the last inequality by the induction hypothesis. \u220e\n\nCorollary 2 (exponential growth). For 1\u2264i\u2264j\u2264h: ri \u2264 2^{(i+1\u2212j)/2} rj. In particular, at the end of the starting sequence (see below) for a run of length r, the current stack height h satisfies h \u2264 4 + 2 log2(n/r).\nProof. From Lemma 1, ri+2 \u2265 2 ri for all i\u2264h\u22122, hence ri \u2264 2^{\u2212k} ri+2k \u2264 2^{\u2212k} ri+2k+1. For the height bound, r = r1 \u2264 r3 \u2264 2^{2\u2212h/2} n by Corollary\u2019s inequality with j=h. \u220e\n\n## Decomposition into starting and ending sequences\nFor each push of a new run R of length r, we split the subsequent while-loop updates into:\n- starting sequence: maximal prefix of consecutive (#2) merges (possibly none),\n- ending sequence: all remaining merges until the next push.\n\nLemma 3 (starting sequences cost O(n)). The total merge cost of all starting sequences is O(n).\nProof. Fix a starting sequence that merges the top k pre-existing runs R1,\u2026,Rk (k\u22652). Its cost C \u2264 \u03a3_{i=1}^k (k+1\u2212i) ri. The last (#2) merge ensures r>rk; by Corollary 2, rk \u2265 2^{(k\u22121\u2212i)/2} ri. Hence C/r \u2264 \u03a3_{i=1}^k (k+1\u2212i) 2^{(i+1\u2212k)/2} = 2 \u03a3_{j=1}^k j 2^{\u2212j/2} < \u03b3 for a constant \u03b3. Summing over pushes (\u03a3 r = n) yields O(n). \u220e\n\n## Token accounting for ending sequences\nWe charge ending-sequence merges to per-element tokens.\n- Credits: when a run is pushed, each of its elements receives 2 c-tokens and 1 s-token. Whenever an ending-sequence merge lowers an element\u2019s height, the element receives again 2 c-tokens and 1 s-token.\n- Spending per merge:\n  (#2) merge (R2,R3): every element of R1 and R2 pays 1 c-token (cost \u2264 r2+r1 \u2265 r2+r3).\n  (#3) merge (R1,R2): every element of R1 pays 2 c-tokens (cost \u2264 2 r1).\n  (#4) or (#5) merge (R1,R2): every element of R1 pays 1 c-token and every element of R2 pays 1 s-token (cost = r1+r2).\n\nLemma 4 (no deficits). No element ever runs out of c- or s-tokens during ending sequences.\nProof. For c-tokens, any merge that lowers an element\u2019s height immediately credits fresh c-tokens, covering charges in the same/next update. For s-tokens, only (#4),(#5) charge R2\u2019s elements. After such a merge, the new top run is R1\u222aR2 and, by the very triggering condition (#4 or #5), another merge must immediately occur; that next merge lowers the height of the top run and thus re-credits an s-token to all its elements, including former R2 elements, before any further s-charge. Induction over updates yields the claim. \u220e\n\nLemma 5 (height bound per element). Let R be of length r. At the end of R\u2019s starting sequence, the stack height satisfies h \u2264 4 + 2 log2(n/r). In particular, each element of R receives O(h) = O(1 + log(n/r)) credits over its ending sequence.\nProof. The height bound is Corollary 2. Each height decrease in an ending sequence triggers a fresh credit; the number of decreases per element is O(h). \u220e\n\nSumming token payments over all elements in ending sequences gives a total merge cost of\n\u03a3_R O(r (1 + log(n/r))) = O(n + \u03a3 r log(n/r)) = O(n + nH).\nTogether with Lemma 3, the total merge cost of the main loop is O(n + nH). Adding O(n) for the run scan and final collapse (or fold the final merges into a last iteration by appending a fictitious run of length n+1) yields:\n\nTheorem A (entropy adaptivity). On inputs with run lengths \u21131,\u2026,\u2113r, Python TimSort performs at most O(n + n H) comparisons.\n\n## Lower bound\nProposition B (information-theoretic). Any comparison sort needs at least nH \u2212 O(n) comparisons on inputs with known run partition (distinct keys).\nProof sketch. The number of compatible permutations is n!/(\u21131!\u22ef\u2113r!). Hence log2 of this is \u2265 nH \u2212 O(n) by Stirling. \u220e\n\nCorollary. TimSort adapts to run-length entropy optimally up to a constant factor and lower-order terms.\n\n## Refined, tight leading constant (sketch)\nDefine potential \u03a6(r) = (3/2) r log2 r. One proves that:\n- Many merges are \u201cbalanced\u201d: merge cost \u2264 \u0394\u03a6. Unbalanced (#2) merges and certain (#3) merges can be paired so that their joint cost \u2264 joint \u0394\u03a6. The first merge of an ending sequence may incur an extra additive +r, telescoping to +n across all runs.\n- Using strengthened invariants (e.g., r2,r3<r4; \u03a3_{k=2}^{i\u22121} rk < \u03c6\u00b7ri), one shows every ending sequence\u2019s cost \u2264 its potential increase + r. Summing gives total merge cost \u2264 \u03a6(n) \u2212 \u03a3 \u03a6(\u2113i) + O(n) = (3/2) nH + O(n).\n- Buss\u2013Knop construct inputs with merge cost \u2265 (3/2 \u2212 o(1)) n log2 n, proving tightness.\nHence comparisons \u2264 (3/2) nH + O(n) and the constant 3/2 is best possible for TimSort.\n\n## Examples / sanity checks\n- Single run (r=1): H=0, no merges; comparisons O(n) for scan.\n- r equal runs, \u2113i=n/r: H=log2 r, token bound yields O(n+n log r).\n\n## Obstacles\n- A proof of \u201c\u2264 nH + O(n)\u201d for TimSort is impossible (contradicts Buss\u2013Knop lower bounds). The presented O(n+nH) is the strongest true leading-term statement for TimSort.\n\n## Next steps\n- Promote Theorem A (with detailed lemmas) to proofs.md/output.md. Optionally add the tight (3/2) nH + O(n) proof with full details (potential grouping and invariants).\n- Note: if a leading constant 1 is truly desired, use nearly-optimal stable natural mergesorts (e.g., peeksort/powersort) which achieve comparisons \u2264 nH + O(n)."
}