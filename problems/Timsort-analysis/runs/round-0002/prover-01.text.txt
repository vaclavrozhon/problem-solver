## Clarifying the target and the model
- We analyze Python’s TimSort (with the de Gouw–et al. fix), under the standard comparison model. The input is greedily decomposed into maximal monotone runs of lengths ℓ1,…,ℓr, with Σℓi=n.
- We write H = Σ (ℓi/n) log2(n/ℓi).
- Important: the statement “TimSort uses ≤ n H + O(n) comparisons” with leading constant 1 is false for TimSort in general; there are inputs with cost ≥ (3/2 − o(1)) n log2 n when H≈log2 n. What we prove here is the entropy-adaptive upper bound O(n + nH), which is tight up to a constant factor, and is the strongest true statement with constant-independent big-Oh. A refined tight upper bound (3/2) nH + O(n) is cited and sketched at the end.

We give a self-contained proof that the number of comparisons is O(n + nH).

## Algorithmic core (abstracted TimSort rule)
Maintain a stack of run lengths (top to bottom) r1,…,rh. When a new run r is pushed, repeatedly apply the first applicable rule among:
- (#2) if h≥3 and r1>r3: merge runs R2 and R3;
- (#3) else if h≥2 and r1≥r2: merge R1 and R2;
- (#4) else if h≥3 and r1+r2≥r3: merge R1 and R2;
- (#5) else if h≥4 and r2+r3≥r4: merge R1 and R2;
otherwise stop. After all pushes, force-collapse until one run remains.

Merge cost model: merging lengths a,b costs a+b. Each merge uses at most a+b−1 comparisons; detecting runs and control overhead is O(n). Hence total comparisons ≤ total merge cost + O(n).

## Stack-growth invariant
Lemma 1 (quiescent invariant). Just before a new push (i.e., after the while-loop stabilizes), the stack satisfies
- r1<r2, r1+r2<r3, r2+r3<r4, and for all i≥3: ri+ri+1<ri+2.
Proof. By induction over updates. If a push just ended, none of (#2–#5) holds, yielding the first three inequalities. A merge shifts indices and preserves the last inequality by the induction hypothesis. ∎

Corollary 2 (exponential growth). For 1≤i≤j≤h: ri ≤ 2^{(i+1−j)/2} rj. In particular, at the end of the starting sequence (see below) for a run of length r, the current stack height h satisfies h ≤ 4 + 2 log2(n/r).
Proof. From Lemma 1, ri+2 ≥ 2 ri for all i≤h−2, hence ri ≤ 2^{−k} ri+2k ≤ 2^{−k} ri+2k+1. For the height bound, r = r1 ≤ r3 ≤ 2^{2−h/2} n by Corollary’s inequality with j=h. ∎

## Decomposition into starting and ending sequences
For each push of a new run R of length r, we split the subsequent while-loop updates into:
- starting sequence: maximal prefix of consecutive (#2) merges (possibly none),
- ending sequence: all remaining merges until the next push.

Lemma 3 (starting sequences cost O(n)). The total merge cost of all starting sequences is O(n).
Proof. Fix a starting sequence that merges the top k pre-existing runs R1,…,Rk (k≥2). Its cost C ≤ Σ_{i=1}^k (k+1−i) ri. The last (#2) merge ensures r>rk; by Corollary 2, rk ≥ 2^{(k−1−i)/2} ri. Hence C/r ≤ Σ_{i=1}^k (k+1−i) 2^{(i+1−k)/2} = 2 Σ_{j=1}^k j 2^{−j/2} < γ for a constant γ. Summing over pushes (Σ r = n) yields O(n). ∎

## Token accounting for ending sequences
We charge ending-sequence merges to per-element tokens.
- Credits: when a run is pushed, each of its elements receives 2 c-tokens and 1 s-token. Whenever an ending-sequence merge lowers an element’s height, the element receives again 2 c-tokens and 1 s-token.
- Spending per merge:
  (#2) merge (R2,R3): every element of R1 and R2 pays 1 c-token (cost ≤ r2+r1 ≥ r2+r3).
  (#3) merge (R1,R2): every element of R1 pays 2 c-tokens (cost ≤ 2 r1).
  (#4) or (#5) merge (R1,R2): every element of R1 pays 1 c-token and every element of R2 pays 1 s-token (cost = r1+r2).

Lemma 4 (no deficits). No element ever runs out of c- or s-tokens during ending sequences.
Proof. For c-tokens, any merge that lowers an element’s height immediately credits fresh c-tokens, covering charges in the same/next update. For s-tokens, only (#4),(#5) charge R2’s elements. After such a merge, the new top run is R1∪R2 and, by the very triggering condition (#4 or #5), another merge must immediately occur; that next merge lowers the height of the top run and thus re-credits an s-token to all its elements, including former R2 elements, before any further s-charge. Induction over updates yields the claim. ∎

Lemma 5 (height bound per element). Let R be of length r. At the end of R’s starting sequence, the stack height satisfies h ≤ 4 + 2 log2(n/r). In particular, each element of R receives O(h) = O(1 + log(n/r)) credits over its ending sequence.
Proof. The height bound is Corollary 2. Each height decrease in an ending sequence triggers a fresh credit; the number of decreases per element is O(h). ∎

Summing token payments over all elements in ending sequences gives a total merge cost of
Σ_R O(r (1 + log(n/r))) = O(n + Σ r log(n/r)) = O(n + nH).
Together with Lemma 3, the total merge cost of the main loop is O(n + nH). Adding O(n) for the run scan and final collapse (or fold the final merges into a last iteration by appending a fictitious run of length n+1) yields:

Theorem A (entropy adaptivity). On inputs with run lengths ℓ1,…,ℓr, Python TimSort performs at most O(n + n H) comparisons.

## Lower bound
Proposition B (information-theoretic). Any comparison sort needs at least nH − O(n) comparisons on inputs with known run partition (distinct keys).
Proof sketch. The number of compatible permutations is n!/(ℓ1!⋯ℓr!). Hence log2 of this is ≥ nH − O(n) by Stirling. ∎

Corollary. TimSort adapts to run-length entropy optimally up to a constant factor and lower-order terms.

## Refined, tight leading constant (sketch)
Define potential Φ(r) = (3/2) r log2 r. One proves that:
- Many merges are “balanced”: merge cost ≤ ΔΦ. Unbalanced (#2) merges and certain (#3) merges can be paired so that their joint cost ≤ joint ΔΦ. The first merge of an ending sequence may incur an extra additive +r, telescoping to +n across all runs.
- Using strengthened invariants (e.g., r2,r3<r4; Σ_{k=2}^{i−1} rk < φ·ri), one shows every ending sequence’s cost ≤ its potential increase + r. Summing gives total merge cost ≤ Φ(n) − Σ Φ(ℓi) + O(n) = (3/2) nH + O(n).
- Buss–Knop construct inputs with merge cost ≥ (3/2 − o(1)) n log2 n, proving tightness.
Hence comparisons ≤ (3/2) nH + O(n) and the constant 3/2 is best possible for TimSort.

## Examples / sanity checks
- Single run (r=1): H=0, no merges; comparisons O(n) for scan.
- r equal runs, ℓi=n/r: H=log2 r, token bound yields O(n+n log r).

## Obstacles
- A proof of “≤ nH + O(n)” for TimSort is impossible (contradicts Buss–Knop lower bounds). The presented O(n+nH) is the strongest true leading-term statement for TimSort.

## Next steps
- Promote Theorem A (with detailed lemmas) to proofs.md/output.md. Optionally add the tight (3/2) nH + O(n) proof with full details (potential grouping and invariants).
- Note: if a leading constant 1 is truly desired, use nearly-optimal stable natural mergesorts (e.g., peeksort/powersort) which achieve comparisons ≤ nH + O(n).