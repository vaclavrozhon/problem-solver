# Ideas

- Precise claim achievable: Python TimSort (with the de Gouw et al. fix r2 + r3 ≥ r4) uses at most C n + C′ n H comparisons on inputs whose maximal-run lengths are ℓ1,…,ℓr, where H = ∑i (ℓi/n) log2(n/ℓi). Why useful: matches “entropy adaptivity” up to constants and is known to be the best possible leading constant for TimSort up to a factor (tight constant is 3/2).
- The stricter claim “comparisons ≤ n H + O(n)” is false for TimSort; Buss–Knop exhibit families with ≥ (3/2 − o(1)) n log2 n comparisons while H ≈ log2 n. Why useful: sets proper target and avoids chasing a false statement.

# Model and setup

- Input: Array A[1..n], greedily decomposed into maximal runs; reverse decreasing runs to keep stability so all runs are nondecreasing. Let run lengths be ℓ1,…,ℓr (Σℓi = n). Define H = ∑i (ℓi/n) log2(n/ℓi).
- Cost model: merging two runs of lengths a,b costs ≤ a + b − 1 comparisons; we upper bound by a + b. Run-detection scan needs ≤ n − 1 comparisons. Hence bounding total “merge cost” M by O(n + n H) suffices.
- TimSort core (translated, Python version): maintain stack S = (R1,…,Rh) of runs (top to bottom). After pushing a new run, repeatedly apply the first applicable rule among
  - (#2) if h ≥ 3 and r1 > r3 then merge (R2,R3);
  - (#3) else if h ≥ 2 and r1 ≥ r2 then merge (R1,R2);
  - (#4) else if h ≥ 3 and r1 + r2 ≥ r3 then merge (R1,R2);
  - (#5) else if h ≥ 4 and r2 + r3 ≥ r4 then merge (R1,R2);
  - else break. After all pushes, merge top pairs until one run remains.
- Decompose each iteration into a starting sequence (maximal consecutive #2 merges) and an ending sequence (begins with #3/#4/#5, contains no push).

# Lemmas and why useful

Lemma 1 (Exponential growth invariant). At any quiescent point (no rule applies), we have r1 < r2, r1 + r2 < r3, r2 + r3 < r4, and for all 3 ≤ i ≤ h − 2: ri + ri+1 < ri+2. In particular, ri ≤ 2−k ri+2k and ri ≤ 2−k ri+2k+1 for all k ≥ 0.
Why useful: yields geometric decay up the stack; powers the starting-sequence bound and the stack-height bound.

Proof sketch. Induct over updates: merges shift tail indices, preserving ri + ri+1 < ri+2 for i ≥ 3; at quiescence, the rules’ negations give the first three inequalities. Chaining gives the 2-ary decay.

Corollary 2 (Height bound after starting sequence). If a run R of length r has just finished its starting sequence, then h ≤ 4 + 2 log2(n/r).
Why useful: bounds per-element amortized budget in ending sequences by O(1 + log(n/r)).

Proof. At that moment r = r1 ≤ r3. Apply Lemma 1 to the pre-push tail to get r3 ≤ 22−h/2 n, hence r ≤ 22−h/2 n.

Lemma 3 (Starting sequences cost O(n)). If a starting sequence triggered by pushing R of length r merges k preexisting runs R1,…,Rk (k ≥ 2), its merge cost is ≤ γ r with γ = 2 ∑j≥1 j 2−j/2; summing over all pushes gives total starting-sequence cost ≤ γ n.
Why useful: isolates O(n) part; the entropy term arises only from ending sequences.

Proof. The cost C ≤ ∑i=1..k (k + 1 − i) ri. From Lemma 1, r > rk ≥ 2(k−1−i)/2 ri, so C/r ≤ 2 ∑j≥1 j 2−j/2.

Token scheme for ending sequences (amortization device). We use two token types, both worth one comparison: c-tokens and s-tokens.
- Credits: Each element receives 2 c-tokens and 1 s-token when its run is pushed; and whenever its height drops due to an ending-sequence merge, it receives again 2 c-tokens; and, in #4/#5 merges, elements of R2 (second from top) also receive 1 s-token at the subsequent height drop (explained below).
- Charges: #2: every element of R1 and R2 pays 1 c; #3: every element of R1 pays 2 c; #4/#5: every element of R1 pays 1 c and every element of R2 pays 1 s.

Lemma 4 (No deficits). Under the above scheme, no element ever runs a negative c- or s-token balance during ending sequences.
Why useful: shows tokens suffice to pay all ending-sequence comparisons.

Proof. For c-tokens, every time elements pay, a height drop occurs for top (and sometimes second) runs; the 2 c-token re-credit per drop covers the charges. For s-tokens, only R2 pays 1 s in #4/#5, and then immediately becomes part of the top run that triggers another ending merge; that next merge drops their height, re-crediting 1 s, and s are never charged to the top run. Induct over merges.

Lemma 5 (Per-element budget). After R finishes its starting sequence with stack height h, any element of R will experience at most h height drops, thus accrue at most 2 h c-tokens and h s-tokens over the whole algorithm.
Why useful: with Corollary 2 yields per-element O(1 + log(n/r)) budget.

Proof. Each height drop credits 2 c and (for #4/#5) refunds s; height can drop at most h times.

# Main bound

Theorem A (Entropy adaptivity up to constants). For run lengths ℓ1,…,ℓr with Σℓi = n and H = ∑i (ℓi/n) log2(n/ℓi), Python TimSort performs at most O(n + n H) comparisons.

Proof. Comparisons = (run scan) + (merges). Scanning ≤ n − 1. Starting sequences sum to ≤ γ n by Lemma 3. For ending sequences, tokens dominate comparisons by Lemma 4; each element in a run of length r contributes O(1 + log(n/r)) tokens by Lemma 5 and Corollary 2; summing gives O(∑r (1 + log(n/r))) = O(n + n H). The final-collapse phase can be folded into the last iteration by appending a fictitious run of length > n (or charged to O(n)).

Proposition B (Lower bound). Any comparison sort needs ≥ n H − O(n) comparisons on inputs with run lengths ℓ1,…,ℓr.

Proof idea. Number of compatible permutations is n!/(ℓ1!⋯ℓr!); by Stirling, log2 of that is n H − Θ(n). Thus any decision tree must have depth ≥ n H − O(n).

# Examples

- Single run (r = 1): H = 0; algorithm scans runs and stops; O(n) bound matches.
- Equal runs (ℓi = n/r): H = log2 r; bound gives O(n + n log r) = O(n log r), as expected.

# Obstacles / caveats

- The requested bound with leading constant 1, “comparisons ≤ n H + O(n),” is false for TimSort; Buss–Knop give families with ≥ (3/2 − o(1)) n log2 n comparisons and H ≈ log2 n. The above theorem is the correct statement for TimSort’s entropy adaptivity up to multiplicative constants.
- Our analysis targets Python TimSort with the repaired guard (#5). Java’s historical variant without it needs extra care; the same asymptotic bounds hold, but the invariant maintenance is subtler.

# Next steps

- Promote Theorem A (with all lemmas and the explicit rule set) to proofs.md as a self-contained proof; summarize in output.md.
- Add Proposition B (lower bound) for completeness.
- Optional: include the refined potential-function analysis that proves the tight upper bound comparisons ≤ (3/2) n H + O(n), matching known lower bounds for TimSort’s merge cost.
