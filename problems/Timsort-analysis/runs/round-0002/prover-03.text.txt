Ideas

- Correct target: For Python’s patched TimSort (with the extra collapse rule r_2 + r_3 ≥ r_4), the number of comparisons on inputs with run lengths (ℓ_i) is O(n + n H) where H = ∑ (ℓ_i/n) log_2(n/ℓ_i). This is the coarse entropy-adaptivity. The sharp constant 3/2 is known but not needed here.
- Strategy: Bound comparisons by merge cost plus O(n). Decompose each iteration into starting vs. ending sequences. Prove starting sequences contribute O(n). For ending sequences, an amortized token scheme credits O(1 + log(n/r)) tokens per element in a run of length r; summing yields O(n + n H).

Rigorous steps

1) Comparisons vs. merge cost.
- Merging two runs of sizes a, b uses ≤ a + b − 1 ≤ a + b comparisons. Counting runs on the fly uses ≤ n − 1 comparisons (each adjacent pair is compared at most once while extending a run; run reversals use no comparisons). So total comparisons ≤ total merge cost + O(n).

2) Invariant and growth.
- After any collapse, the stack (top R_1, next R_2, …) satisfies r_{i+2} > r_{i+1} + r_i and r_{i+1} > r_i, for i in range. Proof: case analysis over #1–#5 shows preservation; merges stop only when no condition holds. Consequence: r_{i+2} ≥ 2 r_i, and for any i ≤ j ≤ h (h = height) when about to push, r_i ≤ 2^{(i+1−j)/2} r_j.

3) Starting sequences cost O(n).
- A starting sequence begins by pushing a run R of length r, then performs k − 1 merges of type #2 (merging R_2,R_3,…,R_k). Its cost is C ≤ ∑_{i=1}^k (k+1−i) r_i. The last #2 implies r > r_k, hence r ≥ r_k ≥ 2^{(k−1−i)/2} r_i for all i; therefore C/r ≤ 2 ∑_{j=1}^k j 2^{−j/2} < γ with γ = 2 q/(1−q)^2 and q = 2^{−1/2}; numerically γ ≈ 16.49. Summing over all starting sequences (each run starts exactly one) yields total cost ≤ γ n = O(n).

4) Ending sequences via tokens.
- Credit rule: When a run is pushed, or when an element’s height decreases due to a merge in an ending sequence, give each element 2 “c-tokens” and 1 “s-token”.
- Spending rule per merge in an ending sequence:
  - #2: every element of R_1 and R_2 pays 1 c-token.
  - #3: every element of R_1 pays 2 c-tokens.
  - #4/#5: every element of R_1 pays 1 c-token and every element of R_2 pays 1 s-token.
- Nonnegativity of balances: In #2/#3/#4/#5, heights of the charged elements strictly decrease, so new credits (2 c + 1 s) are issued after the merge to those elements; c-token spends are thus covered. For s-tokens: #4/#5 cannot end an ending sequence; the very next action is another merge, which decreases the height of the top run and re-credits one s-token before any further s-token is spent; thus s-balances never go negative.

5) Height bound after starting sequence.
- Let run R of length r be pushed; at the end of its starting sequence, no #2 applies. The runs below (indices ≥3) were untouched since the push. From r_1 ≤ r_3 and r_3 ≤ 2^{2−h/2} r_h ≤ 2^{2−h/2} n (by the growth corollary), we get r ≤ 2^{2−h/2} n, hence h ≤ 4 + 2 log_2(n/r).
- Each element of R receives ≤ 2h c-tokens and ≤ h s-tokens over the remainder of the main loop, so O(h) tokens per element.

6) Summation and entropy.
- For a run of length r, token credits per element are O(1 + log(n/r)). Therefore total tokens (and hence total ending-sequence merge cost) is O(∑_i r_i (1 + log(n/r_i))) = O(n + n H).
- Adding starting sequences (O(n)) and run detection (O(n)) yields total merge cost O(n + n H), hence total comparisons O(n + n H).

Examples

- Many short runs: ℓ_i ≈ 1, H ≈ log_2 ρ; bound gives O(n log n). Token bound matches since h = O(log n) for each element.
- One large run r ≈ n and few tiny runs: H = O(1); height bound gives O(1) tokens per element in the big run; total O(n).

Obstacles

- The s-token nonnegativity relies on the corrected Python rule (#5). Without #5 (Java’s original), the immediate-follow-up-merge guarantee can fail; the token proof needs changes.
- Galloping merge heursitics are ignored; they cannot increase comparisons beyond a + b − 1 and thus do not harm the upper bound.

Next steps

- Curate proofs.md with full statements and proofs of: invariant, starting-sequence bound with explicit γ, token lemma, height bound, and the final summation to O(n + n H).
- Optionally, add the sharp (3/2)·nH + O(n) proof via potential Φ(r) = (3/2) r log_2 r: (i) balanced merges (size ratio within φ^2) satisfy cost ≤ ΔΦ; (ii) group the few unbalanced merges within each ending sequence into singletons/pairs so cost ≤ ΔΦ(group) plus at most r for the first group; summing r over runs gives O(n). Lower bound inputs from Buss–Knop give tightness.
