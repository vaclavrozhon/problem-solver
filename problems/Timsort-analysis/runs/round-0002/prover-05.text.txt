# Ideas
- The leading-constant-1 claim “comparisons ≤ n·H + O(n)” is false for TimSort (Buss–Knop show ≥(3/2)·n·H−O(n) in worst case). We aim to: (i) prove the coarse entropy bound comparisons = O(n + n·H); (ii) outline the sharp bound comparisons ≤ (3/2)·n·H + O(n).
- We work with merge-cost (sum of sizes of merged pairs). Since merging a,b uses ≤ a+b−1 comparisons, total comparisons ≤ total merge-cost + O(n) (also +O(n) to detect runs). Thus proving merge-cost = O(n + n·H) suffices.

# Rigorous lemmas toward O(n+nH)
We analyze patched Python TimSort, in the “translated” form with cases #1–#5 (the extra #5 condition).

Lemma 1 (Fibonacci growth invariant).
At any time in the main loop, for the stack S=(R_1,…,R_h) (top to bottom, lengths r_1,…,r_h), we have r_{i+2} > r_{i+1} + r_i for all i≥3; moreover, just before a push finishes (when no further merges are triggered) r_1<r_2, r_1+r_2<r_3, r_2+r_3<r_4.
Proof. By induction over updates #1–#5. Case #1 shifts indices (and we know the collapse conditions are false), preserving the strict inequalities. Cases #2–#5 replace some consecutive runs by their sum and shift the rest; a direct check shows r_{i+2} > r_{i+1}+r_i continues to hold for all i≥3.

Corollary 1 (exponential growth along the stack).
Whenever a push is about to occur (no further merges triggered), for all i≤j≤h, r_i ≤ 2^{(i+1−j)/2} r_j. In particular r_{i+2} ≥ 2 r_i and the sequence increases strictly.
Proof. From r_i+r_{i+1}<r_{i+2} for all i≥1 at that moment, deduce 2 r_i ≤ r_{i+2}. Iterating by jumps of 2 and noting monotonicity yields the inequality.

Definition (starting- vs. ending-sequence of an iteration).
After pushing the new run R of length r (case #1), perform maximal #2 merges (starting-sequence), then continue with merges of type #3/#4/#5 (and possibly #2 interspersed) until no rule applies (ending-sequence). The next push then starts a new iteration.

Lemma 2 (starting-sequences cost O(n)).
Let a starting-sequence merging runs R_1,…,R_k (k≥2) beneath the just-pushed run R of length r>r_k (since the last #2 no longer holds). Its total merge-cost C satisfies C ≤ γ r, where γ=2∑_{j≥1} j·2^{−j/2} (a constant). Summing over all pushes gives O(n).
Proof. The merges produce cost C ≤ ∑_{i=1}^k (k+1−i) r_i. By Corollary 1 applied to the pre-push stack, r ≥ r_k ≥ 2^{(k−1−i)/2} r_i for each i, hence C/r ≤ ∑_{i=1}^k (k+1−i) 2^{(i+1−k)/2} = 2∑_{j=1}^k j 2^{−j/2} < γ. Each element is charged at most once at the push that creates its run, so ∑ r = n gives O(n).

Token accounting for ending-sequences.
- Credit rule: Each element receives 2 c-tokens and 1 s-token when its run is pushed; it also receives 2 c-tokens and 1 s-token whenever its height decreases due to a merge inside an ending-sequence: when merging R_1+R_2, every element of R_1 is credited; when merging R_2+R_3, every element of R_1 and R_2 is credited.
- Spend rule per merge case:
  • #2: every element of R_1 and R_2 pays 1 c-token (covers cost r_1+r_2 ≥ r_2+r_3 since r_1>r_3).
  • #3: every element of R_1 pays 2 c-tokens (cost r_1+r_2 ≤ 2 r_1).
  • #4, #5: every element of R_1 pays 1 c-token and every element of R_2 pays 1 s-token (cost r_1+r_2 equals tokens spent).

Lemma 3 (nonnegativity of token balances).
Throughout the main loop, c- and s-token balances of each element never become negative.
Proof. In any ending-sequence merge, involved elements lose tokens as per spend rule but simultaneously their heights drop, granting credits. For c-tokens, the credits per height drop dominate spends by the above schedule. For s-tokens (only spent by R_2 in #4/#5), after merging R_1+R_2 to become the top run, the patched rule (#5) plus the current sizes imply another merge must immediately follow within the same ending-sequence (no push occurs in between); that next merge decreases the height of the new top run, re-crediting 1 s-token to those elements before any further spend. Induction over the merges in the same ending-sequence proves nonnegativity.

Lemma 4 (height bound after starting-sequence).
Let r be the length of the just-pushed run and h the stack height after its starting-sequence. Then h ≤ 4 + 2 log_2(n/r).
Proof. Runs at positions ≥3 were not merged in the starting-sequence. By Corollary 1 applied to the pre-push tail, r̄_3 ≤ 2^{2−h/2} r̄_h ≤ 2^{2−h/2} n. At the end of the starting-sequence, case #2 no longer applies, so r̄_1=r ≤ r̄_3. Hence r ≤ 2^{2−h/2} n, i.e., h ≤ 4 + 2 log_2(n/r).

Proposition (ending-sequences cost O(n+nH)).
Sum over all ending-sequences of merge-cost ≤ C ∑_runs r (1 + log_2(n/r)) = O(n + nH) for a constant C.
Proof. Each element pays O(1) tokens upon push and O(1) tokens per height level it passes through. By Lemma 4, an element in a run of length r belongs to a stack of height ≤ O(1+log(n/r)) after its starting-sequence; its height decreases at most that many times during later ending-sequences. By Lemma 3, the total tokens minted per element suffice for all spends, so total spend (which equals ending-sequence merge-cost) is O(∑ r (1+log(n/r)))=O(n+nH).

Theorem (coarse entropy bound for TimSort).
On input with greedy run lengths ℓ_1,…,ℓ_r and H=∑ (ℓ_i/n) log_2(n/ℓ_i), patched Python TimSort performs merges of total cost O(n + nH), and hence at most O(n + nH) + O(n) comparisons overall.
Proof. Run detection is O(n). Starting-sequences cost O(n) (Lemma 2). Ending-sequences cost O(n+nH) (Proposition). The final collapse can be enforced during the main loop by appending a sentinel run of length > n (or separately charged O(n)). Since each merge uses ≤ size−1 comparisons and #merges ≤ r−1 ≤ n, add O(n) to convert merge-cost to comparisons.

# Examples
- Two runs: lengths x and n−x. H ≤ 1; TimSort does one merge; comparisons ≤ n ≤ n·H + O(n) holds.
- r equal runs: H = log_2 r; Lemmas give O(n log r) cost; agrees with known O(n+n log r).

# Obstacles
- The s-token nonnegativity (Lemma 3) uses the patched rule #5 to force a continuation of the ending-sequence; without it (older Java variant), the next action might break the ending-sequence, and the simple s-token argument can fail.
- The leading-constant-1 target is unachievable for TimSort; Buss–Knop’s bad-case family yields ≥(3/2)·n·log n comparisons and hence ≥(3/2)·n·H.

# Next steps
- Formalize the above proofs in proofs.md (Lemma 1/Corollary 1, Lemma 2, Lemma 3, Lemma 4, coarse theorem).
- Add the refined (3/2)·n·H + O(n) upper bound via the potential Φ(r) = (3/2) r log_2 r: prove (i) merges within factor φ^2 are “balanced” (cost ≤ ΔΦ); (ii) group the remaining merges of each ending-sequence into singletons/pairs so each group’s cost ≤ ΔΦ(group) except the first (excess ≤ r), summing to O(n). Cite Buss–Knop for matching lower bound.
- Update output.md to state the corrected main theorem (sharp and coarse bounds).
