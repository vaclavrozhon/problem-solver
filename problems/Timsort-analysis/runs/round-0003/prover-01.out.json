{
  "content": "## Ideas\n- The target \u201cTimSort uses O(n H) comparisons\u201d is false in general (H can be 0 for a single run, yet TimSort needs \u0398(n) comparisons to scan). The correct entropy-adaptive statement is comparisons \u2264 C n + C\u2032 n H.\n- I give a self-contained proof for Python TimSort (with the de Gouw\u2013et al. guard r2 + r3 \u2265 r4) that comparisons \u2264 O(n + nH), by amortizing merges via a token scheme and using a Fibonacci-type stack-growth invariant.\n\n## Model and setup\n- Input: n elements decomposed greedily into r maximal monotone runs of lengths \u21131,\u2026,\u2113r (\u03a3\u2113i=n). Let H = \u03a3 (\u2113i/n) log2(n/\u2113i).\n- We analyze TimSort\u2019s core stack rules. The stack holds lengths r1,\u2026,rh (top to bottom). After pushing a run, repeatedly do the first applicable:\n  (2) if h\u22653 and r1>r3: merge (R2,R3);\n  (3) else if h\u22652 and r1\u2265r2: merge (R1,R2);\n  (4) else if h\u22653 and r1+r2\u2265r3: merge (R1,R2);\n  (5) else if h\u22654 and r2+r3\u2265r4: merge (R1,R2);\n  else stop. After all pushes, force-collapse.\n- Cost model: merging runs of sizes a,b costs a+b; comparisons \u2264 total merge cost + O(n) (run detection and control).\n\n## Lemmas and proofs\nLemma 1 (quiescent invariant). At any quiescent point (no rule applies): r1<r2, r1+r2<r3, r2+r3<r4, and for all i\u22653, ri+ri+1<ri+2.\nProof. If quiescent, the negations of (2)\u2013(5) yield the first three. A merge shifts indices down and preserves ri+ri+1<ri+2 for i\u22653 by induction. \u220e\n\nCorollary 2 (exponential growth). For 1\u2264i\u2264j\u2264h: ri \u2264 2^{(i+1\u2212j)/2} rj. In particular, for the top run r=r1, when the starting sequence ends (see below), h \u2264 4+2 log2(n/r).\nProof. From Lemma 1, ri+2 \u2265 2 ri hence ri \u2264 2^{\u2212k} ri+2k \u2264 2^{\u2212k} ri+2k+1. For the height: r1=r \u2264 r3 \u2264 2^{2\u2212h/2} n. \u220e\n\nDefinition (starting/ending sequences). After pushing a run R (length r), the maximal initial block of (2)-merges is the starting sequence; following merges up to the next push form the ending sequence.\n\nLemma 3 (starting sequences are linear). The total merge cost of all starting sequences is O(n).\nProof. A starting sequence that merges the top k preexisting runs R1,\u2026,Rk has cost C \u2264 \u03a3_{i=1}^k (k+1\u2212i) ri. Since the last (2) requires r>rk and by Corollary 2, rk \u2265 2^{(k\u22121\u2212i)/2} ri, we get C/r \u2264 2 \u03a3_{j\u22651} j 2^{\u2212j/2} =: \u03b3. Summing over all pushes (\u03a3 r = n) gives O(n). \u220e\n\nToken scheme for ending sequences. Two token types per element: c- and s-tokens.\n- Credits: upon push, each element gets 2 c + 1 s; whenever an ending-merge lowers an element\u2019s height, it gets again 2 c; for s, see below.\n- Charges: (2) merge (R2,R3): each element of R1 and R2 pays 1 c (r1+r2 \u2265 r2+r3). (3): each element of R1 pays 2 c (cost \u2264 2 r1). (4)/(5): each element of R1 pays 1 c and each element of R2 pays 1 s (cost = r1+r2).\n\nLemma 4 (no deficits). No element ever runs out of c- or s-tokens during ending sequences.\nProof. c: every height drop immediately credits 2 c, covering c-charges in the same/next step. s: only (4)/(5) charge R2; the next ending merge is forced immediately by the triggering condition, lowering the height of the new top run and re-crediting 1 s before any further s-charge. Induction on merges. \u220e\n\nLemma 5 (height bound per element). If R has length r, when its starting sequence ends the stack height h \u2264 4 + 2 log2(n/r). Hence each element of R experiences O(h) height drops and accrues O(1+log(n/r)) credits.\nProof. Corollary 2 yields the bound. Each height drop credits anew; the number of drops per element is O(h). \u220e\n\n## Main theorem and proof\nTheorem. TimSort performs at most O(n + nH) comparisons on inputs with run lengths \u21131,\u2026,\u2113r.\nProof. Starting sequences cost O(n) (Lemma 3). Ending sequences cost at most the total number of tokens spent; per element this is O(1+log(n/r)) (Lemmas 4\u20135). Summing over all runs gives O(\u03a3 r (1+log(n/r))) = O(n + nH). Adding O(n) overhead and using comparisons \u2264 merge cost + O(n) completes the proof. \u220e\n\n## Lower bound (optimal up to constants)\nProposition. Any comparison sort needs \u2265 nH \u2212 O(n) comparisons on inputs with fixed run lengths \u21131,\u2026,\u2113r (distinct keys).\nProof. The number of compatible permutations is n!/(\u21131!\u22ef\u2113r!). Taking logs and applying Stirling yields nH \u2212 O(n). \u220e\n\n## Obstacles\n- The stronger \u201cO(n H)\u201d (without the additive n) is false: a single already-sorted run has H=0 but TimSort uses \u0398(n) comparisons to detect the run and terminate. Moreover, the best-possible leading constant in front of nH for TimSort is 3/2, not 1: there are families with \u2265 (3/2 \u2212 o(1)) n log2 n comparisons (H\u2248log2 n).\n\n## Next steps\n- If desired, I can supply the refined tight bound comparisons \u2264 (3/2) nH + O(n) via a potential function \u03a6(r) = (3/2) r log2 r (grouping merges and showing balancedness), and recall the matching lower-bound family.\n- Clean integration into output: state the O(n + nH) theorem with the above lemmas and remark why O(nH) cannot hold for TimSort."
}