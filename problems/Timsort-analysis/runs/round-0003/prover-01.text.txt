## Ideas
- The target “TimSort uses O(n H) comparisons” is false in general (H can be 0 for a single run, yet TimSort needs Θ(n) comparisons to scan). The correct entropy-adaptive statement is comparisons ≤ C n + C′ n H.
- I give a self-contained proof for Python TimSort (with the de Gouw–et al. guard r2 + r3 ≥ r4) that comparisons ≤ O(n + nH), by amortizing merges via a token scheme and using a Fibonacci-type stack-growth invariant.

## Model and setup
- Input: n elements decomposed greedily into r maximal monotone runs of lengths ℓ1,…,ℓr (Σℓi=n). Let H = Σ (ℓi/n) log2(n/ℓi).
- We analyze TimSort’s core stack rules. The stack holds lengths r1,…,rh (top to bottom). After pushing a run, repeatedly do the first applicable:
  (2) if h≥3 and r1>r3: merge (R2,R3);
  (3) else if h≥2 and r1≥r2: merge (R1,R2);
  (4) else if h≥3 and r1+r2≥r3: merge (R1,R2);
  (5) else if h≥4 and r2+r3≥r4: merge (R1,R2);
  else stop. After all pushes, force-collapse.
- Cost model: merging runs of sizes a,b costs a+b; comparisons ≤ total merge cost + O(n) (run detection and control).

## Lemmas and proofs
Lemma 1 (quiescent invariant). At any quiescent point (no rule applies): r1<r2, r1+r2<r3, r2+r3<r4, and for all i≥3, ri+ri+1<ri+2.
Proof. If quiescent, the negations of (2)–(5) yield the first three. A merge shifts indices down and preserves ri+ri+1<ri+2 for i≥3 by induction. ∎

Corollary 2 (exponential growth). For 1≤i≤j≤h: ri ≤ 2^{(i+1−j)/2} rj. In particular, for the top run r=r1, when the starting sequence ends (see below), h ≤ 4+2 log2(n/r).
Proof. From Lemma 1, ri+2 ≥ 2 ri hence ri ≤ 2^{−k} ri+2k ≤ 2^{−k} ri+2k+1. For the height: r1=r ≤ r3 ≤ 2^{2−h/2} n. ∎

Definition (starting/ending sequences). After pushing a run R (length r), the maximal initial block of (2)-merges is the starting sequence; following merges up to the next push form the ending sequence.

Lemma 3 (starting sequences are linear). The total merge cost of all starting sequences is O(n).
Proof. A starting sequence that merges the top k preexisting runs R1,…,Rk has cost C ≤ Σ_{i=1}^k (k+1−i) ri. Since the last (2) requires r>rk and by Corollary 2, rk ≥ 2^{(k−1−i)/2} ri, we get C/r ≤ 2 Σ_{j≥1} j 2^{−j/2} =: γ. Summing over all pushes (Σ r = n) gives O(n). ∎

Token scheme for ending sequences. Two token types per element: c- and s-tokens.
- Credits: upon push, each element gets 2 c + 1 s; whenever an ending-merge lowers an element’s height, it gets again 2 c; for s, see below.
- Charges: (2) merge (R2,R3): each element of R1 and R2 pays 1 c (r1+r2 ≥ r2+r3). (3): each element of R1 pays 2 c (cost ≤ 2 r1). (4)/(5): each element of R1 pays 1 c and each element of R2 pays 1 s (cost = r1+r2).

Lemma 4 (no deficits). No element ever runs out of c- or s-tokens during ending sequences.
Proof. c: every height drop immediately credits 2 c, covering c-charges in the same/next step. s: only (4)/(5) charge R2; the next ending merge is forced immediately by the triggering condition, lowering the height of the new top run and re-crediting 1 s before any further s-charge. Induction on merges. ∎

Lemma 5 (height bound per element). If R has length r, when its starting sequence ends the stack height h ≤ 4 + 2 log2(n/r). Hence each element of R experiences O(h) height drops and accrues O(1+log(n/r)) credits.
Proof. Corollary 2 yields the bound. Each height drop credits anew; the number of drops per element is O(h). ∎

## Main theorem and proof
Theorem. TimSort performs at most O(n + nH) comparisons on inputs with run lengths ℓ1,…,ℓr.
Proof. Starting sequences cost O(n) (Lemma 3). Ending sequences cost at most the total number of tokens spent; per element this is O(1+log(n/r)) (Lemmas 4–5). Summing over all runs gives O(Σ r (1+log(n/r))) = O(n + nH). Adding O(n) overhead and using comparisons ≤ merge cost + O(n) completes the proof. ∎

## Lower bound (optimal up to constants)
Proposition. Any comparison sort needs ≥ nH − O(n) comparisons on inputs with fixed run lengths ℓ1,…,ℓr (distinct keys).
Proof. The number of compatible permutations is n!/(ℓ1!⋯ℓr!). Taking logs and applying Stirling yields nH − O(n). ∎

## Obstacles
- The stronger “O(n H)” (without the additive n) is false: a single already-sorted run has H=0 but TimSort uses Θ(n) comparisons to detect the run and terminate. Moreover, the best-possible leading constant in front of nH for TimSort is 3/2, not 1: there are families with ≥ (3/2 − o(1)) n log2 n comparisons (H≈log2 n).

## Next steps
- If desired, I can supply the refined tight bound comparisons ≤ (3/2) nH + O(n) via a potential function Φ(r) = (3/2) r log2 r (grouping merges and showing balancedness), and recall the matching lower-bound family.
- Clean integration into output: state the O(n + nH) theorem with the above lemmas and remark why O(nH) cannot hold for TimSort.