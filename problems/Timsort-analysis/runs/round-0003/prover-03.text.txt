Ideas

- Target (coarse entropy adaptivity). For Python’s patched TimSort (with the extra rule “#5: r_2 + r_3 ≥ r_4”), the number of comparisons on inputs with greedy run-lengths ℓ_1,…,ℓ_r and entropy H = ∑(ℓ_i/n) log_2(n/ℓ_i) is O(n + nH). Comparisons ≤ merge cost + O(n) (run detection + constant overhead), so it suffices to bound total merge cost by O(n + nH).
- Decomposition. Split each iteration into a starting sequence (#1 then maximal #2’s) and an ending sequence (begins with #3/#4/#5 and contains no #1). Two central lemmas (proved below) complete the coarse bound: (i) Starting sequences contribute O(n). (ii) Ending sequences’ cost ≤ sum over elements of O(height-changes) = O(∑ ℓ_i (1 + log(n/ℓ_i))) = O(n + nH), by a token scheme and a stack-height bound.

Proof nuggets (to add to proofs.md)

- Lemma 1 (Fibonacci growth invariant). After collapse, for all legal i, r_{i+2} > r_{i+1} + r_i and r_{i+1} > r_i. In particular, when about to push, r_i ≤ 2^{(i+1−j)/2} r_j for i ≤ j. Proof: case analysis over #1–#5; if pushing (#1), none of #2–#5 holds; merges shift indices and preserve the strict inequalities.
- Lemma 2 (Starting sequences cost O(n) with explicit constant). If pushing a run R of length r triggers k−1 merges of type #2 (merging runs R_2,…,R_k), then total cost C ≤ ∑_{i=1}^k (k+1−i) r_i. From the last #2, r > r_k, and the growth corollary gives r ≥ r_k ≥ 2^{(k−1−i)/2} r_i, hence
  C/r ≤ 2 ∑_{j=1}^k j 2^{−j/2} < γ with γ = 2·q/(1−q)^2 and q = 2^{−1/2} ≈ 0.7071; numerically γ ≈ 16.48. Summing over all pushes (∑ r = n) yields total starting cost ≤ γ n = O(n).
- Lemma 3 (Height bound after a starting sequence). Let a run of length r be pushed; when its starting sequence finishes, the stack height h satisfies h ≤ 4 + 2 log_2(n/r). Reason: runs r_3,…,r_h below are untouched, so r_3 ≤ 2^{2−h/2} r_h ≤ 2^{2−h/2} n, and no further #2 holds, so r ≤ r_3.
- Lemma 4 (Ending sequences: token accounting). Credit rule: when a run is pushed, or when an element’s height decreases due to a merge in an ending sequence, credit that element 2 c-tokens and 1 s-token. Spending: #2 spends 1 c from each element of R_1,R_2; #3 spends 2 c from each element of R_1; #4/#5 spend 1 c from each element of R_1 and 1 s from each element of R_2. Nonnegativity: After any #2/#3/#4/#5, every charged element’s height decreases, so the post-merge credit (2 c + 1 s) covers the c-spend. For s-tokens: merges #4/#5 must be followed by another merge (see Lemma 5), which decreases the new top height and re-credits an s-token before any further s-spend. Hence s-balances never go negative.
- Lemma 5 (Follow-up merges after #4/#5). If #4 merges R_1 and R_2, the new top lengths are r_1′ = r_1 + r_2 and r_2′ = r_3, so #3 (r_1′ ≥ r_2′) holds immediately. If #5 merges R_1 and R_2, then r_1′ + r_2′ = (r_1 + r_2) + r_3 ≥ r_1 + (r_2 + r_3) ≥ r_1 + r_4 > r_4 = r_3′, so #4 holds. Thus #4/#5 always force at least one more merge next.
- Summation. Each element in a run of length r experiences at most O(h) height decreases after the starting sequence, with h ≤ 4 + 2 log_2(n/r) (Lemma 3). Thus per element tokens minted = O(1 + log(n/r)), and ending-sequence cost = O(∑ r (1 + log(n/r))) = O(n + nH). Adding starting sequences (O(n)) and run detection (O(n)) yields total merge cost O(n + nH). Because merging a,b needs ≤ a+b−1 comparisons, total comparisons are also O(n + nH).

Examples (sanity checks)

- After #4, #3 next: take (from top) r_1=5, r_2=6, r_3=10. Since 5+6 ≥ 10, #4 merges 5 and 6 → new top 11, next 10; #3 (11 ≥ 10) merges again. This illustrates Lemma 5 and s-token re-crediting.
- Extreme distribution. One run of size n and many of size 1: H = O(1). The height bound gives h = O(1) for the big run’s elements; total cost is linear as predicted.

Obstacles

- The original target “≤ nH + O(n) comparisons” with leading constant 1 is false for TimSort (Buss–Knop show ≥ (3/2) n log n merge cost on some inputs). We keep the coarse O(n + nH) and, if needed, the sharp (3/2)·nH + O(n).
- Our s-token argument relies only on the fact that neither #4 nor #5 can end an ending sequence (Lemma 5), which holds in Python’s patched TimSort. We restrict to that variant; galloping does not increase comparisons.

Next steps

- Move Lemmas 1–5 and the O(n + nH) proof into proofs.md with explicit constants γ and the conversion to comparisons. Note reliance on the Python-patched merge_collapse (includes #5).
- Optionally add the refined (3/2)·nH + O(n) bound via potential Φ(r) = (3/2) r log_2 r: (i) balanced-merge lemma (sizes within φ^2), (ii) forbidden patterns in ending sequences, (iii) grouping unbalanced merges so each group’s cost ≤ ΔΦ plus at most r for the first group; total slack O(n).