{
  "progress_md": "# Ideas\n\n- Define, for any subset of remaining candidates S \u2286 [K] and any a \u2208 S, the top-within-S tally:\n  t_a(S) := Pr_{b\u223cP}[a is the top-ranked among S on ballot b]. These are linear functionals of the population distribution P over S_K; for each fixed (a,S), t_a(S) is the expectation of an indicator.\n- Adding up to \u03b5 mass of additional ballots corresponds to adding a nonnegative measure y on S_K with total mass \u2264 \u03b5. Under addition, the (unnormalized) round-t tallies update by s'_a(S) = t_a(S) + \u2211_r y(r) 1[top_S(r)=a]. The IRV eliminations depend only on comparisons among these s'_a(S) for the relevant S\u2019s.\n- Two complementary approaches to upper bounds:\n  1) Conservative \u201ccertifier\u201d based only on adding c-first ballots. It yields a simple sufficient condition for c to be made winner by \u03b5 additions, reducing to checking all S containing c.\n  2) Exact optimization (for a fixed elimination order) via a linear program whose coefficients are the t_a(S). This characterizes the minimal \u03b5 needed for c to win, and suggests a sample-based estimator with uniform concentration guarantees over the family of functionals t_a(S).\n\n# Clean lemmas and why useful\n\nLemma 1 (LP for a fixed elimination order). Fix an elimination order \u03c0 of [K] with \u03c0(K)=c and define S_1=[K], S_{j+1}=S_j\\{\u03c0(j)}. Let variables y(r)\u22650 for r\u2208S_K and objective \u03b5* = \u2211_r y(r). Consider constraints, for each round j and each a\u2208S_j\\{\u03c0(j)}:\n  t_{\u03c0(j)}(S_j) + \u2211_r y(r) 1[top_{S_j}(r)=\u03c0(j)] \u2264 t_a(S_j) + \u2211_r y(r) 1[top_{S_j}(r)=a].\nThen the minimal \u03b5 needed to realize elimination order \u03c0 with winner c equals the optimum \u03b5* of this LP.\n- Why useful: Reduces the combinatorial IRV dynamics to linear inequalities in additive perturbations; enables sensitivity analysis and sample-based estimation through concentration for the t_a(S).\n- Proof sketch: The inequalities enforce that, at each round j, \u03c0(j) is (weakly) the minimum tally in S_j under the augmented profile; summing new ballots y(r) respects additivity across rounds because the top-within-S indicators are deterministic functions of r. Feasibility is necessary and sufficient to realize \u03c0 under the deterministic tie-breaking rule. Minimizing \u2211 y(r) is exactly minimizing added mass.\n\nLemma 2 (Uniform convergence for all t_a(S)). The family F = {f_{a,S}(r) := 1[top_S(r)=a] : a\u2208S\u2286[K]} has cardinality at most K\u00b72^{K-1}. Given m i.i.d. ballots, with probability at least 1-\u03b4,\n  sup_{a,S} |\\hat t_a(S) - t_a(S)| \u2264 \u03c4\nwhenever m \u2265 C (log(K\u00b72^{K-1}) + log(2/\u03b4)) / \u03c4^2 for a universal constant C.\n- Why useful: Ensures we can estimate all top-within-S tallies uniformly to accuracy \u03c4 with O((K + log(1/\u03b4))/\u03c4^2) dependence up to the 2^K factor from the number of subsets.\n- Proof: Hoeffding + union bound over |F| \u2264 K\u00b72^{K-1} indicators.\n\nLemma 3 (Conservative certificate via c-first boosters). Define for c\u2208[K]\n  M_c := max_{S\u2286[K]: c\u2208S} [ min_{a\u2208S} t_a(S) \u2212 t_c(S) ]_+.\nIf \u03b5 \u2265 M_c, then adding \u03b5 mass of ballots that rank c first (arbitrary completion below) guarantees that c is an IRV winner under the augmented profile, irrespective of tie-breaking among non-c candidates.\n- Why useful: Provides a checkable sufficient condition that depends only on the collection {t_a(S)} and avoids searching elimination orders.\n- Proof: Adding c-first ballots increases c\u2019s top-within-S tally by \u03b5 for every S containing c, and does not decrease any other candidate\u2019s tallies. If \u03b5 \u2265 M_c then for every S\u2287{c}, we have t'_c(S) \u2265 min_{a\u2208S} t'_a(S), so c is never uniquely the lowest in any subset encountered along any elimination path; hence c cannot be eliminated, and thus is the final winner.\n\nLemma 4 (Estimation error for M_c). If sup_{a,S} |\\hat t_a(S)\u2212t_a(S)| \u2264 \u03c4 then |\\hat M_c \u2212 M_c| \u2264 2\u03c4.\n- Why useful: Gives a simple plug-in estimator \\hat M_c with tight additive error control, leading to a clean sample complexity for a correct certificate.\n- Proof: For any fixed S, the quantity min_{a\u2208S} t_a(S) \u2212 t_c(S) changes by at most 2\u03c4 under \u03c4-perturbations; taking max over S preserves this bound.\n\n# Algorithmic upper bound (certifier)\n\n- Input: \u03b5, \u03b4, access to m random ballots.\n- Procedure:\n  1) Estimate all \\hat t_a(S) from the sample.\n  2) Compute \\hat M_c for each c.\n  3) Output any c with \\hat M_c \u2264 \u03b5 \u2212 2\u03c4, where \u03c4 is chosen for the concentration bound.\n- Guarantee: Choose m \u2265 C (log(K\u00b72^{K-1}) + log(2/\u03b4)) / \u03c4^2 and set \u03c4 = \u03b5/4. With probability \u2265 1\u2212\u03b4, every output c is an \u03b5-winner (by Lemma 3 and Lemma 4). Hence\n  m = O((K\u00b72^{K-1} + log(1/\u03b4)) / \u03b5^2)\n  samples suffice for a sound certifier.\n- Note: This is a sufficient-condition algorithm; it may abstain if no c satisfies the threshold, even if an \u03b5-winner exists. It never produces a false positive with the stated probability.\n\n# Exact characterization via LP and a refined plan\n\n- For each candidate c, define\n  g_c(P) := min_{\u03c0: \u03c0(K)=c} OptVal_LP(\u03c0; {t_a(S)}),\n  the true minimal extra mass needed to make c a winner.\n- Sample-based estimator: Replace t_a(S) by \\hat t_a(S) in the LP constraints and compute \\hat g_c. Output a candidate with \\hat g_c \u2264 \u03b5 \u2212 margin.\n- Stability note: In our LP the only estimated quantities are the constants t_a(S); the coefficients of y(r) are exact indicator patterns. Thus the LP optimum is Lipschitz in the vector d of baseline deficits d_{j,a} := t_a(S_j)\u2212t_{\u03c0(j)}(S_j). By standard LP sensitivity (duality), the change in optimum is bounded by the \u2113_1-norm of an optimal dual solution times the \u2113_\u221e perturbation size. We conjecture a bound of the form |\\hat g_c \u2212 g_c| \u2264 C_K \u03c4 with C_K polynomial in K (likely O(K)), whenever sup_{a,S} |\\hat t_a(S)\u2212t_a(S)| \u2264 \u03c4. This would yield a sample complexity m = O((K\u00b72^{K-1}+log(1/\u03b4)) / (\u03b5/C_K)^2).\n- Gap: We have not yet derived an explicit, audited constant C_K from the dual; this is a priority for the next round.\n\n# Special cases and examples\n\n- K=2 (majority): IRV reduces to plurality with two candidates. For c, g_c(P) = [1/2 \u2212 p_c]_+ where p_c is the share of ballots ranking c over the other. Sample complexity \u0398((log(1/\u03b4))/\u03b5^2) is both necessary and sufficient.\n- K=3 toy profile: Suppose t_A({A,B,C})=0.34, t_B=0.33, t_C=0.33. Also t_A({A,B})=0.49, t_B=0.51; t_A({A,C})=0.52, t_C=0.48; t_B({B,C})=0.55, t_C=0.45. Compute M_A:\n  \u2022 S={A,B,C}: min=0.33, deficit 0.33\u22120.34 = 0 (no deficit).\n  \u2022 S={A,B}: min=0.49, deficit 0.49\u22120.49=0.\n  \u2022 S={A,C}: min=0.48, deficit 0.48\u22120.52=0.\n  Thus M_A=0; certifier declares A a 0-winner (indeed A already wins via IRV: eliminate C first, then A beats B pairwise). This illustrates the certificate can be tight.\n\n# Lower bounds (initial)\n\n- Baseline: Any algorithm must use m = \u03a9((log(1/\u03b4))/\u03b5^2) samples, even for K=2, by standard coin-flip mean estimation.\n- Dependence on K (heuristic): We conjecture an \u03a9(K/\u03b5^2) lower bound in the worst case by constructing a packing of profiles where, for each of \u0398(K) subsets S_j containing a fixed c, the gap min_{a\u2208S_j} t_a(S_j) \u2212 t_c(S_j) is either +\u0398(\u03b5) or \u2212\u0398(\u03b5), and these choices are close to statistically independent under the sampling distribution. Distinguishing whether M_c \u2264 0 versus M_c \u2265 \u0398(\u03b5) would then require estimating \u0398(K) such gaps to accuracy \u0398(\u03b5), costing \u03a9(K/\u03b5^2) samples by a direct-sum argument. Gap: A full construction over permutations ensuring consistency of the family {t_a(S)} remains to be written.\n\n# Obstacles and gaps\n\n- Exponential factor 2^{K}: The certifier\u2019s union bound over all S is crude. It is open whether one can control M_c using only O(poly(K)) statistics (e.g., along a carefully chosen chain of subsets) while preserving correctness.\n- LP sensitivity constant C_K: We need an explicit bound (preferably O(K)) derived from the dual to turn \\hat g_c into a sound estimator with polynomial-in-K sample complexity.\n- Computational complexity: Enumerating all \u03c0 is factorial; our focus here is sample complexity, but a separation oracle for the dual (or column generation over S) might avoid enumerating all S/\u03c0 and also reduce the effective number of estimated functionals needed for certification.\n\n# Next steps\n\n- Prove a formal sensitivity bound for the LP optimum in Lemma 1 with respect to perturbations of {t_a(S)}, aiming for |\\hat g_c \u2212 g_c| \u2264 O(K)\u00b7\u03c4.\n- Investigate whether M_c can be exactly expressed as the optimum of a simpler min-max problem over subsets S (potentially reducing the number of required S), or whether there is an equivalent chain condition that only needs O(K) subsets per c.\n- Develop and verify a lower bound construction in the K\u226b1 regime to establish \u03a9(poly(K)/\u03b5^2) sample complexity, even for certifiers.\n- Explore a two-tier algorithm: run the certifier; if it abstains, fall back to solving the LP for a small set of promising elimination orders inferred from the sample, and quantify the additional estimation needed.\n\n# Gaps relative to output.md\n\n- No output.md exists yet; the claims above (Lemma 1\u20134 and the certifier upper bound) are new and should be checked and, if correct, curated into output.md. We flagged the LP sensitivity as a gap to be filled before curating an LP-based upper bound with polynomial-in-K sample complexity."
}