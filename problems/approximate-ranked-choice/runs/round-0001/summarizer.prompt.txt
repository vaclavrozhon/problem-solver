=== SYSTEM ===
You are a research **summarizer**. Summarize this *last round only* for a human log.

Include:
- 3–7 bullet **Highlights** (facts learned, reductions, counterexamples, partial bounds).
- 1–3 **Open questions / TODOs** for the next round.
- 1–3 **Citations to files** you relied on (e.g. round files or papers by name).

**Return strictly JSON**:
{
  "summary_md": "Readable summary of the round (≤200 words)",
  "highlights": [],
  "next_questions": []
}

=== USER ===
=== prover-01 ===

# Ideas

- Define, for any subset of remaining candidates S ⊆ [K] and any a ∈ S, the top-within-S tally:
  t_a(S) := Pr_{b∼P}[a is the top-ranked among S on ballot b]. These are linear functionals of the population distribution P over S_K; for each fixed (a,S), t_a(S) is the expectation of an indicator.
- Adding up to ε mass of additional ballots corresponds to adding a nonnegative measure y on S_K with total mass ≤ ε. Under addition, the (unnormalized) round-t tallies update by s'_a(S) = t_a(S) + ∑_r y(r) 1[top_S(r)=a]. The IRV eliminations depend only on comparisons among these s'_a(S) for the relevant S’s.
- Two complementary approaches to upper bounds:
  1) Conservative “certifier” based only on adding c-first ballots. It yields a simple sufficient condition for c to be made winner by ε additions, reducing to checking all S containing c.
  2) Exact optimization (for a fixed elimination order) via a linear program whose coefficients are the t_a(S). This characterizes the minimal ε needed for c to win, and suggests a sample-based estimator with uniform concentration guarantees over the family of functionals t_a(S).

# Clean lemmas and why useful

Lemma 1 (LP for a fixed elimination order). Fix an elimination order π of [K] with π(K)=c and define S_1=[K], S_{j+1}=S_j\{π(j)}. Let variables y(r)≥0 for r∈S_K and objective ε* = ∑_r y(r). Consider constraints, for each round j and each a∈S_j\{π(j)}:
  t_{π(j)}(S_j) + ∑_r y(r) 1[top_{S_j}(r)=π(j)] ≤ t_a(S_j) + ∑_r y(r) 1[top_{S_j}(r)=a].
Then the minimal ε needed to realize elimination order π with winner c equals the optimum ε* of this LP.
- Why useful: Reduces the combinatorial IRV dynamics to linear inequalities in additive perturbations; enables sensitivity analysis and sample-based estimation through concentration for the t_a(S).
- Proof sketch: The inequalities enforce that, at each round j, π(j) is (weakly) the minimum tally in S_j under the augmented profile; summing new ballots y(r) respects additivity across rounds because the top-within-S indicators are deterministic functions of r. Feasibility is necessary and sufficient to realize π under the deterministic tie-breaking rule. Minimizing ∑ y(r) is exactly minimizing added mass.

Lemma 2 (Uniform convergence for all t_a(S)). The family F = {f_{a,S}(r) := 1[top_S(r)=a] : a∈S⊆[K]} has cardinality at most K·2^{K-1}. Given m i.i.d. ballots, with probability at least 1-δ,
  sup_{a,S} |\hat t_a(S) - t_a(S)| ≤ τ
whenever m ≥ C (log(K·2^{K-1}) + log(2/δ)) / τ^2 for a universal constant C.
- Why useful: Ensures we can estimate all top-within-S tallies uniformly to accuracy τ with O((K + log(1/δ))/τ^2) dependence up to the 2^K factor from the number of subsets.
- Proof: Hoeffding + union bound over |F| ≤ K·2^{K-1} indicators.

Lemma 3 (Conservative certificate via c-first boosters). Define for c∈[K]
  M_c := max_{S⊆[K]: c∈S} [ min_{a∈S} t_a(S) − t_c(S) ]_+.
If ε ≥ M_c, then adding ε mass of ballots that rank c first (arbitrary completion below) guarantees that c is an IRV winner under the augmented profile, irrespective of tie-breaking among non-c candidates.
- Why useful: Provides a checkable sufficient condition that depends only on the collection {t_a(S)} and avoids searching elimination orders.
- Proof: Adding c-first ballots increases c’s top-within-S tally by ε for every S containing c, and does not decrease any other candidate’s tallies. If ε ≥ M_c then for every S⊇{c}, we have t'_c(S) ≥ min_{a∈S} t'_a(S), so c is never uniquely the lowest in any subset encountered along any elimination path; hence c cannot be eliminated, and thus is the final winner.

Lemma 4 (Estimation error for M_c). If sup_{a,S} |\hat t_a(S)−t_a(S)| ≤ τ then |\hat M_c − M_c| ≤ 2τ.
- Why useful: Gives a simple plug-in estimator \hat M_c with tight additive error control, leading to a clean sample complexity for a correct certificate.
- Proof: For any fixed S, the quantity min_{a∈S} t_a(S) − t_c(S) changes by at most 2τ under τ-perturbations; taking max over S preserves this bound.

# Algorithmic upper bound (certifier)

- Input: ε, δ, access to m random ballots.
- Procedure:
  1) Estimate all \hat t_a(S) from the sample.
  2) Compute \hat M_c for each c.
  3) Output any c with \hat M_c ≤ ε − 2τ, where τ is chosen for the concentration bound.
- Guarantee: Choose m ≥ C (log(K·2^{K-1}) + log(2/δ)) / τ^2 and set τ = ε/4. With probability ≥ 1−δ, every output c is an ε-winner (by Lemma 3 and Lemma 4). Hence
  m = O((K·2^{K-1} + log(1/δ)) / ε^2)
  samples suffice for a sound certifier.
- Note: This is a sufficient-condition algorithm; it may abstain if no c satisfies the threshold, even if an ε-winner exists. It never produces a false positive with the stated probability.

# Exact characterization via LP and a refined plan

- For each candidate c, define
  g_c(P) := min_{π: π(K)=c} OptVal_LP(π; {t_a(S)}),
  the true minimal extra mass needed to make c a winner.
- Sample-based estimator: Replace t_a(S) by \hat t_a(S) in the LP constraints and compute \hat g_c. Output a candidate with \hat g_c ≤ ε − margin.
- Stability note: In our LP the only estimated quantities are the constants t_a(S); the coefficients of y(r) are exact indicator patterns. Thus the LP optimum is Lipschitz in the vector d of baseline deficits d_{j,a} := t_a(S_j)−t_{π(j)}(S_j). By standard LP sensitivity (duality), the change in optimum is bounded by the ℓ_1-norm of an optimal dual solution times the ℓ_∞ perturbation size. We conjecture a bound of the form |\hat g_c − g_c| ≤ C_K τ with C_K polynomial in K (likely O(K)), whenever sup_{a,S} |\hat t_a(S)−t_a(S)| ≤ τ. This would yield a sample complexity m = O((K·2^{K-1}+log(1/δ)) / (ε/C_K)^2).
- Gap: We have not yet derived an explicit, audited constant C_K from the dual; this is a priority for the next round.

# Special cases and examples

- K=2 (majority): IRV reduces to plurality with two candidates. For c, g_c(P) = [1/2 − p_c]_+ where p_c is the share of ballots ranking c over the other. Sample complexity Θ((log(1/δ))/ε^2) is both necessary and sufficient.
- K=3 toy profile: Suppose t_A({A,B,C})=0.34, t_B=0.33, t_C=0.33. Also t_A({A,B})=0.49, t_B=0.51; t_A({A,C})=0.52, t_C=0.48; t_B({B,C})=0.55, t_C=0.45. Compute M_A:
  • S={A,B,C}: min=0.33, deficit 0.33−0.34 = 0 (no deficit).
  • S={A,B}: min=0.49, deficit 0.49−0.49=0.
  • S={A,C}: min=0.48, deficit 0.48−0.52=0.
  Thus M_A=0; certifier declares A a 0-winner (indeed A already wins via IRV: eliminate C first, then A beats B pairwise). This illustrates the certificate can be tight.

# Lower bounds (initial)

- Baseline: Any algorithm must use m = Ω((log(1/δ))/ε^2) samples, even for K=2, by standard coin-flip mean estimation.
- Dependence on K (heuristic): We conjecture an Ω(K/ε^2) lower bound in the worst case by constructing a packing of profiles where, for each of Θ(K) subsets S_j containing a fixed c, the gap min_{a∈S_j} t_a(S_j) − t_c(S_j) is either +Θ(ε) or −Θ(ε), and these choices are close to statistically independent under the sampling distribution. Distinguishing whether M_c ≤ 0 versus M_c ≥ Θ(ε) would then require estimating Θ(K) such gaps to accuracy Θ(ε), costing Ω(K/ε^2) samples by a direct-sum argument. Gap: A full construction over permutations ensuring consistency of the family {t_a(S)} remains to be written.

# Obstacles and gaps

- Exponential factor 2^{K}: The certifier’s union bound over all S is crude. It is open whether one can control M_c using only O(poly(K)) statistics (e.g., along a carefully chosen chain of subsets) while preserving correctness.
- LP sensitivity constant C_K: We need an explicit bound (preferably O(K)) derived from the dual to turn \hat g_c into a sound estimator with polynomial-in-K sample complexity.
- Computational complexity: Enumerating all π is factorial; our focus here is sample complexity, but a separation oracle for the dual (or column generation over S) might avoid enumerating all S/π and also reduce the effective number of estimated functionals needed for certification.

# Next steps

- Prove a formal sensitivity bound for the LP optimum in Lemma 1 with respect to perturbations of {t_a(S)}, aiming for |\hat g_c − g_c| ≤ O(K)·τ.
- Investigate whether M_c can be exactly expressed as the optimum of a simpler min-max problem over subsets S (potentially reducing the number of required S), or whether there is an equivalent chain condition that only needs O(K) subsets per c.
- Develop and verify a lower bound construction in the K≫1 regime to establish Ω(poly(K)/ε^2) sample complexity, even for certifiers.
- Explore a two-tier algorithm: run the certifier; if it abstains, fall back to solving the LP for a small set of promising elimination orders inferred from the sample, and quantify the additional estimation needed.

# Gaps relative to output.md

- No output.md exists yet; the claims above (Lemma 1–4 and the certifier upper bound) are new and should be checked and, if correct, curated into output.md. We flagged the LP sensitivity as a gap to be filled before curating an LP-based upper bound with polynomial-in-K sample complexity.


=== prover-02 ===

Ideas
- Define, for a distribution P over full rankings and a candidate c, the tallies after eliminating a set S ⊆ C \ {c} as T_x(S) = P[the top-ranked among C \ S is x]. These are linear functionals of P.
- If we add an α-fraction of ballots all ranking c first, then T_c(S) increases by α for all S, while T_j(S) for j ≠ c are unchanged. Hence the minimal α that guarantees c is never last at any elimination stage is
  f_c(P) := max_{S ⊆ C\{c}} ( min_{j ∉ S ∪ {c}} T_j(S) − T_c(S) )_+.
  Why useful: If f_c(P) ≤ ε then c is an ε-winner (sufficient certificate); conversely, any addition strategy cannot do better for the “never-last” condition by allocating mass away from c-first ballots, since that weakly increases min_{j≠c} T_j(S).
- Necessary condition via pairwise margins: For any j ≠ c, considering S = C \ {c, j} (so R = {c, j}) gives T_j(S) − T_c(S) = P[j ≻ c] − P[c ≻ j]. Therefore f_c(P) ≥ max_j (P[j ≻ c] − P[c ≻ j])_+.

Special case K = 3 (exact formula)
- Let candidates be {a, b, c}. Then the only relevant S for c are ∅, {a}, {b}. Thus
  f_c(P) = max{ (min{T_a(∅), T_b(∅)} − T_c(∅))_+, (P[a ≻ c] − P[c ≻ a])_+, (P[b ≻ c] − P[c ≻ b])_+ }.
  Here T_x(∅) are first-place shares. Proof sketch: T_x({y}) with x ∈ {b, c} equals head-to-head shares between x and the remaining opponent, because R = {x, c} or {x, b}; for S = ∅ we compare first-round tallies. There are no other S.
- Usefulness: For K = 3, identifying an ε-winner reduces to estimating three quantities (two pairwise margins w.r.t. c and the first-place deficit against the smaller of {a, b}).

Sample-complexity implications
- Upper bound for K = 3: With m = O((log(1/δ))/ε^2) samples, we can estimate first-place shares and pairwise margins within ±ε/4 (Hoeffding + union bound over a constant number of events). If min_c f̂_c ≤ ε/2, then with probability ≥ 1 − δ, the true f_c ≤ ε and the returned c is an ε-winner.
- General K (existence, exponential in K): Estimating all T_x(S) uniformly within ±τ over all pairs (S, x ∉ S) requires m = O(((K 2^{K}) + log(1/δ))/τ^2) samples by a union bound. Then computing f̂_c exactly from these estimates yields a correct certificate whenever min_c f̂_c ≤ ε − 2τ.
- General lower bound: Even with K = 2, the problem subsumes estimating a Bernoulli mean within ε to decide if a candidate is an ε-winner, implying m = Ω((1/ε^2) log(1/δ)). Therefore the dependence on ε and δ is necessary.
- K-dependence lower bound (sketch): Distinguishing among ≈ K hypotheses where exactly one candidate is an ε-winner (constructed by small perturbations of P concentrating probability mass among disjoint top patterns) suggests m = Ω((log K)/ε^2) via Fano’s inequality. Details to be worked out.

Examples
- K = 3 toy distribution: Suppose first-place shares are (a, b, c) = (0.36, 0.34, 0.30), and pairwise margins are P[a ≻ c] − P[c ≻ a] = 0.07, P[b ≻ c] − P[c ≻ b] = 0.01. Then f_c(P) = max{0.04, 0.07, 0.01} = 0.07; c is an ε-winner iff ε ≥ 0.07.
- K = 4 phenomenon: One can construct P where f_c(P) is driven by a 3-way residual set R of size 3 (not captured by first-place or pairwise deficits). E.g., c has small first-place share and loses many “top among {c, j, k}” contests due to a strong third candidate siphoning top positions when both j and k remain. This indicates that for K ≥ 4, relying only on pairwise margins and first-round shares is insufficient for certification.

Obstacles
- Exact computation/certification of f_c(P) for general K requires knowing T_x(S) for exponentially many S. This leads to exponential dependence on K in naïve sampling algorithms.
- Deriving tight necessary and sufficient conditions in terms of only polynomially many statistics (e.g., pairwise margins, a bounded collection of multiway-top events) remains open.

Next steps
- Prove rigorously the K = 3 formula above (write out the short formal proof) and add it to output.md.
- Seek structural reductions for K ≥ 4: is sup over S attained at sets where |C \ S| ≤ 3? If yes, certification reduces to O(K^3) multiway-top probabilities; otherwise produce a counterexample.
- Develop a polynomial-time, polynomial-sample upper bound by proposing a relax-and-certify scheme: consider only all R of size ≤ r (e.g., r = 3 or 4), compute f_c^r = max over such R of (min_{j∈R\{c}} T_j(R) − T_c(R))_+. If f_c^r ≤ ε we certify; analyze how conservative this is and whether, under mild distributional assumptions (e.g., smoothness of rank distributions), r = 3 suffices.
- Strengthen lower bounds in K via explicit Fano constructions tying ε-winner identity to a log K-bit index encoded in small perturbations of top-of-R events.

Gaps in output.md
- There is currently no output. We can add the precise K = 3 characterization and the general sufficient certificate f_c(P) ≤ ε with associated sample-complexity bounds, plus the Ω((1/ε^2) log(1/δ)) lower bound.


=== Verifier Feedback ===

Overall, both provers offered promising directions, but several rigor issues need fixing and some claims are overstated.

Key corrections and auditing:
- Prover 01’s Lemma 3 (conservative certificate) has a crucial typo: the deficit must compare against the minimum over other candidates in S. The correct deficit is min_{a∈S\{c}} t_a(S) − t_c(S), not min over all a∈S (which is always ≤ t_c(S) and hence yields 0). Also, to be independent of tie-breaking, one needs strict separation (or use a tiny slack). With strict inequality ensured by adding an arbitrarily small extra mass (still ≤ ε when we keep a margin), the certificate is sound.
- Prover 01’s LP for a fixed elimination order is a good formulation idea, but as stated it does not encode the fixed tie-breaking rule. Weak inequalities allow ties in which the fixed tie-breaker might eliminate someone other than π(j). This can often be cured by introducing an arbitrarily small slack to force strict inequalities or by encoding the lexicographic tie-break in the constraints; either way, these details must be made precise before this can go into output.md. The sensitivity bound is not yet derived, so this remains in notes.
- Prover 02’s function f_c (identical in spirit to the corrected certificate of Prover 01) is a valid sufficient condition using only c-first added ballots. However, the claim of an exact characterization for K = 3 is not correct in general: allowing non–c-first added ballots can reduce the required total added mass compared to the c-first-only strategy by altering which opponent gets eliminated first. A concrete counterexample is given in the notes.
- Sample complexity statements tied to the certificate are fine: estimating all top-within-S tallies uniformly within ±τ via Hoeffding + union bound over K·2^{K-1} events (for all S containing c and all a ∈ S) is standard. The induced Lipschitz bound for the plug-in estimator of the certificate value is ≤ 2τ.
- Lower bounds: the Ω((1/ε^2) log(1/δ)) bound via K = 2 is correct and should be included. The conjectured Ω(K/ε^2) (Prover 01) and Ω((log K)/ε^2) (Prover 02) bounds need construction/proofs and stay in notes.

What to keep vs. defer:
- Keep: The uniformly convergent estimators for t_a(S); the corrected c-first certificate (sufficient condition) and its sample-complexity guarantee; the basic lower bound from K = 2.
- Defer to notes: LP-based exact characterization and sensitivity; any claim of exactness for K ≥ 3 based solely on c-first ballots; K-dependent lower bounds.

Concrete next steps:
1) Formalize the dual of the LP for a fixed elimination order with precise handling of tie-breaking, and derive an explicit Lipschitz/sensitivity constant in terms of K (aim for O(K)).
2) For K = 3, characterize the true minimal augmentation by allowing mixtures of added ballot types. Provide a closed-form minimum over two strategies: (i) survivability + pairwise vs the eventual opponent (c-first only), and (ii) eliminating the disfavored opponent first by boosting both c and the other opponent’s first-place tallies, while preserving c’s pairwise win in the final.
3) Investigate whether the worst-case S attaining the c-first certificate necessarily has |S| ≤ r for small r; if yes, this would reduce exponential dependence.
4) Develop explicit lower-bound constructions in K (packing/Fano) to distinguish many profiles encoding different ε-winner identities via near-independent top-of-S events.
5) If time permits, implement a two-tier algorithm: run the certifier; if it abstains, solve the LP for a small set of promising orders inferred from the sample, with confidence intervals propagated via LP sensitivity.
