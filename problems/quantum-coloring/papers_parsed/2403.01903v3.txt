
--- Page 1 ---
Online Locality Meets Distributed
Quantum Computing
Amirreza Akbari · Aalto University, Finland
Xavier Coiteux-Roy · School of Computation, Information and Technology, Technical
University of Munich, Germany · Munich Center for Quantum Science and Technology, Germany
Francesco d’Amore · Aalto University, Finland · Bocconi University, Italy · BIDSA, Italy
François Le Gall · Nagoya University, Japan
Henrik Lievonen · Aalto University, Finland
Darya Melnyk · Technische Universität Berlin, Germany
Augusto Modanese · Aalto University, Finland
Shreyas Pai · Aalto University, Finland
Marc-Olivier Renou · Inria, Université Paris-Saclay, Palaiseau, France · CPHT, Ecole
Polytechnique, Institut Polytechnique de Paris, Palaiseau, France
Václav Rozhoň · ETH Zurich, Switzerland
Jukka Suomela · Aalto University, Finland
Abstract. We connect three distinct lines of research that have recently explored extensions of the
classical LOCAL model of distributed computing:
A. distributed quantum computing and non-signaling distributions [e.g. STOC 2024],
B. finitely-dependent processes [e.g. Forum Math. Pi 2016], and
C. locality in online graph algorithms and dynamic graph algorithms [e.g. ICALP 2023].
We prove new results on the capabilities and limitations of all of these models of computing, for
locally checkable labeling problems (LCLs). We show that all these settings can be sandwiched
between the classical LOCAL model and what we call the randomized online-LOCAL model. Our
work implies limitations on the quantum advantage in the distributed setting, and we also exhibit a
new barrier for proving tighter bounds. Our main technical results are these:
1. All LCL problems solvable with locality O(log∗n) in the classical deterministic LOCAL model
admit a finitely-dependent distribution with locality O(1). This answers an open question by
Holroyd [2024], and also presents a new barrier for proving bounds on distributed quantum
advantage using causality-based arguments.
2. In rooted trees, if we can solve an LCL problem with locality o(log log log n) in the randomized
online-LOCAL model (or any of the weaker models, such as quantum-LOCAL), we can solve it
with locality O(log∗n) in the classical deterministic LOCAL model. One of many implications
is that in rooted trees, O(log∗n) locality in quantum-LOCAL is not stronger than O(log∗n)
locality in classical LOCAL.
arXiv:2403.01903v3  [cs.DC]  5 Nov 2024

--- Page 2 ---
1
Introduction
In this work, we connect three distinct lines of research that have recently explored extensions of the
classical LOCAL model of distributed computing:
A. Distributed quantum computing and non-signaling distributions [3, 27, 36].
B. Finitely-dependent processes [44, 45, 47].
C. Locality in online graph algorithms and dynamic graph algorithms [2, 22].
We prove new results on the capabilities and limitations of all of these models of computing, for
locally checkable labeling problems (LCLs), with the help of a unifying model that we call randomized
online-LOCAL. Our work implies limitations on the quantum advantage in the distributed setting,
and we also exhibit a new barrier for proving tighter bounds.
1.1
Highlights
Our main technical results are these:
1. All LCL problems solvable with locality O(log∗n) in the classical deterministic LOCAL
model admit a finitely-dependent distribution, i.e., a bounded-dependence distribution with
constant locality:
classical LOCAL algorithm, locality O(log∗n)
bounded-dependence distribution, locality O(1)
non-signaling distribution, locality O(1)
This answers an open question by Holroyd [44]. This also presents a new barrier for proving
bounds on distributed quantum advantage: all current quantum-LOCAL lower bounds are, in
essence, lower bounds for non-signaling distributions, and our result shows that fundamentally
different techniques will be needed to solve some of the biggest open questions in this area
(e.g., showing that there is no constant-round quantum-LOCAL algorithm for coloring cycles).
2. In rooted trees, if we can solve an LCL problem with locality o(log log log n) in the randomized
online-LOCAL model (or any of the weaker models, such as quantum-LOCAL), we can solve it
with locality O(log∗n) in the classical deterministic LOCAL model:
quantum-LOCAL algorithm, locality o(log log log n)
bounded-dependence distribution, locality o(log log log n)
randomized online-LOCAL algorithm, locality o(log log log n)
classical LOCAL algorithm, locality O(log∗n)
One of many implications is that in rooted trees, O(log∗n) locality in quantum-LOCAL is not
stronger than O(log∗n) locality in classical LOCAL, and also finitely-dependent distributions
are not stronger than O(log∗n) locality in classical LOCAL.
We will now proceed to explain what all of these terms and models mean, and how they are connected
with each others.
1

--- Page 3 ---
1.2
Roadmap
As our main goal is to unify and relate several distinct models studied in prior work, we will need to
introduce a fair number of models of computing. We recommend that the reader keep the roadmap
that we have in Fig. 10 (final page) at hand while reading the introduction, in order to maintain a
clear view of things, as well as to consult this overview again when needed.
We start our adventure in Section 1.3 by introducing the classical models that we have at the
very top of Fig. 10 and then relate these to the current landscape of LCLs in Section 1.4. Next, we
gradually work our way through the quantum as well as bounded-dependence and non-signaling
models in Section 1.5, after which we take our first break. At this point, we are familiar with the top
half of Fig. 10, and we are ready to state our first main contributions related to symmetry breaking
with finitely-dependent processes in Section 1.6.
In Section 1.7, we then turn to models that at first may seem completely unrelated. They deal
with locality in sequential, dynamic, and online settings. As we will see in Section 1.8, however, we
can connect all of these models into a single hierarchy, with seemingly orthogonal models sandwiched
between deterministic LOCAL and randomized online-LOCAL, and we can prove various strong
results that connect the complexity landscape between these two extremes.
1.3
Classical models
Let us first recall the definitions of the classical models of distributed graph algorithms [54, 61] that
form the foundation for our work; we keep it brief here and postpone formal definitions to Section 4.
• Deterministic LOCAL: Our input graph G = (V, E) represents a computer network; each
node v ∈V is a computer and each edge {u, v} ∈E is a communication link between two
computers. Each node is labeled with a unique identifier from {1, 2, . . . , poly(|V |)}. All nodes
follow the same distributed algorithm. Initially a node is only aware of its own identifier and
its own degree. Computation proceeds in synchronous rounds, and in each round a node can
send and receive a message to and from each neighbor and update its state. Eventually each
node must stop and announce its local output (its part of the solution, e.g. in graph coloring its
own color). The running time, round complexity, or locality of the algorithm is the (worst-case)
number of rounds T(n) until the algorithm stops in any n-node graph.
• Randomized LOCAL: As above, but each node also has a private source of random bits.
We also define the following variants (see e.g. [50] for more on the impact of shared global information):
• Deterministic LOCAL (shared): Deterministic LOCAL with shared global information. The
set of nodes and their unique identifiers is globally known, and hence we also know n = |V |.
• Randomized LOCAL (shared): Randomized LOCAL with shared global information and
shared randomness. The set of nodes and their unique identifiers is globally known, and in
addition to the private sources of random bits, there is also a shared source of random bits
that all nodes can access.
We can interpret the shared versions of the models so that we get to see the set of nodes V and
their unique identifiers in advance, and we can also initialize the nodes as we want based on this
information (and hence in the randomized model, we can also initialize all nodes with the same
shared random string), but the set of edges E is only revealed later. This interpretation will be
useful especially with the quantum models.
2

--- Page 4 ---
1.4
Landscape of LCL problems
There has been more than three decades of work on understanding the capabilities and limitations of
the classical deterministic and randomized LOCAL models, but for our purposes most interesting is
the recent line of work that has studied distributed algorithms for locally checkable labeling problems,
or LCLs. This is a family of problems first introduced by Naor and Stockmeyer [57]. LCL problems
are graph problems that can be defined by specifying a finite set of valid neighborhoods. Many
natural problems belong to this family: coloring graphs of maximum degree ∆with ∆+ 1 colors,
computing a maximal independent set, finding a maximal matching, etc.
Since 2016, we have seen a large body of work dedicated to understanding the computational
complexity of LCL problems in the deterministic and randomized LOCAL models [4–9, 11, 16, 17,
19, 20, 34, 37, 39, 40, 62], and nowadays there are even algorithms and computer tools available
for exploring such questions [9, 23, 59]. As a result of this large international research effort, a
landscape of the localities of LCL problems emerges [64]. We can classify LCL problems in discrete
classes based on their locality, and we also understand how much randomness helps in comparison
with deterministic algorithms. Our main goal in this work is to extend this understanding of LCL
problems far beyond the classical models, and especially explore what can be computed very fast in
models that are much stronger than deterministic or randomized LOCAL.
1.5
Quantum-LOCAL and finitely-dependent processes
We start our exploration of stronger models with distributed quantum computation. The key
question is understanding the distributed quantum advantage: what can we solve faster if our nodes
are quantum computers and our edges are quantum communication channels? There is a long line of
prior work exploring this theme in different models of distributed computing [3, 18, 27, 33, 35, 36,
43, 48, 49, 51, 52, 55, 66–68], but for our purposes these are the models of interest:
• Quantum-LOCAL: This model of computing is similar to the deterministic LOCAL model
above, but now with quantum computers and quantum communication links. More precisely,
the quantum computers manipulate local states consisting of an unbounded number of qubits
with arbitrary unitary transformations, the communication links are quantum communication
channels (adjacent nodes can exchange any number of qubits), and the local output can be the
result of any quantum measurement.
• Quantum-LOCAL (shared): Quantum-LOCAL with shared global information and a shared
quantum state. As above, but now the algorithm may inspect and manipulate the set of nodes
(before any edges are revealed). In particular, it may initialize the nodes with a globally shared
entangled state.
As quantum theory intrinsically involves randomness, quantum-LOCAL is at least as strong as
randomized LOCAL. There are some (artificial) problems that are known to be solvable much faster
in quantum-LOCAL than deterministic or randomized LOCAL [52]; however, whether any LCL admits
such a quantum advantage is a major open question in the field.
Directly analyzing quantum-LOCAL is beyond the scope of current techniques. In essence, the
only known technique for proving limitations of quantum-LOCAL is sandwiching it between the
classical randomized-LOCAL model and more powerful models than quantum-LOCAL that do not
explicitly refer to quantum information. These more powerful models are based on the physical
causality principle (a.k.a. non-signaling principle). The idea is perhaps easiest to understand with
the help of the following thought experiment:
3

--- Page 5 ---
Example 1.1. Fix a distributed algorithm A in the quantum-LOCAL model (with shared global
information and quantum state) that runs in T rounds on graphs with n nodes. Let G = (V, E) be
some n-node input graph. Apply A repeatedly to G to obtain some probability distribution Y (G)
of outputs. Now fix some subset of nodes U ⊆V , and consider the restriction of Y (G) to U, in
notation Y (G)↾U. Let G[U, T] be the radius-T neighborhood of set U in G. Now modify G outside
G[U, T] to obtain a different n-node graph G′ with G[U, T] = G′[U, T]. Apply A to G′ repeatedly,
and we obtain another probability distribution Y (G′) of outputs. If Y (G)↾U ̸= Y (G′)↾U, it would
be possible to use A to transmit information in T time steps between two parties, Alice and Bob,
that are within distance T + 1 from each other: Bob holds all nodes of U, and he can, therefore,
observe Y (G)↾U, while Alice controls the graph outside G[U, T] = G′[U, T], and she can, therefore,
instantiate either G or G′. This would enable Alice to send a signal to Bob even if no physical
communication occurred from Alice to Bob (as they are at distance T + 1 from each other and only
T communication steps occurred), and thus violate the non-signaling principle.
This thought experiment suggests the following definition, also known as the φ-LOCAL model
and the causal model [3, 36]:
• Non-signaling model: We can produce an arbitrary output distribution as long as it does
not violate the non-signaling principle: for any set of nodes U, modifying the structure of the
input graph at more than a distance T(n) from U does not affect the output distribution of U.
We also need to introduce the following definition to better connect our work with the study of
finitely-dependent processes and in particular finitely-dependent colorings [44, 45, 47]:
• Bounded-dependence model: We can produce an arbitrary output distribution as long as
it does not violate the non-signaling principle, and, furthermore, distant parts are independent:
if we fix any sets of nodes U1 and U2 such that their radius-T(n) neighborhoods are disjoint,
then the output labels of U1 are independent of the output labels of U2.
Now if we set T(n) = O(1), algorithms in the bounded-dependence model are in essence what is
usually called finitely-dependent processes.
Now we can connect all the above models with each others as follows, sandwiching the two
versions of quantum-LOCAL between other models (see Appendix A for details; the connection with
the non-signaling model is known [3, 36] but the connection with the bounded-dependence model is
to our knowledge new):
deterministic LOCAL
deterministic LOCAL (shared)
randomized LOCAL
randomized LOCAL (shared)
quantum-LOCAL
quantum-LOCAL (shared)
bounded-dependence
non-signaling
(1)
Here an arrow M1 →M2 indicates that an algorithm with locality (or round complexity) T(n) in
model M1 implies an algorithm with the same locality in M2. For some problems it is possible to
prove near-tight bounds for quantum-LOCAL by using diagram (1). For example, a very recent work
[27] used these connections to prove limits for the distributed quantum advantage in approximate
graph coloring: they prove an upper bound for the deterministic LOCAL model and a near-matching
lower bound for the non-signaling model.
4

--- Page 6 ---
1.6
Contribution 1: symmetry breaking with finitely-dependent processes
Now we are ready to state our first contribution. Recall the following gap result by Chang et al.
[21]: all LCL problems that can be solved with locality o(log n) in deterministic LOCAL or with
locality o(log log n) in randomized LOCAL can also be solved with locality O(log∗n) in deterministic
LOCAL. The class of problems with locality Θ(log∗n) contains in essence all symmetry-breaking
problems: these are problems that could be solved with constant locality if only we had some means
of breaking symmetry (e.g. distance-k coloring for some constant k would suffice). In Section 6 we
show the following result:
Theorem 1.2. Let Π be any LCL problem with locality O(log∗n) in the deterministic LOCAL
model. Then Π can be also solved with locality O(1) in the bounded-dependence model. Fur-
thermore, the resulting finitely-dependent processes are invariant under subgraph isomorphism.
Put otherwise, there is a finitely-dependent distribution over valid solutions of Π. Here the invariance
under subgraph isomorphisms implies that, for any two graphs G, H that share some isomorphic
subgraphs G′ and H′ such that their radius-O(1) neighborhoods are still isomorphic, the finitely-
dependent processes solving Π restricted to G′ and H′ are equal.
For any constant d, the task of coloring d-regular trees with d + 1 colors is a problem with
locality O(log∗n) in the deterministic LOCAL model. Hence, we can answer the open question
by Holroyd [44]:
Corollary 1.3. For each d ≥2, there is a finitely-dependent coloring with d + 1 colors in
d-regular trees. Furthermore, the resulting process is invariant over subgraph isomorphisms.
More specifically, there exists a finitely-dependent 4-coloring distribution of the infinite 3-regular
tree that is invariant under automorphisms.
Theorem 1.2 also introduces a formal barrier for proving limitations on distributed quantum
advantage. Recall that all current quantum-LOCAL lower bounds are, in essence, lower bounds in the
non-signaling model. Before our work, there was a hope that we could discover a symmetry-breaking
problem Π with the following properties: (1) its locality is O(log∗n) in deterministic LOCAL, and
(2) we can show that its locality is Ω(log∗n) in the non-signaling model, and therefore (3) Π cannot
admit any distributed quantum advantage. However, our work shows that no such problem Π
can exist. In particular, arguments related to non-signal distributions are not sufficient to exclude
distributed quantum advantage in this region.
1.7
Locality in online and dynamic settings
Let us now switch gears and consider a very different line of work. Ghaffari et al. [38] introduced a
sequential counterpart of the classical LOCAL model:
• Deterministic SLOCAL model: The nodes are processed in an adversarial order. When a
node v is processed, the algorithm gets to see all information in its radius-T(n) neighborhood
(including states and outputs of previously processed nodes). The algorithm has to label v
with its local output, and the algorithm can also record other information in v, which it can
exploit when other nodes near v are later processed.
• Randomized SLOCAL model: As above, with access to a source of random bits.
Clearly SLOCAL is stronger than LOCAL. One key feature is that the processing order naturally
breaks symmetry, and all symmetry-breaking LCLs can be solved with O(1) locality in SLOCAL.
5

--- Page 7 ---
One interpretation of our first contribution is that we also establish a new, unexpected similarity
between SLOCAL and the bounded-dependence model: both are able to solve any symmetry-breaking
LCL with constant locality.
A recent work [2] introduced the following models that capture the notion of locality also in the
context of centralized dynamic graph algorithms and centralized online graph algorithms:
• Deterministic dynamic-LOCAL model: The adversary constructs the graph one edge at a
time. The algorithm has a global view of the graph (including states and outputs of previously
processed nodes), but it has to maintain a feasible solution after each update. The algorithm
is restricted so that after a modification at node v, it can only update the solution within
distance T(n) from v.
• Deterministic online-LOCAL model: The adversary presents the input graph one node at
a time. When a node v is presented, the adversary also reveals the radius-T(n) neighborhood
of v. The algorithm has to then choose the output label of v. Crucially, the algorithm has
access to a global view of the graph (including states and outputs of previously processed
nodes). This model can be seen as a stronger version of the deterministic SLOCAL model
where all nodes have access to some global shared memory.
Both SLOCAL and dynamic-LOCAL can be sandwiched between LOCAL and online-LOCAL [2]:
deterministic LOCAL
deterministic SLOCAL
deterministic dynamic-LOCAL
deterministic online-LOCAL
(2)
There are also some problems in which deterministic online-LOCAL is much stronger than deterministic
LOCAL: 3-coloring in bipartite graphs has locality ˜Θ(√n) in deterministic LOCAL [17, 27] but O(log n)
in online-LOCAL [2]; very recently Chang et al. [22] also showed that this is tight for online-LOCAL.
1.8
Contribution 2: connecting all models for LCLs in rooted trees
At first sight, the models discussed in Sections 1.5 and 1.7 seem to have very little in common;
they seem to be orthogonal extensions of the classical deterministic LOCAL model. Furthermore,
we have already seen evidence that online-LOCAL can be much stronger than deterministic LOCAL.
Nevertheless, we can connect all these models in a unified manner, and prove strong limits on their
expressive power. To this end, we introduce yet another model:
• Randomized online-LOCAL model: Like deterministic online-LOCAL, but the algorithm
has access to a source of random bits, and we play against an oblivious adversary (the adversary
fixes the graph and the order of presenting nodes before the algorithm starts to flip coins).
Trivially, this is at least as strong as all models in diagram (2). However, the big surprise is that it
is also at least as strong as all models in diagram (1). In Section 5 we prove:
Theorem 1.4. Any LCL that can be solved in the non-signaling model with locality T(n) can
also be solved in the randomized online-LOCAL model with the same locality.
Then we zoom into the case of rooted trees in Section 7 and prove:
Theorem 1.5. Any LCL on rooted trees that can be solved in the randomized online-LOCAL
model with locality o(log log log n) can also be solved in the deterministic LOCAL model with
locality O(log∗n).
6

--- Page 8 ---
Together with Theorem 1.2 and previously-known results, we also obtain the following corollary:
Corollary 1.6. In rooted trees, the following families of LCLs are the same:
• locality O(log∗n) in deterministic or randomized LOCAL or quantum-LOCAL,
• locality O(1) in bounded-dependence model, non-signaling model, deterministic or ran-
domized SLOCAL, dynamic-LOCAL, or deterministic or randomized online-LOCAL.
In rooted trees, there is no LCL problem with locality between ω(log∗n) and o(log log log n)
in any of these models: deterministic and randomized LOCAL, quantum-LOCAL, bounded-
dependence model, non-signaling model, deterministic and randomized SLOCAL, dynamic-
LOCAL, and deterministic and randomized online-LOCAL.
In particular, when we look at LCLs in rooted trees, O(log∗n)-round quantum algorithms are not
any stronger than O(log∗n)-round classical algorithms. (However, it is still possible that there are
some LCLs in trees that can be solved in O(1) rounds in quantum-LOCAL and that require Θ(log∗n)
rounds in deterministic LOCAL; recall the discussion in Section 1.6.)
Theorem 1.5 can be seen as an extension of the result of Akbari et al. [2] that connects deterministic
online-LOCAL with LOCAL for LCLs on rooted regular trees without inputs. Our result is applicable
to the randomized online-LOCAL (and hence we can connect it with the non-signaling and quantum
models), and it holds for any LCLs on rooted trees (possibly with irregularities and inputs). Recall
that the presence of inputs makes a huge difference already in the case of directed paths [5, 23], and
we need fundamentally new ideas, as we can no longer build on the classification from [9, 11].
1.9
Big picture
By putting together all our contributions (including some auxiliary results that we discuss later
in Section 3), the landscape shown in Fig. 10 emerges. We can sandwich all models between
deterministic LOCAL and randomized online-LOCAL. Going downwards, we get symmetry breaking
for free (as indicated by the blue arrows). And in the case of rooted trees, for the low-locality region
o(log log log n), we can also navigate upwards (as indicated by the orange arrows). Table 1 gives
some concrete examples of localities for LCL problems across the landscape of models.
Model
Symmetry-breaking problems
3-coloring in bipartite graphs
Deterministic LOCAL
Θ(log∗n)
by definition
˜Θ(√n)
[27]
Randomized LOCAL
Θ(log∗n)
[19]
˜Θ(√n)
[27]
Quantum LOCAL
O(log∗n)
trivial
˜Θ(√n)
[27]
Bounded-dependence
O(1)
Theorem 6.16
˜Θ(√n)
[27]
Deterministic SLOCAL
O(1)
[38]
˜O(√n), nΩ(1)
[2, 27]
Randomized SLOCAL
O(1)
[38]
˜O(√n), nΩ(1)
[2, 27]
Deterministic dynamic-LOCAL
O(1)
Theorem 9.2
˜O(√n), Ω(log n)
[22, 27]
Deterministic online-LOCAL
O(1)
[2]
Θ(log n)
[2, 22]
Randomized online-LOCAL
O(1)
[2]
Θ(log n)
Theorem 8.1
Table 1: Examples of localities across the models. Here symmetry-breaking problems refer to LCL
problems with locality Θ(log∗n) in the deterministic LOCAL model; this includes many classical
problems such as maximal independent set, maximal matching, and (∆+ 1)-vertex coloring.
7

--- Page 9 ---
2
Overview of techniques and key ideas
In this section, we give an overview of the techniques and key ideas that we use to prove our main
results, and we also provide a roadmap to the rest of this paper. We note that our first contribution
is presented in Section 6, while the second contribution comes before it in Section 5—the proofs are
ordered this way since Section 5 also develops definitions that will be useful in Section 6.
2.1
Bounded-dependence model can break symmetry (Section 6)
Let us first present an overview of the proof of Theorem 1.2 from Section 1.6. We show that
the bounded-dependence model can break symmetry with constant locality; that is, there is a
finitely-dependent process for any symmetry-breaking LCL.
It is well known that any LCL problem Π that has complexity O(log∗n) in the LOCAL model has
the following property: there exists a constant k ∈N+ (that depends only on the hidden constant
in O(log∗n)) such that, if the graph is given a distance-k coloring (with sufficiently small number
of colors) as an input, then Π is solvable in time O(1) in the LOCAL model (using the distance-k
coloring as a local assignment of identifiers) [20].
We prove that for each bounded-degree graph, there is a finitely-dependent process providing a
distance-k coloring for constant k. Then, we can combine such a process with the LOCAL algorithm
that solves the problem with locality O(1) if a distance-k coloring is given, and we prove that
the resulting process is still a finitely-dependent distribution. Furthermore, we also prove that all
these processes are invariant under subgraph isomorphisms (even those that do not preserve node
identifiers), meaning that, for any two graphs G and H sharing two isomorphic subgraphs with
isomorphic radius-O(1) neighborhoods, the restrictions of the finitely-dependent processes solving Π
over G and H restricted to G′ and H′ are equal in law.
One of the key observations that we use is that LOCAL algorithms that do not exploit the specific
assignment of node identifiers and do not depend on the size of the graph provide finitely-dependent
distributions that are invariant under subgraph isomorphisms whenever the input labeling for the
graphs is invariant under subgraph isomorphisms.
Overview.
The cornerstone of our proof is a surprising result by Holroyd and Liggett [45] and
its follow-up in [47], that state that there exist k-dependent distributions giving a q-coloring of the
infinite path and of cycles for (k, q) ∈{(1, 4), (2, 3)} that are invariant under subgraph isomorphisms.
Recently, Holroyd has combined the finitely-dependent distributions of infinite paths to provide
a finitely-dependent 4-coloring of the d-dimensional lattice [44]. Getting a translation invariant
distribution is quite easy: First, use the distributions for the paths on each horizontal and vertical
path obtaining a distance-k coloring (with k being a large enough constant) of the lattice with
constantly many colors as shown in [45, Corollary 20]. Second, apply some LOCAL algorithm
that starts from a distance-k coloring and reduces the number of colors to 4 while keeping the
resulting distribution symmetric (e.g., the algorithms from [10, 17]). The major contribution of [44]
is transforming such a distribution into a process that is invariant under subgraph isomorphisms.
However, this symmetrization phase is quite specific to the considered topology.
We come up with a new approach that obtains similar results in all bounded-degree graphs
through the following steps:
1. We show that the finitely-dependent coloring of paths and cycles can be combined to obtain
finitely-dependent 3-coloring distributions of rooted pseudoforests of bounded-degree that are
invariant under subgraph isomorphisms.
8

--- Page 10 ---
2. We observe that all graphs of bounded-degree admit a random decomposition in rooted
pseudoforests that satisfies the required symmetry properties.
3. We prove that such a random decomposition can be combined with the finitely-dependent
3-coloring of rooted pseudoforests to obtain finitely-dependent distributions that give a (∆+1)-
coloring of graphs of maximum degree ∆that are invariant under subgraph isomorphism.
4. We show that we can use this finitely-dependent (∆+ 1)-coloring distributions to provide a
distance-k coloring for bounded-degree graphs, which is enough to simulate any O(log∗n)-
round LOCAL algorithms that solves an LCL Π. Such combinations result in finitely-dependent
processes that are invariant under subgraph-isomorphisms and solve Π.
Notice that, in spirit, steps 1 to 3 are similar to the steps needed to produce a (∆+ 1)-coloring
in time O(log∗n) in the LOCAL model [42, 60]: however, the detailed way these steps are obtained
in the bounded-dependence model is quite different and requires a careful analysis.
Step 1: Finitely-dependent 3-coloring distributions of rooted pseudoforests.
A rooted
pseudoforest is a directed graph in which each node has outdegree at most 1. Let us now fix any
rooted pseudoforest of maximum degree ∆. Consider the following process: each node v colors its
in-neighbors with a uniformly randomly permutation of {1, . . . , indeg(v)}. The graph Gi induced by
nodes colored with color i is a union of directed paths and cycles (see Fig. 1) and, hence, admits a
finitely-dependent 4-coloring given by [45] that is invariant under subgraph isomorphisms; if a node is
isolated, it can deterministically join any of the Gis, say G1. The sequence of graphs (G1, . . . , G∆in)
is said to be a random ∆in-decomposition of the rooted pseudoforest. Furthermore, if two graphs
G, H have isomorphic subgraphs G′, H′ (together with some constant-radius neighborhoods), the
decompositions in directed paths and cycles induced in G′ and H′ have the same distribution
(because node colors are locally chosen uniformly). We prove that the combination of the random
decomposition and the finitely-dependent coloring yields a finitely-dependent 4∆-coloring which
is invariant under subgraph isomorphisms: by further combining such distribution with the Cole–
Vishkin color reduction algorithm [29, 42, 60] (that has complexity O(log∗k) with k being the
size of the input coloring), we can obtain a finitely-dependent 3-coloring distribution for rooted
pseudoforests of maximum degree ∆that is invariant under subgraph isomorphisms.
Steps 2–3: Finitely-dependent (∆+ 1)-coloring distribution of bounded-degree graphs.
First, if the input graph is undirected, make it a directed graph by duplicating all edges and
assigning both orientations to duplicated edges. Since a coloring of the nodes can be given in
both cases equivalently, we focus on the directed case for simplicity. Second, consider the following
process: each node v labels its out-edges with a uniformly sampled permutation of the elements
of {1, . . . , outdeg(v)}; this way we obtain a random decomposition of the edges of the graph into
rooted pseudoforests, as each node has at most one out-edge with label i. Furthermore, if two
graphs G, H have isomorphic subgraphs G′, H′ (together with some constant-radius neighborhoods),
the decompositions induced in G′ and H′ have the same distribution (because edge labelings are
locally chosen uniformly). We prove that if we apply the finitely-dependent 3-coloring from step 1 to
each pseudoforest, we obtain a finitely-dependent 3∆-coloring of the input graph which is invariant
under subgraph isomorphisms. By further combining such a distribution with a variant of the
Cole–Vishkin color reduction algorithm, we obtain a finitely-dependent (∆+ 1)-coloring distribution
for bounded-degree graphs of maximum degree ∆that is invariant under subgraph isomorphisms.
Step 4: Finitely-dependent distribution solving Π.
Consider any graph G of maximum
degree ∆, and its k-th power graph defined as follows: simply add edges to G between each pair of
9

--- Page 11 ---
nodes at distance at most k, where k is some large enough constant. Observe that Gk is a graph of
maximum degree ∆k. Now, step 3 implies that there is a finitely-dependent (∆k + 1)-coloring of Gk
that is invariant under subgraph isomorphisms: such distribution yields a distance-k coloring of G.
For any LCL Π that has complexity O(log∗n) in LOCAL, we know that there exists a constant k
such that, if given a distance-k coloring in input (with a constant number of colors), then there is
an O(1)-round port-numbering algorithm solving Π [20]: the combination of the input distance-k
coloring of G given by step 2-3 with such an algorithm yields a finitely-dependent distribution solving
Π that is invariant under subgraph isomorphisms.
Random decomposition of a graph.
In steps 1 and 3 we proceed in an analogous way: First,
we construct a process that induces a random decomposition of a graph. Second, we consider
finitely-dependent distributions of output labelings over the outputs of the random decomposition.
The combination of the random decomposition and the finitely-dependent distributions gives rise to
a process over the whole graph. In Section 6, we derive a general result (Lemma 6.8) which gives
sufficient conditions on the random decomposition and the finitely-dependent distributions in order
to ensure the final process is still finitely-dependent (possibly with symmetry properties). Lemma 6.8
is then the tool used in practice in steps 1 and 3.
Independent related work.
Very recently, an independent and parallel work provided a finitely-
dependent coloring of bounded-degree graphs with exponentially many colors (in the degree of the
graph) [65]. The technique employed in [65] is very similar to ours: it exploits the decomposition of
graphs in rooted pseudoforests, and then colors rooted pseudoforests using the finitely-dependent
coloring of paths and cycles [45, 47]. However, [65] stops at the mere coloring problem and does
not make use of color reduction algorithms, which are the key ingredient for extending results to all
symmetry-breaking LCLs.
2.2
Simulating non-signaling in randomized online-LOCAL (Section 5)
Let us now give the intuition behind the proof of Theorem 1.4 from Section 1.8: we show that the
non-signaling model can be simulated in randomized online-LOCAL without any loss in the locality.
A randomized online-LOCAL algorithm is given in input the size of the input graph, and a
distribution that is non-signaling beyond distance T and that solves some problem Π over some
graph family F. When the adversary picks any node v1 and shows to the randomized online-LOCAL
algorithm its radius-T neighborhood, the randomized online-LOCAL algorithm simply goes over all
graphs of n nodes in F until it finds one, say H1, that includes the radius-T neighborhood of v1:
then, it samples an output according to the restriction of the non-signaling distribution in H1 to
v1. Notice that such distribution does not change if the topology of the graph changes outside the
radius-T neighborhood of v1. Recursively, when the adversary picks the i-th node vi, the randomized
online-LOCAL algorithm goes over all graphs of n nodes in F until it finds one, say Hi, that includes
the union of radius-T neighborhoods of v1, . . . , vi (it must necessarily exist as the graph chosen
by the adversary is a valid input): hence, it samples an output according to the restriction of the
non-signaling distributions in Hi to vi conditional on the outputs of v1, . . . , vi−1. We prove that
the non-signaling property ensures that the algorithm described above fails with at most the same
probability of failure of the non-signaling distribution.
10

--- Page 12 ---
2.3
Online-LOCAL can be simulated in SLOCAL for rooted trees (Section 7)
Next we give an overview of the proof of Theorem 1.5 from Section 1.8: we show that a randomized
online-LOCAL algorithm that solves an LCL problem in rooted trees with locality o(log log log n)
can be simulated in the deterministic SLOCAL model with locality O(1), and therefore also in the
deterministic LOCAL model with locality O(log∗n).
Online-LOCAL algorithms can be seen simply as SLOCAL algorithms with global memory. Notice
that SLOCAL algorithms instead only have a form of “incremental” memory, i.e., they keep track of
an incremental sequence of intersecting neighborhoods N1, N2. . . ., where Ni intersects Ni+1.
The new ingredient we use in this section are component-wise online-LOCAL algorithms. Roughly
speaking, a component-wise algorithm is a deterministic online-LOCAL algorithm that, when pro-
cessing a node v, uses information only coming from the connected component of the input graph
that has been revealed so far to which v belongs, and nothing else. (If two or more components are
merged, then the algorithm may use information it knows from any component.)
We prove Theorem 1.5 in three steps:
1. We first show that any randomized online-LOCAL algorithm solving an LCL with locality
T(n) can be turned into a deterministic component-wise online-LOCAL algorithm with locality
T(2O(2n2)).
2. We then prove that, for LCLs on rooted trees, we can simulate the component-wise algorithms
in SLOCAL.
3. Finally, we show that SLOCAL algorithms solving any LCL Π with locality o(log n) over rooted
trees can be turned into an O(log∗n)-round LOCAL algorithm solving Π over rooted trees.
Step 1: Constructing component-wise algorithms from deterministic online-LOCAL
algorithms.
To give some intuition, consider an LCL problem Π on a family F of graphs that is
closed under disjoint graph union and node and edge removals. Suppose there is a deterministic
online-LOCAL algorithm A solving Π with locality T(n) on n-node graphs. Note that the output
label A chooses for a node may depend arbitrarily on everything the algorithm has seen so far.
We show how to turn algorithm A into an algorithm whose output for isolated nodes depends
only on the local topology and inputs and is oblivious to any previously-processed nodes. We call
such algorithms 1-amnesiac. Here with isolated we mean the node v is such that all nodes belong to
the radius T-neighborhood around v are new to algorithm A, that is, A has no knowledge of how v
is connected (if at all) to the parts of the graph it has seen thus far.
Let N1 = |Σout| |Σin| n · 2n2 · n2, and let G1 be the set of all possible subgraphs of any n-node
graphs (from F) with inputs (up to isomorphisms) that are the radius-T(N1) neighborhood of some
node, which we call the center of the neighborhood. Let g1 = |G1| and notice that g1 ≤2n2|Σin| n.
Consider now the following experiment:
1. Construct a simulation graph H1 that consists of |Σout| · n copies of all graphs in G1. The size
of H1 is at most N1 = n2|Σout| · g1 ≤|Σout| |Σin| n · 2n2 · n2.
2. Reveal the center node of each of those neighborhood graphs to A in an arbitrary order with
locality T(N1). For each type of radius-T(N1) neighborhood T1 (i.e., any element of G1), there
exists some output label σT1 that occurs at least n times. We call such neighborhoods good
and such a label a canonical labeling of T1.
3. Continue labelling nodes of H1 using A under an arbitrary ordering of the nodes.
We describe a new online-LOCAL algorithm B that, using this experiment, produces a correct
labeling. Let G be an input graph n nodes, and let node v be revealed to B along with its radius-
T ′(n) neighborhood, where T ′(n) = T(N1). Whenever v is an isolated node, algorithm B finds
11

--- Page 13 ---
a “fresh” (i.e., not previously chosen) good neighborhood in the experiment graph matching the
radius-T(N1) neighborhood of v in G. It then takes that unused good neighborhood, identifies all
nodes with the revealed input neighborhood, and labels v accordingly. An unused good neighborhood
always exists since there are at least n good neighborhoods in the experiment graph matching the
radius-T(N1) neighborhood of v in G. Algorithm B effectively cuts and pastes the neighborhood
from the experiment graph to the actual input graph without algorithm A noticing. For non-isolated
nodes, B just simulates what A would do, following the adversarial order of the nodes presented to B.
This is always possible because the labels of isolated nodes come from valid online-LOCAL runs of A.
The correctness of algorithm B follows from that of A. Moreover, when labeling an isolated node,
B always labels it in the same way that depends only on the local structure and inputs of the graph;
hence B is 1-amnesiac. Clearly, there is an exponential overhead in the locality: the locality of B is
T ′(n) = T(N1) = T(2O(n2)).
Using the above, we now describe how to obtain a 2-amnesiac algorithm, that is, an algorithm
that always produces the same labels for the same types of connected components formed by the
union of intersecting neighborhoods of two distinct nodes. We modify the previous experiment as
follows:
1. First we must increase the size of the experiment graph. Let N2 = |Σout| 2|Σin| n · 2n · n2 and
redefine G1 with the radius-T(N2) neighborhoods.
2. Instead of considering |Σout| · n many disjoint copies of elements of G1, we now take |Σout| 2 · n
copies. By the same argument as before, there are at least n · |Σout| good neighborhoods.
3. Let G2 be the set of all possible unions of two non-disjoint radius-T(N2) neighborhoods of two
different nodes of any n-node graph (in F), with all possible input labelings and orderings of
the center nodes. Notice that the size of G2 is g2 ≤2n2|Σin| n. We take |Σout| · n many disjoint
copies of all graphs in G2, with the catch that the neighborhood of the center node that comes
first in the processing order is chosen arbitrarily among the good neighborhoods. The resulting
graph H2 is our new experiment graph, whose size is now N2 ≤|Σout| |Σin| n · 2n2 · n3.
4. Use A to label all nodes that come first in the input order in each graph, then all nodes that
come second in the same respective order.
5. Use A to label the second center node of each connected component. By the pigeonhole
principle, for all types of such connected components T2 there are at least n identical labelings.
These make out the canonical labelings σT2.
The 2-amnesiac algorithm B starts by running the above experiment. When given in input an
n-node graphs, it outputs the canonical labeling σT1 for isolated nodes whose radius-T ′(n) = T(N2)
neighborhood matches type T1. Similarly, B outputs the canonical labeling σT2 for nodes seeing a
connected component of type T2 when we look at their radius-T ′(n) = T(N2) neighborhood. The
correctness argument is the same as that for 1-amnesiac algorithms. For the remaining nodes, B just
simulates A using global memory as usual.
We can continue this process all the way up to n-amnesiac algorithms, which are simply
component-wise online-LOCAL algorithms. See Lemma 7.5 for the formal details. As a remark,
notice the restriction to LCLs is necessary to prove correctness: if the amnesiac algorithm fails,
it must fail locally; hence also the original online-LOCAL algorithm fails locally, contradicting its
correctness.
Dealing with randomness.
Let us now turn to the setting where A is randomized. For deter-
ministic online-LOCAL algorithms, we adaptively picked the good neighborhoods before processing
further; however, since in randomized online-LOCAL the adversary is oblivious, we must adapt our
strategy.
12

--- Page 14 ---
Our experiment graph Hn is now random. It is constructed exactly as before, though now
the good connected components have to be “guessed” uniformly at random each time. Clearly,
the probability that our guesses are good is incredibly small. Hence we would like to amplify the
success probability so that the probability that the guesses are good enough and the randomized
online-LOCAL algorithm works correctly is bounded away from zero. (Once we have this, we may
apply a standard derandomization argument.) The amplification is by replicating k times the
experiment graph Hn, guessing the good components for each copy of Hn independently. Since the
randomness of the algorithm and the randomness of these guesses are independent for each copy of
Hn, a simple union bound together with the inclusion-exclusion principle give a positive probability
that, in at least one copy of Hn, the guesses are correct and the algorithm works properly.
We now apply a standard derandomization argument: Since there exists an assignment of a
random bit string to the randomized online-LOCAL algorithm as well as for “guessing” the good
components in the k copies of the experiment graph, there is a fixed, deterministic realization of Hn
that yields a (correct) deterministic online-LOCAL algorithm. Hence our n-amnesiac algorithm B
goes over all possible definitions of Hn and of deterministic online-LOCAL algorithms (according
to an arbitrary order) until it finds this good combination. It must eventually succeed because,
when the size of the input graph is fixed, there are only finitely many combinations. The proof then
reduces to the previous case. See Lemma 7.6 for the formal details.
Step 2: From component-wise algorithms to SLOCAL algorithms on rooted trees.
We
heavily exploit the fact that, in rooted trees, there is a consistent orientation of the edges towards
the root. We adapt results from [23, Section 7] to the SLOCAL model to show how to “cluster” a
rooted tree in connected components (which are also rooted trees) in time O(α) and so that the
following properties are met:
1. All connected components have depth Θ(α).
2. All leaves of a connected component that are not at distance Θ(α) from the root of the
component are real leaves of the original rooted tree.
3. All other leaves are either real leaves or roots of other connected components.
The formal details can be found in Lemma 7.8.
Suppose now we are given an n-amnesiac (equivalently, component-wise) algorithm A solving
an LCL Π on rooted trees with locality T(n). We briefly describe how to construct an SLOCAL
algorithm B that solves Π with locality O(T(n)) on rooted trees. Recall that in SLOCAL we may
compose two algorithms with localities T1 and T2 and obtain an SLOCAL algorithm with locality
O(T1 + T2) [38]. Algorithm B is the composition of the following four algorithms with locality O(T):
1. B1 constructs a clustering with properties 1-3 above with α = O(T), where the hidden constant
is large enough.
2. B2 ensures each root of a connected component of the cluster precommits a solution in the
neighborhood of the leaves of the component using A. This can be done independently between
different components if the localities are appropriately chosen. The root of the original tree
also outputs a solution for itself.
3. B3 outputs the precommitments on the nodes designated by B2.
4. The fact that we used A independently on disjoint components of the graph (and A being
correct) ensures that a solution to the LCL exists and the “inner part” of all connected
components can be completed with a correct solution. Hence B4 simply brute-forces a solution
inside the clusters.
13

--- Page 15 ---
Since Π is an LCL, different components will have compatible solutions as B2 precommitted a
solution around leaf nodes, which are roots of other connected components.
Step 3: From SLOCAL algorithms to LOCAL algorithms on rooted trees.
Any o(log n)-
time SLOCAL algorithm A solving an LCL over rooted trees can be turned into an O(1)-time
SLOCAL algorithm B achieving the same. This is obtained by exploiting the same tree decomposition
described above and providing fake, repeating identifiers to each cluster so that two equal identifiers
are “far enough”. Then, we use A as a black-box and lie to A by providing the size of a cluster
as the input graph size. Once we have an O(1)-time SLOCAL algorithm B, how to turn it into an
O(log∗n)-time LOCAL algorithm is folklore.
3
Additional results
We will now discuss some additional results that help to establish the missing parts of the big picture
in Fig. 10, and provide further intuition and examples on these models and their key properties.
3.1
Lower bound on 3-coloring in randomized online-LOCAL (Section 8)
So far we have connected randomized online-LOCAL with other models through simulation arguments
that only work in rooted trees. Let us now put limitations on randomized online-LOCAL in a broader
setting. Recall that in deterministic online-LOCAL we can 3-color bipartite graphs with locality
O(log n) [2], and this is tight [22]. In Section 8 we show that randomness does not help:
Theorem 3.1. 3-coloring in bipartite graphs is not possible with locality o(log n) in the
randomized online-LOCAL model.
This demonstrates that even though randomized online-LOCAL is a very strong model, strong enough
to simulate e.g. any non-signaling distribution, it is nevertheless possible to prove strong lower
bounds in this model (which then imply lower bounds across the entire landscape of models).
Here it is important to assume that the adversary is oblivious, i.e., it cannot see the random
decisions of the randomized algorithm. This lower bound complements a recent result of Chang et al.
[22] showing the same bound for the deterministic online-LOCAL model.
In this proof, we use the notion of a b-value defined in [22] as a measure of the number of
incompatible boundaries present in a region of a grid. We start with the assumption that a grid can
be 3-colored with locality o(log n) and derive a contradiction. The high level idea is to construct
two path segments below each other, where one path segment has a large count of incompatible
boundaries (a high b-value) and the other segment has a low boundary count (incompatible b-value
to the upper path). This forces an algorithm to make boundaries escape on the side between the
two segments. We show that the boundary count is, however, too large compared to the distance
between the two segments and thus the boundaries “cannot escape”.
Two difficulties arise in the randomized case compared to the deterministic lower bound: (i) In
order to create a path with a large b-value we have to use a probabilistic construction that produces
a segment with a large b-value with high probability; (ii) Since the first construction is probabilistic
and the adversary oblivious, we cannot “see” the large b-value segment constructed in (i), that
is, we can neither predict its position nor its size. We therefore need to use another probabilistic
construction that positions the segment in a position that forces a contradiction (and which succeeds
with constant probability).
14

--- Page 16 ---
3.2
Deterministic dynamic-LOCAL can derandomize LOCAL (Section 9)
It is known that deterministic SLOCAL is strong enough to simulate randomized LOCAL. In Section 9
we show that the same holds also for dynamic-LOCAL, using the method of conditional expectation
in a manner similar to how the result is proved for SLOCAL:
Theorem 3.2. Deterministic dynamic-LOCAL can simulate randomized LOCAL.
We also show that dynamic-LOCAL can break symmetry for free, similar to SLOCAL and the
bounded-dependence model: if we can solve an LCL problem with O(log∗n) locality in LOCAL, we
can solve it with O(1) locality in dynamic-LOCAL.
3.3
Randomized online-LOCAL with adaptive adversary (Section 10)
The new model that we introduced, randomized online-LOCAL, is defined using an oblivious adversary.
In Section 10 we show that this is also necessary: if we defined randomized online-LOCAL with an
adaptive adversary, it would be as weak as the deterministic online-LOCAL model.
We show that an adaptive adversary in randomized online-LOCAL is so strong that a succeeding
randomized online-LOCAL algorithm of locality T would admit a single random-bit string that
outputs a good solution for all possible graphs of a given size: hence, a correct deterministic online-
LOCAL algorithm exists. Since deterministic online-LOCAL algorithms of locality T for graphs of n
nodes are only finitely many, the deterministic online-LOCAL algorithm in its initialization phase
can go over all of them until it finds the one working for all graphs of n nodes: it then uses that one.
3.4
Randomized online-LOCAL in paths and cycles (Section 11)
Our final technical part shows that LCL problems in paths and cycles have complexity either O(1)
or Θ(n) in the randomized online-LOCAL model; moreover the locality is O(1) in randomized online-
LOCAL if and only if it is O(log∗n) in the deterministic LOCAL model. Together with prior work,
this also shows that locality of an LCL problem in paths and cycles is decidable across all models [5]
(with the caveat that we cannot distinguish between O(1) and Θ(log∗n) for quantum-LOCAL). The
proof is a reworking of its deterministic variant from [2]. The main take-home message of this result
is the following: cycles are not a fundamental obstacle for simulating randomized online-LOCAL in
weaker models. Hence, there is hope for generalizing the simulation result of Section 7 from trees to
a broader class of graphs.
3.5
Quantum, bounded-dependence, and non-signaling (Appendix A)
Appendix A aims at serving a dual purpose. First, it aims at formally introducing the non-signaling
model based on the non-signaling principle, and at explaining why it is more powerful than the
quantum-LOCAL model. This is not a new result, but included for completeness and to clarify the
early works of Gavoille et al. [36] and Arfaoui and Fraigniaud [3]. Second, it formally introduces the
bounded-dependence model based on finitely-dependent processes and argues why the relations in
diagram (1) hold, and in particular why quantum-LOCAL without shared quantum state is contained
not only in the non-signaling model but also in the bounded-dependence model. While all the
ingredients are well-known, to our knowledge this relation between the quantum-LOCAL model and
the bounded-dependence model is not made explicit in the literature before.
15

--- Page 17 ---
3.6
Open questions
Our work suggests a number of open questions; here are the most prominent ones:
Question 1. Is quantum-LOCAL stronger than randomized LOCAL for any LCL problem? In
particular, is there any LCL problem with constant locality in quantum-LOCAL but super-constant
locality in LOCAL? We conjecture that such a problem does not exist. Our work proves that to
show this conjecture, new proof techniques are needed.
Question 2. Does shared global information or shared quantum state ever help with any LCL
problem (beyond the fact that shared quantum state can be used to generate shared randomness,
which is known to help [13])?
Question 3. Is it possible to simulate deterministic or randomized online-LOCAL in SLOCAL and
LOCAL also in a broader graph class than rooted trees? If we could extend the result to unrooted
trees, it would also imply new lower bounds for the widely-studied sinkless orientation problem
[12, 16] across all models.
3.7
Follow-up work
Since the first versions of this work originally appeared in arXiv earlier this year, this work has
already influenced at least two follow-up papers:
1. Dhar et al. [32] study the relation between online-LOCAL and deterministic LOCAL in much
greater depth, especially outside the o(log log log n) region. It turns out that e.g. in regular
rooted trees the complexity classes of LCL problems in randomized online-LOCAL and deter-
ministic LOCAL exactly coincide, and as a corollary all models in Fig. 10 are exactly as strong
for this graph family in the Ω(log∗n) region.
2. Balliu et al. [13] show that there are LCL problems in which shared randomness strictly helps.
This implies a number of new separations between the models in Fig. 10; for example, quantum-
LOCAL with shared quantum state is strictly stronger than quantum-LOCAL without shared
quantum state, the non-signaling model is strictly stronger than the bounded-dependence
model, and randomized online-LOCAL is strictly stronger than randomized SLOCAL.
Put together, these papers demonstrate that especially in restricted graph classes such as trees,
one can indeed often cover the entire hierarchy of models with a single theorem about randomized
online-LOCAL, while in general we are dealing with a large number of genuinely distinct models.
4
Preliminaries
We use the notation N = {0, 1, 2, . . . } and N+ = N \ {0}. For any positive integer n ∈N+, we denote
the set {1, . . . , n} by [n].
Graphs.
In this work, a graph G = (V, E) can be either directed (E ⊆V 2) or undirected (E ⊆
 V
2

).
If the set of nodes and the set of edges are not specified, we refer to them by V (G) and E(G),
respectively. For any edge e = (u, v) ∈E(G) we say that e is directed from u to v and is incident to
u and to v (the latter holds also for undirected edges). All graphs in this paper are simple graphs
without self-loops unless differently specified. The degree of a node v is the number of edges that
are incident to v and is denoted by degG(v), or simply by deg(v) when G is clear from the context.
The indegree of a node v is the number of directed edges that are directed towards v and is denoted
16

--- Page 18 ---
by indegG(v), while the outdegree of v is the number of directed edges that are incident to v but
directed to some other vertex and is denoted by outdegG(v). Again, we omit the suffix G if the
graph is clear from the context.
If G is a subgraph of H, we write G ⊆H. For any subset of nodes A ⊆V , we denote by
G[A] the subgraph induced by the nodes in A. For any nodes u, v ∈V , distG(u, v) denotes the
distance between u and v in G (i.e., the number of edges of any shortest path between u and v
in G—it doesn’t need to be a directed path); if u and v are disconnected, then distG(u, v) = +∞.
If G is clear from the context, we may also simply write dist(u, v) = distG(u, v). Also, for subset
of nodes A, B ⊆V and any node v ∈V , we can define distG(v, A) = minu∈A distG(u, v) and, by
extension, distG(A, B) = minu∈A distG(u, B). We assume that distG(A, ∅) = +∞. Similarly, for
subgraphs G1, G2 ⊆G, we define distG(G1, G2) = distG(V (G1), V (G2)): here, we also assume
distG(G1, ∅) = +∞where ∅is now the empty graph. For T ∈[n], the T-neighborhood of a node
u ∈V of a graph G is the set NT (u, G) = {v ∈V | distG(u, v) ≤T}. The T-neighborhood of a subset
A ⊆V is the set NT (A, G) = {v ∈V | ∃u ∈A : distG(u, v) ≤T}. Similarly, the T-neighborhood of
a subgraph H ⊆G is the set NT (H, G) = {v ∈V | ∃u ∈V (H) : distG(u, v) ≤T}. If G is clear from
the context, we just write NT (u), NT (A), and NT (H). If u /∈V , A∩V = ∅, or V (H)∩V (G) = ∅, then
the neighborhood NT (u) = ∅, NT (A) = ∅, or NT (H) = ∅, respectively. We make use of some graph
operations: For any two graphs G, H, we denote by G∩H the intersection graph defined by G∩H =
(V (G)∩V (H), E(G)∩E(H)). The graph union is defined by G∪H = (V (G)∪V (H), E(G)∪E(H)).
Moreover, the graph difference is the graph G \ H = (V (G) \ V (H), E(G) \ E(H)).
Finally, for any two graphs G and H, we write G ∼f H to denote that G and H are isomorphic
and f : V (G) →V (H) is an isomorphism.
Labeling problems.
We start with the notion of labeling problem.
Definition 4.1 (Labeling problem). Let Σin and Σout two sets of input and output labels, respectively.
A labeling problem Π is a mapping (G, λin) 7→{λ(out,i)}i∈I, with I being a discrete set of indexes,
that assigns to every graph G with any input labeling λin : V (G) →Σin a set of permissible
output vectors λ(out,i) : V (G) →Σout that might depend on (G, λin). The mapping must be closed
under graph isomorphism, i.e., if φ : V (G) →V (G′) is an isomorphism between G and G′, and
λ(out,i) ∈Π((G′, λin)), then λ(out,i) ◦φ ∈Π((G, λin ◦φ)).
A labeling problem can be thought as defined for any input graph of any number of nodes. If
the set of permissible output vectors is empty for some input (G, λin), we say that the problem
is not solvable on the input (G, λin): accordingly, the problem is solvable on the input (G, λin) if
Π(G, λin) ̸= ∅.
One observation on the generality of definition of labeling problem follows: one can actually
consider problems that require to output labels on edges.
We actually focus on labeling problems where, for any input graph, an output vector λout is
permissible if and only if the restrictions of the problem on any local neighborhoods can be solved
and there exist compatible local permissible output vectors whose combination provides λout. This
concept is grasped by the notion of locally checkable labeling (LCL) problems, first introduced by
Naor and Stockmeyer [57]. For any function f : A →B and any subset A′ ⊆A, let us denote the
restriction of f to A′ by f ↾A′. Furthermore, we define a centered graph to be a pair (H, vH) where
H is a graph and vH ∈V (H) is a vertex of H that we name the center of H. The radius of a
centered graph is the maximum distance from vH to any other node in H.
Definition 4.2 (Locally checkable labeling problem). Let r, ∆∈N. Let Σin and Σout two finite
sets of input and output labels, respectively, and Π a labeling problem. Π is locally checkable with
17

--- Page 19 ---
checking radius r if there exists a family S = {((H, vH), ¯λin, ¯λout)i}i∈I of tuples, where (H, vH) is a
centered graph of radius at most r and maximum degree at most ∆, ¯λin : V (H) →Σin is an input
labeling for H, ¯λout : V (H) →Σout is an output labeling for H (which can depend on ¯λin) with the
following property
• for any input (G, λin) to Π with deg(G) ≤∆, an output vector λout : V (G) →Σout is
permissible (i.e., λout ∈Π((G, λin))) if and only if, for each node v ∈V (G), the tuple
((G[Nr(v)]), λin ↾Nr(v), λout ↾Nr(v)) belongs to S (up to graph isomorphisms).
Notice that the family S can be always thought to be finite up to graph isomorphisms, as r and
∆are fixed and the set of input/output labels are finite. We now define the computational models
we work in.
The port-numbering model.
A port-numbered network is a triple N = (V, P, p) where V is the
set of nodes, P is the set of ports, and p : P →P is a function specifying connections between ports.
Each element x ∈P is a pair (v, i) where v ∈V , i ∈N+. The connection function p between ports
is an involution, that is, p(p(x)) = x for all x ∈P. If (v, i) ∈P, we say that (v, i) is port number i
in node v. The degree of a node v in the network N is degN(v) is the number of ports in v, that
is, degN(v) = |{i ∈N : (v, i) ∈P}|. Unless otherwise mentioned, we assume that port numbers are
consecutive, i.e., the ports of any node v ∈V are (v, 1), . . . , (v, degN(v)). Clearly, a port-numbered
network identifies an underlying graph G = (V, E) where, for any two nodes u, v ∈V , {u, v} ∈E if
and only if there exists ports xu, xv ∈P such that p(xu) = xv. Clearly, the degree of a node degN(v)
corresponds to degG(v).
In the port-numbering model we are given distributed system consisting of a port-numbered
network of |V | = n processors (or nodes) that operates in a sequence of synchronous rounds. In each
round the processors may perform unbounded computations on their respective local state variables
and subsequently exchange of messages of arbitrary size along the links given by the underlying
input graph. Nodes identify their neighbors by using ports as defined before, where port assignment
may be done adversarially. Barring their degree, all nodes are identical and operate according to the
same local computation procedures. Initially all local state variables have the same value for all
processors; the sole exception is a distinguished local variable x(v) of each processor v that encodes
input data.
Let Σin be a set of input labels. The input of a problem is defined in the form of a labeled graph
(G, x) where G = (V, E) is the system graph, V is the set of processors (hence it is specified as part
of the input), and x: V →Σin is an assignment of an input label λin(v) ∈Σin to each processor v.
The output of the algorithm is given in the form of a vector of local output labels λout : V →Σout,
and the algorithm is assumed to terminate once all labels λout(v) are definitely fixed. We assume
that nodes and their links are fault-free. The local computation procedures may be randomized by
giving each processor access to its own set of random variables; in this case, we are in the randomized
port-numbering model as opposed to the deterministic port-numbering model.
The running time of an algorithm is the number of synchronous rounds required by all nodes to
produce output labels. If an algorithm running time is T, we also say that the algorithm has locality
T. Notice that T can be a function of the size of the input graph. We say that a problem Π over
some graph family F has complexity T in the port-numbering model if there is a port-numbering
algorithm running in time T that solves Π over F, and T = T(n) is the minimum running time
(among all possible algorithms that solve Π over F) in the worst case instance of size n. If the
algorithm is randomized, we also require that the failure probability is at most 1/n, where n is the
size of the input graph.
18

--- Page 20 ---
We remark that the notion of an (LCL) problem is a graph problem, and does not depend on
the specific model of computation we consider (hence, the problem cannot depend on, e.g., port
numbers).
The LOCAL model.
The LOCAL model was first introduced by Linial [53]: it is just the port-
numbering model augmented with an assignment of unique identifiers to nodes. Let c ≥1 be a
constant, and let Σin be a set of input labels. The input of a problem is defined in the form of a
labeled graph (G, x) where G = (V, E) is the system graph, V is the set of processors (hence it
is specified as part of the input), and x: V →[nc] × Σin is an assignment of a unique identifier
id(v) ∈[nc] and of an input label λin(v) ∈Σin to each processor v. The output of the algorithm is
given in the form of a vector of local output labels λout : V →Σout, and the algorithm is assumed
to terminate once all labels λout(v) are definitely fixed. We assume that nodes and their links are
fault-free. The local computation procedures may be randomized by giving each processor access to
its own set of random variables; in this case, we are in the randomized LOCAL (randomized LOCAL)
model as opposed to deterministic LOCAL (deterministic LOCAL). Notice that the knowledge of n
makes the randomized port-numbering model roughly equivalent to the randomized LOCAL model,
as unique identifiers can be produced with high probability. We say that a problem Π over some
graph family F has complexity T in the LOCAL model if there is a LOCAL algorithm running in time
T that solves Π over F, and T = T(n) is the minimum running time (among all possible algorithms
that solve Π over F) in the worst case instance of size n. If the algorithm is randomized, we also
require that the failure probability is at most 1/n, where n is the size of the input graph.
The sequential LOCAL model.
The sequential LOCAL model was first introduced by [38]: it is
a sequential version of the LOCAL model. Nodes are processed according to an adversarial order
σ = v1, . . . , vn. When processing a node vi, a T-round algorithm collects all inputs in the radius-T
neighborhood of vi (including the states and the outputs of previously processed nodes in NT (Vi), i.e.,
vj ∈NT (Vi) for j < i): we say that such an algorithm has complexity T. Note that the algorithm
might store all inputs in NT (vi) in the state of vi: hence, when processing vi, it can see the input of vj,
j < i, if and only if there is a subsequence of nodes {vhk}k∈[m] with j = hk < hk+1 < · · · < hkm = i
such that vhk ∈NT (vhk+1) for all k ∈[m].
If the algorithm is given an infinite random bit string, we talk about the randomized SLOCAL
model, as opposed to the deterministic SLOCAL model. We assume that the adversarial order
according to which nodes are processed is oblivious to the random bit string, as in the original
definition of the model. We say that a problem Π over some graph family F has complexity T in
the SLOCAL model if there is an SLOCAL algorithm running in time T that solves Π over F, and
T = T(n) is the minimum running time (among all possible algorithms that solve Π over F) in
the worst case instance of size n. If the algorithm is randomized, we also require that the failure
probability is at most 1/n, where n is the size of the input graph.
The dynamic-LOCAL model.
The deterministic dynamic-LOCAL was introduced in [2]. It is
a centralized model of computing where the adversary constructs the graph one edge at a time.
An adversary construct the input graph by adding one edge at a time (with an ordering of the
nodes). The algorithm has a global view of the current state of the graph and has to commit for
the newly added nodes (according to the ordering), but it has to maintain a feasible solution after
each update. The algorithm is restricted so that after a modification at node v, it can only update
the solution within distance T(n) from v. We say that a problem Π over some graph family F has
complexity T(n) in the dynamic-LOCAL model if T(n) is the minimum function such that there
19

--- Page 21 ---
is a dynamic-LOCAL algorithm running in time T(n) that solves Π over F, and T = T(n) is the
minimum running time (among all possible algorithms that solve Π over F) in the worst case instance
of size n.
The online-LOCAL model.
The (deterministic) online-LOCAL model was introduced in [2]. It is
basically equivalent to the SLOCAL model with global memory. More specifically, the online-LOCAL
model is a centralized model of computing where the algorithm initially knows only the set of
nodes of the input graph G. The nodes are processed with respect to an adversarial input sequence
σ = v1, v2, . . . , vn. The output of vi depends on Gi = G[Si
j=1 NT (vj)], i.e., the subgraph induced
by the radius-T neighborhoods of v1, v2, . . . , vi (including all input data), plus all the outputs of
previously processed nodes (in order).
We define the randomized online-LOCAL model as a randomized variant of the online-LOCAL
model where the label assigned by the algorithm to vi is a random outcome.
Note that this
model is oblivious to the randomness used by the algorithm. In particular this means that the
graph G \ Gi cannot be changed depending on the label assigned to vi. One could also define the
randomized online-LOCAL model in an adaptive manner, but it turns out that this is equivalent to
the deterministic online-LOCAL model as we show in Section 10. We say that a problem Π over
some graph family F has complexity T in the online-LOCAL (randomized online-LOCAL) model if
there is an online-LOCAL (randomized online-LOCAL) algorithm running in time T that solves Π
over F, and T = T(n) is the minimum running time (among all possible algorithms that solve Π
over F) in the worst case instance of size n. If the algorithm is randomized, we also require that the
failure probability is at most 1/n, where n is the size of the input graph.
5
Simulating non-signaling in randomized online-LOCAL
5.1
Framework
In this section we give the necessary framework to define the non-signaling model and is largely
inspired by the definitions given in [27, 36]. Next definition introduces the concept of outcome.
Definition 5.1 (Outcome). Let Σin and Σout be two sets of input and output labels, respectively,
and let F be a family of graphs. An outcome O over F is a mapping (G, x) 7→{(λ(out,i), pi)}i∈I,
with I being a discrete set of indexes, assigning to every input graph G ∈F with any input data
x = (id : V (G) →[|V (G)|c], λin : V (G) →Σin), a discrete probability distribution {pi}i∈I over
output vectors λ(out,i) : V (G) →Σout such that:
1. for all i ∈I, pi > 0;
2. P
i∈I pi = 1;
3. pi represents the probability of obtaining λ(out,i) as the output vector of the distributed system.
We say that an outcome O over some graph family F solves problem Π over F with probability p
if, for every G ∈F and any input data x = (id, λin), it holds that
X
(λ(out,i),pi)∈O((G,x)) :
λ(out,i)∈Π((G,λin))
pi ≥p.
When p = 1, we will just say that O solves problem Π over the graph family F.
The next computational model tries to capture the fundamental properties of any physical
computational model (in which one can run either deterministic, random, or quantum algorithms)
20

--- Page 22 ---
that respects causality. The defining property of such a model is that, for any two (labeled) graphs
(G1, x1) and (G2, x2) that share some identical subgraph (H, y), every node u in H must exhibit
identical behavior in G1 and G2 as long as its local view, that is, the set of nodes up to distance T
away from u together with input data and port numbering, is fully contained in H. As the port
numbering can be computed with one round of communication through a fixed procedure (e.g.,
assigning port numbers 1, 2, . . . , deg(v) based on neighbor identifiers in ascending order) and we care
about asymptotic bounds, we will omit port numbering from the definition of local view.
The model we consider has been introduced by [36]. In order to proceed, we first define the
non-signaling property of an outcome. Let T ≥0 be an integer, and I a set of indices. For any set
of nodes V , subset S ⊆V , and for any input (G = (V, E), x), we define its T-local view as the set
vT (G, x, S) = {(u, x(u)) | ∃u ∈V, v ∈S such that distG(u, v) ≤T} ,
where distG(u, v) is the distance in G. Furthermore, for any subset of nodes S ⊆V and any output
distribution {λ(out,i), pi}i∈I, we define the marginal distribution of {λ(out,i), pi}i∈I on set S as the
unique output distribution defined as follows: for any λout : V (G) →Σout, the probability of λout ↾S
on S is given by
p(λout, S) =
X
i∈I : λout↾S=λ(out,i)↾S
pi,
where λout ↾S and λ(out,i) ↾S are the restrictions of λout and λ(out,i) on S, respectively.
Definition 5.2 (Non-signaling outcome). Let F be a family of graphs. An outcome O : (G, x) 7→
{(λ(out,i), pi)}i∈I over F is non-signaling beyond distance T = T(G, x) if for any pair of inputs (G1 =
(V1, E1), x1), (G2 = (V2, E2), x2), with the same number of nodes, such that vT(G1,x1)(G1, x1, S) is
isomorphic to vT(G1,x1)(G2, x2, S) and G1, G2 ∈F, the output distributions corresponding to these
inputs have identical marginal distributions on the set S.
Definition 5.2 is also the more general definition for the locality of an outcome: an outcome O
has locality T if it is non-signaling beyond distance T.
The φ-LOCAL model.
The φ-LOCAL model is a computational model that produces non-signaling
outcomes over some family of graphs F. Let p ∈[0, 1]. A problem Π over some graph family F has
complexity T (and success probability p) if there exists an outcome O that is non-signaling beyond
distance T which solves Π over F (with probability at least p), and T = T(n) is the minimum
“non-signaling distance” (among all possible outcomes that solve Π over F) in the worst case instance
of size n.
As every (deterministic or randomized) algorithm running in time at most T in the LOCAL model
produces an outcome which has locality T, we can provide lower bounds for the LOCAL model by
proving them in the φ-LOCAL model.
Notice that algorithms in the LOCAL model can be always thought as producing outputs for any
input graph: when the computation at any round is not defined for some node, we can make the node
output some garbage label, say ⊥. If we require that also outcomes are defined for every possible
graph, then we are restricting the power of φ-LOCAL because outcomes must be defined accordingly.
This gives rise to a slightly weaker model, the non-signaling model, which was considered in other
works such as [27] and is still stronger than any classical or quantum variation of the LOCAL model.
Theorem 5.3. Let Π be any LCL problem over any family of graphs F. Let O : (G, λin) 7→
{(λ(out,h), pi)}h∈H be an outcome over F which solves Π with failure probability at most ε and is
non-signaling at distance greater than T. There exists a randomized online-LOCAL algorithm A with
complexity T that solves Π over F and has failure probability at most ε.
21

--- Page 23 ---
We want to design a randomized online-LOCAL algorithm A with complexity T that solves Π
over F and has failure probability at most ε that somehow simulates O. We need to assume that
the number of nodes of the input graph is known by A.
Fix any graph G ∈F of n nodes and any input labeling λin, and fix any sequence of nodes
v1, . . . , vn the adversary might choose to reveal to the algorithm.
The adversary initially shows G[NT (v1)] to the algorithm (including input labels and identifiers)
and asks it to label v1. In order for the algorithm to choose an appropriate output, it can arbitrarily
choose a graph H1 ∈F with n nodes that contains a subgraph isomorphic to G[NT (v1)] (again,
including input labels and identifiers). Notice that H1 necessarily exists since G itself is such a
graph. We stress that the arbitrariness in the choice of H1 is thanks to the non-signaling property,
which ensures that the restriction of the output distribution O(H1, λin) over NT (v1) does not change
if the topology of the graph outside G[NT (v1)] differs (i.e., no matter how the adversary chooses it).
Indeed, if O did not have the non-signaling property, then it would be impossible to sample from it
correctly since the marginal output distribution on G[NT (v1)] would depend on the topology of the
graph beyond it, which the algorithm still has no knowledge of.
For any λout : V (G) →Σout, the probability that A labels v1 with λout(v1) is
p(λout, v1) =
X
k: λout↾{v1}=λ(out,k)↾{v1}
pk,
where {(λ(out,k), pk)}k∈K1 = O(H1, λin).
Let Λi be the random variable yielding the label assigned to vi by A. In general, for any
λout : V (G) →Σout let p(λout, vi) denote the probability that Λi = λout(vi). Assume now that
G[NT (vi+1)] is shown to the algorithm. Conditional on Λ1, . . . , Λi, for any λout : V (G) →Σout such
that λout(vj) = Λj for all j = 1, . . . , i, the probability that Λi+1 = λout(vi+1) is
p(λout, vi+1) =
X
k: λout↾{vj}=λ(out,k)↾{vj}
∀1≤j≤i+1
pk
Q
1≤l≤i p(λout, vl),
where {(λ(out,k), pk)}k∈Ki+1 = O(Hi+1, λin) for any graph Hi+1 ∈F of n nodes that contains a
subgraph isomorphic to G[∪i+1
i=1NT (vj)] (including input labels and identifiers). As before, Hi+1 may
be chosen arbitrarily due to the non-signaling property.
Now consider O(G, λin) = {(λ(out,h), ph)}h∈H for the right input graph G, and take any
(λ(out,h⋆), ph⋆) ∈O(G, λin).
The probability that the outcomes of Λ1, . . . , Λn give exactly λ(out,h⋆) is
Pr

Λ1 = λ(out,h⋆)(v1), . . . , Λn = λ(out,h⋆)(vn)

= Pr

Λn = λ(out,h⋆)(vn)
Λ1 = λ(out,h⋆)(v1), . . . , Λn−1 = λ(out,h⋆)(vn−1)

· Pr

Λn−1 = λ(out,h⋆)(vn−1)
Λ1 = λ(out,h⋆)(v1), . . . , Λn−2 = λ(out,h⋆)(vn−2)

. . .
· Pr

Λ1 = λ(out,h⋆)(v1)

= p(λ(out,h⋆), v1) · . . . · p(λ(out,h⋆), vn)
=
Y
1≤l≤n−1
p(λout, vl) ·
X
kn: λ(out,h⋆)↾{vj}=λ(out,kj)↾{vj}
∀1≤j≤n
pkn
Q
1≤l≤n−1 p(λout, vl)
22

--- Page 24 ---
=
X
kn: λ(out,h⋆)↾{vj}=λ(out,kj)↾{vj}
∀1≤j≤n
pkn.
Notice that
X
kn: λ(out,h⋆)↾{vj}=λ(out,kj)↾{vj}
∀1≤j≤n
pkn = ph⋆
as Hn is necessarily isomorphic to G. By the hypothesis,
X
h: λ(out,h) is valid for (G,λin)
ph ≥1 −ε,
implying that A succeeds with probability at least 1 −ε.
6
Bounded-dependence model can break symmetry
For any graph G = (V, E), a random process (or distribution) on the vertices of G is a family of
random variables {Xv}v∈V , indexed by V , while a random process on the edges of G is a family of
random variables {Xe}e∈E indexed by E. More generally, a random process on G is a family of
random variables {Xy}y∈V ∪E indexed by V ∪E. The variables of a random process live in the same
probability space and take values in some label set Σ. In general, we will consider random processes
over vertices of graphs unless otherwise specified.
We now introduce the notion of T-dependent distribution. To do so, we extend the definition
of distance to edges as follows: For any two edges e = {v1, v2}, e′ = {u1, u2} ∈E, distG(e, e′) =
mini,j∈[2] distG(vi, uj). Similarly, the distance between any edge e = (v1, v2) and a vertex v is
distG(e, v) = mini∈[2] distG(vi, v). The definition extends easily to subsets containing vertices and
edges.
Definition 6.1 (T-dependent distribution). Let T ∈N be a natural number and G = (V, E) be
any graph. A random process {Xv}v∈V on the vertices G is said to be a T-dependent distribution
if, for all subsets S, S′ ⊆V such that distG(S, S′) > T, the two processes {Xv}v∈S and {Xv}v∈S′
are independent. Analogous definitions hold for random processes on the edges of a graph and for
random processes on the whole graph.
A way to define T-dependent distributions that uses the same notation of Section 5.1 is by
describing the output probability of global labelings: Let I be a discrete set of indices, and G = (V, E)
some graph. A distribution {(λi, pi)}i∈I over output labelings, where λi : V →Σ is an output
labeling, is T-dependent if the following holds: for all output labelings λ in {(λi, pi)}, for every two
subsets of nodes S1, S2 ⊆V (G) such that distG(S1, S2) > T, we have that
p(λ, S1 ∪S2) = p(λ, S1) · p(λ, S2).
Notice that outcomes, as defined in Definition 5.1, output a random process for every input. Often,
we have a family of graphs of arbitrarily large size n on which a T(n)-dependent distribution is
defined.1
Now we define the hypothetical computational model that outputs T-dependent distributions on
some input graph.
1Note that the dependency T might depend on other graph parameters such as the maximum degree ∆, the
chromatic number χ, etc.
23

--- Page 25 ---
The bounded-dependence model.
The bounded-dependence model is a computational model
that, for a given family of graphs F, produces an outcome (as defined in Definition 5.1) over F
that is non-signaling beyond distance T = T(G, x) (as defined in Definition 5.2), where G ∈F
and x represents the input, which, in turn, produces T(G, x)-dependent distributions. The random
processes produced by an outcome are said to be finitely-dependent if T = O(1) for all graphs in
F and all input data. If an outcome with the aforementioned properties solves a problem Π over
a graph family F with probability at least p, we say that the pair (Π, F) has complexity T (with
success probability p), and T = T(n) is the minimum dependence (among all possible distributions
solving Π over F) in the worst case instance of size n. We remark that T is also called the locality
or the complexity of the corresponding output distributions.
We are particularly interested in T-dependent distributions that satisfy invariance properties:
We say that a random process {Xv}v∈V over vertices of a graph G = (V, E) is invariant under
automorphisms if, for all automorphisms f : V →V of G = (V, E), the two processes {Xv}v∈V and
{Yv = Xf(v)}v∈V are equal in law. The definition is easily extendable to random processes on edges
and random processes on the whole graph.
A stronger requirement is the invariance under subgraph isomorphism: Suppose we have an
outcome O : (G, x) 7→{Xv}v∈V (G) that maps each input graph G from family of graphs F and any
input data x to a T = T(G, x)-dependent distribution over G from a family of random process R. We
say that the random process over vertices in R are invariant under subgraph isomorphisms if, given
any two graphs G1, G2 ∈F of size n1, n2 with associated process {X(1)
v }v∈V (G1) and {X(2)
v }v∈V (G2),
and any two subgraphs H1 ⊆G1, H2 ⊆G2 such that G1[NT(n1)(H1)] and G2[NT(n2)(H2)] are
isomorphic (with the isomorphism that brings H1 into H2), then {X(1)
v }v∈V (H1) and {X(2)
v }v∈V (H2)
are equal in law.2 Trivially, invariance under subgraph isomorphisms implies invariance under
automorphisms and the non-signaling property. This definition is again easily extendable to the case
of families of random processes over edges or over graphs in general.
The baseline of our result is a finitely-dependent distribution provided by [45, 47] on paths and
cycles.
Theorem 6.2 (Finitely-dependent coloring of the integers and of cycles [45, 47]). Let G = (V, E) be
a graph that is either a cycle with at least 2 nodes or has V = Z and E = {{i, i + 1} : i ∈Z}. For
(k, q) ∈{(1, 4), (2, 3)}, there exists a k-dependent distribution {X(G)
v
}v∈V (G) that gives a q-coloring
of G. Furthermore, such distributions can be chosen to meet the following properties: If {Xi}i∈[n] is
the k-dependent q-coloring of the n-cycle and {Yi}i∈Z is the k-dependent q-coloring of the integers,
then {Xi}i∈[n−k] is equal in law to {Yi}i∈[n−k]. If n = 2, then the finitely-dependent colorings on the
2-cycle and on a path of 2 nodes are identical in distribution.
It is immediate that the disjoint union of any number of paths and cycles (even countably many)
admits such distributions as well.
Corollary 6.3. Let F be the family of graphs formed by the disjoint union (possibly uncountably
many) paths with countably many nodes and cycles of any finite length. For all G ∈F and for
(k, q) ∈{(1, 4), (2, 3)}, there exists a k-dependent distribution {X(G)
v
}v∈V (G) that gives a q-coloring
of G. Furthermore, such distributions can be chosen to meet all the following properties:
1. On each connected component H ⊆G, {X(G)
v
}v∈V (H) is given by Theorem 6.2.
2. {{X(G)
v
}v∈V (G)}G∈F is invariant under subgraph isomorphisms.
2We remark that, as opposed to Definition 5.2, the isomorphism must preserve the input but not the node identifiers.
24

--- Page 26 ---
We will use this result to provide “fake local identifiers” to the nodes of the graph to simulate an
O(log∗n)-round LOCAL algorithm through a random process with constant dependency. In order
to do that, we introduce some results on the composition of T-dependent distributions.
Trivially, every T-round (deterministic or randomized) port-numbering algorithm defines a 2T-
dependent distribution over the input graph. Furthermore, if the underlying port-numbering model
has access to random bits, the distribution can be made invariant under subgraph isomorphisms
(provided that, whenever a distribution over input labelings is given together with the input graph,
such distribution is also invariant under subgraph isomorphisms). The composition of the T2-
dependent distribution obtained by a T2-round port-numbering algorithm and any T1-dependent
distribution yields a (2T2 + T1)-dependent distribution.
Lemma 6.4. Let Σ(1) and Σ(2) be two label sets with countably many labels. Let F be any family of
graphs, and let R = {{Xv}v∈V (G) : G ∈F} be a family of T1-dependent distributions taking values in
Σ(1), where T1 might depend on parameters of G. Consider any T2-round port-numbering algorithm
A that takes as an input G ∈F labelled by {Xv}v∈V (G): it defines another distribution {Yv}v∈V (G)
taking values in some label set Σ(2). Then, the following properties hold:
1. {Yv}v∈V (G) is a (2T2 + T1)-dependent distribution on G.
2. If the processes in R are invariant under subgraph isomorphisms, T2 is constant, and A does
not depend on the size of the input graph and permutes port numbers locally u.a.r. at round 0,
then the processes in {{Yv}v∈V (G) : G ∈F} are invariant under subgraph isomorphisms.
Proof. We prove the claim 1 first. Fix any G = (V, E) ∈F, and the corresponding T2-dependent
distribution {Xv}v∈V ∈R. Fix any two subsets S, S′ ⊆V such that distG(S, S′) > 2T2 + T1.
Consider any output labeling λ(2) : V →Σ(2). Then,
Pr
h
∩v∈S∪S′{Yv = λ(2)(v)}
i
=
X
λ(1) : V →Σ(1)
Pr
h
∩v∈S∪S′{Yv = λ(2)(v)}
∩v∈V {Xv = λ(1)(v)}
i
· Pr
h
∩v∈V {Xv = λ(1)(v)}
i
=
X
λ(1) : V →Σ(1)
Pr
h
∩v∈S∪S′{Yv = λ(2)(v)}
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
(3)
· Pr
h
∩v∈V {Xv = λ(1)(v)}
i
=
X
λ(1) : NT2(S∪S′)→Σ(1)
Pr
h
∩v∈S∪S′{Yv = λ(2)(v)}
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
· Pr
h
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
,
where Eq. (3) holds because the output of {Yv}v∈S∪S′ is independent of {Xv}v /∈NT2(S∪S′). Since
distG(S, S′) > 2T2,
X
λ(1) : NT2(S∪S′)→Σ(1)
Pr
h
∩v∈S∪S′{Yv = λ(2)(v)}
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
· Pr
h
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
25

--- Page 27 ---
=
X
λ(1) : NT2(S∪S′)→Σ(1)
Pr
h
∩v∈S{Yv = λ(2)(v)}
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
· Pr
h
∩v∈S′{Yv = λ(2)(v)}
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
· Pr
h
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
=
X
λ(1) : NT2(S∪S′)→Σ(1)
Pr
h
∩v∈S{Yv = λ(2)(v)}
∩v∈NT2(S){Xv = λ(1)(v)}
i
· Pr
h
∩v∈S′{Yv = λ(2)(v)}
∩v∈NT2(S′){Xv = λ(1)(v)}
i
· Pr
h
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
.
Now observe that distG(NT2(S), NT2(S′)) > T1. Since {Xv}v∈V is a T1-dependent distribution, it
holds that
X
λ(1) : NT2(S∪S′)→Σ(1)
Pr
h
∩v∈S{Yv = λ(2)(v)}
∩v∈NT2(S){Xv = λ(1)(v)}
i
· Pr
h
∩v∈S′{Yv = λ(2)(v)}
∩v∈NT2(S′){Xv = λ(1)(v)}
i
· Pr
h
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
=
X
λ(1) : NT2(S∪S′)→Σ(1)
Pr
h
∩v∈S{Yv = λ(2)(v)}
∩v∈NT2(S){Xv = λ(1)(v)}
i
· Pr
h
∩v∈S′{Yv = λ(2)(v)}
∩v∈NT2(S′){Xv = λ(1)(v)}
i
· Pr
h
∩v∈NT2(S){Xv = λ(1)(v)}
i
Pr
h
∩v∈NT2(S′){Xv = λ(1)(v)}
i
= Pr
h
∩v∈S{Yv = λ(2)(v)}
i
· Pr
h
∩v∈S′{Yv = λ(2)(v)}
i
.
We now prove claim 2. Given any G, H ∈F of size nG and nH, respectively, consider any
subgraph isomorphism f : N2T2+T1(nG)(G′, G) →N2T2+T1(nH)(H′, H) for any two G′ ⊆G, H′ ⊆H
such that f restricted to G′ is an isomorphism to H′. Let {X(G)
v
}v∈V (G) and {X(H)
v
}v∈V (H), and
{Y (G)
v
}v∈V (G) and {Y (H)
v
}v∈V (H) be the corresponding distributions of interest before and after the
combination with the port-numbering algorithm, respectively. Fix any subset of nodes U ⊆V (G′)
and consider any family of labels {λu}u∈U indexed by U. In order to prove property 1, it is sufficient
to show that
Pr
h
∩u∈U{Y (G)
u
= λu}
i
= Pr
h
∩u∈U{Y (H)
f(u) = λu}
i
.
Notice that Pr [∩u∈U{Yu = λu}] depends solely on the graph G[NT2(U, G)] = ∪u∈UG[NT2(u, G)],
the distribution of the port numbers in G[NT2(U, G)], and the random process {Xu}u∈NT2(U). By
hypothesis, {X(G)
u
}u∈NT2(U,G) is equal in law to {X(H)
f(u)}u∈NT2(U,G). Furthermore, the restriction
of f to G[NT2(U, G)] defines an isomorphism from G[NT2(U, G)] to H[NT2(f(U), H)], hence the
distribution of the port numbers in G[NT2(U, G)] is the same as that in H[NT2(f(U), H)] because
each node permutes the port numbers locally u.a.r. Thus, Pr
h
∩u∈U{Y (G)
u
= λu}
i
must be the same
as Pr
h
∩u∈U{Y (H)
f(u) = λu}
i
.
26

--- Page 28 ---
T-dependent distributions over different graphs can be combined to obtain a T-dependent
distribution over the graph union.
Lemma 6.5. Let {Xv}v∈V1 and {Yv}v∈V2 be a T1-dependent distribution over a graph G1 = (V1, E1)
taking values in Σ(1) and a T2-dependent distribution over a graph G2 = (V2, E2) taking values
in Σ(2), respectively. Assume {Xv}v∈V1 and {Yv}v∈V2 to be independent processes. Consider the
graph H = (V = V1 ∪V2, E = E1 ∪E2) and a distribution {Zv}v∈V over H taking values in
Σ = (Σ(1) ∪{0}) × (Σ(2) ∪{0}) defined by
Zv =





(Xv, 0)
if v ∈V1 \ V2,
(Xv, Yv)
if v ∈V1 ∩V2,
(0, Yv)
if v ∈V2 \ V1.
Then, {Zv}v∈V is max(T1, T2)-dependent.
Proof. For any vector v ∈Σ1 × · · · × Σn, we write v[i] to denote its i-th entry. Fix any output
labeling λ : V →Σ such that λ(v)[2] = 0 for all v ∈V1 \ V2 and λ(v)[1] = 0 for all v ∈V2 \ V1.
Observe that for any subset S ⊆V it holds that
Pr [∩v∈S{Zv = λ(v)}]
= Pr [(∩v∈S∩V1{Xv = λ(v)[1]}) ∩(∩v∈S∩V2{Yv = λ(v)[2]})]
= Pr [∩v∈S∩V1{Xv = λ(v)[1]}] · Pr [∩v∈S∩V2{Yv = λ(v)[2]}] ,
(4)
where the latter equality follows by independence between {Xv}v inV1 and {Yv}v inV2. W.l.o.g.,
suppose T1 ≥T2. Consider two subsets S, S′ ⊆V such that distG(S, S′) > T1. Fix any output
labeling λ : V →Σ such that λ(v)[2] = 0 for all v ∈V1 \ V2 and λ(v)[1] = 0 for all v ∈V2 \ V1. Using
Eq. (4), we have that
Pr [∩v∈S∪S′{Zv = λ(v)}]
= Pr

∩v∈(S∪S′)∩V1{Xv = λ(v)[1]}

· Pr

∩v∈(S∪S′)∩V2{Yv = λ(v)[2]}

= Pr

∩v∈(S∩V1)∪(S′∩V1){Xv = λ(v)[1]}

· Pr

∩v∈(S∩V2)∪(S′∩V2){Yv = λ(v)[2]}

= Pr [∩S∩V1{Xv = λ(v)[1]}] · Pr [∩S′∩V1{Xv = λ(v)[1]}]
(5)
· Pr [∩S∩V2{Yv = λ(v)[2]}] · Pr [∩S′∩V2{Yv = λ(v)[2]}]
= Pr [(∩v∈S∩V1{Xv = λ(v)[1]}) ∩(∩v∈S∩V2{Yv = λ(v)[2]})]
(6)
· Pr [(∩v∈S′∩V1{Xv = λ(v)[1]}) ∩(∩v∈S′∩V2{Yv = λ(v)[2]})]
= Pr [∩v∈S{Zv = λ(v)}] · Pr [∩v∈S′{Zv = λ(v)}] ,
where Eq. (5) holds because {Xv}v∈V1 is T1-dependent and {Yv}v∈V2 is T2-dependent, while Eq. (6)
holds because {Xv}v∈V1 and {Yv}v∈V2 are independent.
Now we present a final lemma on the composition of random processes. To do so, we first
introduce the notation of random decomposition of a graph.
Definition 6.6 (Random decomposition). Let G = (V, E) be any graph and P a family of subgraphs
of G. For any k ∈N, let Γ(G) be a random variable taking values in Pk that is sampled according
to any probability distribution. We say that Γ(G) is a random k-decomposition of G in P.
27

--- Page 29 ---
Given a random k-decomposition Γ(G) of G in P, for any y ∈V ∪E, we define the random
variable Γ(G)y ∈{0, 1}k as follows: Γ(G)y[i] = 1 if y belongs to Γ(G)[i] and 0 otherwise. Notice that
{Γ(G)y}y∈V ∪E is a random process on G. If {Γ(G)y}y∈V ∪E is invariant under automorphisms, then
we say that the random k-decomposition Γ(G) is invariant under automorphisms. If, for a family
of graphs F and any graph G ∈F, {Γ(G)y}y∈V (G)∪E(G) is T-dependent (with T being a function
of the size of G) and the processes in {{Γ(G)y}y∈V (G)∪E(G) : G ∈F} are invariant under subgraph
isomorphisms, then we say that the random k-decompositions in {Γ(G) : G ∈F} are T-dependent
and invariant under subgraph isomorphisms.
For a random decomposition, we define the notion of induced random process.
Definition 6.7 (Induced process). Let G = (V, E) be a graph that admits a family of subgraphs P.
Suppose there exists a random process {Xv}v∈V (H(P)) with H(P) being the graph obtained by the
disjoint union of all elements of P. Let Γ(G) be a random k-decomposition of G in P. For all v ∈V
and G′ ∈P, define the random process {X(G′)
v
}v∈V by setting X(G′)
v
= XfG′(v) for all v ∈V (G′),
where fG′ : V (G′) →V (H(P)) is the natural immersion of G′ into H(P) otherwise set X(G′)
v
= 0.
Let {Y (Γ(G))
v
}v∈V be a random process that we define conditional on the output of Γ(G): for all
G ∈Pk, conditional on Γ(G) = G,
Y (Γ(G))
v
= Y (G)
v
= (X(G[1])
v
, . . . , X(G[k])
v
).
The random process {Y (Γ(G))
v
}v∈V on G is said to be induced by the action of {Xv}v∈V (H(P)) over
the random k-decomposition Γ(G).
Now we present a result on the induced random process whenever the random decomposition
and the family of random processes that acts on the random decomposition meet some invariance
properties.
Lemma 6.8. Let F be a family of graphs. For any G = (V, E) ∈F, let PG be any family of
subgraphs of G that is closed under node removal and disjoint graph union, that is, if G1, G2 ∈
PG and V (G1) ∩V (G2) = ∅, then G1 ∪G2 ∈PG. Furthermore, suppose that, for each pair of
isomorphic subgraphs G1, G2 ⊆, G1 ∈PG
=⇒
G2 ∈PG.
Moreover, let Γ(G) be a random
k-decomposition of G in PG that is T1-dependent, and suppose that the random decompositions
in {Γ(G) : G ∈F} are invariant under subgraph isomorphism. Suppose there is T2-dependent
distribution {Xv}v∈V (H(PG)), taking values in a finite set Σ, such that {{Xv}v∈V (H(PG)) : G ∈F} is
invariant under subgraph isomorphism, where H(PG) is obtained by the disjoint union of a copy of each
element of PG. Let {Y (Γ(G))
v
}v∈V (G) be the random process induced by the action of {Xv}v∈V (H(PG))
over Γ(G). Then, {Y (Γ(G))
v
}v∈V (G) is a (T1 +2T2)-dependent distribution. Furthermore, the processes
in {{Xv}v∈V (H(PG)) : G ∈F} are invariant under subgraph isomorphism.
Proof. Fix G ∈F and let Γ = Γ(G), P = PG. Since Pk might be uncountable, we consider the
density function fΓ and the probability measure P associated to Γ. Consider two subsets of nodes
S, S′ ⊆V at distance at least max(T1, T2) + 1. Fix any labeling λ : V →Σk. It holds that
Pr
h
∩v∈S∪S′{Y (Γ)
v
= λ(v)}
i
=
Z
Pk Pr
h
∩v∈S∪S′{Y (Γ)
v
= λ(v)}
 Γ = G
i
fΓ(G) dP
(7)
=
Z
Pk Pr
h
∩v∈S∪S′{Y (G)
v
= λ(v)}
i
fΓ(G) dP
28

--- Page 30 ---
=
Z
Pk Pr

∩v∈S{Y G
v
= λ(v)}

Pr

∩v∈S′{Y G = λ(v)}

fΓ(G) dP
(8)
=
Z
Pk
Y
i∈[k]
Pr
h
∩v∈S{XG[i]
v
= λ(v)[i]}
i
Pr
h
∩v∈S′{XG[i]
v
= λ(v)[i]}
i
fΓ(G) dP ,
(9)
where Eq. (7) holds by the law of total probability, Eq. (8) holds since {Y (G)
v
}v∈V is T2-dependent
for all G ∈Pk by Lemma 6.5, and Eq. (9) holds since {XG[i]
v
}v∈V and {XG[j]
v
}v∈V are independent
if i ̸= j. Notice that, for any set S ⊆V , G′ = G[i][NT2(S, G[i])] ∈P and the event ∩v∈S{XG[i]
v
=
λ(v)[i]} has the same probability as ∩v∈S{XG′
v
= λ(v)[i]} because {Xv}v∈V (H(P)) is invariant under
subgraph isomorphisms.
For any subset U ⊆V and any integer T ≥0, let
H(T, U) =
n
(G[1][NT (U, G[1])], . . . , G[k][NT (U, G[k])])
 G ∈Pko
⊆Pk,
and let P[H(T, U)] be the restriction of P to H(T, U) defined as follows: for any event E,
P[H(T, U)](E) = P(E ∩H(T, U))/P(H(T, U)).
Finally, define the random variable Γ(T,U) to be a k-dimensional vector, taking values in H(T, U),
whose i-th entry is Γ[i][NT (U, Γ[i])], and let fΓ(T,U) be its density function. Define U = S ∪S′:
Eq. (9) becomes
Z
Pk
Y
i∈[k]
Pr
h
∩v∈S{XG[i]
v
= λ(v)[i]}
i
Pr
h
∩v∈S′{XG[i]
v
= λ(v)[i]}
i
fΓ(G) dP
(10)
=
Z
H(T2,U)
Y
i∈[k]
Pr
h
∩v∈S{XH[i]
v
= λ(v)[i]}
i
Pr
h
∩v∈S′{XH[i]
v
= λ(v)[i]}
i
fΓ(T2,U)(H) dP[H(T2, U)] .
Now notice that, since the random decomposition Γ is T1-dependent and distG(S, S′) > T1 + 2T2,
the probability space H(T2, U) (with measure P[H(T2, U)]) is isomorphic to the product space
H(T2, S) × H(T2, S′) (with product measure P[H(T2, S)] × P[H(T2, S′)]). The isomorphism brings
any element
(G[1][NT2(U, G[1])], . . . , G[k][NT2(U, G[k])])
of H(T2, U) into
 (G[1][NT2(S, G[1])], . . . , G[k][NT2(S, G[k])]), (G[1][NT2(S′, G[1])], . . . , G[k][NT2(S′, G[k])])

which belongs to H(T2, S) × H(T2, S′). Hence, we get
Z
H(T2,U)
Y
i∈[k]
Pr
h
∩v∈S{XH[i]
v
= λ(v)[i]}
i
Pr
h
∩v∈S′{XH[i]
v
= λ(v)[i]}
i
fΓ(T2,U)(H) dP[H(T2, S)]
=
Z
H(T2,S)
Z
H(T2,S′)
Y
i∈[k]
Pr
h
∩v∈S{XH[i]
v
= λ(v)[i]}
i
Pr
h
∩v∈S′{XH[i]
v
= λ(v)[i]}
i
· fΓ(T2,S)(H1)fΓ(T2,S′)(H2) dP[H(T2, S)] dP[H(T2, S′)] .
The latter becomes
Z
H(T2,S)
Z
H(T2,S′)
Y
i∈[k]
Pr
h
∩v∈S{XH[i]
v
= λ(v)[i]}
i
Pr
h
∩v∈S′{XH[i]
v
= λ(v)[i]}
i
29

--- Page 31 ---
· fΓ(T2,S)(H1)fΓ(T2,S′)(H2) dP[H(T2, S)] dP[H(T2, S′)]
=
Z
H(T2,S)
Y
i∈[k]
Pr
h
∩v∈S{XH[i]
v
= λ(v)[i]}
i
fΓ(T2,S)(H1) dP[H(T2, S)]
·
Z
H(T2,S′)
Y
i∈[k]
Pr
h
∩v∈S′{XH[i]
v
= λ(v)[i]}
i
fΓ(T2,S′)(H2) dP[H(T2, S′)]
=
Z
Pk
Y
i∈[k]
Pr
h
∩v∈S{XG[i]
v
= λ(v)[i]}
i
fΓ(G) dP
(11)
·
Z
Pk
Y
i∈[k]
Pr
h
∩v∈S′{XG[i]
v
= λ(v)[i]}
i
fΓ(G) dP
= Pr
h
∩v∈S{Y (Γ(G))
v
= λ(v)}
i
Pr
h
∩v∈S′{Y (Γ(G))
v
= λ(v)}
i
,
where Eq. (11) follows by the same reasoning as for Eq. (10) but in reverse.
Now we want to prove that {{Y (Γ(G))
v
}v∈V : G ∈F} is invariant under subgraph isomorphism.
Fix any two graphs G, H ∈F of sizes nG and nH, respectively. Consider any isomorphism α
between the radius-(T1(nG) + 2T2(nG)) neighborhoods of any subgraph G′ ⊆G and the radius-
(T1(nH)+2T2(nH)) neighborhoods of any subgraph H′ ⊆H, such that the restriction of α to G′ is an
isomorphism to H′. With an abuse of notation, for any subgraph K ⊆G′, let us denote α(K) ⊆H′
its isomorphic image in H′ through α. Let TG = T1(nG) + 2T2(nG) and TH = T1(nH) + 2T2(nH).
Fix any labeling λ : V →Σk. We have that
Pr
h
∩v∈V (G′){Y (Γ(G))
v
= λ(v)}
i
=
Z
Pk
G
Pr
h
∩v∈V (G′){Y (Γ(G))
v
= λ(v)}
 Γ(G) = G
i
fΓ(G)(G) dPG .
=
Z
Pk
G
Pr
h
∩v∈V (G′){Y (G)
v
= λ(v)}
i
fΓ(G)(G) dPG
=
Z
Pk
G
Y
i∈[k]
Pr
h
∩v∈V (G′){X(G[i])
v
= λ(v)[i]}
i
fΓ(G)(G) dPG
=
Z
HG(TG,V (G′))
Y
i∈[k]
Pr
h
∩v∈V (G′){X(H[i])
v
= λ(v)[i]}
i
fΓ(G)(TG,V (G′))(H) dPG(HG(TG, V (G′)))
=
Z
HG(TG,V (G′))
Y
i∈[k]
Pr
h
∩v∈V (G′){X(α(H[i]))
α(v)
= λ(v)[i]}
i
fΓ(G)(TG,V (G′))(H) dPG(HG(TG, V (G′))) ,
where the latter holds because
Pr
h
∩v∈V (G′){X(H[i])
v
= λ(v)[i]}
i
= Pr
h
∩v∈V (G′){X(α(H[i]))
α(v)
= λ(v)[i]}
i
as {{Xv}v∈V (H(PG)) : G ∈F} is T2-dependent and invariant under subgraph isomorphism. Further-
more, since the processes in {Γ(G) : G ∈F} are T1-dependent and invariant under subgraph isomor-
phism, we have that fΓ(G)(TG,V (G′))(H) = fΓ(H)(TH ,V (H′))((α(H[1]), . . . , α(H[k]))) almost everywhere
in HG(TG, V (G′)), and that the probability space HG(TG, V (G′)) with measure dPG(HG(TG, V (G′)))
is isomorphic to HH(TH, V (H′)) with measure dPH(HH(TH, V (H′))), where the isomorphism brings
30

--- Page 32 ---
H into (α(H[1]), . . . , α(H[k])). Hence,
Z
HG(TG,V (G′))
Y
i∈[k]
Pr
h
∩v∈V (G′){X(α(H[i]))
α(v)
= λ(v)[i]}
i
fΓ(G)(TG,V (G′))(H) dPG(HG(TG, V (G′)))
=
Z
HH(TH,V (H′))
Y
i∈[k]
Pr
h
∩v∈V (H′){X(H[i])
v
= λ(v)[i]}
i
fΓ(H)(TH ,V (H′))(H) dPH(HH(TH, V (H′)))
= Pr
h
∩v∈V (H′){Y (Γ(H))
v
= λ(v)}
i
,
concluding the proof.
Remark 6.9. When the underlying graph is a directed graph, Lemma 6.8 guarantees invariance
under subgraph isomorphisms that keep edge orientation.
We are going to work on rooted pseudotrees and pseudoforests. A pseudotree is a graph that
is connected and contains at most one cycle. A pseudoforest is a graph obtained by the disjoint
union of pseudotrees; an equivalent definition of pseudoforest is a graph in which each connected
component has no more edges than vertices. Note that a pseudotree might contain multiple edges:
however, we assume it does not contain self-loops as self-loops are useless communication links in
the LOCAL model. A rooted tree is a tree where each edge is oriented and all nodes have outdegree
at most 1: it follows that all but one node have outdegree exactly 1 and one node (the root) has
outdegree 0. Trivially, a tree can be rooted by selecting one node and orienting all edges towards
it. A rooted pseudotree is a pseudotree where each edge is oriented and each node has outdegree at
most 1: if the pseudotree contains a cycle, then all nodes necessarily have outdegree exactly 1. Any
pseudotree can be oriented so that it becomes rooted: just orient the cycle first (if it exists) in a
consistent way, then remove it, and make the remaining trees rooted at nodes that belonged to the
cycle. A rooted pseudoforest is the union of rooted pseudotrees.
We will show that pseudoforests of maximum degree ∆admit a O(log∗∆)-dependent 3-coloring
distributions. In order to do so, we use a color reduction technique that follows by known revisions
of the Cole–Vishkin technique [29, 42].
Lemma 6.10 (port-numbering algorithm for color reduction in pseudoforests [29, 42]). Let G be
a pseudoforest with countably many nodes. Assume G is given as an input a k-coloring for some
k ≥3. There exists a deterministic port-numbering algorithm that does not depend on the size of G
and outputs a 3-coloring of G in time O(log∗k).
Now we are ready to prove our result on pseudoforests.
Lemma 6.11 (Finitely-dependent coloring of rooted pseudoforests). Let F be a family of rooted
pseudoforests of countably many nodes of maximum degree ∆. Then, there exists an outcome that
associates to each graph G ∈F a O(log∗∆)-dependent distribution on the vertices of G that gives
a 3-coloring of G. Furthermore, the family of distributions outputted by the outcome are invariant
under subgraph isomorphisms.
Proof. Let us fix the rooted pseudoforest G ∈F. Let PG be the family of all subgraphs of G formed
by the disjoint union of directed paths and cycles. Notice that PG is closed under node removal
and disjoint graph union. Furthermore, for any two pair of isomorphic subgraphs G1, G2 ⊆G,
G1 ∈PG =⇒G2 ∈PG. Let H(PG) be the graph formed by the disjoint union of a copy of each
element of PG. By Corollary 6.3, H(PG) admits a 1-dependent 4-coloring distribution {Xv}v∈H(PG)
(with colors in [4]), such that {{Xv}v∈H(PG) : G ∈F} is invariant under subgraph isomorphism.
31

--- Page 33 ---
Figure 1: A decomposition of rooted pseudoforests in directed paths and cycles: each node v colors
its indegree neighbors with a uniformly sampled permutation of the elements in [indeg(v)]. The
graph induced by nodes colored with color i is a disjoint union of directed paths and cycles.
Consider now a (non-proper) coloring of the pseudoforest in which each node u colors its indegree
neighbors with a permutation of {1, . . . , indeg(u)} sampled uniformly at random: if a node has
outdegree zero, then it is deterministically colored with color 1. Such a coloring is described by a
2-dependent distribution {Zv}v∈V that is (trivially) invariant under subgraph isomorphisms that
keep edge orientation. Also, {Zv}v∈V identifies ∆in disjoint random subset of nodes V1, . . . , V∆in,
where nodes in Vi are colored with the color i, and ∆in is the maximum indegree of the graph.
Let Γ(G) = (G[V1], . . . , G[V∆in]), where Γ(G)[i] is the random graph induced by Vi. Furthermore,
observe that, the output of Γ(G)[i] is the disjoint union of oriented paths and/or oriented cycles,
with Γ(G)[i] being the i-th entry of the ∆in-tuple Γ(G) (see Fig. 1). Notice that process Γ(G) is
2-dependent and is a random ∆in-decomposition of G in PG (according to Definition 6.6), such
that the random decompositions in {Γ(G) : G ∈F} are invariant under subgraph isomorphism. By
Lemma 6.8, the random process {Y (Γ(G))
v
}v∈V , that is induced by the action of {Xv}v∈H(PG) over
the random ∆in-decomposition Γ(G) (according to Definition 6.7), is a 4-dependent distribution that
gives a 4∆in-coloring of G: in fact, Γ(G)[i] and Γ(G)[j] are disjoint if i ̸= j, hence only one entry of
Y (Γ(G))
v
is non-zero, for all v ∈V .
We then combine {Y (Γ(G))
v
}v∈V and a modified version of the port-numbering algorithm from
Lemma 6.10 where at round 0 each node permutes port numbers locally u.a.r.: by Lemma 6.4, we
obtain an O(log∗∆)-dependent 3-coloring distribution {Q(G)
v
}v∈V (G) of G such that processes in
{{Q(G)
v
}v∈V (G) : G ∈F} are invariant under subgraph isomorphisms.
Our finitely-dependent coloring of pseudoforests can be used as a baseline to provide a (∆+ 1)-
coloring of graphs with maximum degree ∆.
The tool we use is again an application of the
Cole–Vishkin color reduction technique [56].
Lemma 6.12 (port-numbering algorithm for color reduction of general graphs [56]). Let G = (V, E)
be a graph with maximum degree ∆and countably many nodes. Suppose G is given in input a k-coloring
32

--- Page 34 ---
1
2
5
4
3
6
7
1
2
5
4
3
6
7
1
1
1
1
1
1
1
2
2
2
2
2
2
2
3
3
3
3
3
4
4
5
(a) Each node v rearranges its port numbers uniformly at random.
1
2
5
4
3
6
7
1
2
5
4
3
6
7
1
2
5
4
3
6
7
1
2
5
4
3
6
7
1
2
5
4
3
6
7
H!
H"
H#
H$
H%
(b) The ∆= 5 rooted pseudoforests that we take by considering port numbers i ∈[∆].
Figure 2: A decomposition of a graph of maximum degree ∆= 5 in rooted pseudoforests: for the sake
of image clarity, we focus on the undirected case. In Fig. 2a, each node v rearranges its port-numbers
with a uniformly sampled permutation of the elements in [deg(v)]. As shown in Fig. 2b, edges
hosting port number i at some endpoint are oriented away from that port (in case both endpoints
host port number i, the edge is duplicated) and form a rooted pseudoforest.
33

--- Page 35 ---
for some k ≥∆+ 1. There exists a deterministic port-numbering algorithm that does not depend on
the size of the input graph and outputs a (∆+ 1)-coloring of G in time O
 log∗k + √∆log ∆

.
We first present a corollary of Lemma 6.12 where we characterize the combination of an input
finitely-dependent coloring distribution and the port-numbering color-reduction algorithm.
Corollary 6.13. Let G = (V, E) be a graph with maximum degree ∆and countably many nodes. Let
{Xv}v∈V be a T-dependent distribution that gives a k-coloring of G, with k ≥∆+1. Then there exists
a distribution Yvv∈V that gives a (∆+ 1)-coloring of G and is O
 log∗k + √∆log ∆+ T

-dependent.
Furthermore, if {Xv}v∈V is invariant under subgraph isomorphism, then so it is {Yv}v∈V .
Proof. We combine the distribution {Xv}v∈V with a modified version of the port-numbering algorithm
from Lemma 6.12 where at round 0 each node permutes port numbers locally u.a.r.: Lemma 6.4
implies the existence of an O
 log∗k + √∆log ∆+ T

-dependent (∆+ 1)-coloring distribution of G.
If {Xv}v∈V is invariant under subgraph isomorphism, Lemma 6.4 implies that {Yv}v∈V has the same
property.
Lemma 6.14 (Finitely-dependent coloring of bounded-degree graphs). Let F be a family of graphs
of countably many nodes and maximum degree ∆. Then, there exists an outcome that associates
to each graph G ∈F an O(√∆log ∆)-dependent distribution on the vertices of G that gives a
(∆+1)-coloring of G. Furthermore, the family of distributions outputted by the outcome are invariant
under subgraph isomorphisms.
Proof. Let us fix G = (V, E) ∈F First, if G is not directed, then duplicate each edge and give
to each pair of duplicates different orientations. Since a coloring of the original graph is a proper
coloring if and only if the same coloring is proper in the directed version, w.l.o.g., we can assume G
to be directed.
Let PG be a family of all subgraphs of G formed by rooted pseudotrees and disjoint union of rooted
pseudotrees. Notice that PG is closed under node removal and disjoint graph union. Furthermore,
for any two pair of isomorphic subgraphs G1, G2 ⊆G, G1 ∈PG =⇒G2 ∈PG. The graph H(PG)
that is the disjoint union of all elements of copies of each PG is a rooted pseudoforest of maximum
degree ∆and, by Lemma 6.11, admits a 3-coloring O(log∗∆)-dependent distribution {Xv}v∈H(PG)
such that processes in {{Xv}v∈H(PG) : G ∈F} are invariant under subgraph isomorphism.
Now, consider a process in which each node v samples uniformly at random a permutation of
a port numbering from {1, . . . , outdeg(v)} for its outgoing edges. For each i ∈[∆out], consider the
graph Gi induced by edges that host port i: notice that Gi is a rooted pseudoforest as each node
has at most one out-edge with port i. If a node has degree 0, it deterministically joins G1, which
remains a pseudoforest. The random choice of port numbering defines a random variable Γ ∈Pk
G,
where Γ[i] is the graph induced by port number i: according to Definition 6.6, we obtain a random
∆out -decomposition Γ(G) of G in PG which is 2-dependent (by construction): also, the random
decompositions in {Γ(G) : G ∈F} are invariant under subgraph isomorphisms. For an example of a
possible output of the random decomposition, see Fig. 2.
Hence, the random process {Y (Γ(G))
v
}v∈V from Definition 6.7 is well defined, and provides a
proper 3∆-coloring of G. By Lemma 6.8, the random process {Y (Γ(G))
v
}v∈V is O(log∗∆)-dependent
and, when G ∈F varies, the processes {Y (Γ(G))
v
}v∈V are invariant under subgraph isomorphisms.
By Corollary 6.13 we obtain an O(√∆log ∆)-dependent (∆+ 1)-coloring distribution on G that
is invariant under subgraph isomorphism (as G ∈F varies).
Lemma 6.14 answers an open question posed by Holroyd [44]. (See also Corollary 1.3 and the
discussion around it.)
34

--- Page 36 ---
Corollary 6.15. Let G = (V, E) be the infinite d-regular tree. There exists a finitely-dependent
distribution giving a (d + 1)-coloring of G that is invariant under automorphisms.
Proof. Finding a (d + 1)-coloring of any d-regular tree has complexity O(1) in SLOCAL; the coloring
can just be performed greedily. Lemma 6.14 yields the desired result.
Consider any graph G = (V, E). For any k ∈N+, a distance-k coloring of G is an assignment of
colors c : V →Σ such that, for each node v ∈V , all nodes in Nk(v) \ {v} = {u ∈V : distG(u, v) ≤
k} \ {v} have colors that are different from c(v).
It is well known that any LCL problem Π that has complexity O(log∗n) in the LOCAL model has
the following property: there exists a constant k ∈N+ (that depends only on the hidden constant in
O(log∗n)) such that, if the input graph is given a distance-k coloring, then Π is solvable in time
O(1) in the port-numbering model [20]. Furthermore, no knowledge of the size of the input graph is
required.
Theorem 6.16. Consider any LCL problem Π with checking radius r that has complexity T ≥r in
the LOCAL model over a family F of graphs with maximum degree ∆, where T = O(log∗n) for input
graphs of size n. For each G ∈F, there exists an O(f(∆))-dependent distribution {Y (G)
v
}v∈V (G)
that solves Π over G. Furthermore, the processes in {{Y (G)
v
}v∈V (G) : G ∈F} are invariant under
subgraph isomorphisms.
Proof. Fix G ∈F of size n. As said before, there exists a constant k ∈N+ (that depends only on the
description of the Π) such that, if the input graph is given a distance-k coloring, then Π is solvable
in time O(1) (hiding some dependence on ∆) in the port-numbering model [20]. Furthermore, no
knowledge of the size of the input graph is required. Consider the power graph Gk, where k ≥T,
defined by Gk = {V, Ek} with Ek = {{u, v} : u, v ∈V, distG(u, v) ≤k}. The maximum degree of
Gk is ∆k. By Lemma 6.14, Gk admits an O
p
k∆k log ∆

-dependent (∆k + 1)-coloring distribution
{Xv}v∈V that is invariant under subgraph isomorphisms (as G ∈F varies). Notice that such a
coloring provides a distance-k coloring for G.
Let A be the algorithm in port-numbering model that solves Π in time O(1) while given the
distance-k coloring in input. Consider a port-numbering algorithm A′ that simulates A and is defined
as follows: At round 0, A′ permutes ports locally u.a.r. Then, A′ simply simulates A using identifiers
given by the distance-k coloring and properly solves Π by the hypotheses. Notice that {Yv}v∈V , that
is, the random process induced by combining {Xv}v∈V and A′ is a O(f(∆))-dependent distribution
on G by Lemma 6.4 with the required invariance properties, and we get the thesis by choosing
k = T.
7
Simulation of online-LOCAL in SLOCAL for rooted trees
In this section, we show how to turn an online-LOCAL algorithm solving an LCL problem in rooted
forests into a deterministic SLOCAL algorithm solving the same problem. More concretely, we prove
the following theorems:
Theorem 7.1. Let Π be an LCL problem with degree constraint ∆, input label set Σin, output label
set Σout, and checking radius r > 0. In addition, let A be an online-LOCAL algorithm solving Π with
locality T(n) over rooted forests. Then the following holds:
1. If A is deterministic, then there exists a deterministic SLOCAL algorithm solving Π with locality
O(r) + T(2O(n3)).
35

--- Page 37 ---
2. If A is randomized and has success probability p(n) > 0, then there exists a deterministic
SLOCAL algorithm solving Π with locality O(r) + T(2O(n3) + 2O(2n2) · log
1
p(n)).
Theorem 7.1 implies that any randomized online-LOCAL algorithm with locality o(log log log n)
solving an LCL Π over rooted trees can be turned into an SLOCAL algorithm solving Π with locality
o(log n). Next theorem shows that, over rooted trees, the class of LCL problems with complexity
o(log n) is the same as that of LCL problems with complexity O(1).
Theorem 7.2. Let A be an SLOCAL algorithm solving an LCL problem Π that runs with locality
o(log∆n) over rooted forests of maximum degree ∆and n nodes. Then, there exists an SLOCAL
algorithm B solving Π with locality O(1).
It is folklore that any O(1)-round SLOCAL algorithm solving an LCL can be turned into an
O(log∗n)-round LOCAL algorithm solving the same LCL, implying the thesis of Theorem 1.5.
7.1
Amnesiac online-LOCAL algorithms
We start by formalizing what an online-LOCAL algorithm sees when run for a fixed number of steps
on a graph. We then define formally what we mean by amnesiac algorithms:
Definition 7.3 (Partial online-LOCAL run of length ℓ). Let G be a graph with an ordering of nodes
v1, v2, . . . , vn. Consider the subgraph Gℓ⊆G induced by the radius-T neighborhoods of the first ℓ
nodes v1, . . . , vℓ. We call (Gℓ, (v1, . . . , vℓ)) the partial online-LOCAL run of length ℓof G as this is
exactly the information that an online-LOCAL algorithm would know about G when deciding the
output for node vℓ.
We denote by the pair ( ¯Gℓ, (w1, . . . , wk)) where ¯Gℓ⊆Gℓis the connected component containing
vℓ, and (w1, . . . , wk) is the maximal subsequence of (v1, . . . , vℓ) of nodes that belong to ¯Gℓ. In such
case, k is the length of (Gℓ, (v1, . . . , vℓ))[vℓ].
Trivially, wk = vℓ.
If (Gℓ, (v1, . . . , vℓ))[vℓ] = (Gℓ, (v1, . . . , vℓ)), then we say that (Gℓ, (v1, . . . , vℓ)) is a partial one-
component online-LOCAL run of length ℓof G. In such case, we call vℓthe center of the neighborhood.
Finally, we denote by G−
ℓthe disjoint set of partial one-component online-LOCAL runs formed
by v1, . . . , vℓ−1, that is, one step shorter than Gℓ; this is exactly the information that an online-
LOCAL algorithm knows before labeling node vℓwhen (Gℓ, (v1, . . . , vℓ)) is a partial one-component
online-LOCAL run.
Definition 7.4 (Amnesiac algorithm). Let A be a deterministic online-LOCAL algorithm, and let
us fix the number of nodes to be n. We say that A is amnesiac if the following condition is met:
Consider any two graphs G, H of n nodes and any adversarial orderings of the nodes
(v1, . . . , vn) (for G) and (u1, . . . , un) (for H). Fix any pair (i, j) ∈[n]2 of indices such
that
(Gi, (v1, . . . , vi))[vi] = ( ¯Gi, (v′
1, . . . , v′
k)) and
(Hj, (u1, . . . , uj))[uj] = ( ¯Hi, (u′
1, . . . , u′
k))
and are isomorphic (with the isomorphism being order-preserving, i.e., bringing v′
h into
u′
h, for all h ∈[k]). Then the outputs of ui and vj coincide.
Intuitively, A is amnesiac if the output of A for some node v depends only on the local connected
component of the partial online local run and not anything else the algorithm has seen.
In general, an online-LOCAL algorithm uses global memory and hence it is not amnesiac.
36

--- Page 38 ---
7.2
Online to amnesiac
We are now ready to generalize the intuition we provided in Section 2.3 for turning any online-LOCAL
algorithm into an amnesiac algorithm with the cost of blowing up its locality.
Lemma 7.5. Let Π be an LCL problem with degree constraint ∆, input label set Σin and output
label set Σout. Let A be a deterministic online-LOCAL algorithm solving Π over a family F of graphs
that is closed under disjoint graph union and node/edge removal. Assume A has locality T(n) for
an n-node graph. Then there exists an amnesiac online-LOCAL algorithm A′ that solves Π on an
n-node graph in F with locality T(2O(n3)).
Proof. Let T = T(N) be the locality of the following experiment; we determine the size N of
the experiment graph later. Let Gℓbe the set of all partial one-component online-LOCAL runs
of length ℓfor n-node graphs in F (up to isomorphisms). We denote gℓ= |Gℓ| and remark that
gℓ≤g = 2n2|Σin| n. Notice that the term 22n takes into accounts not only all possible topologies (up
to isomorphisms), but also all possible orderings of the nodes: indeed, there are at most 22n directed
graphs of n nodes where the vertices are labelled with elements of [n] (which defines an ordering).
We set Nℓ= (3|Σout| ng)n−ℓ+1n.
We now adaptively construct an experiment graph H in n phases. In the first phase, we construct
N1 copies of all graphs in G1, that is, we construct N1g1 disjoint components describing all possible
isolated neighborhoods an online-LOCAL algorithm might see. We then show the centers of these
regions to A and let it label them. As there are N1 copies of each partial online local run of length
1, for each of these, say T , there exists a canonical label σT that appears at least N1/|Σout| times,
by the pigeonhole principle. We say that such online-LOCAL runs of length 1 are good, and ignore
the rest.
In each subsequent phase ℓ, we again construct Nℓcopies of all graphs in Gℓ, with the catch
that, for each graph (G, (v1, . . . , vℓ)) ∈Gℓand for each component of G−, we take the corresponding
good partial one-component online-LOCAL run from a previous phase; we defer arguing why such
good runs exist for now. Next we show node vℓto A and let it label the node. Finally, again by the
pigeonhole principle, for each partial one-component online-LOCAL run T (of length ℓ) we find a
canonical label σT that appears at least Nℓ/|Σout| times, and mark the corresponding runs as good.
Now our new online-LOCAL algorithm B works as follows: Before even processing the first node
of the input, B runs the above-described experiment by simulating A on H with locality T. Notice
that the nodes of the experiment graph will be processed according to a global ordering which is
locally consistent with that of the nodes in the single partial one-component online-LOCAL runs. We
do not care about the specific global ordering of the nodes.
When processing node v, algorithm B looks at partial one-component online-LOCAL run around
v and finds a corresponding good and unused run from the experiment graph H. Algorithm B labels
v with the good label that it found in H and marks the neighborhood in H used.
In each step, algorithm B can find such unused good neighborhoods as after the whole input
has been processed, what the algorithm has seen corresponds to a partial online-LOCAL run, and in
particular each component of this run corresponds to a partial one-component online-LOCAL run
in H. There are at most n such component. By construction, there are at least Nn copies of each
type of partial one-component runs in H. At least Nn/|Σout| ≫n of those are good, and hence
the algorithm can find good and unused neighborhoods for each of the final partial one-component
online-LOCAL runs. But as each good run in H is formed by combining only good components in
H, there must also be a good and unused partial one-component online-LOCAL run corresponding
to each processed node v. This construction ensures that B is amnesiac.
37

--- Page 39 ---
Now, by contradiction, assume that B doesn’t solve Π. Since Π is an LCL, there must be a node
v of the input graph such that the whole output in its radius-r neighborhood, with r being the
checking radius, is not admissible. However, the output of B in this neighborhood is the output of A
from the experiment graph in a partial one-component online-LOCAL run, which must be correct by
the hypothesis.
The only thing left to do is to argue that we can always find a good online-LOCAL run in the
construction and to compute the final size of the experiment graph, and hence the locality of B. We
start with the former: Consider phase ℓ. All subsequent phases contain Pn
k=ℓ+1 Nkgk graphs, the
simulation uses at most n graphs, and each of those may use at most n previously-used components.
Hence, nodes from phase ℓcan be used at most
n + n
n
X
k=ℓ+1
Nkgk ≤n + ng
n
X
k=ℓ+1
Nk ≤n +
Nℓ
2|Σout|
As n ≪Nℓ, we get that
Nℓ
|Σout| ≥n + n
n
X
k=ℓ+1
Nkgk,
that is the future phases won’t run out of components.
Finally, the size of the experiment graph is
N = n
n
X
ℓ=1
Nℓgℓ≤N0 = n(3|Σout| gn)n+1 = n2O(n3) = 2O(n3),
and it belongs to F as F is closed under disjoint graph union and node/edge removal.
The next lemma shows how to generalize the idea behind Lemma 7.5 all the way up to randomized
online-LOCAL.
Lemma 7.6. Let Π be an LCL problem with degree constraint ∆, input label set Σin and output
label set Σout. Let A be a randomized online-LOCAL algorithm solving Π over a family Fof graphs
that is closed under disjoint graph union and node and edge removals. Assume A has locality T(n)
and success probability p(n) > 0 for an n-node graph. Then there exists an amnesiac online-LOCAL
algorithm A′ that solves Π on a graph in F with n nodes with locality T(2O(n3) + 2O(2n2) · log
1
p(n)).
Note the locality is such that, if p(n) converges to 1 fast enough, then we only have a 2poly(n)
blowup in the locality (instead of a doubly-exponential one).
Proof. The main idea is to adapt the proof of Lemma 7.5. The main challenge is that the construction
of the simulation graph in the proof of Lemma 7.5 was adaptive to the output of the deterministic
online-LOCAL algorithm; however, the adversary in the randomized online-LOCAL model is oblivious
to the randomness of the algorithm. In fact only a q′ = 1/|Σout| fraction of components in each
phase of the proof of Lemma 7.5 are good, and we cannot adaptively choose to use only those.
To combat this, we modify the experiment: instead of adaptively choosing only the good
components and discarding the rest, we sample the components from the previous phases uniformly
at random without replacement. We later show that the sampled component is good with probability
at least q = q′/2. In the worst case, each component at layer Nℓmay use up to n partial one-
component online-LOCAL runs from the previous layers N1, . . . , Nℓ−1, each of which is sampled to be
good with probability only q. As the construction is n levels deep (i.e., there are n layers N1, . . . , Nn)
38

--- Page 40 ---
and the whole construction needs to work for all up to g = 2n2|Σin| n different partial one-component
online-LOCAL runs, the total probability of finding a good label in all Nℓ, ℓ∈[n], is at least qgn2.
This probability is minuscule, but we can boost it by increasing the size of the construction by
considering
k = 1 +

q−2n2|Σin|nn2 log
1
p(n)

disjoint copies of the simulation graph independently. Letting N be the size of a single simulation
graph, kN is then the size of the whole experiment. Since N = 2O(n3) in Lemma 7.5, we have
kN = 2O(n3) + 2O(2n2) log
1
p(n).
The probability that each simulation graph does not contain all the necessary good labels in all
layers is at most

1 −qgn2k
≤e−kqgn2
= e−kq2n2
|Σin|nn2
< p(n).
Since the success probability of A is p(n), by the inclusion-exclusion principle, we get positive
probability that least one simulation graph in the experiment contains all the necessary good labels
and, in addition, A does not fail on it.
We show that the probability of sampling a good component is indeed at least q = 1/(2|Σout| ).
Consider the components in phase ℓ. For each component type, there are at least Nℓ/|Σout| that are
good. By the calculations in the proof of Lemma 7.5, future layers will use at most Nℓ/(2|Σout| ) of
them. Hence, after each step, at least 1/(2|Σout| ) = q fraction of the components are still good and
unused, as desired.
We finish the proof by showing that there indeed exists an amnesiac algorithm A′ as in the claim.
As argued above, our experiment succeeds with positive probability. After fixing the randomness
f : V (H) →{0, 1}N of the algorithm A, we obtain a uniquely defined deterministic online-LOCAL
algorithm A[f] that behaves exactly as A when given the random bit string f as input. In particular,
for such f, the following holds:
1. There exists a simulation graph with the necessary number of good labels in all layers.
2. A[f] does not fail on the aforementioned simulation graph.
Now the amnesiac algorithm B works as follows: Since there are finitely many possible simulation
graphs and finitely many behaviors of A[f] (for all possible f), B executes a preprocessing phase in
which it goes over all possible simulation graphs and tries all possible deterministic online-LOCAL
algorithms (according to some ordering, e.g., lexicographical in the description) until it finds the
pair with the properties 1 and 2 above. We take such pair and use the labeling for that component
as the base for our amnesiac algorithm. Proceeding as in the proof of Theorem 7.1, we then obtain
an amnesiac algorithm that has locality
T

2O(n3) + 2O(2n2) log
1
p(n)

.
7.3
From online-LOCAL to SLOCAL
We first show how the SLOCAL model can nicely “partition” a rooted forest. The idea is not new
and comes from [23, Section 7] where it is directly applied to the LOCAL model; we present here
an adaptation to SLOCAL. The definition of rooted forest is given in Section 6. For a rooted forest
39

--- Page 41 ---
Figure 3: A (3, 4)-clustering of a rooted tree. The leader nodes are colored and their closed clusters
marked with their respective color.
G = (V, E) and each node v ∈V , we denote by Gv the subtree of G that is rooted at v. A root-to-leaf
path v0v1 . . . vk, where vi ∈V for all i ∈{0, 1, . . . , k}, is a path of a rooted tree such that (vi, vi−1)
is an edge for all i ∈[k]: we say that the path starts at v0 and ends at vk.
Definition 7.7 ((α, β)-clustering of rooted trees). Let G = (V, E) be a rooted forest. An (α, β)-
clustering of G is a subset L ⊆V of leader nodes that contains the root and is such that, for each
v ∈L, the following properties are met:
1. Gv does not contain elements of L at levels 1, . . . , α −1.
2. Each maximal oriented path in Gv contains exactly one element u ∈L such that distGv(u, v) ∈
[α, β], unless the length of the maximal oriented path is at most β −1, in which case there is
at most one element of L in the path (and possibly none).
A cluster is a maximally connected component of non-leader nodes. A closed cluster is a cluster
together with its adjacent leader nodes. See Fig. 3 for an example.
We will combine many SLOCAL algorithms: it is easy to prove that the combination of two
SLOCAL algorithms with localities T1, T2 gives an SLOCAL algorithm with locality O(T1 + T2) [38,
Lemma 2.3].
Lemma 7.8. Let α ∈N+, and let G = (V, E) be a rooted forest. There is an SLOCAL algorithm
with locality O(α) that produces an (α −1, 2α + 1)-clustering of G.
Proof. We combine some SLOCAL algorithms. Consider first the following algorithm A1: Suppose a
node v ∈V is picked by the adversary and asked to commit to something. For each root-to-leaf path
v0v1 . . . v2α−1 (with v0 = v) that v can distinguish using locality 2α −1, in parallel, v precommits
40

--- Page 42 ---
that the node vα−1 is the leader of the path vα−1vα . . . v2α−1 unless there is another precommitment
on the path within distance α from v.
Next we define an algorithm A2 that takes as input a rooted forest labelled by A1: Each node v
looks at its radius-α neighborhood and checks if there is some other (unique) node that precommitted
for v in the neighborhood. If so, it becomes a leader and stores the path that is under its leadership,
otherwise it does nothing.
The final algorithm A3 takes as input a rooted forest labelled by A2 and is defined as follows:
Each node v becomes a leader if and only if it belongs to an oriented root-to-leaf path v0v1 . . . vα−1,
with vα−1 = v lead by v0. All other nodes do not output anything, except the root, that becomes a
leader.
We now prove that the SLOCAL algorithm A providing the clustering is the composition of A1,
A2, and A3, and has locality O(α).
Notice that the root is a leader thanks to A3. Property 1 in Definition 7.7 is satisfied due to A3
as well. Furthermore, for each maximal root-to-leaf path, consecutive leader nodes must be within
distance at most 2α + 1 between each other, unless the path ends with a leaf at distance at most 2α
from the last leader. In fact, if the distance between consecutive leaders is at least 2α + 2, or there
is only one leader and the path is longer than 2α from the last leader, there would be at least one
non-leader node that does not see any leader within distance α in the path, which is impossible due
to how precommitments are done in A1.
We can now prove Theorem 7.1, which we restate here for the reader’s convenience:
Theorem 7.1. Let Π be an LCL problem with degree constraint ∆, input label set Σin, output label
set Σout, and checking radius r > 0. In addition, let A be an online-LOCAL algorithm solving Π with
locality T(n) over rooted forests. Then the following holds:
1. If A is deterministic, then there exists a deterministic SLOCAL algorithm solving Π with locality
O(r) + T(2O(n3)).
2. If A is randomized and has success probability p(n) > 0, then there exists a deterministic
SLOCAL algorithm solving Π with locality O(r) + T(2O(n3) + 2O(2n2) · log
1
p(n)).
Proof. Let G denote the input graph, which is a rooted forest, and assume A is a deterministic
online-LOCAL algorithm. We can apply Lemma 7.5 to get an amnesiac algorithm A′ that solves
Π with locality T ′(n) = T(2O(n3)). We now show how to get an SLOCAL algorithm B solving the
problem with roughly the same locality. B is the composition of four different SLOCAL algorithms
B1, B3, B3, B4, each of them having locality O(T ′):
1. We first use Lemma 7.8 with α = 10T ′ + 4r, where r is the checking radius of Π, and obtain
an algorithm B1 that outputs an (α −1, 2α + 1)-clustering of G with locality O(α).
2. Now consider an algorithm B2 with locality 2α + 4r that takes as input G as labelled by B1
and works as follows: When processing a leader node v, it collects the topology of the radius-2r
neighborhood of the set composed of the closest leaders v sees in each root-to-leaf path. Then,
v runs A′ in this neighborhood and precommits a solution to the LCL for the nodes in such
neighborhood. If v is the root, it also presents its own radius-2r neighborhood to A′ and
precommits a solution for the whole neighborhood. Observe that all such neighborhoods are
disjoint by construction of the (α −1, 2α + 1)-clustering.
3. B3 also has locality 2α + 4r and just makes all nodes whose label has been precommitted by
some other node actually output the precommitted label. (The output of B2 guarantees there
are no conflicts to be resolved.)
41

--- Page 43 ---
4. Finally, B4 has again locality 2α + 4r and just brute-forces a solution in each cluster. The
solution is guaranteed to exist because A′ was run in all disjoint neighborhoods and works
correctly. In fact, B4 can just continue calling A′ on each cluster it sees.
The combination of B1, B2, B3, and B4 yields a deterministic SLOCAL algorithm B that has
locality O(α) = O(r) + O(T ′(n)).
The same argument applies to a randomized online-LOCAL algorithm, the only change is that
now T ′ is T ′(n) = T(2O(n3) + 2O(2n2) · log
1
p(n)).
7.4
From SLOCAL to LOCAL
It is folklore that all LCL problems that have complexity O(1) in SLOCAL belong to the complexity
class O(log∗n) in LOCAL. Then, to obtain Theorem 1.5, it suffices to show that all LCLs with
complexity o(log n) in SLOCAL in rooted trees actually belong to the complexity class O(1). We
restate Theorem 7.2.
Theorem 7.2. Let A be an SLOCAL algorithm solving an LCL problem Π that runs with locality
o(log∆n) over rooted forests of maximum degree ∆and n nodes. Then, there exists an SLOCAL
algorithm B solving Π with locality O(1).
Proof. Assume Π has checking radius r ≥0, and T(n) = o(log∆n) to be the locality of A. Further-
more, w.l.o.g., suppose T(n) ≥r for all n large enough. Let N be a large enough integer such that
T(N) = k ≥r. Let G be a rooted tree of maximum degree ∆with n nodes. We now construct a
new SLOCAL algorithm B which is the composition of many SLOCAL algorithms.
For the first SLOCAL algorithm B1, we make use of Lemma 7.8 where α = ⌊(log∆N −2)/4⌋.
Hence, B1 yields an (α −1, 2α + 1)-clustering of G in time O(α), with α −1 ≥(log∆N −10)/4 and
2α + 1 ≤(log∆N)/2. Hence, any closed cluster will have at most ∆2α+1 ≤
√
N nodes (including
the adjacent leader nodes).
Then, we consider a second SLOCAL algorithm B2 that takes G and the (α −1, 2α + 1)-clustering
of G in input and reassigns identifiers from the set [N] “locally”. To better describe how B2 works,
let us define some notation. For each leader node v, let Cv denote the closed cluster where v is the
leader node of minimum level, and let Lv be the set of leader nodes in Cv except for v. Consider a
partition of the nodes in (Cv \ Nk(v)) ∪Nk(Lv) according to their distance from v. More specifically,
C(1)
v
contains all nodes that have distance between k + 1 and ⌊(α −1)/4⌋from v, while, for i ∈{2, 3},
C(i)
v
contains nodes that have distance between ⌊(α −1)/(6 −i)⌋+ 1 and ⌊(α −1)/(5 −i)⌋from v.
Finally, C(4)
v
contains all the other nodes in Cv, which have distance at least ⌊(α −1)/2⌋+ 1 from v.
Notice that |(Cv \ Nk(v)) ∪Nk(Lv)| ≤∆2α+1+k ≤∆(log∆N)/2+o(log∆N) ≤N2/3 for N large enough.
Then, B2 works as follows: When a non-leader node is picked by the adversary, nothing happens.
When a leader node v is selected, it precommits identifiers for the nodes in (Cv \ Nk(v)) ∪Nk(Lv). In
details, it assigns identifiers from 1 to ⌊N/4⌋to nodes in C(1)
v , from ⌊N/4⌋+ 1 to ⌊N/2⌋to C(3)
v , from
⌊N/2⌋+ 1 to ⌊3N/4⌋to C(2)
v , from ⌊3N/4⌋+ 1 to N to C(4)
v . Notice that, since
C(i)
v
 ≤N2/4, then
even ⌊N/5⌋distinct identifiers are enough to cover the whole region C(i)
v
when N is large enough.
Furthermore, if v is the root of the whole graph, it precommits distinct identifiers from the set
{⌊3N/4⌋+ 1, . . . , N} for the nodes that have distance at most k from v (v itself included).
The third and last SLOCAL algorithm B3 takes as input the whole rooted tree with the clustering
given by B1 and the output of leader nodes given by B2, and computes the solution to the problem
as follows: Every node u (that does not belong to Cv where v is the root of the graph) looks at its
two closest leader nodes v(1)
u
(the closest one) and v(2)
u
(the second closest one) that are ancestors
42

--- Page 44 ---
(if u is a leader, it still looks up in the tree for two different leader ancestor), and collects all the
information regarding identifiers for G[Nk(Cv(1)
u )]. In this way, u can locally simulate A on a “virtual
graph” Gu = G[Nk(Cv(1)
u )] with
Nk(Cv(1)
u )
 ≤N nodes. The adversarial ordering according to which
A processes Gu = G[Nk(Cv(1)
u )] is induced by the ordering of the identifiers. Notice that it might
still be that A processes two nodes at the same time but, due to the assignment of identifiers done
by B2, the outputs of these nodes can be determined independently of each other. Then, u outputs
whatever A outputs on u according to this simulation. If u is the root of the whole graph, then it
knows already the all the identifiers needed to run A in G[Nk(Cu)]. If u is in Cv and Cv is the cluster
of the root node of the graph, then by accessing the memory of v it gets access to all the information
it needs to compute its output.
Notice that each Bi has locality O(α), hence the whole algorithm B obtained by the composition of
B1, B2, and B3 has locality O(α) by [38, Lemma 2.3]. Observe also that O(α) = O(log∆N) = O(1).
Also, the final output of B is correct: Suppose, by contradiction, that there is a failure somewhere,
that is, a node v could detect its neighborhood Nr(v) as non-admissible. Suppose v does not belong
Cu where u is the root of the graph, and denote its two closest ancestors that are leader nodes by
v(1)
u
(the closest one) and v(2)
u
(the second closest one). We have two cases. If u ∈C(4)
v(2)
u ∪C(1)
v(1)
u ∪C(2)
v(1)
u ,
then its output must be correct: it is completely determined by G[Nk(Cv(1)
u ∩(C(4)
v(2)
u ∪C(1)
v(1)
u ∪C(2)
v(1)
u ))]
which contains only distinct identifiers (because it is a subgraph of G[C(4)
v(2)
u
∪C(1)
v(1)
u
∪C(2)
v(1)
u
∪C(3)
v(1)
u ])
and hence can be extended to a valid input for A with N nodes (choosing identifiers arbitrarily
in [N2] \ [N] and extending the adversarial processing order respecting the ordering induced by
identifiers). In the second case, u ∈C(3)
v(1)
u ∪C(4)
v(1)
u . Also in this case the output of u must be correct:
it is completely determined by G[Nk(Cv(1)
u ∩(C(3)
v(1)
u ∪C(4)
v(1)
u ))] which contains only distinct identifiers
(because it is a subgraph of G[C(2)
v(1)
u ∪C(3)
v(1)
u ∪C(4)
v(1)
u ]) and hence can be extended to a valid input for A
with N nodes (choosing identifiers arbitrarily in [N2] and extending the adversarial processing order
respecting the ordering induced by identifiers). An analogous argument holds for nodes in Cv where
v is the root node of the graph.
8
Lower bound for 3-coloring grids in randomized online-LOCAL
In this section, we will show that 3-coloring (√n × √n)-grids in randomized online-LOCAL requires
Ω(log n)-locality:
Theorem 8.1. The locality of a randomized online-LOCAL algorithm for solving 3-coloring in
(√n × √n)-grids is Ω(log n).
We will base our proof on the recent result of Chang et al. [22], where the authors show a similar
lower bound for the deterministic online-LOCAL model. We will start with a brief overview of the
techniques used in [22].
8.1
Relevant ideas from Chang et al. [22]
The lower bound in [22] is based on the idea that any coloring of a grid G with the three colors
{1, 2, 3} can be partitioned into regions with colors 1 and 2 that are separated by boundaries of
color 3. Formally, a region is a maximal connected component that is colored only with colors 1 and
2, while a boundary is a maximal connected component in G2 that is colored only with color 3. It
43

--- Page 45 ---
B1
B2
1
1
1
1
1
2
2
2
2
2
2
2
2
3
3
3
3
3
u
v
Figure 4: Example of a 3-colored grid with two boundaries B1 and B2 that have different parities.
As one can see, b(u, v) = 2: No matter if we take the blue or the red path from u to v, we always
cross B1 and then B2.
is crucial to observe that the boundaries of color 3 are not always compatible and that they have
parities of their own (see Fig. 4). Indeed, the core idea of the proof is to constrict many incompatible
boundaries of color 3 to a small space, thus requiring a view of Ω(log n) to resolve them.
Using the same terminology as [22], we count incompatible boundaries between two points by
using so-called a- and b-values. The a-value is defined as an edge weight between any two nodes and
captures the change of colors 1 and 2.
Definition 8.2 (a-value [22]). Given a directed edge (u, v) and a 3-coloring of the nodes c : V 7→
{1, 2, 3}, we define
a(u, v) =
(
c(u) −c(v),
if c(u) ̸= 3 and c(v) ̸= 3
0,
otherwise.
Observe that the a-value of any directed 4-cycle in a grid is equal to 0. Using the a-value, we
define the b-value of a path.
Definition 8.3 (b-value [22]). For a directed path P, its b-value is defined as
b(P) =
X
(u,v)∈H
a(u, v).
On a high level, the b-value of a path describes the cumulative total of incompatible boundaries
along this path. Note we say “cumulative” because in this count boundaries of the same parity cancel
each other out. Indeed, if we consider the b-value of a simple directed cycle in a grid, then it must
be equal to 0:
Lemma 8.4 (b-value of a cycle is zero [22]). Let C be a directed cycle in G. Then b(C) = 0.
As an example, observe that a path that starts and ends with color 3 and otherwise is colored
with colors 1 and 2 always has a b-value of 0 or 1. In particular, the b-value is 1 if the distance
between the nodes of color 3 is even (and thus the boundaries are incompatible). Meanwhile, a path
that goes through two incompatible regions has a total b-value of 2. Nevertheless, a path going
through two boundaries that are compatible has a total b-value of 0.
44

--- Page 46 ---
Lemma 8.5 (Parity of the b-value [22]). Let P denote any directed path of length ℓthat starts in
node u and ends in node v in a grid. Then, the parity of b(P) is
b(P) ≡β(u) + β(v) + ℓ(mod 2)
where β is an indicator variable stating whether a node is of color 3 or not:
β(u) =
(
1,
if c(u) = 3
0,
otherwise.
Observe that the parity of the b-value of a path is determined by the colors of the endpoints of
this path.
8.2
From deterministic to randomized online-LOCAL
Suppose that we are given a randomized online-LOCAL algorithm with visibility radius T = o(log n).
Our goal is to prove the algorithm fails to solve the 3-coloring problem. Using Yao’s minimax
principle, we show how to construct an (oblivious) adversarial distribution of inputs so that any
deterministic online-LOCAL algorithm fails with noticeable probability.
As in [22], the lower bound consists of two main steps:
1. First we show how to force paths to have an arbitrarily large b-value. Generally we cannot
force a large b-value between the path’s endpoints (or in fact between any two fixed nodes),
but we do get the guarantee that it contains two nodes v1 and v2 where b(v1, v2) is large. Note
the location of v1 and v2 is completely unknown to us since we are working with an oblivious
adversary. The construction is inductive: Given a procedure that generates a path with b-value
≥k −1 with probability ≥1/2, we show how to generate a path with b-value ≥k also with
probability ≥1/2. (Cf. the construction in [22] with an adaptive adversary, which succeeds
every time.) Since we invoke the construction for k −1 a constant number of times, we are
able to obtain any desired b-value of k = o(log n) with high probability. Note it is logical that
we cannot do much better than this as it would contradict the existing O(log n) deterministic
online-LOCAL algorithm.
2. The second step is to actually obtain a contradiction. (See Fig. 5.) First we construct a path
P1 with large b-value, say ≫4T, between nodes us and vt. To get the contradiction, we wish
to place two nodes ws and wt next to us and vt, respectively, so that the four node cycle has
positive b-value (which is impossible due to Lemma 8.4). If we had an adaptive adversary as
in [22], this would be relatively simple: Since the adaptive adversary knows the location of
us and vt, it just constructs an arbitrary path P2 with the same size as P1, picks any two ws
and wt that are at the same distance from each other as us and vt, mirrors P2 if needed to
obtain a non-negative b-value, and then places this at minimal distance to P1. We show that,
allowing for some failure probability, we do not need any information about us and vt (i.e., nor
their location nor the distance between them) in order to obtain the same contradiction.
We now proceed with the proof as outlined above. Accordingly, the first step is the following:
Lemma 8.6. Given any k = o(log n), there is an adversarial strategy to construct a directed path of
length no(1) with a b-value of at least k against any online-LOCAL algorithm with locality T = o(log n).
Moreover, this strategy succeeds with high probability.
Proof. Consider the following recursive construction:
45

--- Page 47 ---
• If k = 0, create a single node with previously unrevealed nodes all around it (inside the visibility
radius T).
• Otherwise, repeat the following steps four times in total:
– Create four distinct paths P1, P2, P3, P4 by following the procedure for k −1.
– Toss independent fair coins c1, c2, c3 ∈{0, 1}.
– Connect the Pi’s horizontally aligned and in order while placing ci + 1 nodes between
paths Pi and Pi+1.
Let Q1, Q2, Q3, Q4 be the four paths created by this procedure (each having their own four
Pi’s coming from the procedure in the previous iteration k −1). Next, we connect the Qi’s
horizontally aligned with each other and in arbitrary order. Note that we need to place an
additional node between each pair of Qi’s. Otherwise, we would have to have revealed the
edge between the two endpoints too early to the algorithm.
Thus, for k ≥1 we have 16 invocations of the procedure for k −1 in total. We argue that, with
probability at least 1/2, the path yielded by this procedure contains a segment with b-value at least
k. By repeating this procedure O(log n) times independently, we obtain at least one path with the
desired property with high probability.
To prove that the recursive construction works, we proceed by induction. Fix k ≥1 and suppose
that the procedure for k −1 succeeds with probability p ≥1/2 at yielding a segment with b-value at
least k −1. Let us first consider Q1. Let Xi be a random variable that is 1 if this occurs for path Pi
and 0 otherwise. Then we have
Pr
" 4
X
i=1
Xi < 2
#
= Pr
" 4
X
i=1
Xi = 0
#
+ Pr
" 4
X
i=1
Xi = 1
#
= (1 −p)4 + 4p(1 −p)3
= (1 −p)3(1 + 3p)
≤1
2.
Hence, with probability at least 1/2 there are at least two paths Pi and Pj, i < j, for which the
construction succeeds.
Since we are dealing with paths, we may simplify the notation and write b(u, v) for the b-value
of the (unique) segment that starts at u and ends at v. Let thus ui, vi, uj, vj appear in this order in
Q1 and |b(ui, vi)|, |b(uj, vj)| ≥k −1. Next we will show that, conditioned on this assumption, the
probability that Q1 contains a segment with b-value at least k is at least 1/2. Hence, a priori, Q1
contains such a segment with probability at least 1/4. Since all Qi’s are constructed the in the same
way and independently of one another, the probability that at least one of the Qi’s contains such a
segment is at least 1 −(1 −1/4)4 > 1 −1/e > 1/2.
Let us write σ(x) for the sign function of x (i.e., σ(x) = 1 if x > 0, σ(x) = −1 if x < 0, and
σ(0) = 0). To see why the above holds for Q1, consider the two following cases:
Case 1: σ(b(ui, vi)) = σ(b(uj, vj)). Using Lemma 8.5, we have that b(vi, uj) ≡β(vi) + β(uj) +
ci + · · · + cj−1 (mod 2). Since β(vi) and β(uj) are fixed, and the coin tosses are independent,
we have |b(vi, uj)| ̸≡k −1 (mod 2) with probability 1/2. Assuming this holds, we have either
46

--- Page 48 ---
|b(vi, uj)| ≥k, in which case we are done, or |b(vi, uj)| ≤k −2. Since b(ui, vi) and b(uj, vj)
have the same sign, we have
|b(ui, vj)| = |b(ui, vi) + b(vi, uj) + b(uj, vj)|
≥|b(ui, vi) + b(uj, vj)| −|b(vi, uj)|
≥2(k −1) −(k −2)
= k.
Case 2: σ(b(ui, vi)) ̸= σ(b(uj, vj)). Arguing by using Lemma 8.5 as before, we obtain that
|b(vi, uj)| ̸≡0 (mod 2) holds with probability 1/2. Assuming this is the case, we have thus
|b(vi, uj)| ≥1. Without restriction, let σ(b(ui, vi)) = σ(b(vi, uj)). Then
|b(ui, uj)| = |b(ui, vi) + b(vi, uj)| ≥k −1 + 1 = k.
Finally, let us confirm that the construction fits into the (√n × √n)-grid. We only reveal at
most 2T + 1 = o(√n) in a column, so we need to only consider nodes along a row. The initial path
contains m0 = 2T + 1 visible nodes and in the i-th recursive step we have mi ≤16pi−1 + 27 visible
nodes in total for i ≥1. (Inside each Qi we need at most 2(4 −1) = 6 additional nodes to join the
four Pi’s, and to join the four Qi’s we need an additional 3 nodes.) Solving the recursion, in the
k-th step we have thus
mk = 1
5

24k+1(5T + 7) −9

= no(1)
visible nodes along the path since k, T = o(log n).
We now illustrate the idea for getting the contradiction previously described. (See Fig. 5.)
Invoking Lemma 8.6, we obtain a path P1 with a b-value of 4T + 4 between two nodes us and vt
(whose positions are unknown to us). Letting L be the length of P1, we (arbitrarily) create a second
path P2 of length 10L and then randomly choose how to align P1 and P2. More specifically, letting
u be the first node in P1, we choose some node w of P2 uniformly at random and align u and w;
then we mirror P2 with probability 1/2 and reveal it at distance 2T + 2 to P1 (which is consistent
with all previously revealed nodes).
The reason why this works is the following: Since P1 has length L and P2 length 10L, with at least
4/5 we align the paths so that each node in P1 has a matching node underneath it in P2. Let ws and
wt be the nodes matching us and vt, respectively. Then because we mirror P2 with probability 1/2,
we get that b(ws, . . . , wt) is at least zero in expectation (conditioned on having properly aligned the
two paths). Hence, with probability at least 2/5 we obtain a cycle (us, . . . , vt, . . . , wt, . . . , ws, . . . , us)
where b(us, . . . , vt) > 4T + 4, b(wt, . . . , ws) ≥0, and b(vt, . . . , wt), b(ws, . . . , us) ≥−2T −2 (due to
the distance between the two paths).
Proof of Theorem 8.1. Observe that, using Lemma 8.6, we can construct a path P1 = (u0, . . . , uL)
of length L = no(1) where some segment (us, . . . , ut) of P1 has a b-value of k > 4T + 4. Next we
construct a path P2 = (v0, . . . , v10L) of length 10L that will be placed below P1. We assume that
the points of the path are revealed to the algorithm in some predefined order.
The position and orientation of P2 are chosen as follows:
1. Choose a node vr ∈[L, 9L] of P2 uniformly at random. This node is placed below the node u0
of P1 at 2T + 2 distance from it.
2. Throw a fair coin m ∈{0, 1}. If m = 1, mirror P2 along the vertical axis that goes through u0
and vr.
47

--- Page 49 ---
v0
vr
ws
wt
v10L
u0
us
ut
uL
P2
P1
b(us, . . . , ut) ≥k
b(wt, . . . , ws) ≥0
T
T
2T + 1
Figure 5: How to turn paths with large b-value into a contradiction. Here the blue area includes
the nodes revealed so far around the path segments (u0, . . . , uL) and the corresponding part of P2
underneath it. The green segments are the two segments we consider in the proof. A cycle going
through both paths leads to a contradiction.
The nodes of P2 are revealed to the algorithm in the same predefined and possibly mirrored order.
See Fig. 5 for an example.
We next prove that we obtain the desired lower bound. First notice that, since we pick vr ∈[L, 9L],
every node in P1 has a counterpart in P2 whether we mirror P2 or not. Let (ws, . . . , wt) denote the
segment matched to (us, . . . , ut). Consider the case where either of the following is true:
• m = 0 and r ∈[L, 9L −s −t]
• m = 1 and r ∈[L + s + t, 9L]
Denoting by E the event in which this occurs, note we have
Pr[E] = 1
2 Pr[r ∈[L, 9L −s −t]] + 1
2 Pr[r ∈[L + s + t, 9L]] = 8L −s −t + 1
9L + 1
≥6L + 1
9L + 1 > 2
3.
Now conditioned on E, notice that every segment (vx, . . . , vy) where x ∈[L + s, 9L −s] and
y ∈[L + t, 9L −t] has equal probability of being matched with (us, . . . , ut) either in the same
direction (i.e., ws = vx and ut = vy) or reversed (i.e., ws = vy and wt = vx). Hence,
Pr[b(wt, . . . , ws) ≥0 | E] ≥1
2.
(In fact, the probability is exactly 1/2 if b(wt, . . . , ws) > 0 and 1 if b(wt, . . . , ws) = 0.) Thus, the
probability that b(wt, . . . , ws) ≥0 is > (2/3) · (1/2) = 1/3.
From here on, we proceed as in [22]. By Lemma 8.4, the cycle (us, . . . , ut, . . . , wt, . . . , ws, . . . , us)
must have a b-value of 0. However, recall that the b-value of a path is bounded by its length by
definition. In our case, −2T −2 < b(ut, . . . , wt) < 2T + 2, −2T −2 < b(ws, . . . , us) < 2T + 2,
b(us, . . . , ut) ≥k, and b(wt, . . . , ws) ≥0. In order for the b-value of the cycle to be 0, we would need
to have 2(2T + 2) ≥k, which is a contradiction. Since this occurs with noticeable probability (i.e.,
> 1/3), the claim follows.
9
Dynamic-LOCAL derandomizes LOCAL and breaks symmetry
This section presents a derandomization result for the dynamic-LOCAL model: we show that not
only dynamic-LOCAL can simulate randomized LOCAL with no overhead in the locality, but actually
it brings the complexity class O(log∗n) in randomized LOCAL down to O(1).
48

--- Page 50 ---
We make use of the method of conditional expectations from [39] to derandomize the model of
dynamic-LOCAL computation. We note that while the following theorems are proven for the class of
all graphs, they can be extended to any subclass of graphs.
Theorem 9.1. Let Π be an LCL problem, and let A be a randomized LOCAL algorithm solving Π
with locality T(n) and probability p > 1 −1/n. Then there exists a deterministic dynamic-LOCAL
algorithm A′ solving Π with locality O(T(n)).
Proof. The randomized LOCAL algorithm A can be viewed as a deterministic LOCAL algorithm
which is given i.i.d. random variables Rv locally for each node v. We show that there exists a
dynamic-LOCAL algorithm with locality O(T(n)) that assigns fixed values ρv for each Rv such
that when A is run on these values as Rv, it produces a correct output for problem Π. Such
dynamic-LOCAL clearly implies an O(T(n))-locality dynamic-LOCAL algorithm for problem Π as
one can compose it with A. The proof uses a technique similar to that of derandomizing LOCAL
algorithms in SLOCAL [39].
We use the method of conditional expectation. Let Fv be a flag that is 1 when the output around
node v is invalid, and 0 otherwise. Note that Fv depends only on the radius-r neighborhood of
node v. Let F = P
v∈V Fv. As Π is an LCL problem, F = 0 iff the labeling is correct for the whole
graph, and otherwise F ≥1. By definition, E[F] = P
v∈V E[Fv] ≤n(1 −p) < 1.
Let σ = e1, e2, . . . , em be the order of edges in which the adversary dynamically modifies the
graph, and let Gi be the graph after modification i. Note that any edge can appear multiple times
in the sequence if the adversary also removes edges.
Now algorithm A′ sets the randomness as follows: In step i, algorithm A′ first clears ρu for all
nodes u with dist(u, ei) ≤T(n) + r. Then
E[F |
^
u,dist(u,ei)>T(n)+r
Ru = ρu] < 1
as
E[F |
^
u
Ru = ρu] < 1
in the previous step. Hence, there exists some concrete values for ρu for dist(u, ei) ≤T(n) + r such
that E[F | V
u Ru = ρu] < 1. Algorithm A′ sets all ρu to such values. Finally, algorithm A′ simulates
A for all nodes within radius T(n) + r from ei with randomness fixed at ρ.
This produces a correct labeling for all nodes as E[F | V
u Ru = ρu] < 1, and hence
E[F |
^
u
Ru = ρu] = 0.
Theorem 9.2. Let Π be an LCL problem, and let there exist a randomized LOCAL algorithm solving
it with locality O(log∗n). Then there exists a dynamic-LOCAL algorithm solving Π with locality O(1).
Proof. Using [21], a randomized LOCAL algorithm for solving Π with locality O(log∗n) implies the
existence of a deterministic LOCAL algorithm solving Π with locality O(log∗n). Moreover, the
deterministic LOCAL algorithm can be normalized into an algorithm that first finds a distance-k
coloring with O(∆k) colors for some constant k, and then applies an O(k)-locality LOCAL algorithm
A on this coloring.
The dynamic-LOCAL algorithm for solving Π maintains a distance-k coloring with O(∆k) colors
on the graph, and then applies A on these colors. When the dynamic-LOCAL algorithm encounters
an update, it first clears the colors of all nodes within distance k from the update, and greedily
49

--- Page 51 ---
assigns new colors for those nodes. The greedy assignment always succeeds since each node can
have at most ∆k neighbors within distance k hence they can use at most ∆k of the available colors.
Finally, the algorithm applies A on all nodes of the graph. As A is a deterministic LOCAL algorithm
with locality O(k), and only the colors of nodes within distance k of the update have changed, we
have that only the output of nodes within distance O(k) = O(1) from the update change.
10
Randomized online-LOCAL with an adaptive adversary
This section aims at showing that randomized online-LOCAL with an adaptive adversary is as strong
as its deterministic counterpart. The proof is very similar to the proof of Theorem 9.1 and uses,
again, the method of conditional expectations. Also, as in the previous section, the results can be
extended to any subclass of graphs.
Theorem 10.1. Let Π be an LCL problem, and let A be an online-LOCAL algorithm with an adaptive
adversary solving Π with locality T(n) and probability p > 1 −1/n. Then there exists a deterministic
online-LOCAL algorithm A′ solving Π with locality T(n).
Proof. Let A be an algorithm in the online-LOCAL model with an adaptive adversary and with round
complexity T(n). We construct a deterministic online-LOCAL algorithm A′ with the same round
complexity T(n) as follows: The algorithm A′ simulates A with certain fixed random-bit-strings. In
particular, whenever new nodes arrive at the input, the algorithm A′ fixes the random bits in all
newly arrived nodes in the way we describe below.
We view a run of an online-LOCAL algorithm with an adaptive adversary as a game between an
algorithm A and an adversary. In each step of that game, first the adversary chooses a set of nodes
that arrive at the input (one special node and its neighborhood). Then the algorithm A samples the
random bits of the newly arrived nodes and fixes the label of the arrived node. After i steps of this
game, we use F to denote the event that the adversary wins the game, that is algorithm A produces
an invalid output according to problem Π. By definition, we have Pr [F] ≤1/n. Here and from now
on, the probability expressions assume that the adversary maximizes the probability of F happening.
Our algorithm A′ in each i-th step fixes the random bits of the newly arrived nodes in a way
that guarantees that
Pr [F|B1 = b1, . . . , Bi = bi] ≤Pr [F|B1 = b1, . . . , Bi−1 = bi−1] .
Here, Bj = bj stands for fixing the values of random bits of nodes that arrived in the j-th step to bj.
We note that this can always be done since, by definition, we have
Pr [F|B1 = b1, . . . , Bi−1 = bi−1] = EBi [Pr [F|B1 = b1, . . . , Bi = bi]] .
Moreover, the online-LOCAL algorithm importantly both knows all the past arrived nodes and their
randomness, and can also consider all the different choices of the adversary in the future, and hence
can compute the above conditional probabilities.
At the end of the simulation of A, we have Pr [F|B1 = b1, . . . , Bn = bn] < 1, and hence the bad
event F does not occur. This implies that the algorithm A′ is always correct.
Remark 10.2. This proof assumes that we have white-box access to the randomized online-LOCAL
algorithm and that it uses finitely many random bits. If either of these assumptions does not hold,
we can use a more inefficient derandomization along the lines of [30]. Here, we just observe that an
online-LOCAL algorithm working against an adaptive adversary implies the existence of a function f
that maps all possible input sequences on all possible n-node graphs that can be produced by the
adversary to a valid output of the problem Π. The deterministic online-LOCAL algorithm finds such
a function f at the beginning of its execution and produces the output according to f.
50

--- Page 52 ---
11
LCL problems in paths and cycles in randomized online-LOCAL
In this section, we show that the complexity of LCLs in paths and cycles is either O(1) or Θ(n) in
randomized online-LOCAL (with an oblivious adversary).
Theorem 11.1. Let Π be an LCL problem on paths and cycles (possibly with inputs). If the locality
of Π is T in the randomized online-LOCAL model, then its locality is O(T + log∗n) in the LOCAL
model.
This theorem is a simple corollary of the following two lemmas:
Lemma 11.2. Let Π be an LCL problem on paths and cycles (possibly with inputs), and let A be a
randomized online-LOCAL algorithm solving Π with locality o(n). Then there exists a randomized
online-LOCAL algorithm A′ solving Π with locality O(1).
Lemma 11.3. Let Π be an LCL problem on paths and cycles (possibly with inputs), and let A be
a randomized online-LOCAL algorithm solving Π with locality O(1). Then there exists a LOCAL
algorithm A′ solving Π with locality O(log∗n).
By previous results [2], it is known that, in the case of paths and cycles, any (deterministic)
online-LOCAL algorithm with sublinear locality can be sped up to an online-LOCAL algorithm with
constant locality. We show how to extend [2, Lemma 5.5]. We start by constructing a large virtual
graph P ′ such that, when the original algorithm runs on the virtual graph P ′, the labeling produced
by the algorithm is locally compatible with the labeling in the original graph P.
Proof of Lemma 11.2. Let Π be an LCL problem in paths or cycles with checking-radius r, let P
be a path or a cycle with n nodes, and let A be a randomized online-LOCAL algorithm solving Π
with locality T(n) = o(n). In the proof of [2, Lemma 5.5], the authors use three phases to speed
up (deterministic) online-LOCAL with sublinear locality to only constant locality. We use the same
strategy to construct a randomized online-LOCAL algorithm A′ for solving Π with constant locality.
The phases for constructing randomized online-LOCAL algorithm A′ are as follows:
1. In the first phase, the algorithm deterministically creates an (α, α)-ruling set R for the path
P, mirroring the approach outlined in the proof of [2, Lemma 5.5].
2. In the second phase, the algorithm constructs a larger virtual path P ′ with N nodes and
simulates algorithm A on P ′ in the neighborhoods of nodes in R. Intuitively this path P ′
is constructed based on the pumping-lemma-style argument on LCL problems presented by
Chang and Pettie [19], and it only relies on (the definition of) problem Π, not the algorithm
A. During this simulation, the algorithm encounters a failure only if A fails within specific
neighborhoods of P ′. Consequently, the algorithm’s success in this phase aligns with the
success rate of A, ensuring a high probability of success.
3. The third phase is also as in [2, Lemma 5.5]: The algorithm extends the fixed labels around R
to the entire path P by applying brute force for nodes outside the neighborhood of R. Note that
this extending is feasible because of the way the path P ′ is created and the pumping-lemma-style
argument as discussed in [2].
In the end, we compose these three phases together to obtain the randomized online-LOCAL algorithm
A′ for solving Π with constant locality.
51

--- Page 53 ---
Proof of Lemma 11.3. This proof closely follows the argument presented in [2, Lemma 5.6]. Let
Π denote an LCL problem with a constant checking-radius r, and suppose A is a randomized
online-LOCAL algorithm solving Π with constant locality T. Define β = T + r + 1. As in [2, Lemma
5.6], we consider an input-labeled graph P formed by many copies of all feasible input neighborhoods
with a radius of β. We can depict P as a collection of disjoint path fragments that we later connect
to each other and create a long path with. Each of these path fragments has size 2β + 1, so the node
in the center of each segment (i.e., the (β + 1)-th node in the segment) has the same view (up to
radius β) as in the final path. Let V be the set of central nodes within these fragments.
We apply A to each node within the radius-r neighborhood of the nodes in V following an
arbitrary order and then terminate. These nodes have the same view as in the final path because
their distance to the endpoints is at most β −r = T + 1. We iterate the process multiple times,
yielding a distribution of output labels around the central nodes. Given that the size of P is constant,
there exists an output labeling L of the nodes occurring with probability p = Ω(1). If needed, we
can augment P with (constantly many) additional nodes such that |P| > 1/p.
We set this labeling L as the deterministic output for graph P and proceed similarly to the
deterministic case by constructing the canonical labeling f from L. Then, we use the function f
to construct a LOCAL algorithm with O(log∗n) locality following the same steps as in the proof of
[2, Lemma 5.6]. It is important to highlight that it is feasible to fill any gap of sufficient length
between parts labeled with the canonical labeling: If the algorithm A would never produce a valid
labeling for this gap, then the algorithm would fail to label P with probability at least p and, since
p ≥1/|P|, the algorithm A would not succeed with high probability.
Acknowledgments
We thank anonymous reviewers for their helpful feedback on previous versions of this work. This
work was supported in part by the Research Council of Finland, Grant 333837. Xavier Coiteux-
Roy is supported by the Swiss National Science Foundation. Francesco d’Amore is supported
by MUR FARE 2020 - Project PAReCoDi CUP J43C22000970001. Darya Melnyk is supported
by the European Research Council (ERC), grant agreement No. 864228 (AdjustNet), Horizon
2020, 2020-2025. Augusto Modanese and Shreyas Pai are supported by the Helsinki Institute for
Information Technology (HIIT). Marc-Olivier Renou acknowledges funding by INRIA through the
Action Exploratoire project DEPARTURE, and by the ANR for the JCJC grant LINKS (ANR-23-
CE47-0003).
Errata.
An earlier version of this manuscript (arXiv:2403.01903v1, posted on 2024-03-04) had
a mistake: we claimed a result analogous to Theorem 1.5 for unrooted trees (which would also
have implications on the complexity of the sinkless orientation problem). However, the proof had a
missing step, and we do not know if the proof can be fixed.
References
[1] Jon Aaronson, David Gilat, Michael Keane, and Vincent de Valk. An algebraic construction of
a class of one-dependent processes. The Annals of Probability, 17(1):128–143, 1989.
[2] Amirreza Akbari, Navid Eslami, Henrik Lievonen, Darya Melnyk, Joona Särkijärvi, and Jukka
Suomela. Locality in online, dynamic, sequential, and distributed graph algorithms. In Kousha
Etessami, Uriel Feige, and Gabriele Puppis, editors, 50th International Colloquium on Automata,
52

--- Page 54 ---
Languages, and Programming, ICALP 2023, July 10-14, 2023, Paderborn, Germany, volume
261 of LIPIcs, pages 10:1–10:20. Schloss Dagstuhl - Leibniz-Zentrum für Informatik, 2023.
doi:10.4230/LIPICS.ICALP.2023.10.
[3] Heger Arfaoui and Pierre Fraigniaud.
What can be computed without communications?
SIGACT News, 45(3):82–104, 2014. doi:10.1145/2670418.2670440.
[4] Alkida Balliu, Juho Hirvonen, Janne H. Korhonen, Tuomo Lempiäinen, Dennis Olivetti, and
Jukka Suomela. New classes of distributed time complexity. In Ilias Diakonikolas, David Kempe,
and Monika Henzinger, editors, Proceedings of the 50th Annual ACM SIGACT Symposium on
Theory of Computing, STOC 2018, Los Angeles, CA, USA, June 25-29, 2018, pages 1307–1318.
ACM, 2018. doi:10.1145/3188745.3188860.
[5] Alkida Balliu, Sebastian Brandt, Yi-Jun Chang, Dennis Olivetti, Mikaël Rabie, and Jukka
Suomela. The distributed complexity of locally checkable problems on paths is decidable. In
Peter Robinson and Faith Ellen, editors, Proceedings of the 2019 ACM Symposium on Principles
of Distributed Computing, PODC 2019, Toronto, ON, Canada, July 29 - August 2, 2019, pages
262–271. ACM, 2019. doi:10.1145/3293611.3331606.
[6] Alkida Balliu, Sebastian Brandt, Dennis Olivetti, and Jukka Suomela. How much does ran-
domness help with locally checkable problems? In Yuval Emek and Christian Cachin, editors,
PODC ’20: ACM Symposium on Principles of Distributed Computing, Virtual Event, Italy,
August 3-7, 2020, pages 299–308. ACM, 2020. doi:10.1145/3382734.3405715.
[7] Alkida Balliu, Sebastian Brandt, Juho Hirvonen, Dennis Olivetti, Mikaël Rabie, and Jukka
Suomela. Lower bounds for maximal matchings and maximal independent sets. Journal of the
ACM, 68(5):39:1–39:30, 2021. doi:10.1145/3461458.
[8] Alkida Balliu, Sebastian Brandt, Dennis Olivetti, and Jukka Suomela. Almost global problems
in the LOCAL model. Distributed Computing, 34(4):259–281, 2021. doi:10.1007/S00446-020-
00375-2.
[9] Alkida Balliu, Sebastian Brandt, Yi-Jun Chang, Dennis Olivetti, Jan Studený, and Jukka
Suomela. Efficient classification of locally checkable problems in regular trees. In Christian
Scheideler, editor, 36th International Symposium on Distributed Computing, DISC 2022, October
25-27, 2022, Augusta, Georgia, USA, volume 246 of LIPIcs, pages 8:1–8:19. Schloss Dagstuhl -
Leibniz-Zentrum für Informatik, 2022. doi:10.4230/LIPICS.DISC.2022.8.
[10] Alkida Balliu, Juho Hirvonen, Darya Melnyk, Dennis Olivetti, Joel Rybicki, and Jukka Suomela.
Local mending. In Merav Parter, editor, Structural Information and Communication Complexity
- 29th International Colloquium, SIROCCO 2022, Paderborn, Germany, June 27-29, 2022,
Proceedings, volume 13298 of Lecture Notes in Computer Science, pages 1–20. Springer, 2022.
doi:10.1007/978-3-031-09993-9_1.
[11] Alkida Balliu, Sebastian Brandt, Yi-Jun Chang, Dennis Olivetti, Jan Studený, Jukka Suomela,
and Aleksandr Tereshchenko. Locally checkable problems in rooted trees. Distributed Computing,
36(3):277–311, 2023. doi:10.1007/S00446-022-00435-9.
[12] Alkida Balliu, Janne H. Korhonen, Fabian Kuhn, Henrik Lievonen, Dennis Olivetti, Shreyas Pai,
Ami Paz, Joel Rybicki, Stefan Schmid, Jan Studený, Jukka Suomela, and Jara Uitto. Sinkless
orientation made simple. In Telikepalli Kavitha and Kurt Mehlhorn, editors, 2023 Symposium
53

--- Page 55 ---
on Simplicity in Algorithms, SOSA 2023, Florence, Italy, January 23-25, 2023, pages 175–191.
SIAM, 2023. doi:10.1137/1.9781611977585.CH17.
[13] Alkida Balliu, Mohsen Ghaffari, Fabian Kuhn, Augusto Modanese, Dennis Olivetti, Mikaël
Rabie, Jukka Suomela, and Jara Uitto. Shared randomness helps with local distributed problems,
2024. URL https://arxiv.org/abs/2407.05445.
[14] Salman Beigi and Marc-Olivier Renou. Covariance decomposition as a universal limit on
correlations in networks. IEEE Transactions on Information Theory, 68(1):384–394, 2021.
[15] Max Born. Quantenmechanik der Stoßvorgänge. Zeitschrift für Physik, 38(11-12):803–827, 1926.
doi:10.1007/bf01397184.
[16] Sebastian Brandt, Orr Fischer, Juho Hirvonen, Barbara Keller, Tuomo Lempiäinen, Joel Rybicki,
Jukka Suomela, and Jara Uitto. A lower bound for the distributed Lovász local lemma. In
Daniel Wichs and Yishay Mansour, editors, Proceedings of the 48th Annual ACM SIGACT
Symposium on Theory of Computing, STOC 2016, Cambridge, MA, USA, June 18-21, 2016,
pages 479–488. ACM, 2016. doi:10.1145/2897518.2897570.
[17] Sebastian Brandt, Juho Hirvonen, Janne H. Korhonen, Tuomo Lempiäinen, Patric R. J.
Östergård, Christopher Purcell, Joel Rybicki, Jukka Suomela, and Przemyslaw Uznanski. LCL
problems on grids. In Elad Michael Schiller and Alexander A. Schwarzmann, editors, Proceedings
of the ACM Symposium on Principles of Distributed Computing, PODC 2017, Washington, DC,
USA, July 25-27, 2017, pages 101–110. ACM, 2017. doi:10.1145/3087801.3087833.
[18] Keren Censor-Hillel, Orr Fischer, François Le Gall, Dean Leitersdorf, and Rotem Oshman.
Quantum distributed algorithms for detection of cliques. In Mark Braverman, editor, 13th
Innovations in Theoretical Computer Science Conference, ITCS 2022, January 31 - February
3, 2022, Berkeley, CA, USA, volume 215 of LIPIcs, pages 35:1–35:25. Schloss Dagstuhl -
Leibniz-Zentrum für Informatik, 2022. doi:10.4230/LIPICS.ITCS.2022.35.
[19] Yi-Jun Chang and Seth Pettie. A time hierarchy theorem for the LOCAL model. SIAM Journal
on Computing, 48(1):33–69, 2019. doi:10.1137/17M1157957.
[20] Yi-Jun Chang, Tsvi Kopelowitz, and Seth Pettie. An exponential separation between randomized
and deterministic complexity in the LOCAL model. In Irit Dinur, editor, IEEE 57th Annual
Symposium on Foundations of Computer Science, FOCS 2016, 9-11 October 2016, Hyatt
Regency, New Brunswick, New Jersey, USA, pages 615–624. IEEE Computer Society, 2016.
doi:10.1109/FOCS.2016.72.
[21] Yi-Jun Chang, Tsvi Kopelowitz, and Seth Pettie. An exponential separation between randomized
and deterministic complexity in the LOCAL model. SIAM Journal on Computing, 48(1):122–143,
2019. doi:10.1137/17M1117537.
[22] Yi-Jun Chang, Gopinath Mishra, Hung Thuan Nguyen, Mingyang Yang, and Yu-Cheng Yeh.
A tight lower bound for 3-coloring grids in the online-LOCAL model. CoRR, abs/2312.01384,
2023. doi:10.48550/ARXIV.2312.01384.
[23] Yi-Jun
Chang,
Jan
Studený,
and
Jukka
Suomela.
Distributed
graph
problems
through an automata-theoretic lens.
Theoretical Computer Science, 951:113710, 2023.
doi:10.1016/J.TCS.2023.113710.
54

--- Page 56 ---
[24] Giulio Chiribella and Robert W. Spekkens, editors. Quantum Theory: Informational Foundations
and Foils. Springer Netherlands, 2016. doi:10.1007/978-94-017-7303-4.
[25] Xavier Coiteux-Roy, Elie Wolfe, and Marc-Olivier Renou. Any physical theory of nature must
be boundlessly multipartite nonlocal. Physical Review A, 104(5):052207, 2021.
[26] Xavier Coiteux-Roy, Elie Wolfe, and Marc-Olivier Renou.
No Bipartite-Nonlocal Causal
Theory Can Explain Nature’s Correlations. Physical Review Letters, 127(20):200401, 2021.
doi:10.1103/physrevlett.127.200401.
[27] Xavier Coiteux-Roy, Francesco d’Amore, Rishikesh Gajjala, Fabian Kuhn, François Le Gall,
Henrik Lievonen, Augusto Modanese, Marc-Olivier Renou, Gustav Schmid, and Jukka Suomela.
No distributed quantum advantage for approximate graph coloring. In Proc. 56th Annual ACM
Symposium on Theory of Computing (STOC 2024). ACM Press, 2024.
[28] Xavier Coiteux-Roy, Owidiusz Makuta, Fionnuala Curran, Remigiusz Augusiak, and Marc-
Olivier Renou. The genuinely multipartite nonlocality of graph states is model-dependent, 2024.
In preparation.
[29] Richard Cole and Uzi Vishkin. Deterministic coin tossing with applications to optimal parallel
list ranking. Information and Control, 70(1):32–53, 1986. doi:10.1016/S0019-9958(86)80023-7.
[30] Sameep Dahal, Francesco D’Amore, Henrik Lievonen, Timothé Picavet, and Jukka Suomela.
Brief announcement: Distributed derandomization revisited. In Rotem Oshman, editor, 37th
International Symposium on Distributed Computing, DISC 2023, October 10-12, 2023, L’Aquila,
Italy, volume 281 of LIPIcs, pages 40:1–40:5. Schloss Dagstuhl - Leibniz-Zentrum für Informatik,
2023. doi:10.4230/LIPICS.DISC.2023.40.
[31] Giacomo Mauro D’Ariano, Giulio Chiribella, and Paolo Perinotti.
Quantum Theory
from First Principles:
An Informational Approach.
Cambridge University Press, 2016.
doi:10.1017/9781107338340.
[32] Anubhav Dhar, Eli Kujawa, Henrik Lievonen, Augusto Modanese, Mikail Muftuoglu, Jan
Studený, and Jukka Suomela. Local problems in trees across a wide range of distributed models.
In Proc. 28th International Conference on Principles of Distributed Systems (OPODIS 2024),
Leibniz International Proceedings in Informatics (LIPIcs). Schloss Dagstuhl–Leibniz-Zentrum
für Informatik, 2024.
[33] Michael Elkin, Hartmut Klauck, Danupon Nanongkai, and Gopal Pandurangan. Can quantum
communication speed up distributed computation? In Magnús M. Halldórsson and Shlomi
Dolev, editors, ACM Symposium on Principles of Distributed Computing, PODC ’14, Paris,
France, July 15-18, 2014, pages 166–175. ACM, 2014. doi:10.1145/2611462.2611488.
[34] Manuela Fischer and Mohsen Ghaffari.
Sublogarithmic distributed algorithms for Lovász
local lemma, and the complexity hierarchy. In Andréa W. Richa, editor, 31st International
Symposium on Distributed Computing, DISC 2017, October 16-20, 2017, Vienna, Austria,
volume 91 of LIPIcs, pages 18:1–18:16. Schloss Dagstuhl - Leibniz-Zentrum für Informatik, 2017.
doi:10.4230/LIPICS.DISC.2017.18.
[35] Pierre Fraigniaud, Maël Luce, Frédéric Magniez, and Ioan Todinca. Even-cycle detection in
the randomized and quantum CONGEST model. In Ran Gelles, Dennis Olivetti, and Petr
Kuznetsov, editors, Proceedings of the 43rd ACM Symposium on Principles of Distributed
55

--- Page 57 ---
Computing, PODC 2024, Nantes, France, June 17-21, 2024, pages 209–219. ACM, 2024.
doi:10.1145/3662158.3662767.
[36] Cyril Gavoille, Adrian Kosowski, and Marcin Markiewicz. What can be observed locally? In
Idit Keidar, editor, Distributed Computing, 23rd International Symposium, DISC 2009, Elche,
Spain, September 23-25, 2009. Proceedings, volume 5805 of Lecture Notes in Computer Science,
pages 243–257. Springer, 2009. doi:10.1007/978-3-642-04355-0_26.
[37] Mohsen Ghaffari and Hsin-Hao Su. Distributed degree splitting, edge coloring, and orientations.
In Philip N. Klein, editor, Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on
Discrete Algorithms, SODA 2017, Barcelona, Spain, Hotel Porta Fira, January 16-19, pages
2505–2523. SIAM, 2017. doi:10.1137/1.9781611974782.166.
[38] Mohsen Ghaffari, Fabian Kuhn, and Yannic Maus. On the complexity of local distributed graph
problems. In Hamed Hatami, Pierre McKenzie, and Valerie King, editors, Proceedings of the
49th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2017, Montreal, QC,
Canada, June 19-23, 2017, pages 784–797. ACM, 2017. doi:10.1145/3055399.3055471.
[39] Mohsen Ghaffari, David G. Harris, and Fabian Kuhn. On derandomizing local distributed algo-
rithms. In Mikkel Thorup, editor, 59th IEEE Annual Symposium on Foundations of Computer
Science, FOCS 2018, Paris, France, October 7-9, 2018, pages 662–673. IEEE Computer Society,
2018. doi:10.1109/FOCS.2018.00069.
[40] Mohsen Ghaffari, Juho Hirvonen, Fabian Kuhn, Yannic Maus, Jukka Suomela, and Jara Uitto.
Improved distributed degree splitting and edge coloring. Distributed Computing, 33(3-4):293–310,
2020. doi:10.1007/S00446-018-00346-8.
[41] Nicolas Gisin, Jean-Daniel Bancal, Yu Cai, Patrick Remy, Armin Tavakoli, Emmanuel Zambrini
Cruzeiro, Sandu Popescu, and Nicolas Brunner. Constraints on nonlocality in networks from
no-signaling and independence. Nature Communications, 11(1):2378, 2020. doi:10.1038/s41467-
020-16137-4.
[42] Andrew V. Goldberg, Serge A. Plotkin, and Gregory E. Shannon. Parallel symmetry-breaking in
sparse graphs. SIAM Journal on Discrete Mathematics, 1(4):434–446, 1988. doi:10.1137/0401044.
[43] Atsuya Hasegawa, Srijita Kundu, and Harumichi Nishimura.
On the power of quantum
distributed proofs. In Ran Gelles, Dennis Olivetti, and Petr Kuznetsov, editors, Proceedings
of the 43rd ACM Symposium on Principles of Distributed Computing, PODC 2024, Nantes,
France, June 17-21, 2024, pages 220–230. ACM, 2024. doi:10.1145/3662158.3662788.
[44] Alexander E. Holroyd. Symmetrization for finitely dependent colouring. Electronic Communi-
cations in Probability, 29, 2024. doi:10.1214/24-ecp600.
[45] Alexander E. Holroyd and Thomas M. Liggett.
Finitely Dependent Coloring.
Forum of
Mathematics, Pi, 4:e9, 2016. doi:10.1017/fmp.2016.7.
[46] Alexander E. Holroyd, Oded Schramm, and David B. Wilson. Finitary coloring. The Annals of
Probability, 45(5):2867–2898, 2017. doi:10.1214/16-aop1127.
[47] Alexander E. Holroyd, Tom Hutchcroft, and Avi Levy. Finitely dependent cycle coloring.
Electronic Communications in Probability, 23, 2018. doi:10.1214/18-ecp118.
56

--- Page 58 ---
[48] Taisuke Izumi and François Le Gall. Quantum distributed algorithm for the all-pairs short-
est path problem in the CONGEST-CLIQUE model. In Peter Robinson and Faith Ellen,
editors, Proceedings of the 2019 ACM Symposium on Principles of Distributed Computing,
PODC 2019, Toronto, ON, Canada, July 29 - August 2, 2019, pages 84–93. ACM, 2019.
doi:10.1145/3293611.3331628.
[49] Taisuke Izumi, François Le Gall, and Frédéric Magniez. Quantum distributed algorithm for
triangle finding in the CONGEST model. In Christophe Paul and Markus Bläser, editors, 37th
International Symposium on Theoretical Aspects of Computer Science, STACS 2020, March
10-13, 2020, Montpellier, France, volume 154 of LIPIcs, pages 23:1–23:13. Schloss Dagstuhl -
Leibniz-Zentrum für Informatik, 2020. doi:10.4230/LIPICS.STACS.2020.23.
[50] Amos Korman, Jean-Sébastien Sereni, and Laurent Viennot. Toward more localized local
algorithms: removing assumptions concerning global knowledge. Distributed Computing, 26
(5-6):289–308, 2013. doi:10.1007/S00446-012-0174-8.
[51] François Le Gall and Frédéric Magniez. Sublinear-time quantum computation of the diameter in
CONGEST networks. In Proceedings of the 2018 ACM Symposium on Principles of Distributed
Computing, pages 337–346. ACM, 2018. doi:10.1145/3212734.3212744.
[52] François Le Gall, Harumichi Nishimura, and Ansis Rosmanis. Quantum advantage for the
LOCAL model in distributed computing. In Rolf Niedermeier and Christophe Paul, editors,
36th International Symposium on Theoretical Aspects of Computer Science, STACS 2019, March
13-16, 2019, Berlin, Germany, volume 126 of LIPIcs, pages 49:1–49:14. Schloss Dagstuhl -
Leibniz-Zentrum für Informatik, 2019. doi:10.4230/LIPICS.STACS.2019.49.
[53] Nathan Linial. Distributive graph algorithms-global solutions from local data. In 28th Annual
Symposium on Foundations of Computer Science, Los Angeles, California, USA, 27-29 October
1987, pages 331–335. IEEE Computer Society, 1987. doi:10.1109/SFCS.1987.20.
[54] Nathan Linial. Locality in distributed graph algorithms. SIAM Journal on Computing, 21(1):
193–201, 1992. doi:10.1137/0221015.
[55] Frédéric Magniez and Ashwin Nayak. Quantum distributed complexity of set disjointness on a
line. ACM Transactions on Computation Theory, 14(1):5:1–5:22, 2022. doi:10.1145/3512751.
[56] Yannic Maus and Tigran Tonoyan. Linial for lists. Distributed Computing, 35(6):533–546, 2022.
doi:10.1007/S00446-022-00424-Y.
[57] Moni Naor and Larry J. Stockmeyer. What can be computed locally?
SIAM Journal on
Computing, 24(6):1259–1277, 1995. doi:10.1137/S0097539793254571.
[58] Michael A. Nielsen and Isaac L. Chuang. Quantum Computation and Quantum Information:
10th Anniversary Edition. Cambridge University Press, 2012. doi:10.1017/cbo9780511976667.
[59] Dennis Olivetti. Round eliminator: a tool for automatic speedup simulation, 2019. URL
https://github.com/olidennis/round-eliminator.
[60] Alessandro Panconesi and Romeo Rizzi. Some simple distributed algorithms for sparse networks.
Distributed Computing, 14(2):97–100, 2001. doi:10.1007/PL00008932.
[61] David Peleg. Distributed Computing: A Locality-Sensitive Approach. Society for Industrial and
Applied Mathematics, 2000. doi:10.1137/1.9780898719772.
57

--- Page 59 ---
[62] Václav Rozhon and Mohsen Ghaffari. Polylogarithmic-time deterministic network decomposition
and distributed derandomization. In Konstantin Makarychev, Yury Makarychev, Madhur
Tulsiani, Gautam Kamath, and Julia Chuzhoy, editors, Proceedings of the 52nd Annual ACM
SIGACT Symposium on Theory of Computing, STOC 2020, Chicago, IL, USA, June 22-26,
2020, pages 350–363. ACM, 2020. doi:10.1145/3357713.3384298.
[63] Yinon Spinka. Finitely dependent processes are finitary. The Annals of Probability, 48(4):
2088–2117, 2020. doi:10.1214/19-aop1417.
[64] Jukka Suomela. Landscape of locality (invited talk). In Susanne Albers, editor, 17th Scandinavian
Symposium and Workshops on Algorithm Theory, SWAT 2020, June 22-24, 2020, Tórshavn,
Faroe Islands, volume 162 of LIPIcs, pages 2:1–2:1. Schloss Dagstuhl - Leibniz-Zentrum für
Informatik, 2020. doi:10.4230/LIPICS.SWAT.2020.2.
[65] Ádám Timár.
Finitely dependent random colorings of bounded degree graphs.
CoRR,
abs/2402.17068, 2024. doi:10.48550/arXiv.2402.17068.
[66] Joran van Apeldoorn and Tijn de Vos. A framework for distributed quantum queries in the
CONGEST model. In Alessia Milani and Philipp Woelfel, editors, PODC ’22: ACM Symposium
on Principles of Distributed Computing, Salerno, Italy, July 25 - 29, 2022, pages 109–119. ACM,
2022. doi:10.1145/3519270.3538413.
[67] ChengSheng Wang, Xudong Wu, and Penghui Yao.
Complexity of eccentricities and all-
pairs shortest paths in the quantum CONGEST model.
CoRR, abs/2206.02766, 2022.
doi:10.48550/ARXIV.2206.02766.
[68] Xudong Wu and Penghui Yao.
Quantum complexity of weighted diameter and radius in
CONGEST networks.
In Alessia Milani and Philipp Woelfel, editors, PODC ’22: ACM
Symposium on Principles of Distributed Computing, Salerno, Italy, July 25 - 29, 2022, pages
120–130. ACM, 2022. doi:10.1145/3519270.3538441.
58

--- Page 60 ---
A
Quantum, bounded-dependence, and non-signaling
This appendix introduces both the non-signaling model and the bounded-dependence model, which
are the most powerful models that satisfy physical causality, and thus they generalize the quantum-
LOCAL model. The distinction between the non-signaling model and the bounded-dependence
depends on whether shared states are available (in the non-signaling model) or not (in the bounded-
dependence model). We illustrate the difference between these models by analyzing the problem of
c = 2-coloring a lifebuoy-shaped graph (see Fig. 6 and Fig. 7b) with locality T = 2.
We first introduce a circuit formalism which allows us to clarify the early works of Arfaoui and
Fraigniaud [3], and Gavoille et al. [36], by re-expressing the randomized LOCAL and quantum-LOCAL
models in this formalism (see Appendix A.1). Second, we introduce the concept of light-cones and
the principle of non-signaling, explaining how (together with the symmetries of the graph) they define
the non-signaling model (see Appendices A.1.3 and A.1.4). Third, we show in Appendix A.2 that
lifebuoy-shaped graphs are not 2-colorable in the non-signaling model with locality T = 2 through a
reduction from the 2-colorability of the cheating graph H shown in Fig. 7a. At last, we define the
bounded-dependence model based on our circuit formalism and on the following three principles:
device replication; non-signaling and independence [14, 25, 26, 41]; and invariance under symmetries
of the graph (see Appendix A.3). We stress its connection to the concept of finitely-dependent
distributions [1, 44, 45, 47, 63].
Figure 6: An example of a lifebuoy-shaped graph G. The lifebuoy-shaped graphs are defined by the
set G of graphs that are isomorphic to the above. Notice that their chromatic number is 2. In our
case, the node labels required by the LOCAL model are unique and go from 1 to 12. Granting this
extra power is not restrictive as we are proving a lower bound.
A.1
Randomized LOCAL, quantum-LOCAL, and non-signaling models
In the next two sections, we re-introduce the randomized LOCAL model and the quantum-LOCAL
model for coloring lifebuoy-shaped graphs in a circuit formalism. This will later enable us to clarify
the definitions of the non-signaling and bounded-dependence models.
A.1.1
Randomized LOCAL model
We consider twelve nodes with unique identifiers ranging from 1 to 12 and that are connected in
a lifebuoy-shaped graph that is a priori unknown to the nodes3 (an example of such graph is the
labeled graph G0 ∈G illustrated in Fig. 7b). The nodes try to color this graph in the randomized
3A reader used to standard quantum nonlocality should see the graph — H or G ∈G — as an input of the problem,
split and distributed among the local parties.
59

--- Page 61 ---
(a) H has chromatic number 3.
(b) A distributed algorithm that finds a 2-
coloring of the lifebuoy-shaped graphs G ∈
G would by definition 2-color the particular
instance G = G0.
Figure 7: The joint view of the couple of nodes u, v = 1, 2 after T = 2 rounds of communication
is limited to the gray area. In this region the graphs G0 and H are identical. The non-signaling
principle implies that the outputs (c1, c2) must therefore be identically distributed in both G0 and H.
LOCAL model within T = 2 steps of synchronous communication. The difficulty is that a given
node ignore which G ∈G connects the set of labelled nodes: it can only discover a local part of the
structure of G by communicating to its neighbors. The most general (T = 2)-round strategy for the
node 1 consists of the following procedure, which alternates between randomized processing steps
and communication steps (the computational power and size of exchanged messages are unbounded):
Processing 0: Sample a random real number and store it locally.
Communication 1: Send all stored information, including the sampled random number, to all
neighbors. Receive information from all neighbors and store it for subsequent rounds (in G0,
the neighbors are 2, 3, 5).
Processing 1: Process all stored information (possibly in a randomized way) and store the result.4
Communication 2: Send all stored information, including all received messages and the outputs
of processing steps, to all neighbors. Receive information from neighbors and store it.
Processing 2: Process all stored information (possibly in a randomized way) to output a color.
Such T-round strategy on the graph G can be represented formally as a circuit CG,T , such as in
Fig. 8a where semicircles, line wires, and squares respectively represent the sampling of a random
number, the transfer (or storage) of information, and the processing of information. Once the
concrete operations performed by the nodes (i.e. randomness sampling and processing) are made
explicit, it is possible to compute (using classical information theory) the exact output distribution
of the strategy on graph G, that is, the probability distribution Pr [c1, . . . , cn | CG,T ] of observing
that the set of nodes {1, . . . , n} outputs the colors {c1, . . . , cn} when connected as per one of the
lifebuoy-shaped graphs G ∈G. Importantly, in our model, the operations performed by the nodes
cannot depend on the connection graph G.
4In classical information theory, it is known that intermediate processing gates can be taken as identity gates, that
is, any strategy can be simulated by a two-layer circuit where the parties send their first random number to all parties
up to a distance T, and then make a unique processing step after all the communication has taken place. In quantum
and non-signaling theories, this is not the case anymore [28].
60

--- Page 62 ---
A generic classical strategy with shared randomness can be in the same way represented by the
general circuit of Fig. 8b, by initializing the circuit with a source of randomness common to all nodes
(the large semicircle).
A.1.2
Quantum-LOCAL model
Any quantum strategy can also be represented by the circuit formalism of Fig. 8 by using resources
and processing operations that are quantum rather than classical. Quantum information theory
provides a concrete mathematical formalism (based on the tensor product of Hilbert spaces) with
rules to represent the potential operations performed by each of the gates of the circuit. Semicircles,
line wires, and squares now respectively represent the creation of a quantum state (a density matrix),
the transfer (or storage) of quantum information, and the processing of quantum information with
quantum channels (or quantum measurements in the last layer) represented by completely positive
operators. Once the quantum states and channels are made explicit, the Born rule of quantum
information theory [15, 58] allows computing Pr [c1, . . . , cn |CG,T ], the output distribution of the
strategy on graph G.
However, analyzing the quantum-LOCAL model directly is complicated. Instead, we employ the
fact that it is possible to bound the time complexity of the quantum-LOCAL model by analyzing
models that do not depend on the mathematical formalism of quantum information theory (and which
are, therefore, arguably simpler). In the present appendix, we utilize the fact that quantum-LOCAL is
sandwiched between the randomized LOCAL model (less powerful) and the non-signaling model (the
most powerful model satisfying the information-theoretic principles of non-signaling, independence
and device replication we introduce bellow). We next introduce the non-signaling model.
A.1.3
The non-signaling model (with unique identifiers)
The non-signaling model is the most powerful model of synchronous distributed computing that does
not violate physical causality, when a pre-established shared resource exists.
The formulation of the non-signaling model is radically different from the randomized LOCAL
and quantum-LOCAL models. The randomized LOCAL and quantum-LOCAL models are based
on classical (randomized) and quantum information theory which both provide a mathematical
formalism to describe information processing gates and to compute the probability distribution of
outputs when these gates are placed in a circuit. To show that some probability distribution is
feasible in these models, one needs to propose a valid strategy in these mathematical formalisms.
The non-signaling model does not rely on any underlying mathematical formalism, but on some
information-theoretical principles which should not be violated. More precisely, to show that some
probability distribution is feasible in the non-signaling model, one needs to explain how to obtain
it, but only to make sure that this probability distribution is compatible with the non-signaling
principle in a way we now explain.
Before introducing this principle, we state the following definition of light-cones:
Definition A.1 (Past light-cone). Consider a circuit. Consider a subset of gates R, and another
gate s /∈R in that circuit. We say that s is in the past light-cone of R if starting from s, one can
reach a gate in R by traveling down the circuit. For instance, in Fig. 8b, the past light-cone of the
second processing gates of nodes {1, 2} is composed of all gates in red.
Remark A.2. Light-cones allow to formalize the fact that, in a circuit, the precise time ordering in
which the gates process information has no influence over the result, as long as physical causality
(that is, information can be transferred only through communication) is preserved. For instance, in
61

--- Page 63 ---
12
c12
10
c10
8
c8
6
c6
4
c4
2
c2
1
c1
3
c3
5
c5
7
c7
9
c9
11
c11
11
9
12
10
Processing 0
Communication 1
Processing 1
Communication 2
Processing 2
Output
(a) Circuit representation of a
non-signaling strategy on graph
G0 of Fig. 7b, without a shared
resource. Note the cyclicity of
the circuit. Highlighted in red
is the past-light-cone of the joint
output (c1, c2), that is the set of
gates which connects to the out-
put gates producing (c1, c2).
12
c12
10
c10
8
c8
6
c6
4
c4
2
c2
1
c1
3
c3
5
c5
7
c7
9
c9
11
c11
11
9
12
10
Processing 0
Communication 1
Processing 1
Communication 2
Processing 2
Output
(b) Circuit representation of a
non-signaling strategy on graph
G0 of Fig. 7b, with an arbitrary
shared resource. The joint out-
put (c1, c2) remain, after T = 2
rounds of communication, inde-
pendent of the graph structure
around nodes 11 and 12, because
the difference lies outside their
joint past light-cones.
12
c12
10
c10
8
c8
6
c6
4
c4
2
c2
1
c1
3
c3
5
c5
7
c7
9
c9
11
c11
11
9
12
10
Processing 0
Communication 1
Processing 1
Communication 2
Processing 2
Output
(c) Circuit representation of a
non-signaling strategy on graph
H of Fig. 7a, with an arbitrary
shared resource. Note the differ-
ence between this circuit and the
one of Fig. 8b (namely, the differ-
ent connections between the top
layer and bottom layer of the cir-
cuit) is only manifested outside
the joint past light-cone of the
outputs (c1, c2).
Figure 8: The above circuits represent non-signaling strategies (it includes as special cases the
classical strategies and quantum strategies) executed by the nodes 1 and 2 in various scenarios. The
semicircles represent private (Fig. 8a) or shared (Fig. 8b and Fig. 8c) arbitrary-but-non-signaling
resources; the wires depict communication (or storage), and the squares are local operations (using
possibly private resources). The last layer of gates (or measurements) outputs the individual colors
of the nodes (i.e. classical variables). Since the nodes start with no knowledge about the identity of
their neighbors, the operations of the gates are a priori independent of the graph structure (as long
as the nodes have the right degree). For the special cases of classical and quantum strategies, the
output distribution can be computed directly from those circuits, which define it uniquely.
62

--- Page 64 ---
Fig. 8a, our drawing of the circuit represents the processing-1 gate of node 8 as being in the past of
the processing-2 gate of node 2. However, by stretching the communication lines, another drawing
in which this time ordering is exchanged exists, and this is possible as long as one node is not in the
past light cone of another. The name “light-cone” refers to relativity, where physical causality is
bounded by the speed of light. Circuits provide an abstracted representation of physical causality
that is not based on any notion of spacetime.
We now state the non-signaling principle5, which is essentially the only constraint in the non-
signaling model.
Definition A.3 (Non-signaling principle). Consider a set of gates, two different circuits C, C′
connecting them, and corresponding distributions Pr [c1, . . . , cn | C], Pr [c1, . . . , cn | C′]. Let U be a
subset of measurement gates whose past light-cones in C and C′ coincide (i.e. they are composed of
the same gates which are connected in the same way). Then Pr [{ci}i∈U | C] = Pr [{ci}i∈U |C′].
Implicitly, a non-signaling theory assumes that, given a set of gates and a valid way to connect
them in a circuit C, one obtains a corresponding distribution Pr [c1, . . . , cn | C]6 (here the alphabet
of the outputs ci is not limited: e.g., in case of unexpected circuits, the measurement gates can
produce failure outputs).
We are now ready to define the non-signaling model, which is associated to circuits with a
pre-shared non-signaling resource such as in Fig. 8b:
Definition A.4 (Non-signaling model, with unique identifiers). The distribution
Pr [c1, . . . , cn | CG,T ]
is feasible in the non-signaling model (with unique identifiers) with locality T on graph G if and
only if, for all possible alternative connecting graphs H of the nodes, there exists a distribution
P = Pr [c1, . . . , cn | CH,T ] such that the no-signaling principle is respected.7
Note that H might not be a lifebuoy-shaped graph: in the case a gate ‘discovers’ this unexpected
situation, it has the possibility to produce a new output from a set of error outputs (i.e. it crashes
and no further useful constraint can be derived).
A.1.4
The non-signaling model without unique identifiers
We have up until now considered N = 12 nodes with unique identifiers ranging from 1 to N = 12.
When the nodes do not start with unique identifiers, the situation is slightly more complicated. In
that case, the resulting distribution should be invariant under subgraph isomorphism, as all nodes
are running identical programs and the circuit is thus completely symmetric under permutations of
nodes8. For instance, if the nodes were to color the graph of Fig. 7b without being a priori assigned
5Chiribella and Spekkens [24] call this principle no-signaling from the future.
6Note that the gates have “types” and can only be connected to other gates of matching types: For instance, in
our case, the inputs of gates from the second processing step must correspond to the outputs of gates from the first
processing step. The theory of circuits can be formalized using category theory — see, e.g. [31].
7Note that considering scenarios with more than one copies of each node does not allow us to derive additional
constraints, since the pre-shared non-signaling resource cannot by definition be cloned and extended to more than one
copy of each of its original recipient.
8Note that while a shared classical resource is inherently symmetric, because it can be without a loss of generality
taken to be distributed identically to each party, a non-signaling resource is not a priori symmetric under permutation
of the parties that it connects. The absence of identifiers thus forces the non-signaling model to pre-share only a
subset of all possible non-signaling resources, namely the subset that respects such symmetry.
63

--- Page 65 ---
unique identifiers, the resulting circuit CG,T would have some symmetries (as all processing gates
would be the same in any layer of the respective steps 0, 1 and 2), implying that the distribution
should be invariant by several non-trivial graph isomorphisms cyclically permuting the nodes, or
inverting the inner and outer cycle of 6 nodes.
Definition A.5 (Non-signaling model, without unique identifiers). The distribution
Pr [c1, . . . , cn | CG,T ]
is feasible in the non-signaling model (without unique identifiers) in T communication steps on
graph G if and only if the following two conditions are respected: for all possible alternative
connecting graphs H of the nodes, there exists a distribution P = Pr [c1, . . . , cn | CH,T ] such that the
no-signaling principle is respected; and the distributions in G and H are invariant under subgraph
isomorphism.
This definition can also be generalized to the case where several nodes with the same identifiers
are present in G, or were the number of identifiers ranges from 1 to M ̸= N.
A.2
Graph G is not 2-colorable in T = 2 rounds
We now show by contradiction that the nodes 1, . . . , 12 cannot 2-color the set G of lifebuoy-shaped
graphs with a non-signaling strategy (including pre-shared non-signaling resources) in T = 2 rounds
of communication. More precisely, we prove that if there existed such a non-signaling algorithm able
to color any G ∈G, then the same algorithm would also color the cheating graph H with 2 colors,
which is impossible.
Proof. Assume by contradiction that there exists such a non-signaling algorithm, that is, there exist
gates as in Fig. 8b such that the resulting probability distribution Pr [c1, . . . , c12 | CG,T ] is a proper
coloring for all lifebuoy-shaped graphs G ∈G. Such proper coloring means that for all G ∈G, and
for all nodes u, v that are neighbors in G, it holds that Pr [cu ̸= cv | CG,T ] = 1.
We consider the same nodes performing the same gates, but we change the edges so that the
connected nodes now form the graph H in Fig. 7b. Let Pr [c1, . . . , c12 | CH,T ] be the distribution
of output colors in that new configuration9. Consider two nodes connected by an edge in H: by
symmetry of H, we can without a loss of generality assume that these are nodes 1 and 2. We
introduce the lifebuoy-shaped graph G0 of Fig. 7b (G0 ∈G depends on our choice of nodes, here
1, 2, in H). Then, we observe that the common past light-cones of the two nodes is the same when
connected through H or through G0 (compare the circuit of Fig. 8b with the circuit of Fig. 8c). It
hence holds that Pr [c1 ̸= c2 | CH,T ] = 1 = Pr [c1 ̸= c2 | CG0,T ] due to the non-signaling principle.
We conclude that the non-signaling distributed algorithm outputs a 2-coloring for H, which is
impossible.
A.3
Bounded-dependence model
The bounded-dependence model is similar to the non-signaling model, but the former does not allow
pre-shared non-signaling resources between the nodes. The following two new principles are needed
to define feasible distributions in the bounded-dependence model.
9While we are deceiving the nodes by promising a lifebuoy-shaped connecting graph but imposing instead H, the
nodes cannot locally detect the fraud in T = 2 communication steps or less. (More formally, the past light-cone in H
of any node is then compatible with a lifebuoy-shaped graph — an individual node cannot detect the difference and
must therefore, according to the non-signaling principle, output a color as if it were in a lifebuoy-shaped graph.)
64

--- Page 66 ---
Figure 9: In the bounded-dependence model, one can find non-trivial subgraph isomorphisms even
when the nodes are provided with unique identifiers.
Definition A.6 (Independence principle). Consider a set of gates connected in a circuit C, and
the corresponding distribution Pr [c1, . . . , cn | C]. Let U, V be two subsets of measurement gates
producing the outputs {cu}u∈U and {cv}v∈V , respectively. If the past light-cones of U and V do
not intersect, then Pr [{cw}w∈U∪V | C] = Pr [{cu}u∈U | C] · Pr [{cv}v∈V | C], that is their output
distributions are independent.
Definition A.7 (Device-replication principle). Identical and independent copies of non-signaling
gates and non-signaling resources can be prepared10.
Then, we obtain the following definition:
Definition A.8 (Bounded-dependence model, with unique identifiers). The distribution
Pr [c1, . . . , cn | CG,T ]
with unique identifiers has bounded dependence with locality T on graph G (without pre-shared
non-signaling resources) if and only if for all possible alternative connecting graph H of the nodes
and their replicates, there exists a distribution Pr [c1, . . . , cm | CH,T ] such as the non-signaling and
independence principles are respected, and such that the distribution is invariant under subgraph
isomorphisms.
Note a subtlety related to subgraph isomorphisms in the bounded-dependence model. There
is the variant where the nodes have identifiers in G, and the one where they do not. When the
nodes do not have any identifiers, the class of subgraph isomorphisms of all alternative graphs H
created out of the nodes in G and their replicates is obviously larger than with identifiers, because
the subgraph isomorphisms must respect the identifiers. However, even if the nodes of G do have
distinct identifiers, as H is created out of possibly many copies of the original nodes of G, H might
contain several nodes with the same identifiers. Hence, the group of subgraph isomorphism of H
might be nontrivial even if all nodes in G have distinct identifiers. For instance, in lifebuoy-shaped
graphs, one could consider the case represented in Fig. 9, which starts from the graph G0 in Fig. 7b,
duplicates all nodes, and constructs a new graph H of 24 nodes with identifiers ranging from 1 to 12
with one non-trivial graph isomorphism cyclically permuting the nodes.
10Note that this principle does not imply that one can duplicate unknown non-signaling resources: device-replication
compatible with the quantum no-cloning theorem.
65

--- Page 67 ---
A.3.1
Relation with finitely-dependent distributions
Our bounded-dependence model is directly connected to the concept of finitely-dependent distri-
butions introduced in mathematics [1, 44–47, 63]. In this framework, in a graph H, the color ci
produced by each node i is seen as the result of a random process Ci. The set of all random
processes {Ci}i is said to be k-dependent in graph H if, for any two subsets U, V of the nodes of
H which are at least at distance k + 1, the two sets of processes {Cu}u∈U and Cvv∈V are inde-
pendent. In our notation, assuming even k and taking T = k/2, this is equivalent to asking that
Pr [{cw}w∈U∪V | CH,T ] = Pr [{cu}u∈U | C] · Pr [{cv}v∈V | CH,T ].
Hence, the question of the existence of distributions with bounded dependence that solve some
problem can directly be formulated in terms of the existence of finitely dependent distributions over
a family of graphs that satisfy additional constraints of compatibility (to satisfy the non-signaling
principle) and symmetries (to cope with subgraph isomorphisms).
66

--- Page 68 ---
Distributed,
parallel,
message-
passing
models
Probability
distributions
Distributed
sequential
models
Centralized
sequential
models
New result
New result
New result
New result
Simulation
of stronger
models in
weaker
models
(for rooted
trees)
Free symmetry
breaking in
stronger models
deterministic
LOCAL
randomized
LOCAL
quantum-
LOCAL
bounded-
dependence
deterministic
LOCAL
(shared)
randomized
LOCAL
(shared)
quantum-
LOCAL
(shared)
non-signaling
deterministic
SLOCAL
randomized
SLOCAL
deterministic
dynamic-
LOCAL
deterministic
online-
LOCAL
randomized
online-
LOCAL
Figure 10: Landscape of models and their relations for LCL problems. A black arrow X →Y
indicates that model Y is at least as strong as model X and can simulate any algorithm designed
there. A blue arrow X →Y indicates that we additionally get symmetry-breaking for free: locality
O(log∗n) in model X implies locality O(1) in model Y . An orange arrow X →Y indicates that at
least in rooted trees we can simulate highly-localized algorithms in model X using the weaker model
Y so that e.g. locality O(log∗n) in model X implies locality O(log∗n) in model Y (see Theorem 7.1
and [38] for details).
67
