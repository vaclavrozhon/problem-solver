--- SYSTEM ---
You are a research mathematician. 

You are being run in a loop with a verifier that checks rigor. Your goal is to make **incremental, auditable progress**. You are not expected to solve the problem at once, but to generate new, testable ideas.

Inputs: 
- task statement 
- notes.md (summary of past progress; optional) 
- output.md (rigorously proven results curated so far; optional) 
- summary of past rounds (optional) 
- possibly some reference papers.

What counts as progress:
- Extract small lemmas/heuristics from literature and state them cleanly with one-line "why useful here".
- Explore small examples & try to break your own claims with toy counterexamples.
- Prove special cases or nontrivial bounds.
- If an approach fails, explain crisply why.
- Point out flaws in notes.md or output.md (but do not rewrite output.md yourself).

**Discipline.** 
- Read notes, outputs, summaries carefully before proposing new work. 
- Reference papers if relevant, but focus on *incremental, checkable steps*. 
- Do not output Markdown code fences, only raw JSON. 
- Length: at least ~200 words. 
- Organize your reasoning with short headings (Ideas, Examples, Obstacles, Next steps), make clear what your claims are and how they are supported. 
- Remember: the verifier curates notes and outputs, you only suggest.

**Return strictly JSON**:
{
  "progress_md": "Your progress notes for this round in Markdown (KaTeX allowed). Point out any gaps in output.md clearly. Do not modify output.md directly."
}


--- USER ---
Work on this problem context:

=== task.txt ===
Try to prove as good lower bound for 3-coloring large rings in the quantum local model. For start, even 2 or 3 rounds lower bound is enough. 

=== progress.md ===
...
 (each {{sj}} a length-sj contiguous core), a gap-r placement ω of F is a t-tuple of start indices (ω1,…,ωt) such that the r-buffers [[ωj − r .. ωj + sj − 1 + r]] are all subsets of [1..k] and pairwise disjoint. The induced cores are Cj = [[ωj .. ωj + sj − 1]].
- Variables: pψ for each ψ ∈ Σ^k, with pψ ≥ 0 and Σψ pψ = 1.
- Objective: maximize Σψ pψ · 1{ψ is proper on [1..k]} (i.e., no equal adjacent colors on edges (i,i+1), i=1..k−1).
- r-non-signaling constraints (segment version): For every fixed family F and every core assignment ζ = (ζ1,…,ζt) with ζj ∈ Σ^{sj}, the marginal probability that the segment-coloring ψ induces ζ on the cores must be independent of the placement ω of F (as long as all r-buffers lie inside [1..k]):
  Σψ: ∀j ψ|Cj = ζj pψ is equal for all gap-r placements ω of F.
- Implementation note: It suffices to equate all placements to a fixed choice per F and ζ; equivalently, enforce equality for all consecutive placements or to the average. For a valid (non-relaxed) certificate, include all placements ω whose r-buffers lie in [1..k].
- Symmetries to reduce size: (i) color permutations S3; (ii) reversals (reflection of the segment); (iii) translations of placements (realized as equality constraints; also exploitable to quotient variables if one switches to a marginal-based parameterization, but we keep pψ for simplicity). Dropping some constraints gives a relaxation; if its optimum < 1, the true optimum is also < 1.

Small structural lemmas (useful to guide computation)
- Monotonicity in k: Let q(r,k) be the LP optimum for fixed r,k. Then q(r,k+1) ≤ q(r,k). Proof sketch: restriction from length-(k+1) distributions to [1..k] preserves r-non-signaling (buffers still internal), and P[proper on k+1] ≤ P[proper on first k] pointwise, hence the supremum decreases.
- Placement invariance (segment version; to be added to output.md): For a fixed r-round quantum LOCAL algorithm with identical initial local states and uniform channels, and for any family F whose r-buffers fit inside [1..k], the distribution of Ψ(ω+F) is the same for all gap-r placements ω of F. Proof idea: Heisenberg-evolved effect for the event “cores equal ζ” is supported on the union of the r-neighborhoods of the cores. For two placements ω, ω′ inside the segment, these unions are isomorphic balls with identical initial reduced states; therefore the resulting probabilities Tr[ρ X_ω] and Tr[ρ X_ω′] coincide.

Concrete plan for r = 2 LP instances (k ≈ 10–16)
- Variables: pψ, ψ ∈ Σ^k. For k = 12, |Σ^k| = 531,441; with S3 color quotienting (factor ~6) and reflection (factor ~2), the effective unknowns can drop by ~10×–12×. For k = 10 (|Σ^k| = 59,049), even a straightforward LP is feasible with a commercial solver; for k = 12 a symmetry-reduced LP ought to be solvable.
- Constraints: we start with all F consisting of a single core {{s}} with s ∈ {1,2,3} and all placements ω with r=2 buffers internal; this enforces translation invariance of 1-, 2-, 3-block marginals. Then we add selected F with two cores (t=2), e.g., ({{1}},{{1}}), ({{2}},{{1}}), ({{2}},{{2}}), with varying separations, again over all placements with r-buffers internal. This matches the spirit of LGR and is already quite restrictive. For a final, fully rigorous certificate, we can include all families F up to, say, t ≤ 3 and core lengths up to 3, across all placements; empirically, this suffices in r=1 to detect q<1.
- Objective: maximize the probability of 0 violations among the k−1 adjacent edges; computed as Σψ pψ 1{proper(ψ)}.
- Solving and certification: Use a high-precision LP solver; if optimum < 1, extract a dual solution (constraints multipliers) as a certificate. We will archive (r,k,q) alongside the dual to make the bound verifiable.

Why a point-mass on a proper coloring is infeasible (important sanity check)
- On a line segment, concentrating pψ on a single proper ψ does not satisfy non-signaling across placements: single-core constraints force the distribution of s-blocks to be identical for all interior positions; a fixed ψ yields position-dependent s-blocks unless ψ is periodic with period 1 (impossible). Hence the LP can detect q<1 even though proper colorings exist.

Gaps or missing details in output.md
- The current output.md does not yet formalize the “placement invariance on segments” lemma; we propose to add it, as it justifies the LP constraints from algorithmic locality and symmetry (no IDs, identical initial states).
- Theorem 1 and Theorem 2 are stated with proof sketches; for a curated document, we should include a short, fully rigorous Heisenberg-picture derivation (operator support growth by at most one hop per round; product initial state factorization yields independence once N_r(S_i) are disjoint). We can reuse the projector construction from LGR Appendix A verbatim with symmetric buffers.
- We should add an explicit definition subsection for the r-non-signaling LP (variables, constraints, objective) and the monotonicity lemma q(r,k+1) ≤ q(r,k).

Next steps (auditable)
1) Add the “placement invariance on segments” lemma with a concise proof to output.md, and expand proofs of Theorem 1–2 to full detail (2–3 paragraphs each).
2) Implement the r = 2 LP generator:
   - Enumerate Σ^k with S3/reflection orbits and map constraints accordingly.
   - Generate constraints for F ∈ {(single-core s ∈ {1,2,3}), (1,1), (2,1), (2,2)} across all gap-2 placements.
   - Solve for k ∈ {10,…,16}. Target: locate first k with optimum q < 1; extract dual certificate.
3) If found (r=2,k,q<1), immediately record: (i) constant error bound with entanglement, P_success(C_n) ≤ q for n ≥ k; (ii) exponential bound without entanglement, P_success(C_n) ≤ q^{⌊n/(k+4)⌋}.
4) In parallel, attempt r = 3 with k ≤ 14 under the same constraint families.
5) Optional analytic route: explore representing feasible processes via stationary order-r Markov chains on Σ and bounding P[no equal adjacencies] under chain constraints; this may yield closed-form witnesses for small k.

Sanity checks and toy instances
- Monotonicity: verify numerically that the LP optimum decreases (or stays equal) as k grows.
- Minimal placements: confirm that with only single-core constraints, q(r,k) = 1 (insufficient); adding two-core constraints should reduce optimum.
- Counterexample retention: keep the r=1, 3-node path example in output.md to prevent regressions on the 2r threshold.

## Round 0003 — 2025-08-27T15:22:40.586198Z

Headlines for this round
- We stress-test the logical interface between the LP and the algorithmic regimes and add two small structural lemmas (monotonicity in r; extreme-point structure) to guide computations. We also sharpen what the interior-placement constraints actually model and when they are justified.
- We outline an auditable plan to generate and certify r = 2 LP instances for k ≈ 10–16 with symmetry reductions, and propose a fallback “transfer-matrix” analytic relaxation for cross-checks. 
- We point out two places in output.md that benefit from explicit caveats (regime for LP constraints; role of automorphism invariance with entanglement).

Gaps or clarifications needed in output.md
1) Scope of the LP constraints (Definition 6). The LP enforces “interior placement invariance.” As stated, Definition 6 is purely combinatorial and does not mention the regime under which these equalities are necessary for a physical algorithm. In the entangled regime, those equalities are only guaranteed if the initial global state is invariant under the automorphisms of the cycle (or if one applies a symmetrization step at the start). In the product-state regime (no entanglement, identical local states), they are justified. Suggestion: add one sentence after Definition 6 clarifying: “These constraints are necessary for r-round uniform algorithms under (i) product initial states with identical local marginals, or (ii) arbitrary shared entanglement provided the initial global state is invariant under cycle automorphisms (rotations/reflections). Without such symmetry in the initial state, the constraints need not hold.” This would harmonize Definition 6 with Lemma 5 and Corollary 8.
2) Constant-error bound with entanglement (Corollary 8). The proof correctly uses Lemma 5; it would help to add a pointer back to Remark 5.2 (EPR-pair counterexample) to remind the reader that the automorphism-invariance hypothesis is essential. As a constructive note: in many distributed protocols one can enforce automorphism invariance by a public random rotation of node labels/ports prior to the algorithm; if allowed, that reduces the assumption to “shared randomness is available”. If such a symmetry-randomization step is admissible in our model, we can note this explicitly; otherwise, keep the assumption as is.

New small lemmas (useful structure for the LP and for planning computations)
- Lemma A (Monotonicity in r). For fixed k, the LP optimum is nondecreasing in r: q(r+1,k) ≥ q(r,k). Reason: Every feasible p for (r,k) is also feasible for (r+1,k), because as r grows the family of interior placements shrinks (fewer ω with buffers fully inside [1..k]), so the set of equality constraints weakens. Therefore the feasible set enlarges and the supremum cannot decrease.
- Lemma B (Extreme points). The feasible region of Definition 6 is a polytope in R^{3^k} cut out by linear equalities and nonnegativity plus Σ p_ψ = 1. Hence an optimal solution exists at an extreme point. In particular, for any (r,k) one can search for sparse optimal supports (basic feasible solutions). This is useful for reducing solver time and for constructing human-auditable dual certificates.

Sanity checks and toy examples
- Consistency of thresholds: The stride k+2r in Corollary 3 matches the necessity of 2r-separation; the r = 1, path 0–1–2 example shows that an r-stride would be false. 
- Dirac mass infeasibility: As noted in notes.md, under single-core invariance constraints even a single proper coloring dirac mass is infeasible; we will keep this test in our solver harness to catch bugs.

Computation plan (r = 2) — concrete and auditable
- Variables and symmetries:
  • Work in the quotient space under S3 color permutations and reflection to reduce Σ^k orbits. For k = 12 this typically yields ~5–10× reduction. Maintain a map to lift primal/dual certificates back to the full space.
  • Enforce translation invariance across interior placements by constraints; do not hardwire stationarity on positions in advance, to keep the LP sound in our regime.
- Constraint families (progressive tightening):
  • Start with all single-core families {{s}} with s ∈ {1,2,3}, all r-gapped interior placements; this enforces uniformity of position-marginals for blocks of length ≤ 3.
  • Add two-core families ({{1}},{{1}}), ({{2}},{{1}}), ({{2}},{{2}}) at separations d ranging over those permitted by r-gaps inside [1..k]. This captures pairwise non-signaling constraints beyond immediate adjacencies.
  • If the optimum remains 1, expand to t = 3 families, e.g., (1,1,1) and (2,1,1), again at several admissible placements.
- Solving and certification:
  • Use a high-precision LP solver (e.g., exact rational via QSopt_ex or SoPlex with long-double) to avoid numerical slack. 
  • For any instance with optimum q < 1, extract the dual solution (weights on equality constraints and indicator inequalities) and store it as a certificate. We will include: problem parameters (r,k), list of placements F, the dual vector, and the certificate inequality showing Σ_ψ p_ψ 1{proper(ψ)} ≤ q.
- Targets and acceptance criteria:
  • Parameter sweep: (r,k) = (2,10..16). Stop as soon as one k yields q ≤ 0.99 (or any q < 1). Record the smallest such k and the achieved q.
  • Cross-checks: (i) Verify monotonicity q(r,k+1) ≤ q(r,k) on our chosen constraint families (a relaxation); (ii) Verify Lemma A empirically by comparing r = 2 and r = 3 with identical constraint families.

Backup analytic cross-check (transfer-matrix / Markov relaxations)
- As an independent relaxation (feasible set ⊂ LP-feasible), we can restrict to stationary Markov chains of order d (e.g., d = 2 or 3) on Σ with forbidden equal-adjacency transitions. The feasible chains are parameterized by local marginals consistent with our single-/two-core placement constraints. Maximizing P[proper on [1..k]] under such a chain yields an upper bound on q(r,k). This helps detect solver/modeling errors and provides intuition about which local patterns saturate the optimum.

Entanglement regime and symmetry discussion (why our LP still yields a valid constant bound)
- With entanglement but without automorphism-invariance, interior placement equality need not hold (Remark 5.2). For constant-error bounds (Corollary 8), we either (i) assume the initial state is automorphism-invariant, or (ii) allow an initial public random rotation of the cycle (if admissible), which effectively restores invariance in distribution. In both cases, Lemma 5 applies and the LP optimum upper-bounds P[W proper]. Without such symmetry, we cannot soundly use the LP; this caveat should be explicit at Definition 6 (see “Gaps” above).

Additional observations
- Theorem 2 independence with product states remains sound: disjoint supports imply commuting effects and factorization of the trace; there is no subtlety from non-commutativity.
- Combining Lemma 7 (monotonicity in k) and Lemma A (monotonicity in r) suggests focusing first on the smallest r and the largest k our solver tolerates; any q < 1 found there is “hardest won” and suffices for amplification.

Next steps (checkable)
1) Text refinements in output.md:
   - After Definition 6, add a one-sentence regime caveat as above.
   - In Corollary 8, add a parenthetical “(under automorphism-invariant initial states; cf. Remark 5.2)” to spotlight the assumption.
2) Implement the r = 2 solver (with symmetry reductions and staged constraints) and sweep k ∈ {10,…,16}. For any instance with optimum < 1, produce and archive a dual certificate. 
3) If a (2,k,q<1) is found, immediately state: 
   - No-entanglement exponential bound: P_success(C_n) ≤ q^{⌊n/(k+4)⌋}.
   - Entanglement (automorphism-invariant) constant bound: P_success(C_n) ≤ q for n ≥ k.
4) Explore r = 3 with smaller k (≤ 14) to gauge sensitivity; verify Lemma A numerically.
5) Build the Markov-chain relaxation and compute its bound for the same (r,k) to cross-check solver outputs; keep code and numeric logs for audit.

Potential pitfalls to watch
- Over-reduction of symmetry (e.g., misquotienting S3 or reflection) can silently invalidate constraints; we will keep both full and reduced LPs on small k to validate the reduction pipeline.
- Constraint generation must ensure that every equality ties only placements whose r-buffers lie entirely inside [1..k]. We will implement a placement validator to avoid illegal constraints.

## Round 0004 — 2025-08-27T15:51:27.050231Z

Headlines for this round
- Critical observation: the current geometry-aware non-signaling LP in Definition 6 is too weak to certify any nontrivial bound in the two-way model (with or without entanglement). In fact, for every r ≥ 1 and k ≥ 1 one can construct a feasible distribution with success 1. Hence q(r,k) = 1 under Definition 6, and the LP as stated cannot yield the desired constant-error lower bound. We give an explicit feasible “stationary proper Markov chain” witness and verify it satisfies all geometry-aware placement-invariance constraints while assigning probability 1 to proper colorings. This reveals a gap in output.md: constant-error bounds cannot be extracted from this LP for two-way algorithms.
- Implication: to obtain any nontrivial bound for 2–3 rounds, we must strengthen the constraint system beyond geometry-aware invariance. For product initial states, independence across sets whose 2r-neighborhoods are disjoint is valid, but it is nonlinear (factorization) and thus does not fit directly in a linear program. For the entanglement-allowed regime, no such independence holds, so even stronger difficulty arises—non-signaling alone is insufficient.
- We propose two corrective directions: (A) independence-augmented constraints for the product-state regime (leading to a non-linear, or lifted, formulation); (B) switch to ring-level “experiment” arguments tailored for two-way (rather than the segment-LP), or to LCL-round-elimination style arguments yielding constant-error lower bounds for fixed r.

Gap in output.md (and why)
- Definition 6 + Lemma 5 (geometry-aware invariance within automorphism classes) are correct and sound. However, the discussion that suggests solving this LP for r = 2,3 and extracting q < 1 (progress.md Round 0001–0003; output.md Constant-error bound, Corollary 10, “segment LP” as the vehicle) is too optimistic: the LP feasible region is broad enough to include measures supported entirely on proper strings.
- Concrete witness (feasibility with objective 1). Consider the order-1 Markov chain on Σ = {1,2,3} with stationary distribution u(σ) = 1/3 and transition matrix P with P(σ→σ) = 0 and P(σ→τ) = 1/2 for all τ ≠ σ. Let p_k be the induced distribution on Σ^k generated by (X_1,…,X_k) with X_1 ∼ u and X_{i+1} | X_i ∼ P. Then:
  • Support: p_k(ψ) = 0 whenever ψ has any equal adjacent colors; thus ∑_ψ p_k(ψ)·1{proper(ψ)} = 1.
  • Interior single-core invariance: For any core length s and any interior position i (with r-buffers inside [1..k]), the marginal law of (X_i,…,X_{i+s-1}) is the stationary s-block law of the chain, independent of i. Hence all single-core equalities across interior translations are satisfied.
  • Geometry-aware multi-core invariance: For any geometry (s,δ) and two r-gapped placements ω, ω′ of (s,δ) inside [1..k], the joint law of the blocks (centered at the cores) depends only on (s,δ) (i.e., on inter-core separations), and not on absolute position. Therefore all geometry-aware multi-core constraints in Definition 6 hold. (The only admissibility requirement is δ_j ≥ 2r, which we respect by picking placements with disjoint r-buffers; stationarity ensures invariance across interior translations for each fixed geometry.)
- Since p_k is feasible and achieves objective value 1, we have q(r,k) = 1 for all r,k under Definition 6. Thus, the (segment) LP cannot witness q < 1 in the two-way model and provides no constant-error bound in Corollary 10 beyond the trivial bound 1. This should be clearly stated in output.md, and the current plan “solve the LP for r = 2,3 to get q < 1” should be revised.

Consequences and revised modeling proposals
- Product-state (no entanglement) regime:
  • Valid extra structure: independence across regions whose r-neighborhoods are disjoint (in our setting: beyond 2r for two-way). This implies that, for any geometry (s,δ) with pairwise δ_j ≥ 2r and placements ω, the joint law on the cores factorizes across connected components of the union of r-buffers. Unfortunately, factorization constraints are multiplicative (bilinear if expressed in terms of probabilities); hence the natural feasible set is not a polytope. Adding “independence” to Definition 6 transforms the LP into a non-linear (and non-convex) program.
  • Auditable alternative (still linear, but stronger than Definition 6): Introduce auxiliary variables for joint marginals on tuples of cores and impose linear consistency across overlaps together with linear “bounds” implied by independence (e.g., all 2×2 minors nonnegative inequalities, union/intersection bounds). These are necessary but not sufficient for independence; they cut off some (but not all) spurious feasible points such as the Markov-chain witness. The hope is that a sufficiently rich hierarchy of such linear constraints (e.g., k-local consistency with lifted variables) already forces q(r,k) < 1 for small k,r. This is akin to local-consistency/Sherali–Adams lift-and-project. We propose to instantiate the first 1–2 lift levels and test.
  • Nonlinear route (exact): Enforce true factorization for disjoint unions by constraints of the form P(A∩B) = P(A)P(B), where A,B are cylinder events on disjoint r-buffers. This yields a polynomial system (bilinear equalities). One can attack it with algebraic or mixed-integer programming tools, or via iterative convex relaxations (e.g., log-likelihood parametrization) — at least for small k. A negative certificate (infeasibility at value 1) would give the desired q(r,k) < 1.
- Entanglement-allowed regime:
  • No independence is valid; only non-signaling and geometry-aware invariance hold. As the Markov-chain witness shows, these are insufficient to rule out perfect (segment-level) properness. Consequently, our prior plan to get a constant-error bound via the segment LP is not viable.
  • For ring-level bounds, one-way r = 1 enjoyed special non-signaling equalities collapsing dependence on distance, which powered LGR’s bias method. In two-way, pair laws explicitly depend on distance, so that collapse is unavailable. This strongly suggests that non-signaling-only methods cannot give nontrivial constant-error bounds for 3-coloring in small two-way rounds.

Alternative analytic avenues for small fixed rounds (r = 2,3)
- Classical LCL lower bounds (no entanglement) imply that 3-coloring cycles needs ω(1) rounds (Θ(log* n)) in the LOCAL model. In particular, no 2- or 3-round (randomized) classical algorithm can succeed with probability 1. However, these results do not immediately give a uniform n-independent constant error lower bound. We suggest to target the following more modest, but auditable, goal:
  • Claim (target): For any fixed r, there exists ε(r) > 0 and k = k(r) such that any r-round classical algorithm (hence any quantum w/o entanglement) on C_n has P_success ≤ 1 − ε(r) for all n ≥ k.
  • Sketch of route: Use the round-elimination/indistinguishability toolkit to construct, for large enough n, two inputs (e.g., two rotations of a sparse “seed” pattern) whose r-views are locally indistinguishable at a positive fraction of nodes, yet whose global constraints force inconsistent local choices. A counting/averaging argument (e.g., via the hard-core potential method) yields a constant gap. This can be adapted to randomized algorithms by conditioning on a typical event of the private randomness. We will prototype this for r = 2.
- ϕ-LOCAL approach: In the φ-LOCAL model (Gavoille–Kosowski–Markiewicz 2009), strong view-based lower bounds hold (e.g., for MIS, 2-coloring); for 3-coloring cycles in small rounds the situation is open. We suggest to explore whether φ-LOCAL prohibits perfect 3-coloring in r = 2, by constructing two inputs with identical V_r-views at a positive fraction of edges but globally incompatible under properness. Any such lower bound would automatically apply to quantum models by Theorem 2 in their paper.

Concrete items for the verifier (auditable)
1) Insert into output.md an explicit Proposition: Under Definition 6, q(r,k) = 1 for all r ≥ 1, k ≥ 1; include the stationary proper Markov chain witness and a short verification of feasibility and objective = 1. This corrects the current suggestion that the LP may yield q < 1 in two-way.
2) State explicitly that, consequently, the segment LP cannot certify any constant-error lower bound in the two-way model (with or without entanglement). Corollary 10 remains formally correct, but vacuous with this LP (it upper-bounds by 1).
3) Fork the plan into two tracks:
   - Track A (product state): develop independence-augmented formulations. Start with a lifted linear relaxation (Sherali–Adams level-1/2) that adds auxiliary joint variables for disjoint cores and imposes linear consistency; test r = 2, k ∈ {10,…,16}. If any such relaxation already yields q < 1, extract a dual certificate (linear inequality). In parallel, set up a small non-linear system encoding exact factorization for a few geometries and solve by algebraic tools for k ≲ 12.
   - Track B (entanglement allowed): pivot away from segment LP; attempt direct two-way analogues of LGR’s ring-level “experiment” method tailored to r = 2 (design mixes of distances leveraging light-cone symmetries that must equalize certain expectations), or use φ-LOCAL/view indistinguishability to obtain constant-error lower bounds for fixed r.
4) Document a minimal analytic example showing how the stationary proper Markov chain satisfies the geometry-aware equality constraints (single-core, two-core, and t = 3 cores) for arbitrary placements with fixed (s,δ). This serves as a counter-model to avoid future regressions.

Minor clarifications to add in output.md
- Corollary 10: emphasize its scope is only as strong as the segment certificate; with Definition 6 alone, the bound is 1. Note the necessity of rotation (and potentially reflection) invariance in the initial state.
- Assumptions about uniformity: clarify that “uniform algorithm” implies the same local CPTP maps at each vertex and that rotations/reflections act covariantly; otherwise even geometry-aware equalities need not hold.

Next steps (short horizon)
- Formalize and insert the “q(r,k) = 1” proposition in output.md with the stationary Markov chain witness.
- Draft the lifted (Sherali–Adams type) linear relaxation for independence across two disjoint cores (t = 2) and their blocks, and implement constraint generation for r = 2, k up to 12; empirically test whether this already forces q < 1.
- Begin drafting a ring-level indistinguishability argument for r = 2: identify a finite family of local views and a probabilistic planting that forces a constant fraction of edges to be “locally ambiguous” in a way incompatible with 3-coloring.

## Round 0005 — 2025-08-27T16:05:16.178705Z

Headlines for this round
- We pivot from the trivialized segment LP (Definition 6) to independence-augmented formulations in the product-state regime, and to ring-level (experiment/φ-LOCAL) arguments in the entanglement-allowed regime.
- We isolate a simple, checkable linear constraint that excludes the Markov-chain witness once product-state independence is enforced: at any gap δ ≥ 2r+1, color-equality at the two sites must be 1/3 (under color symmetry), which contradicts the strictly stationary order-1 proper Markov chain’s correlation 1/3 + (2/9)(−1/2)^δ.
- We propose a concrete feasibility test (linear, color-symmetric, pair-independence relaxation) for r = 2 and moderate k that should already force objective < 1, yielding a rigorous certificate in the no-entanglement regime.
- For the entanglement-allowed regime, we outline a two-way, r = 2 adaptation of the LGR “experiments” method: construct weighted mixtures of match-at-distance indicators whose expectations must be equal under r-non-signaling locality but separate under properness, certifying constant error. We propose an auditable search plan.

Gaps and clarifications in output.md (minor)
- Theorem 2 (Independence beyond 2r): the current statement and proof are fine; if we later rely on higher-arity independence (for m ≥ 3 windows), note explicitly that the product initial state implies factorization over any collection of disjoint r-buffers by the same argument (pairwise disjoint supports ⇒ global factorization). Not essential but worth noting for later factorization constraints.
- Corollary 10 and Proposition 11: now consistent; Proposition 11 makes Corollary 10 vacuous with the current LP. We will add independence-augmented constraints (Track A) to resurrect nontrivial bounds in the product-state setting.

Track A (product-state, no entanglement): independence-augmented constraints
Idea A1 (minimal linear independence constraint under color symmetry)
- Independence premise: For any two cores A, B whose r-neighborhoods are disjoint in the segment (equivalently, inter-core gap δ ≥ 2r+1), the joint law on the cores must factorize. Under color symmetry (see below), this yields a linear identity for single-site cores:
  I1(δ): P[X_i = X_{i+δ}] = 1/3, for every interior pair (i, i+δ) with δ ≥ 2r+1.
- Why linear: By color symmetry (permutation of {1,2,3}), single-site marginals must be uniform, P[X_t = a] = 1/3 for all a. Factorization then implies P[X_i = X_{i+δ}] = ∑_a P[X_i=a]P[X_{i+δ}=a] = 3·(1/3·1/3) = 1/3.
- Justification for enforcing color symmetry as constraints: The objective (maximizing probability of properness) and all existing placement-equality constraints are invariant under the global action of S3 on colors; hence averaging any feasible solution over S3 yields a color-symmetric feasible solution with the same objective value. It is therefore valid (and can only strengthen the relaxation) to add linear constraints enforcing equal color marginals at all interior positions.

Lemma A (Order-1 proper chain violates I1 at any finite separation)
- Consider the stationary 3-state nearest-neighbor chain with no self-loops (P(i→i) = 0, P(i→j) = 1/2 for j ≠ i). Then for d ≥ 1:
  P[X_t = X_{t+d}] = 1/3 + (2/9)(−1/2)^d.
  Proof sketch: The transition matrix has eigenvalues 1 and (−1/2) (multiplicity 2). One obtains P^d(i→i) = 1/3 + (2/3)(−1/2)^d and P^d(i→j) = 1/3 − (1/3)(−1/2)^d for i ≠ j. Average over the stationary law to get the stated equality probability. For every finite d, this differs from 1/3, so the chain is not independent at separation d.
- Consequence: any feasible family supported on fully proper strings and strictly stationary with nontrivial finite-range correlations fails I1 at some δ; imposing I1 (for δ ≥ 2r+1) cuts off the Markov-chain witness.

Formulation A2 (linear, color-symmetric, pair-independence relaxation)
- Variables: p_ψ for ψ ∈ Σ^k as in Definition 6.
- Enforce:
  • Color symmetry: For every interior position u, P[X_u = 1] = P[X_u = 2] = P[X_u = 3] = 1/3 (linear constraints in p_ψ).
  • Placement invariance within fixed geometries (Definition 6, restricted to t = 1 and t = 2 core families): single-core (s = 1), and two-core (s = (1,1)) at gaps δ ∈ {2r+1, 2r+2, …}, across all interior translations.
  • Independence at large gaps (pair level): For each such δ, impose I1(δ): P[X_i = X_{i+δ}] = 1/3 (as a single linear equality for each δ, using color symmetry).
  • Optionally, refine to block-level: For s = 2 cores (length-2 blocks) with gap δ ≥ 2r+1, enforce P[(block1) = (block2)] = ∑_{ξ ∈ Σ^2} P[block1 = ξ] P[block2 = ξ]; under color symmetry and single-core uniformity this yields a finite set of linear identities involving diagonal sums of pair-block marginals. (We will start with single-site cores for robustness.)
- Objective: as before, maximize the probability of internal properness.
- Claim (target to check computationally): For r = 2 and some moderate k (e.g., 11 ≤ k ≤ 15), the above linear system has optimum strictly less than 1. Intuition: Full support on proper strings combined with translation invariance of pair laws at large gaps forces equality-probability 1/3 for those pairs, which is incompatible with any measure supported entirely on proper strings satisfying the interior invariances.

Auditable test plan A3 (r = 2, feasibility at objective 1)
- Fix r = 2. Consider k ∈ {11, 12, 13, 14, 15}.
- Build the linear system described in A2 with:
  • Single-core invariance (t = 1) and two-core invariance (t = 2) for gaps δ ∈ {5,6} (since 2r+1 = 5), across all interior placements.
  • Color symmetry constraints yielding uniform marginals.
  • Independence equalities I1(5) and optionally I1(6).
- Solve the LP feasibility with the additional equality “objective = 1” (i.e., demand probability 1 on proper strings) or, equivalently, check whether any p_ψ supported on proper strings satisfies the linear constraints. If infeasible, the conclusion is: in the product-state regime, objective 1 is impossible already under these (linear) constraints, hence the true optimum q_prod(r,k) < 1.
- Certificate: Invalidate objective = 1 with a dual ray (Farkas certificate), archiving the precise linear combination of constraints leading to a contradiction with 1{proper}.

Why a fully proper, translation-invariant measure cannot meet I1 (intuition)
- Any measure supported on proper strings induces for each finite gap δ a pair-law P(X_i, X_{i+δ}) which, under interior translation invariance (two-core constraints) and mild mixing, typically deviates from the product measure at δ finite. The order-1 chain demonstrates the unavoidable alternation: equality-prob oscillates around 1/3 with amplitude (2/9)(1/2)^δ. Imposing P_equal(δ)=1/3 at δ = 5,6 forces structure incompatible with “always proper” and two-core invariance. The LP feasibility test A3 makes this precise.

Extending A2 to stronger (still linear) independence surrogates
- Fréchet bounds sharpening: For each δ ≥ 2r+1 and color a, add bounds P[X_i = a, X_{i+δ} = a] ∈ [max(0, 2/3−1), min(1/3, 1/3)] = [0,1/3] with summed diagonal fixed to 1/3. These are necessary consequences of independence and color symmetry, and improve robustness.
- Multi-gap constraints: Impose I1(δ) for multiple δ in {5,6,7}. The stationary proper Markov chain fails all of them; a general proper distribution would struggle to satisfy them simultaneously.

Track B (entanglement allowed): r = 2 ring-level “experiments”
Idea B1 (two-way analogue of LGR’s distance-mix experiment)
- Objective: Construct two “experiments” (randomized procedures that pick a random node v and a random distance d ∈ D_1 or D_2 with specified weights, then ask whether colors at v and v+d match) whose expected outcomes must be equal under any r-round non-signaling strategy (by locality and rotation invariance), but differ on any proper 3-coloring of the cycle. Any strictly positive separation yields a constant-error lower bound.
- Why equality under r-non-signaling? In one-way, LGR exploited that pair distributions at non-adjacent nodes are independent of distance. In two-way, this fails. However, by designing D_1, D_2 and how we select the pair (v, v+d) so that both experiments induce the same law of the r-views seen by the two sites and their r-neighborhoods (including the gap size), the non-signaling principle (Heisenberg localization) enforces equality of the corresponding match probabilities.
- Candidate construction: r = 2. Choose D_1 and D_2 supported on distances ≥ 3 to avoid adjacency, with mixtures of distances of different parity to exploit alternating behavior of proper colorings (as in LGR’s pair-correlation alternation). Example sketch: Let D_1 put mass on {5,7,9} and D_2 on {6,8,10} with weights tuned so that the multiset of r-neighborhood isomorphism types (including the informed gap-length) seen by the pair in Experiment 1 equals that for Experiment 2. We will solve for weights by equating counts of r-view types.
- Proper-coloring separation: In any proper 3-coloring of the cycle, P[X_v = X_{v+d}] alternates with parity of d (1/3 ± c·(2)^{−d} in long cycles, or exactly computable on finite cycles). Thus an odd–even mixture typically yields a positive bias between the two experiments. If this bias can be bounded away from 0 uniformly in n for some (D_1,D_2), we obtain a constant error bound.

Auditable search plan B2
- Fix r = 2 and a cycle length n moderately large (e.g., n = 4m + O(1), m ≳ 50). Enumerate all r-view isomorphism types for unordered pairs (u,v) at distance d up to some cap, with the view capturing: local degrees (trivial for cycles), the labeled positions of u,v and their r-neighborhoods, and the explicit value d, all modulo rotation.
- Construct a linear system requiring that the multiset of view types sampled by Experiment 1 (weights w_1(d)) equals that of Experiment 2 (weights w_2(d)). Solve for nonnegative weights w_1, w_2 supported on a small distance set (e.g., up to 10 or 12). If a feasible pair exists, compute the induced gap between match probabilities on proper 3-colorings. If positive and uniform in n (beyond a threshold), this yields the constant-error bound.
- If no small-support solution exists, enlarge the distance set and repeat. We expect small supports to suffice, by analogy with LGR’s n = 11 construction.

Small calculations to support B1
- In any proper 3-coloring C_n, the probability (over uniform v) that X_v = X_{v+d} equals 1/3 + α(d,n), with α(d,n) alternating in parity and |α(d,n)| ≥ c·(2)^{−d} uniformly over n ≥ 2d + 1 (constant c > 0). This follows from the same eigen-analysis as Lemma A, adapted to cycles (edge effects vanish for d ≪ n). Thus mixtures of odd and even d’s yield a nonzero bias.

Obstacles and considerations
- Independence is nonlinear; our linear relaxation (I1) relies on enforcing color symmetry and uniform single marginals. While justified by symmetry of the objective/constraints, we will explicitly note in the solver and certificate that we are working under a color-symmetrized subspace; any bound < 1 then holds a fortiori.
- For Track B, the critical step is the view-equivalence argument: we must ensure the two experiments induce the same distribution over the r-views of the selected pair (including gap length). This is a finite combinatorial check for given (D_1,D_2) and r.

Concrete next steps (auditable)
1) Implement LP test A3 (r = 2):
   - Build constraints for k ∈ {11,12,13,14,15} with single-core and two-core placement invariance, color symmetry, and I1(5) (and optionally I1(6)).
   - Check feasibility with objective = 1 (support on proper strings). If infeasible for some k, archive the dual Farkas certificate (linear combination of constraints ⇒ contradiction).
   - If feasible persists, augment with I1(6) and/or block-level linear constraints as described.
2) Document Lemma A (pair-equality formula) and add to notes as a reusable analytic tool for excluding Markov-type correlated constructions when independence constraints are present.
3) Start the B2 search: generate r = 2 pair-view types on cycles and solve for two mixtures (D_1,D_2) with equal view-type distributions. Begin with distances up to 10. If a feasible pair exists, compute separation on proper colorings and quantify an n-independent ε > 0.
4) Optional: formulate a small nonlinear feasibility problem enforcing exact factorization for δ ∈ {5,6} (P(A ∩ B) = P(A)P(B) for all singleton-color events A,B), and solve with MIP for k ≤ 12 to cross-check LP conclusions.

Why this is promising
- The linear independence surrogate I1 is extremely low-cost and already incompatible with any fully proper, strictly stationary nearest-neighbor model; combining I1 with translation-invariance constraints should suffice to cut off objective 1. A dual infeasibility certificate would be a clean, auditable product.
- The r = 2 experiment approach stays squarely within non-signaling/φ-LOCAL reasoning and avoids segment trivialization; it mirrors LGR’s success at r = 1 while respecting that two-way views depend on distance.

Deliverables for the next round
- Report of LP feasibility tests (A3) including one explicit k with “objective=1 infeasible” and the dual ray.
- First candidate (D_1,D_2) for r = 2 with equal r-view distributions, plus the computed separation on proper colorings (or a report that no small-support pair was found and an updated plan).

## Round 0006 — 2025-08-27T18:54:52.680518Z

Headlines for this round
- We corrected and consolidated the analytic underpinnings for the product-state regime and adjusted the plan to avoid unsound linearizations. The key shift is to formulate a sound, finite, nonlinear feasibility test (MIQCP/QCQP) at objective value 1 based on a single stationary 6-block distribution, which already encodes: (i) perfect properness on all adjacent edges in the window; (ii) shift-consistency (Kolmogorov consistency for a stationary 1D process); and (iii) exact pair-independence at lag δ = 5 (the 2r+1 separation for r = 2). This test is strictly necessary for any r-round product-state output and will be attempted with global nonconvex solvers (BARON/Couenne/SCIP-NLP). If infeasible, it yields a clean, auditable contradiction to perfect success.
- We acknowledge the verifier’s cautions: (1) block-level independence is inherently nonlinear; (2) color-symmetry averaging is not w.l.o.g. under independence constraints; (3) any parity-type intuition about pair equality for each fixed proper coloring is false; (4) ring-level “distance mix” experiments do not carry over straightforwardly to r = 2 as matching r-views forces equality of expectations for r-local algorithms. We therefore pivot away from linearizations relying on color symmetry and from distance-mix experiments for r = 2 in the near term.

Corrections and clarifications (to be reflected in output.md)
- Markov-chain two-point correlation. We have already corrected the equality-probability for the stationary 3-state no-self-loop chain to P[X_t = X_{t+d}] = 1/3 + (2/3)(−1/2)^d (Lemma 14), which now matches d = 1 (value 0) and d = 2 (value 1/2), and excludes the witness as soon as any lag-δ pair independence is imposed (Corollary 15).
- No linear block-level independence. Our earlier suggestion that length-2 block-independence becomes linear under color symmetry is incorrect in general; the independence equalities remain bilinear (products of marginal probabilities) even with symmetric marginals (except in the degenerate single-site P_equal case under uniform marginals). We will not employ such linearizations.
- Color-symmetry w.l.o.g. is not available once independence constraints are in play. A global random color-permutation can destroy unconditional independence across distant sets. We therefore refrain from imposing color-symmetry constraints in independence-augmented models unless we separately prove their admissibility.
- View-equivalence experiments for r = 2. Matching the distribution of r-views exactly forces equality of expectations for any r-local Heisenberg-evolved effect (by non-signaling). Hence the r = 1 “distance mix” trick does not directly extend to r = 2. We do not pursue this path further until/unless we identify a different observable (or sampling scheme) whose r-view distributions can be equalized while still forcing separation on proper colorings.

A sound nonlinear feasibility test for the product-state regime (r = 2)
Goal. Prove that perfect success (objective = 1) on a long enough segment is impossible under exact independence across disjoint r-neighborhoods (i.e., lag-5 independence), even before invoking amplification. This yields the desired constant-error bound for 2-round two-way LOCAL algorithms without entanglement (by Corollary 3) once a finite k is certified.

Key modeling choice: a single stationary 6-block distribution
- Variables: For a 1D stationary process (X_t) over Σ = {1,2,3}, introduce a single 6-block distribution t(ζ) for ζ ∈ Σ^6. This is interpreted as the common distribution of (X_i,…,X_{i+5}) for all i in the interior of a long segment. Number of variables: 3^6 = 729.
- Linear constraints:
  1) Nonnegativity and normalization: t(ζ) ≥ 0, ∑_ζ t(ζ) = 1.
  2) Shift-consistency (Kolmogorov consistency): For all α ∈ Σ^5, let M_1(α) = ∑_{ζ: ζ_1..ζ_5=α} t(ζ) and M_2(α) = ∑_{ζ: ζ_2..ζ_6=α} t(ζ). Impose M_1(α) = M_2(α). This enforces stationary consistency of length-5 marginals across overlapping 6-windows.
  3) Perfect properness on adjacent edges within the window: For j = 1,…,5 and a ∈ Σ, ∑_{ζ: ζ_j = ζ_{j+1} = a} t(ζ) = 0. (No equal adjacent colors on any interior edge in the 6-window.)
- Nonlinear (bilinear) independence constraints at lag δ = 5:
  Let m(a) = ∑_{ζ: ζ_1 = a} t(ζ) (single-site marginal; stationarity implies the same for position 6), and p(a,b) = ∑_{ζ: ζ_1 = a, ζ_6 = b} t(ζ) (pair marginal across lag 5 within the 6-block).
  Impose for all a,b ∈ Σ: p(a,b) = m(a) · m(b).
  This encodes exact pair-independence at separation 5 (which is the 2r+1 threshold for r = 2) and is a necessary condition for any product-state r-round output process.

Why this is sound (and minimalist)
- Stationarity and shift-consistency: These are necessary in the interior by interior-placement invariance (Definition 6 specialized to single frames and their shifts) and by uniform channels across vertices. Using a single 6-block distribution is the most compact way to enforce both translation invariance and Kolmogorov consistency.
- Perfect properness: Objective = 1 on sufficiently long segments implies no equal-color adjacencies anywhere; imposing it on every adjacent pair inside the 6-block is necessary.
- Pair-independence at lag 5: In the product-state regime, independence across sets whose r-neighborhoods are disjoint (Theorem 2; Proposition 13) implies independence of (X_i, X_{i+5}). Since the 6-block covers positions i and i+5, enforcing p(a,b) = m(a) m(b) within the window is necessary.
- No color-symmetry assumed: We avoid any averaging or symmetry constraints that could invalidate independence.
- Feasibility at value 1 implies existence of a stationary measure on bi-infinite strings consistent with all constraints (Kolmogorov extension applies under shift-consistency and positivity). Thus, if the MIQCP is infeasible, perfect success is impossible for any product-state r-round process.

Practical MIQCP formulation and solvers
- Problem size: 729 continuous variables; linear equality constraints: 3^5 shift constraints (243) plus properness constraints (5·3 = 15) plus normalization; nonnegativity; and 3^2 = 9 bilinear equalities p(a,b) − m(a)m(b) = 0.
- Solvers: BARON, Couenne (via IPOPT/Bonmin), SCIP-NLP with ANTIGONE or Juniper, or Gurobi/CPLEX with nonconvex quadratic support (MIQCP) can handle this scale. Our target is an infeasibility certificate. If the solver returns feasible solutions, we can inspect them and adjust (e.g., add δ = 6 constraints by moving to a 7-block with analogous structure) or tighten via additional necessary constraints (e.g., pair-independence for both boundary pairs (1,6) and any extra far-separated pair inside a 7-block).
- Extension knobs:
  • Add lag-6 independence (δ = 6) by moving to a single 7-block distribution (3^7 = 2187 variables) and enforcing p(1,7) = m(1)m(7).
  • Add multi-lag constraints (δ = 5 and 6) to preclude pathological constructions.

Why we expect infeasibility
- The stationary “no self-loop” Markov chain shows that properness alone is easy. However, that chain exhibits nonzero correlations at lag 5: P_equal(5) = 1/3 + (2/3)(−1/2)^5 ≠ ∑_a m(a)^2 under any nontrivial marginal m(·) consistent with perfect properness. The MIQCP mandates exact independence at lag 5, which the chain fails, and stationarity/shift-consistency constrain the space of candidates enough that we expect no distribution can satisfy all three: (i) perfect properness for all 5 interior edges; (ii) stationarity with shift-consistency; (iii) lag-5 pair independence.

Soundness boundary (why this suffices for Corollary 3 if infeasible)
- If the MIQCP is infeasible, then no stationary r-round product-state output process can be perfectly proper on all edges while obeying lag-5 independence. A fortiori, no interior-invariant segment distribution induced by an r-round product-state algorithm can have objective value 1 on a sufficiently long segment. By Corollary 3, this yields a constant-error lower bound and, with independence, exponential decay for cycles with stride k + 2r.

Actionable next steps (auditable)
1) Implement the stationary 6-block MIQCP (r = 2):
   - Variables: t(ζ), ζ ∈ Σ^6.
   - Linear constraints: nonnegativity, normalization, shift-consistency (243 equalities), properness on 5 interior edges (15 equalities).
   - Nonlinear constraints: 9 bilinear equalities p(a,b) = m(a)m(b).
   - Solver: BARON or Couenne; report feasibility status and, if infeasible, the solver’s proof log/statistics for audit.
2) If 6-block is feasible, move to 7-block with lag-6 independence added; repeat.
3) If still feasible, add both δ = 5 and δ = 6 independence in a single 7-block formulation. If infeasible anywhere, record and archive the exact model file and solver transcript.
4) (If needed) As a cross-check, attempt to construct an explicit candidate distribution numerically (e.g., via alternating projections) to see whether the constraints can be satisfied approximately; this can guide which additional necessary constraints to add.

Small gaps or missing justifications in output.md
- Color symmetry comments. The current output.md correctly avoids using color-symmetry to linearize independence, but it would help to add a short remark stating explicitly that color-symmetry is not w.l.o.g. under independence constraints (cf. our Corrections section), to prevent accidental overuse of symmetry in future modeling.
- Experiments for r = 2. The text mentions the “experiments” route only in a high-level remark; given the obstacles identified (equalizing r-view distributions forces equality of expectations), we suggest adding a note that the r = 1 distance-mix method does not directly carry to r = 2 two-way, thereby motivating our focus on product-state MIQCP.

Why this plan is promising
- The 6/7-block stationary MIQCP precisely encodes only necessary conditions (stationarity, properness, and exact lag-independence) and avoids any extraneous modeling assumptions. A single-block variable drastically reduces dimensionality while preserving shift-consistency and interior invariance. If infeasibility at objective = 1 is certified, it yields a clean lower bound in the product-state regime compatible with our amplification template.

Appendix: explicit constraints summary for the 6-block MIQCP
- Variables: t(ζ), ζ ∈ Σ^6.
- For α ∈ Σ^5: ∑_{ζ: ζ_1..ζ_5=α} t(ζ) − ∑_{ζ: ζ_2..ζ_6=α} t(ζ) = 0.
- For j = 1,…,5 and a ∈ Σ: ∑_{ζ: ζ_j = ζ_{j+1} = a} t(ζ) = 0.
- ∑_ζ t(ζ) = 1; t(ζ) ≥ 0.
- For a ∈ Σ: m(a) = ∑_{ζ: ζ_1 = a} t(ζ).
- For a,b ∈ Σ: p(a,b) = ∑_{ζ: ζ_1 = a, ζ_6 = b} t(ζ) and enforce p(a,b) − m(a)m(b) = 0.
- (Optional convenience) Eliminate p(·,·) by writing constraints directly as ∑_{ζ: ζ_1=a, ζ_6=b} t(ζ) = (∑_{ζ: ζ_1=a} t(ζ)) (∑_{ζ: ζ_1=b} t(ζ)).

We will proceed to implement item (1) immediately and report feasibility status and solver certificates in the next round.



=== summary.md ===

## round-0001 — model summary — 2025-08-27T15:10:50.267068Z
This round set a concrete plan to prove nontrivial lower bounds for 3-coloring cycles in the r-round quantum LOCAL model for r=2,3. Key technical claim: two-way r-round algorithms without initial shared entanglement satisfy an "independence beyond r" property (two-way analogue of LGR Lemma 3) via a symmetric-buffer Heisenberg-picture argument. The team will generalize LGR's line-segment LP (Sec. 4.2) to parameter r and search numerically for a segment length k with LP optimum q(r,k)<1, using S3 color and translation symmetries and smaller generating families of frame-collections to reduce size. If q<1 then (A) without entanglement independence + LGR Lemma 4 gives exponential-in-n decay; (B) with entanglement non-signaling gives a constant-error lower bound via a window-covering argument. Main obstacles: Akbari et al. (2024) barrier and LP growth with r,k. Concrete next steps: formalize the independence lemma, implement the r=2 LP for k≈10–16 and produce primal/dual certificates, then extend to r=3 as feasible. Verifier: success. Citations: prover-01.out.json; Le Gall–Rosmanis (2022); Akbari et al. (2024).

## round-0002 — model summary — 2025-08-27T15:21:04.127516Z
This round fixed the independence/separation threshold to 2r (and updated the amplification stride to k+2r) and isolated a “placement invariance” principle for interior frames on a line segment: for r‑round algorithms with identical initial local states and uniform channels, the marginal on any r‑gapped core (fully r‑buffered inside the segment) is placement‑independent (Heisenberg‑picture operator‑support argument). A precise r‑non‑signaling LP on a segment was formulated: variables p_ψ over Σ^k (Σ={1,2,3}), objective maximizing probability of a proper coloring, and constraints equating core marginals across all gap‑r placements; symmetry reductions (S3, reflection) were proposed to shrink problem size. Useful lemmas (monotonicity q(r,k+1)≤q(r,k); infeasibility of point‑mass proper colorings under placement constraints) were noted. A practical plan targets r=2 LPs for k≈10–16 (single‑core s∈{1,2,3} plus selected two‑core families), solve with high‑precision solver, and extract dual certificates if optimum q<1 to obtain auditable bounds and amplification. Files used: prover-01.out.json; LGR Appendix A (projector construction).

## round-0003 — model summary — 2025-08-27T15:28:56.613389Z
This round tightens the LP ↔ algorithmic interface: we added two structural lemmas (monotonicity in r and an extreme-point characterization), clarified when interior-placement equalities are physically justified (product-state or automorphism-invariant initial states, or a public random rotation), and produced an auditable plan to run r = 2 LP instances with symmetry reductions. The computational plan uses S3+reflection quotienting, staged constraint families (single-core, two-core, t=3), high-precision solvers, and extraction of dual certificates for k ∈ {10..16}, stopping when q < 0.99 (or any q < 1). A transfer-matrix / Markov-chain relaxation is proposed as an independent cross-check. Two textual clarifications are requested in output.md (after Definition 6 and in Corollary 8) to make the symmetry hypothesis explicit. Watchouts: over-reduction of symmetry and illegal interior-placement constraints; include dirac-mass infeasibility as a sanity test. Citations: prover-01.out.json (progress_md), output.md.

## round-0004 — model summary — 2025-08-27T16:03:02.353720Z
Main finding: the geometry-aware non-signaling LP in Definition 6 is too weak for the two-way model — there is an explicit feasible distribution that attains objective value 1 for every r ≥ 1 and k ≥ 1, so q(r,k)=1. Concretely, the order-1 stationary Markov chain on Σ={1,2,3} with uniform stationary law and P(σ→σ)=0, P(σ→τ)=1/2 (τ≠σ) generates only proper strings and satisfies all single- and multi-core geometry-aware translation invariances, so it is a feasible witness with success probability 1. Consequence: the segment LP (Definition 6) cannot certify any nontrivial constant-error lower bound in the two-way model (with or without entanglement); Corollary 10 is vacuous unless the constraint system is strengthened. Recommended corrective directions: (A) for product initial states, add independence/factorization constraints (nonlinear) or a lifted linear relaxation (Sherali–Adams style) to cut off the Markov witness; (B) for the entanglement-allowed regime, pivot to ring-level/ring-experiment or round-elimination/indistinguishability arguments tailored to small fixed r (start with r=2). Citations: prover-01.out.json (progress_md); output.md.

## round-0005 — model summary — 2025-08-27T18:51:08.786646Z
This round pivots from the trivial segment LP to independence-augmented linear relaxations in the product-state regime and to ring-level (experiment/view) arguments in the entanglement-allowed regime. Key technical move: add the linear, color-symmetric independence constraint I1(δ) that for any pair of single-site cores separated by δ ≥ 2r+1 forces P[X_i = X_{i+δ}] = 1/3. Lemma A shows the stationary nearest-neighbor proper Markov chain violates I1 (its equality probability is 1/3 + (2/9)(-1/2)^δ), so I1 excludes that witness. Formulation A2 (color-symmetric, pair-independence LP) and an auditable test A3 for r = 2 (k in 11..15) are proposed: add single- and two-core placement invariances, color-uniformity, and I1(5) (±I1(6)) and check feasibility with objective = 1; infeasibility yields a Farkas certificate. For the entanglement-allowed case, Track B outlines an r = 2 two-way analogue of LGR: search for two distance-mixtures (D1,D2) whose induced distributions over r-views match (view-equivalence), giving equal expectations under r-non-signaling but different expectations on proper colorings, producing a constant-error separation. Citations: prover-01.out.json (progress_md); Verifier (verdict: partial success).

## round-0006 — model summary — 2025-08-27T19:01:44.309310Z
This round corrected analytic foundations and pivoted to a sound nonlinear feasibility test for the product-state r=2 regime. The team formulated a single stationary 6-block MIQCP (729 variables) whose linear constraints enforce shift-consistency and interior properness, and whose 9 bilinear equalities enforce exact pair-independence at lag δ = 5 — a necessary condition for any r=2 product-state perfect output. Key modelling fixes: independence is inherently bilinear (no linearization via color-symmetry) and the r=1 distance-mix trick does not extend to r=2. The stationary no-self-loop Markov chain has two-point correlation P[X_t = X_{t+d}] = 1/3 + (2/3)(−1/2)^d, so it violates lag-5 independence and motivates expectation of MIQCP infeasibility. Action plan: implement the 6-block MIQCP in global nonconvex solvers (BARON/Couenne/SCIP-NLP), escalate to 7-block if needed, and archive solver certificates if infeasible. Citation: prover-01.out.json (progress_md).



=== notes.md ===
Scope and goal
We seek lower bounds for 2–3 round quantum LOCAL algorithms that 3-color an n-cycle. We separate two resource regimes: (i) no initial shared entanglement (initial product state across vertices), and (ii) arbitrary initial shared entanglement. Our strategy follows and extends Le Gall–Rosmanis (LGR, 2022): reduce to a line-segment optimization under r-local non-signaling constraints, then lift to cycles. Two technical pillars are (A) light-cone localization of measurements in r rounds (implying r-non-signaling), and (B) independence across well-separated regions when the initial state is a product.

Key corrections/new facts
- Independence threshold is 2r, not r, in the two-way model without entanglement. After reversing r communication layers, any measurement on a block depends only on the block’s r-neighborhood. Thus independence of multiple blocks requires their r-neighborhoods to be disjoint, i.e., pairwise distances > 2r. Counterexample to “> r” for r = 1: on a path 0–1–2, one round suffices for node 1 to broadcast a private random bit to nodes 0 and 2, correlating their outputs at distance 2.
- Non-signaling beyond r holds with or without shared entanglement: the marginal on a set S depends only on the initial state on N_r(S). This follows from Heisenberg-picture localization of effects under depth-r local circuits/channels.

Amplification templates
- No entanglement (product initial state): If there exists k and q < 1 such that every r-non-signaling distribution on a length-k segment makes the segment proper with probability at most q, then on cycles C_n the success probability is at most q^{⌊n/(k+2r)⌋}. Partition C_n into ⌊n/(k+2r)⌋ disjoint windows of length k separated by gaps of size 2r; window events are independent by the 2r-separation lemma; ring proper implies all windows are proper.
- With entanglement allowed: For any fixed window W of length k, ring proper implies W is proper. The distribution on W (restricted to placements with r-buffers inside W) is feasible for the r-non-signaling LP, hence P[ring proper] ≤ P[W proper] ≤ q. There is no improvement from packing without independence; the optimal general bound is the n-independent constant q.

LP plan for r = 2, 3
- Variables: probabilities over colorings on r-gapped placements (collections of frames) inside [1..k]. Placements include cores and r-buffers fully contained in [1..k].
- Constraints: non-signaling equalities enforcing that the marginal distribution on a given core is independent of the surrounding placement context as long as r-buffers are intact (equalities of marginals across placements that agree on the core).
- Objective: maximize P[all k − 1 edges inside [1..k] are properly 3-colored].
- Symmetries: quotient by S3 color permutations; translations (and reflections, if used). It is safe (as a relaxation) to enforce only a generating set of non-signaling constraints; for the final certificate, include all placements that respect the segment.
- Execution: sweep k ≈ 10–16 for r = 2 (then smaller k for r = 3), solve numerically, and extract dual certificates for any instance with optimum < 1.

What remains to be computed
- A concrete (r, k, q) with q < 1 via the LP. Once obtained, immediately plug into the amplification templates above. Note the stride is k + 2r (not k + r) in the independence-based exponential bound.

Reference counterexample (to avoid regression)
- Two-way, r = 1, no entanglement: path 0–1–2. Node 1 samples b ∈ {0,1}, sends b to 0 and 2, both output b. Outputs at distance 2 are perfectly correlated; independence beyond r = 1 fails. Independence holds only when r-neighborhoods are disjoint (distance > 2r).
Additional clarifications and refinements

1) Interior placement invariance: correct assumptions and a counterexample
- Valid regimes. For an r-round uniform LOCAL algorithm on a cycle C_n, invariance of interior placements (i.e., equality of core marginals for all gap-r placements whose r-buffers lie within a window W) holds under either of the following assumptions:
  (a) No shared entanglement and identical local initial states (product initial state ⊗_v ρ, with the same ρ at every vertex).
  (b) Shared entanglement is allowed, but the global initial state ρ_0 is invariant under the automorphisms of C_n (rotations and reflections). Uniformity of the local channels across vertices is also required.
- Why. In the Heisenberg picture, the effect for a core event depends only on the union of r-neighborhoods of the cores. Two interior placements of the same frame family induce isomorphic unions; the corresponding effects are related by a permutation of registers. If ρ_0 is invariant under that permutation (true in (a) and (b)), the probabilities coincide.
- Necessity of the symmetry assumption with entanglement. Without (b), the statement can fail. Counterexample (r = 0): prepare EPR pairs on disjoint edges (1,2), (3,4), … around the cycle, and have each vertex measure Z and output a color that is a function of its bit. Then the joint distribution on two adjacent cores depends on whether the placement coincides with a paired edge (correlated) or straddles a pair boundary (independent). Hence, equality across placements fails.

2) Segment LP (precise, and what it models)
- Alphabet Σ = {1,2,3}. Fix r ≥ 1 and k ≥ 1. Let a frame family F = ({{s_1}}, …, {{s_t}}), each {{s_j}} a contiguous core of length s_j.
- An r-gapped placement ω of F inside [1..k] is a t-tuple of start positions (ω_1,…,ω_t) such that the r-buffers [[ω_j − r .. ω_j + s_j − 1 + r]] are subsets of [1..k] and pairwise disjoint. The cores are C_j = [[ω_j .. ω_j + s_j − 1]].
- Variables: p_ψ for ψ ∈ Σ^k, with p_ψ ≥ 0 and ∑_ψ p_ψ = 1.
- Objective: maximize ∑_ψ p_ψ · 1{ψ has no equal-color adjacencies on edges (i, i+1), i = 1..k−1}.
- Constraints (interior placement invariance): For every family F and every core assignment ζ = (ζ_1,…,ζ_t), the marginal probability ∑_{ψ: ∀j ψ|_{C_j} = ζ_j} p_ψ is the same for all gap-r placements ω of F (whose r-buffers lie in [1..k]).
- Soundness: These constraints are necessary for distributions induced by r-round uniform algorithms in regimes (1a) or (1b). Dropping some equalities yields a relaxation (weaker constraints and thus a larger feasible set); any optimum < 1 for a relaxation implies the true optimum < 1 as well.

3) Monotonicity in segment length
Let q(r,k) denote the LP optimum at parameters (r,k) as above. Then q(r,k+1) ≤ q(r,k). Proof idea: Any feasible distribution on Σ^{k+1} marginalizes to a feasible distribution on Σ^k (equalities on interior placements survive marginalization), and 1{proper on k+1} ≤ 1{proper on first k} pointwise.

4) Why a point mass on a proper coloring violates the constraints
Under the single-core placement-invariance constraints, the distribution of s-blocks (e.g., s ∈ {1,2}) must be identical for all interior positions. A point mass on a single proper ψ has position-dependent s-blocks unless ψ is constant (impossible if ψ is proper). Hence a Dirac mass cannot be feasible—this is a useful solver sanity check.

5) Amplification stride and regimes
- No entanglement (product initial state): independence requires gaps of size 2r (not r). The exponential amplification stride is k + 2r. This is tight in general (see r = 1 path 0–1–2 counterexample).
- With entanglement: constant-error bounds via the LP above are valid if the initial shared state is automorphism-invariant; without that symmetry, the placement-equality constraints need not hold (cf. the counterexample in item 1).

6) Computational plan (r = 2)
- Variables: p_ψ, ψ ∈ Σ^k. For k = 10, |Σ^k| = 59,049; for k = 12, |Σ^k| = 531,441.
- Symmetry/useful reductions: quotient by S_3 (color permutations) and reflection; treat translation of placements via equality constraints.
- Constraints to start with: all single-core families with s ∈ {1,2,3}; then add two-core families (1,1), (2,1), (2,2) at several separations, over all interior placements.
- Certification: if optimum < 1, extract a dual certificate (constraint multipliers) that verifies the bound.
Important correction: geometry-aware interior placement invariance
- The equalities we enforce must respect automorphism classes of placements. Two placements of t cores are guaranteed to have equal core marginals only if they are related by a cycle automorphism (rotation; reflection only if the model is reflection-invariant). Equating placements with different inter-core distances is not justified by light-cone localization plus uniformity.
- Minimal counterexample (r = 0, entangled, rotation-invariant): let ρ0 be the 1/2-mixture of the two perfect matchings of EPR pairs around the cycle. Adjacent vertices have Z-correlations (EPR half the time); vertices at distance 2 are uncorrelated. Thus, two singleton cores at distance 1 vs distance 2 have different joint marginals, defeating geometry-agnostic equality constraints.
- Fix: Parameterize multi-core constraints by geometry (core lengths s = (s1,…,st) and inter-core gaps δ = (δ1,…,δt−1), where δj is the number of vertices between cores j and j+1). Require equality only across translations inside [1..k] (and optionally reflections) for the same (s, δ), with the additional admissibility condition δj ≥ 2r ensuring disjoint r-buffers.

Monotonicity in r (new)
- Let q(r,k) be the (revised, geometry-aware) LP optimum. Then q(r+1,k) ≥ q(r,k). Reason: when r increases, fewer placements are admissible, so fewer equalities are enforced; the feasible region enlarges and the optimum cannot decrease.

Extreme-point structure (new)
- The feasible set is a nonempty polytope in R^{3^k} (uniform distribution is feasible), defined by linear equalities (geometry-aware invariance), nonnegativity, and normalization. Hence an optimal distribution exists and can be taken at an extreme point (basic feasible solution). This supports sparse-support searches and dual-certificate extraction.

Amplification reminders (unchanged)
- No entanglement: independence requires gaps of size 2r, so the exponential stride is k+2r. The r = 1 path 0–1–2 counterexample shows smaller gaps are insufficient.
- With entanglement: constant-error bounds require automorphism-invariant initial states (or an admissible public random rotation to enforce it). Without that symmetry, interior-placement equalities need not hold.

Computation plan (r = 2), updated to geometry-aware constraints
- Variables: p_ψ, ψ ∈ Σ^k. Quotient by S3 color permutations; do not assume reflection unless explicitly imposed.
- Constraints (progressive):
  • Single-core: s ∈ {1,2,3}, equality across all interior translations.
  • Two-core: (s1,s2) ∈ {(1,1),(2,1),(2,2)}, at several admissible separations δ ≥ 2r; enforce equality across translations for each fixed δ.
  • If needed, add t = 3 families similarly.
- Certification: For any q < 1, extract a dual and archive (r,k), the (s,δ) list, the dual vector, and the inequality certifying ∑_ψ p_ψ·1{proper} ≤ q.

Transfer-matrix/Markov cross-check
- Restricting to stationary Markov chains (order d) is a subset of the LP-feasible set; maximizing properness yields a lower bound on q(r,k), useful for catching modeling/solver errors but not a certifying upper bound.

Pitfalls and checks
- Do not equate placements with different δ. Keep separate runs with and without reflection constraints. Validate symmetry reductions on small k against the full (unreduced) LP.
- Ensure all placements counted in constraints have r-buffers fully inside [1..k].
Critical correction: the segment LP (Definition 6) is too weak for two-way
- New fact. For every r ≥ 1 and k ≥ 1, the LP optimum q(r,k) in Definition 6 equals 1. A feasible witness achieving objective 1 is given by the order-1 Markov chain on Σ={1,2,3} with stationary distribution u≡1/3 and transition matrix P with P(i,i)=0 and P(i,j)=1/2 for j≠i. Let p_k be the law of (X_1,…,X_k) with X_1∼u and X_{t+1}|X_t∼P. Then p_k assigns probability 1 to internally proper strings, and because (X_t) is strictly stationary, all core marginals for any fixed geometry (s,δ) are invariant under interior translations, hence all Definition 6 constraints hold. If reflection constraints are included, the chain remains feasible because it is reversible under u.
- Implication. The current LP cannot certify any nontrivial bound q<1 in the two-way model (with or without entanglement). Corollary 10 remains formally valid but is vacuous with this LP (it upper-bounds by 1).

Why the witness satisfies the geometry-aware equalities (minimal checks)
- Single core (t=1). For any s and any interior position i, the s-block (X_i,…,X_{i+s−1}) has the stationary s-block law; translation of i within the window preserves the law.
- Two cores (t=2). For s=(s1,s2) and gap δ≥2r, the joint law of the two blocks depends only on δ (and s1,s2); by strict stationarity, translating the placement within [1..k] does not change this joint law.
- Three cores (t=3). Similarly, for s=(s1,s2,s3) and gaps δ=(δ1,δ2) with δj≥2r, the joint law of the three blocks depends only on the inter-core separations, not on absolute position; interior translations preserve it.

Consequences for modeling and plan (forked)
- Track A (product-state, no entanglement): Independence across regions whose r-neighborhoods are disjoint (>2r separation) must be used. This is nonlinear (factorization). Two practical approaches:
  1) Lifted linear relaxation (Sherali–Adams style): Introduce auxiliary variables for joint marginals on small tuples of cores; enforce linear consistency across overlaps and interior-translation equalities; add necessary linear bounds implied by independence (e.g., Fréchet inequalities for all pairs). This excludes some spurious correlated witnesses (including the Markov chain) and may already force q<1 for small r,k.
  2) Nonlinear exact factorization: Add constraints P(A∩B)=P(A)P(B) for cylinder events A,B supported on disjoint r-buffers. Solve the resulting bilinear system for r=2 and k≤12 using algebraic/MIP methods. Any infeasibility at value 1 yields the desired q(r,k)<1.
- Track B (entanglement allowed): The segment LP cannot help. Pursue ring-level methods: (i) tailor LGR-style experiments for two-way r=2 to derive linear identities that cannot hold simultaneously under properness; (ii) indistinguishability/φ-LOCAL arguments to prove uniform ε(r)>0 constant-error lower bounds for fixed small r. Start at r=2.

Near-term to-dos
- Archive a formal statement and proof that q(r,k)=1 (now added to output.md) to prevent regressions.
- Implement Track A level-1/2 lift and a small exact factorization instance for r=2, k≤12, and test whether q<1 emerges. Extract and store any dual certificates (linear inequalities) obtained.
- Begin a concrete r=2 indistinguishability construction: enumerate r-views on the cycle; design two globally incompatible templates sharing those r-views on a positive fraction of positions; quantify a constant contradiction via averaging.
Addendum: independence-linearization, color symmetry, and corrected chain correlation

1) Pair independence at large separations and its linearization
- In the product-state regime (no shared entanglement), independence across sets whose r-neighborhoods are disjoint (distance > 2r) implies, for single-site cores at positions i and j with |i − j| ≥ 2r + 1:
  P[X_i = a, X_j = b] = P[X_i = a] · P[X_j = b] for all colors a, b.
- This yields, for the equality event:
  P_equal(i, j) := P[X_i = X_j] = ∑_{a∈{1,2,3}} P[X_i = a] P[X_j = a].
- If, in addition, the single-site marginals are uniform, i.e., P[X_u = a] = 1/3 for all a and all interior positions u, then P_equal(i, j) = 1/3. This is the proposed linear identity I1(δ) for δ ≥ 2r + 1.
- Caution (soundness): Enforcing uniform marginals (color symmetry) is harmless for the base LP (geometry-aware placement equalities), but combining it with independence-derived constraints needs justification. A global random color-permutation used only for symmetrization can introduce correlations across far-apart sets (breaking unconditional independence). Therefore, unless we prove that restricting to color-symmetric algorithms is w.l.o.g. even under independence constraints, using I1(δ) as a necessary linear condition is not sound. As a safe alternative, either (i) keep the exact (nonlinear) independence equalities, or (ii) prove the w.l.o.g. color-symmetry claim for the product-state model.

2) Corrected two-point correlation for the stationary “no self-loop” 3-state chain
Let (X_t) be the stationary order-1 Markov chain on {1,2,3} with transition matrix P(i,i) = 0 and P(i,j) = 1/2 for j ≠ i and stationary distribution u ≡ 1/3. Then, for d ≥ 1,
  P[X_t = X_{t+d}] = 1/3 + (2/3) (−1/2)^d.
This follows from the spectral decomposition of P (eigenvalues 1, −1/2, −1/2). In particular, P[X_t = X_{t+1}] = 0 and P[X_t = X_{t+2}] = 1/2. Consequently, for any finite d ≥ 1, this chain violates the identity P_equal(d) = 1/3.

3) Track A (product-state) implementation notes
- Sound feasibility test at objective 1 should include exact (nonlinear) pair independence for δ ∈ {2r+1, 2r+2}, along with placement equalities by geometry. For r = 2 and k ∈ {10, 11, 12}, this should be within reach of a MIP/CP-SAT solver. An infeasibility certificate at value 1 would be decisive.
- If you pursue the linearized I1(δ) route, first prove rigorously that restricting to color-symmetric strategies is w.l.o.g. with independence preserved in the relevant sense (i.e., that the resulting distribution still satisfies the imposed independence equalities). Otherwise, any certificate obtained may not upper-bound the true product-state optimum.

4) Track B (entanglement allowed) clarifications
- r-view equivalence lemma to formalize: If two experiments induce the same distribution over the Heisenberg-evolved effects for the queried event at depth r (as random placements on the cycle), then every r-LOCAL strategy yields equal expectations for the two experiments. Your weight-solving LP should enforce exact equality of the induced multiset of r-view isomorphism types (including gap size if it is part of the view definition).
- Separation on proper colorings must be uniform over all proper colorings (for n beyond some threshold). The parity-oscillation intuition is valid for the stationary chain or the uniform measure over proper colorings, but not for each fixed coloring; e.g., the 2-color alternating pattern has P_equal(d) ∈ {0,1} depending on parity. Therefore, after finding (D1, D2) with equal r-views, compute the minimum separation over all proper colorings (e.g., by transfer-matrix enumeration) and certify a positive gap.

5) Practical next steps
- Product-state: implement the exact pair-independence feasibility test at value 1 for r = 2, k ≤ 12. If infeasible, record the specific contradiction (solver proof log) and the list of constraints used. If feasible, extend δ or add three-core geometry constraints.
- Entanglement allowed: enumerate r = 2 pair-view types up to distance 10–12; solve for two mixtures with equal view distributions; compute the minimum separation over proper colorings and report whether a uniform ε > 0 is achieved.
Stationary single-block MIQCP for r = 2 (product-state, two-way)

- Block length L = 2r + 2 = 6. Alphabet Σ = {1,2,3}. Variables t(ζ) for ζ ∈ Σ^6.
- Linear constraints:
  • Nonnegativity and normalization: t(ζ) ≥ 0; ∑_ζ t(ζ) = 1.
  • Shift-consistency (stationarity of length-5 marginals): For all α ∈ Σ^5, M_1(α) := ∑_{ζ: ζ_1..ζ_5 = α} t(ζ) equals M_2(α) := ∑_{ζ: ζ_2..ζ_6 = α} t(ζ).
  • Perfect properness on interior edges: For j = 1,…,5 and a ∈ Σ, ∑_{ζ: ζ_j = ζ_{j+1} = a} t(ζ) = 0.
- Nonlinear (bilinear) independence at lag 5:
  • m(a) := ∑_{ζ: ζ_1 = a} t(ζ), p(a,b) := ∑_{ζ: ζ_1 = a, ζ_6 = b} t(ζ).
  • Enforce p(a,b) = m(a) m(b) for all a,b ∈ Σ (equivalently, ∑_{ζ: ζ_1=a, ζ_6=b} t(ζ) = (∑_{ζ: ζ_1=a} t(ζ))(∑_{ζ: ζ_1=b} t(ζ))).

Soundness rationale (concise): For a uniform r-round algorithm on a cycle with product initial state (identical local states), the output process is strictly stationary. Independence at separation 2r+1 follows from Theorem 2. If, on a sufficiently long segment, the interior 5 edges of a 6-block are proper with probability 1, then the 6-block marginal t assigns zero to any ζ with ζ_j = ζ_{j+1}. Hence any such algorithm induces t feasible for the MIQCP above. Conversely, any t satisfying the linear equalities is extendable to a stationary order-5 process with 6-block marginal t (Kolmogorov/Markov extension), so infeasibility certifies impossibility of perfect interior properness at r = 2 in the product-state regime.

Escalation knobs (if L = 6 is feasible):
- Enforce lag-6 independence by moving to L = 7 and adding ∑_{ζ: ζ_1=a, ζ_7=b} t(ζ) = (∑_{ζ: ζ_1=a} t(ζ))(∑_{ζ: ζ_1=b} t(ζ)). Both lag-5 and lag-6 are necessary in the product-state model.
- For stronger constraints, eventually consider triple independence (e.g., positions 1,6,11) requiring L = 11.

Numerical plan:
- Solvers: BARON, Couenne/Bonmin, SCIP-NLP. Archive model files and solver logs. If infeasible at L = 6, immediately use amplification (stride k + 2r) to conclude a constant-error bound (see Corollary below in output.md). If feasible, switch to an optimization variant to upper-bound the maximum properness probability (< 1) numerically.

Cautions reiterated:
- Do not impose color symmetry when independence constraints are active; a global color-permutation randomization can destroy unconditional independence across distant sets.
- The Markov-chain witness p_equal(d) = 1/3 + (2/3)(−1/2)^d shows why the base (linear) segment LP is vacuous but is excluded as soon as any lag-5 independence is enforced.

Analytic angle (optional):
- Let S_t = X_{t+1} − X_t (mod 3) ∈ {±1}. Properness forces S_t ∈ {±1} a.s. Independence at lag 5 forces constraints on the distribution of ∑_{j=0}^4 S_{t+j} (mod 3). An explicit contradiction along these lines would bypass computation and is worth exploring in parallel.

=== output.md ===
Main theorems proved in this file
- Light-cone localization and r-non-signaling for r-round LOCAL algorithms (with or without initial entanglement).
- Independence beyond 2r for two-way r-round LOCAL algorithms with product initial states (no shared entanglement).
- Exponential amplification without entanglement given a segment-level bound q(r,k) < 1.
- Automorphism-covariant interior placement invariance within fixed geometry classes.
- Segment LP with geometry-aware interior invariance; structural lemmas: monotonicity in k, monotonicity in r, extreme-point optimality.
- Constant-error bound with entanglement under automorphism invariance.

Preliminaries
Let G = (V, E) be a graph (cycles are of primary interest). An r-round quantum LOCAL algorithm consists of r synchronous layers of local channels acting on vertex/edge registers, followed by local measurements at the vertices that output colors in {1,2,3}. Each round is modeled as a product of CPTP maps localized on vertices/edges (purifiable to local unitaries by Stinespring dilation). For S ⊆ V, let N_r(S) = {v ∈ V : dist(v, S) ≤ r} denote the r-neighborhood of S.

Theorem 1 (Light-cone localization and r-non-signaling)
Fix an r-round quantum LOCAL algorithm. Let S ⊆ V, and let M_S be any POVM element that depends only on the final local measurements in S. Then there exists a positive operator X_S supported only on the registers associated with N_r(S) (and ancillas therein) such that, for every initial global state ρ (possibly entangled), the probability of M_S is Tr[ρ X_S]. Consequently, if two initial states ρ and ρ′ agree on N_r(S), then the output marginal on S is the same under ρ and ρ′.

Proof sketch (standard): Purify to a depth-r circuit of local unitaries. In the Heisenberg picture, conjugating M_S backward through each round enlarges its support by at most one graph hop. After r rounds, the evolved effect X_S is supported on N_r(S). For any ρ, P[M_S] = Tr[ρ X_S]. If ρ and ρ′ coincide on N_r(S), then Tr[ρ X_S] = Tr[ρ′ X_S].

Theorem 2 (Independence beyond 2r without initial entanglement)
Assume the initial state is a product across vertices, ρ = ⊗_{v∈V} ρ_v. Let S_1, …, S_m ⊆ V have pairwise disjoint r-neighborhoods (equivalently, dist(S_i, S_j) > 2r for i ≠ j). For each i, let M_{S_i} be any event depending only on measurements in S_i, and let X_{S_i} be its Heisenberg-evolved effect from Theorem 1. Then the random outcomes on S_1, …, S_m are mutually independent; in particular,
Tr[ρ X_{S_1} ⋯ X_{S_m}] = ∏_{i=1}^m Tr[ρ_{N_r(S_i)} X_{S_i}].

Proof: Each X_{S_i} acts only on N_r(S_i); these supports are disjoint, and ρ factors across them. The trace of the product factors, which is precisely independence.

Corollary 3 (Exponential amplification without entanglement)
Let r ≥ 1. Fix k ≥ 1 and suppose there exists q < 1 such that, for every distribution on a length-k path segment that satisfies the LP constraints in Definition 6 (below), the probability the segment is internally proper is at most q. Then, for any r-round two-way quantum LOCAL algorithm on the n-cycle with product initial state, the success probability satisfies
P_success(C_n) ≤ q^{⌊n / (k + 2r)⌋}.

Proof: Partition the cycle into m = ⌊n / (k + 2r)⌋ disjoint windows of length k separated by gaps of size 2r. If the cycle is proper, each window is internally proper. Let E_i be “window i is internally proper,” and X_i its Heisenberg-evolved effect. Supports N_r(W_i) are disjoint, so E_i are independent by Theorem 2. By the segment-level bound, P[E_i] ≤ q. Hence P_success(C_n) ≤ ∏_i P[E_i] ≤ q^m.

Remark 4 (Necessity of the 2r separation)
For r = 1 on a path 0–1–2, one round suffices for node 1 to correlate nodes 0 and 2 (e.g., by broadcasting a private random bit), so outputs at distance 2 need not be independent. Thus 2r is tight in general.

Lemma 5 (Automorphism-covariant interior placement invariance for fixed geometries)
Fix an r-round uniform quantum LOCAL algorithm on a cycle C_n, with initial global state ρ_0. Let W ⊆ C_n be any contiguous window of length k. Consider t cores with lengths s = (s_1,…,s_t), and let δ = (δ_1,…,δ_{t−1}) be nonnegative integers encoding the inter-core gaps (δ_j is the number of vertices strictly between core j and core j+1). Let ω and ω′ be two r-gapped placements of (s, δ) inside W (i.e., all r-buffers lie in W and δ_j ≥ 2r). Assume ρ_0 is invariant under the rotations of C_n (reflections as well if the model is reflection-invariant). Then, for every core assignment ζ, the probability that the outputs on the cores equal ζ is the same for ω and ω′.

Proof: Let U_ω ⊆ W and U_{ω′} ⊆ W be the unions of the r-neighborhoods of the cores. Because ω and ω′ have the same geometry (s, δ), there exists a rotation (and possibly a reflection) π of C_n mapping U_ω to U_{ω′} and carrying each core in ω to the corresponding core in ω′. By Theorem 1, there exist positive operators X_ω and X_{ω′} supported on U_ω and U_{ω′} giving the core-event probabilities as Tr[ρ_0 X_ω] and Tr[ρ_0 X_{ω′}]. Uniformity implies covariance under π: X_{ω′} = U_π X_ω U_π^†. Since ρ_0 is invariant under π, Tr[ρ_0 X_{ω′}] = Tr[ρ_0 X_ω].

Definition 6 (Segment LP with geometry-aware interior invariance)
Fix Σ = {1,2,3}, r ≥ 1, k ≥ 1. A geometry is a pair (s, δ) with s = (s_1,…,s_t) positive integers and δ = (δ_1,…,δ_{t−1}) nonnegative integers. An r-gapped placement ω of (s, δ) inside [1..k] is a t-tuple of start positions (ω_1 < ⋯ < ω_t) such that each core C_j = [ω_j .. ω_j + s_j − 1] has its r-buffer C_j^{(+r)} = [ω_j − r .. ω_j + s_j − 1 + r] contained in [1..k], these r-buffers are pairwise disjoint, and ω_{j+1} = ω_j + s_j + δ_j. The variables are p_ψ for ψ ∈ Σ^k, with p_ψ ≥ 0 and ∑_ψ p_ψ = 1. The objective is to maximize ∑_ψ p_ψ · 1{ψ has no equal-color adjacencies on edges (i,i+1), i = 1..k−1}. The constraints enforce interior placement invariance within fixed geometries: for every geometry (s, δ), every core assignment ζ, and every two r-gapped placements ω, ω′ of (s, δ) inside [1..k], the marginal ∑_{ψ: ∀j ψ|_{C_j(ω)} = ζ_j} p_ψ equals ∑_{ψ: ∀j ψ|_{C_j(ω′)} = ζ_j} p_ψ. Denote the optimum by q(r,k).

Remark 6.1 (Soundness regimes and symmetry)
These equality constraints are necessary for r-round uniform algorithms under either of the following assumptions: (i) product initial states with identical local marginals (⊗_v ρ; rotation-invariant), or (ii) arbitrary shared entanglement provided the initial global state is invariant under the rotations of the cycle (reflections as well if the model is reflection-invariant). Without such symmetry in the initial state, the constraints need not hold across placements, even within the same window.

Lemma 7 (Monotonicity in k)
For all r ≥ 1 and k ≥ 1, q(r,k+1) ≤ q(r,k).

Proof: Let p be feasible for (r,k+1). Its marginal p′ on the first k coordinates satisfies all geometry-aware invariance constraints for (r,k): any placement inside [1..k] remains a placement inside [1..k+1], and equalities are preserved under marginalization. Moreover 1{proper on k+1} ≤ 1{proper on first k} pointwise, hence ∑_ψ p_ψ·1{proper on k+1} ≤ ∑_{ψ′} p′_{ψ′}·1{proper on k}. Taking suprema over feasible p proves the claim.

Lemma 8 (Monotonicity in r)
For all r ≥ 1 and k ≥ 1, q(r+1,k) ≥ q(r,k).

Proof: As r increases to r+1, the set of admissible placements (and hence the set of equality constraints) for any geometry (s, δ) weakens: some placements cease to be admissible because r-buffers no longer fit or become non-disjoint. Therefore the feasible set enlarges, and the supremum cannot decrease.

Lemma 9 (Extreme-point optimality)
For each fixed (r,k), the feasible region of Definition 6 is a nonempty polytope in R^{3^k} defined by linear equalities, nonnegativity, and normalization. Hence an optimal solution exists and can be taken at an extreme point (basic feasible solution).

Proof: Nonemptiness follows from the uniform distribution p_ψ = 3^{-k}, which satisfies all equality constraints. Boundedness follows from nonnegativity and normalization. Linear programming theory guarantees that a maximum exists and is achieved at an extreme point of the polytope.

Corollary 10 (Constant-error bound with entanglement under automorphism invariance)
Let r ≥ 1 and k ≥ 1, and let q(r,k) be as in Definition 6. Consider any r-round uniform quantum LOCAL algorithm on C_n whose initial global state is invariant under the rotations of the cycle. Then, for all n ≥ k, the success probability obeys P_success(C_n) ≤ q(r,k).

Proof: Fix any contiguous window W ⊆ C_n of length k. If the cycle is properly colored, then W is internally proper. By Lemma 5, the distribution on W (restricted to events supported on geometry-aware r-buffered placements) satisfies the invariance constraints of Definition 6. Therefore it is feasible for the LP, and the probability that W is internally proper is at most q(r,k). Since {cycle proper} ⊆ {W proper}, P_success(C_n) ≤ q(r,k). (Necessity of the symmetry assumption is illustrated by the EPR counterexample in the notes.)
Proposition 11 (Trivialization of the segment LP under Definition 6)
For every r ≥ 1 and k ≥ 1, the optimum q(r,k) in Definition 6 satisfies q(r,k) = 1.

Proof.
Let Σ = {1,2,3}. Consider the order-1 Markov chain (X_t) with stationary distribution u(i) = 1/3 for i∈Σ and transition matrix P with P(i,i)=0 and P(i,j)=1/2 for j≠i. For k ≥ 1, define a distribution p on Σ^k by drawing (X_1,…,X_k) according to X_1 ∼ u and X_{t+1} | X_t ∼ P.

(i) Objective value. Because P(i,i)=0, adjacent colors are never equal: P[X_t = X_{t+1}] = 0 for all t. Therefore p assigns probability 1 to the event “ψ has no equal-color adjacencies on edges (t,t+1), t=1..k−1,” and the objective equals 1.

(ii) Feasibility (geometry-aware interior invariance). Since u is stationary for P, the process (X_t) is strictly stationary. Fix any geometry (s,δ) and two r-gapped placements ω, ω′ of (s,δ) inside [1..k]. Let C(ω) ⊆ {1,…,k} be the ordered list of core indices of ω (similarly C(ω′)). Because ω and ω′ have the same (s,δ), there exists an integer shift τ such that C(ω′) = C(ω) + τ (coordinatewise). Strict stationarity implies that the joint law of (X_i)_{i∈C(ω)} equals the joint law of (X_{i+τ})_{i∈C(ω)} = (X_j)_{j∈C(ω′)}. Hence for every core assignment ζ, the marginal probability that the cores equal ζ is the same for ω and ω′. Nonnegativity and normalization of p are immediate. Thus p is feasible with objective value 1, and so q(r,k) ≥ 1. Since the objective is at most 1 for all feasible p, q(r,k)=1.

Corollary 12 (No segment-LP constant-error bound in two-way under Definition 6)
Under Definition 6, the segment LP cannot certify any nontrivial bound for two-way algorithms: for all r,k we have q(r,k)=1. Consequently, Corollary 10 specializes to the trivial inequality P_success(C_n) ≤ 1 in the entanglement-allowed regime and gives no constant-error lower bound.

Remark 12.1 (Scope). Proposition 11 does not contradict the soundness of the constraints in Definition 6 for actual r-round algorithms under the symmetry assumptions of Remark 6.1; it shows that these constraints alone are insufficient. To obtain nontrivial upper bounds in the product-state regime, independence across sets with disjoint r-neighborhoods (>2r separation) must be incorporated, which is nonlinear (factorization). In the entanglement-allowed regime, no such independence holds, so segment-based linear constraints of this form cannot lead to q<1.
New results appended

Proposition 13 (Pair-equality identity at large separation in the product-state regime)
Assume no initial entanglement (product initial state). Let r ≥ 1, and let i, j be two vertices in a path segment whose r-neighborhoods are disjoint (equivalently, |i − j| ≥ 2r + 1). Then, for any r-round two-way LOCAL algorithm, the equality probability satisfies
  P[X_i = X_j] = ∑_{a∈{1,2,3}} P[X_i = a] · P[X_j = a].
In particular, if the single-site marginals at i and j are uniform (P[X_i = a] = P[X_j = a] = 1/3 for all a), then P[X_i = X_j] = 1/3.

Proof.
By Theorem 2 in this file, the outcomes on {i} and {j} are independent because their r-neighborhoods are disjoint. Hence, for any a, b,
  P[X_i = a, X_j = b] = P[X_i = a] P[X_j = b].
Summing over a = b gives the displayed identity. If the marginals are uniform, the sum is 3 · (1/3) · (1/3) = 1/3.

Lemma 14 (Two-point correlation for the 3-state no-self-loop chain)
Let Σ = {1,2,3}. Consider the stationary order-1 Markov chain (X_t) with stationary distribution u(i) = 1/3 and transition probabilities P(i,i) = 0, P(i,j) = 1/2 for j ≠ i. Then for all integers d ≥ 1,
  P[X_t = X_{t+d}] = 1/3 + (2/3)(−1/2)^d.

Proof.
The transition matrix P has eigenvalues 1 and −1/2 (with multiplicity 2). Diagonalizing P gives, for i ≠ j,
  P^d(i,i) = 1/3 + (2/3)(−1/2)^d,   P^d(i,j) = 1/3 − (1/3)(−1/2)^d.
Under the stationary initial law u, we have
  P[X_t = X_{t+d}] = ∑_{i} u(i) P^d(i,i) = (1/3) · 3 · [1/3 + (2/3)(−1/2)^d] = 1/3 + (2/3)(−1/2)^d.
This equals 0 at d = 1 and tends monotonically to 1/3 in absolute value with rate (1/2)^d.

Corollary 15 (Markov-chain witness violates the pair-equality identity)
For the chain in Lemma 14 and every d ≥ 1,
  P[X_t = X_{t+d}] ≠ 1/3.
Therefore, for any r ≥ 1 and any δ ≥ 2r + 1, the Markov-chain distributions used in Proposition 11 cannot satisfy the pair-equality identity of Proposition 13 at separation δ (in particular, they cannot satisfy the specialized form P_equal = 1/3 under uniform single-site marginals).

Remark.
Proposition 13 provides a sound linear identity (after imposing uniform marginals) that must be satisfied by any product-state strategy at separations ≥ 2r + 1. Lemma 14 certifies that the order-1 Markov-chain witness (which trivializes the base LP) is excluded as soon as these independence-driven identities are enforced.
Proposition 16 (Single-block reduction for product-state outputs, general r)
Fix r ≥ 1 and alphabet Σ = {1,2,3}. Let L := 2r + 2. Consider a uniform r-round LOCAL algorithm on a cycle C_n with product initial state ⊗_{v∈V} ρ (identical local marginals). Let (X_t)_{t∈ℤ/nℤ} be the output colors. Define t ∈ Δ(Σ^L) to be the common distribution of any contiguous L-block (X_i,…,X_{i+L−1}); by rotation invariance this is well defined. Then t satisfies:
(i) Nonnegativity and normalization: t(ζ) ≥ 0 and ∑_ζ t(ζ) = 1.
(ii) Shift-consistency: For all α ∈ Σ^{L−1}, letting M_1(α) = ∑_{ζ: ζ_1..ζ_{L−1}=α} t(ζ) and M_2(α) = ∑_{ζ: ζ_2..ζ_L=α} t(ζ), we have M_1(α) = M_2(α).
(iii) Perfect properness on the L − 1 interior edges, whenever it holds in the algorithm: If the algorithm achieves P[ζ_j ≠ ζ_{j+1} for all j = 1,…,L−1] = 1 on contiguous L-blocks, then t(ζ) = 0 for every ζ with ζ_j = ζ_{j+1} for some j ∈ {1,…,L−1}.
(iv) Lag-(2r+1) pair-independence at the block ends: Let m(a) = ∑_{ζ: ζ_1=a} t(ζ) and p(a,b) = ∑_{ζ: ζ_1=a, ζ_L=b} t(ζ). Then, for all a,b ∈ Σ, p(a,b) = m(a) m(b).

Proof.
- (i) is immediate.
- (ii) Rotation invariance (strict stationarity) of (X_t) implies the (L−1)-block marginals are equal when shifted by one, i.e., M_1(α) = M_2(α).
- (iii) If P[ζ_j ≠ ζ_{j+1} for all j] = 1 on contiguous L-blocks, then for each fixed j, P[ζ_j = ζ_{j+1}] = 0, which means ∑_{ζ: ζ_j = ζ_{j+1}} t(ζ) = 0. Hence t has support only on internally proper words.
- (iv) For any i, the r-neighborhoods of {i} and {i + (2r+1)} are disjoint. By Theorem 2 (independence beyond 2r in the product-state regime), X_i and X_{i + (2r+1)} are independent. Therefore, for all a,b, P[X_i=a, X_{i+(2r+1)}=b] = P[X_i=a] P[X_{i+(2r+1)}=b]. Identifying t’s (1,L) marginal with this pair law (by stationarity) gives p(a,b) = m(a)m(b).

Remark 16.1 (Color symmetry is not w.l.o.g. under independence constraints)
Averaging a feasible strategy by a random global color permutation can destroy unconditional independence across distant sets. Hence one should not impose color-symmetry constraints in models that also enforce independence equalities, unless admissibility is proved separately.

Lemma 17 (Kolmogorov/Markov extension from shift-consistent L-block marginals)
Let L ≥ 2 and Σ finite. Suppose t ∈ Δ(Σ^L) satisfies nonnegativity, normalization, and the shift-consistency equalities M_1(α) = M_2(α) for all α ∈ Σ^{L−1}. Then there exists a strictly stationary process (X_t)_{t∈ℤ} on Σ whose L-block marginal equals t. Moreover, the process can be taken to be a stationary Markov chain of order L−1 on the state space Σ^{L−1}.

Proof.
Define weights on (L−1)-blocks by μ(α) := M_1(α) = M_2(α). For any pair of (L−1)-blocks α,β that overlap on L−2 symbols (i.e., α_2..α_{L−1} = β_1..β_{L−2}), define a transition probability K(α→β) by
  K(α→β) := t(ζ) / μ(α),
where ζ ∈ Σ^L is the unique concatenation with ζ_1..ζ_{L−1} = α, ζ_2..ζ_L = β. If μ(α) = 0, leave K(α→·) arbitrary (those states are transient). Shift-consistency implies ∑_{β} K(α→β) = 1 and stationarity of μ: ∑_{α} μ(α) K(α→β) = μ(β). Hence μ is a stationary distribution for the order-(L−1) Markov chain on Σ^{L−1} with kernel K. Let (Y_t) be this chain at stationarity and set X_t := (Y_t)_{L−1} (the last symbol). One checks directly that (X_t,…,X_{t+L−1}) has law t for every t, yielding a strictly stationary process with the desired L-block marginal.

Corollary 18 (Implication of MIQCP infeasibility for r = 2)
Let r = 2 and L = 6. Consider the MIQCP that seeks t ∈ Δ(Σ^6) satisfying the linear constraints of Proposition 16 (i)–(iii) and the bilinear lag-5 independence equalities (iv). If this MIQCP is infeasible, then no uniform 2-round LOCAL algorithm with product initial state can achieve P[all 5 interior edges of a contiguous 6-block are proper] = 1 on the cycle. Consequently, there exists q < 1 and k ≥ 6 such that the success probability on C_n obeys P_success(C_n) ≤ q^{⌊n/(k+2r)⌋} by Corollary 3 (exponential amplification without entanglement).

Proof.
If an algorithm achieved perfect interior properness with probability 1 on contiguous 6-blocks, Proposition 16 would produce a feasible t, contradicting infeasibility. The amplification claim then follows from Corollary 3 once any finite k and q < 1 are certified (e.g., by optimizing the same constraints or by extending the infeasibility to a slightly larger window that yields an explicit q).


=== 2212.02768v1.pdf ===

--- Page 1 ---
Non-trivial lower bound for 3-coloring
the ring in the quantum LOCAL model
François Le Gall and Ansis Rosmanis
Graduate School of Mathematics
Nagoya University
December 6, 2022
Abstract
We consider the LOCAL model of distributed computing, where in a single round of
communication each node can send to each of its neighbors a message of an arbitrary
size. It is know that, classically, the round complexity of 3-coloring an n-node ring
is Θ(log∗n). In the case where communication is quantum, only trivial bounds were
known: at least some communication must take place.
We study distributed algorithms for coloring the ring that perform only a single
round of one-way communication. Classically, such limited communication is already
known to reduce the number of required colors from Θ(n), when there is no commu-
nication, to Θ(log n).
In this work, we show that the probability of any quantum
single-round one-way distributed algorithm to output a proper 3-coloring is exponen-
tially small in n.
1
Introduction
Graph coloring is one of the most fundamental tasks considered in distributed computing
(see [BE13] for a recent introduction). The coloring of a ring is particularly well studied
and understood. While it is easy to see that 2-coloring an n-node ring requires exactly n/2
rounds for an even n and is impossible for an odd n, things are much more interesting for 3-
coloring. Cole and Vishkin presented a 1
2 log∗n+O(1) round algorithm for 3-coloring [CV86,
GPS88]. Linial [Lin92] showed the Cole–Vishkin algorithm to be optimal for deterministic
algorithms, and then Naor [Nao91] extended that lower bound to randomized algorithms.
The complexity of graph coloring is much less understood in the quantum setting due
to the diﬃculty of characterizing the power of quantum entanglement. While quantum
entanglement enables non-local correlations, it by itself does not enable communication.
This property is known as non-signaling, and Gavoille, Kosowski, and Markiewicz used it
to show that quantum distributed algorithms for 2-coloring require at least n/4 rounds of
communication [GKM09]. As for 3-coloring, up to the best of our knowledge, prior to the
1
arXiv:2212.02768v1  [quant-ph]  6 Dec 2022

--- Page 2 ---
current work no non-trivial bounds on the round complexity were known. Namely, it was
clear that at least some communication must take place, because a non-communicating
quantum node is no diﬀerent from a non-communicating classical node, but no more than
that was known.
We consider the LOCAL model introduced by Linial [Lin92, Pel00], where the band-
width of communication links is unlimited. We additionally assume that the ring is directed
and each node knows which of its two communication ports is for communicating with its
successor, and which for its predecessor. One can consider the standard, two-way model,
where the communication can go both along and against the direction of a directed link,
and the one-way model, where the messages can be sent only in the direction of the links
(see Figure 1).
standard, two-way model
one-way model
Figure 1: The standard and the one-way LOCAL models on the ring. The direction of links is
indicated by arrows (
), while the direction of communication is indicated by the direction of
the paper plane symbols.
We can observe that, due to node’s ability to forward its entire memory to its succes-
sor, every locally checkable labeling problem1 that can be optimally solved in r rounds in
the one-way model can be solved in ⌈r/2⌉rounds in the standard model, and no faster.
Thus, studying the one-way model can provide a more ﬁne-grained characterization of the
complexity of the problem. For example, r rounds of the standard model enable O(log(2r)n)-
coloring, while r rounds of the one-way model enable O(log(r)n)-coloring. This ﬁne-graining
also allows us to prove the ﬁrst non-trivial hardness result for quantum distributed algo-
rithms for 3-coloring:
Theorem 1. The probability that a single-round one-way quantum distributed algorithm
properly 3-colors an n-node ring is exponentially small in n; in particular, it is at most
(11
15)⌊n/10⌋.
The inspiration for our result is the observation that the uniform distribution over
all proper colorings exhibits some very long-range correlations, which we detail below in
1Essentially, a problem for which the correctness of a solution can be checked in a constant number of
rounds [NS95]. Coloring is clearly locally checkable.
2

--- Page 3 ---
Section 1.1.
We further observe that all proper colorings exhibit a certain correlation
between the distance between two randomly chosen nodes and whether these nodes have
the same color. We sketch this latter observation for an 11-node ring as an example in
Section 1.2, and we note that this observation leads to a weaker version of Theorem 1
having the bound (1382
1383)⌊n/16⌋instead of (11
15)⌊n/10⌋. Improving the base of the exponent
from (1382
1383)1/16 to (11
15)1/10 requires a more thorough inspection of random colorings that
may arise from quantum distributed algorithms. Here, in Section 1.3, we brieﬂy outline
that approach, as well as describe how it might help to address the case of multiple-round
distributed algorithms in the future.
1.1
Uniform coloring requires global communication
As discussed in the works by Gavoille, Kosowski, and Markiewicz [GKM09] and Arfaoui and
Fraigniaud [AF14], the non-signaling arguments, which are used to prove the hardness of
2-coloring in the quantum case, do not seem to be able to generalize the classical Ω(log∗n)
lower bound for 3-coloring [Lin92, Nao91] to the quantum case. To formally conﬁrm the
correctness of such an intuition, one would have to answer the following question in the
aﬃrmative, and trying to do exactly that was the starting point of our research. The raised
question is:
Can one construct a probability distribution over proper 3-colorings of the n-node ring that
is non-signaling beyond distance o(log∗n)? 2
Our ﬁrst attempt at such a construction was the uniform distribution over all proper 3-
colorings. However, as the following argument shows, the uniform distribution is highly
non-local: if one knows exactly the probability that two given nodes have the same color,
one can determine the distance d ∈{1, 2, . . . , ⌊n/2⌋} between them.
Consider a line segment of length ℓ, consisting of ℓ+ 1 nodes connected by ℓlinks. It is
easy to see that there are 3 · 2ℓproper colorings of this line segment. Let aℓand bℓdenote
the number of such proper colorings that, respectively, have and have not both endpoints
colored in the same color. By solving a simple recurrence relation a0 = 3, b0 = 0, and
aℓ= bℓ−1 and bℓ= 2aℓ−1 + bℓ−1 for ℓ≥1, one can see that
aℓ= 2ℓ+ 2(−1)ℓ
and
bℓ= 2(2ℓ−(−1)ℓ).
A properly colored n-node ring can be thought of as a properly colored line segment of
length n with both endpoints being colored in the same color. Hence, there are an proper
colorings of such a ring, and the probability that two given nodes at distance d have the
2Informally, a distribution is non-signaling beyond distance r if, for any collection of ring segments, the
marginal distributions over colorings of these segments do not depend on the mutual distances between the
segments, as long as all these distances are more than r.
3

--- Page 4 ---
same color is
adan−d
3an
= (2d + 2(−1)d)(2n−d + 2(−1)n−d)
3(2n + 2(−1)n)
= 1
3 + 2(−1)n
3
· 1 + (−2)d + (−2)n−d
2n + 2(−1)n
,
which is distinct for every d.
As a result, using non-signaling arguments along the same lines as in [GKM09], it can be
seen that achieving the uniform distribution over all proper 3-colorings is no faster than 2-
coloring. It therefore also follows that the distribution over proper 3-colorings that results
from uniformly at random assigning unique labels to nodes and then running the Cole–
Vishkin algorithm is itself not uniform. We show in Section 3 that distributions that are
non-signaling beyond a given distance r must satisfy certain linear constraints, which can
then be incorporated in a linear program to bound the maximum probability for quantum
distributed algorithms to properly 3-color the ring.
1.2
Impossibility of perfect coloring
As we discovered, looking for correlations between distances among nodes and whether those
nodes have the same color not only establishes the globality of the uniform distribution, but
also leads to certain no-go results for arbitrary distributions. Our proof that the probability
of a one-round algorithm to output a proper 3-coloring is at most (1382
1383)⌊n/16⌋is essentially
a generalization of the following observation, which right away implies that it is impossible
for a quantum single-round one-way distributed algorithm to perfectly color (i.e., without
any error) an 11-node ring.
Given a coloring of the ring of 11 nodes, consider two experiments: Experiment 1 and
Experiment 2. For e ∈{1, 2}, Experiment e starts by ﬁrst randomly choosing the distance
de, where
d1 =
(
2
w.p. 30
41,
3
w.p. 11
41,
and
d2 =
(
4
w.p. 14
41,
5
w.p. 27
41.
Then the experiment chooses uniformly at random one of 11 nodes, and compares its color
with the node distance de ahead of if, outputting Match if the colors match and Differ if
they do not.
Let us consider running these experiments on proper colorings. There are a11 = 2046
such colorings, so a simple computer program (see Appendix C) can quickly check for all
of them what is the probability of Experiments 1 and 2 each returning Match. As it turns
out, for every proper coloring, the probability of Experiment 1 returning Match is at least
by
1
451 greater that the probability of Experiment 2 returning Match.
Now suppose we had a quantum single-round one-way distributed algorithm that per-
fectly 3-colors an 11-node ring, producing some probability distribution over proper color-
ings. Due to non-causality, every two non-adjacent nodes cannot tell what is the distance
4

--- Page 5 ---
between them. Hence, the probability of them returning the same color must be indepen-
dent from the distance between them. However, the observation above implies that it is
impossible. More quantitatively, in Appendix B.1 we show that it implies that the success
probability is at most 451
452. If we additionally analyze Experiments 1 and 2 on improper
colorings, we can improve this bound to 244
245.
To prove the exponential bound (1382
1383)⌊n/16⌋, we have to use a similar observation for
line segments. In addition, we have to consider a more limited set of distributions than
non-signaling distribution, which nonetheless includes all the distributions resulting from
quantum distributed algorithms.
1.3
Linear program for bounding success probability
Probability distributions resulting from quantum r-round one-way distributed algorithms
are non-signaling beyond distance r. Hence, the maximum among success probabilities of
non-signaling distributions—the total probability weight they place on proper colorings—
upper-bounds the maximum success probability of quantum distributed algorithms.
To obtain stricter bounds on the success probability than the ones obtained along the
lines of comparing Experiments 1 and 2, we can exploit the fact that non-signaling dis-
tributions have to satisfy much more constrains than that the probability of two distant
nodes having the same color must be independent from the distance between the nodes. In
particular, we show how to express the maximum success probability of non-signaling dis-
tributions beyond distance r as a linear program. As a result, for example, for n = 11 and
a single round, r = 1, we show that the success probability is at most 32
63, highly improving
upon the bound 244
245 described above.
To prove Theorem 1, we further have to consider line segments and non-signaling dis-
tributions over their colorings. The maximum among their success probabilities can also
be expressed as a linear program.
While it might be possible that this linear program shows impossibility of perfect color-
ing for quantum one-way distributed algorithms of more than one round, computationally
solving the linear program of size large enough to witness this impossibility for r much
larger than 1 is infeasible: one has to consider the number of nodes that is at least the
inverse function of log∗in r, which is astronomically large.
Nevertheless, we hope that a closer inspection of impossibility to perfectly color line
segments—in particular, the inspection of optimal primal and dual solutions of the linear
program—could lead to a technique similar to the round elimination [Bra19], which is
the current go-to theorem for showing the Ω(log∗n) lower bound for classical randomized
distributed algorithms (see [HS21] for a pedagogical description of the technique).
5

--- Page 6 ---
1.4
Organization of the paper
The paper is organized as follows. In Section 2, we formalize some aspects of the problem
of coloring the ring and we informally introduce the model of quantum distributed algo-
rithms, leaving the formal deﬁnition of the model to the appendix. In Section 3, we deﬁne
independent and non-signaling random colorings, and provide a framework for obtaining
exponential bounds on the success probability. In Section 4, we study the linear program
for the maximum success probability of non-signaling random colorings of the ring and line
segments. Using Wolfram Mathematica, we symbolically solve the linear program for cer-
tain cases when the number of nodes is small. These solutions together with the framework
introduced in Section 3 yield our main result, Theorem 1. Independent random colorings
are more constrained that non-signaling colorings, and, in Section 5, we use them to prove
that even a 4-node ring cannot be colored perfectly in a single one-way round. However, the
optimal bounds on the success probability of independent random colorings do not seem to
be expressible as linear programs, prohibiting us from obtaining similar results for larger
number of nodes. Finally, in Section 6, we talk about potential approaches towards proving
impossibility results beyond a single round of communication and other future research.
To make the paper more accessible to readers without a background in quantum com-
puting, aside from a brief description of quantum distributed algorithms in Section 2, we
keep the main body of the text free from details of quantum computation. We describe
the model of quantum distributed computation in more detail in Appendix A, where we
also prove Lemma 3 stating that the random colorings returned by such computation are
independent at distances beyond the number of rounds of communication. In Appendix B,
we observe certain correlations between the distances among the nodes and whether they
have the same color in proper colorings of the ring and line segments. These observations
together with the framework introduced in Section 3 yield the bound (1382
1383)⌊n/16⌋, which is
weaker than Theorem 1, but the observations themselves might be of an independent inter-
est in combinatorics. In Appendix C, we provide and annotate the Wolfram Mathematica
code that we have used for analyzing the example of two experiments for the 11-node ring
described in Section 1.2. This and the rest of the Wolfram Mathematica code used for our
calculations is available online [LGR22].
2
Preliminaries
Let us start by introducing terminology and mathematical formalism that we use when
discussing the directed ring.
Deﬁnition 1. An n-node directed ring is a directed degree-1 graph with the set of vertices
V := Zn = {0, 1, . . . , n−1} and the set of arcs {(v, v+1): v ∈V}. We call v ∈V a node and
we also refer to v as the number of that node. We call arcs of the graph (communication)
links. We say that v −1 precedes v, v + 1 succeeds or follows v, and that they are both
adjacent to v. We also call v + 1 the next node of v.
6

--- Page 7 ---
In the above deﬁnition and throughout the paper, for a node v and any integer k, v + k
denotes the node number v + k mod n. Given v ∈V and D ⊆Zn, let v + D := {v + d: d ∈
D} ⊆V.
Let Σ be some ﬁxed ﬁnite set that we call the set of colors.
We call the function
φ: V →Σ a coloring, and we say that φ is proper if φ(v) ̸= φ(v + 1) for all v ∈V. For
brevity, we may also denote the set of all |Σ|n colorings by ΣV. We also consider colorings
of segments of the ring, and their properness is deﬁned analogously: every pair of adjacent
nodes must have diﬀerent colors.
For a tuple (a1, . . . , aℓ) of distinct elements, let set(a1, . . . , aℓ) := {a1, . . . , aℓ}.
Computational model.
Here we describe the computational model of quantum dis-
tributed algorithm on the directed ring. We leave the precise deﬁnition of the model to
Appendix A, where we provide the proof of Lemma 3, which is a slight adaptation3 of
the folklore fact that random colorings resulting from quantum distributed algorithms are
non-signaling. Aside from establishing Lemma 3, no other aspects of quantum computation
are used.
Each node operates its own quantum processor, executing exactly the same local al-
gorithm as all the other nodes. In addition, every node can receive quantum messages
from the node preceding it and send quantum messages to the node succeeding it. This
circular communication proceeds in synchronous rounds. We are considering the LOCAL
model [Lin92], where there is no bandwidth limitations on the size of messages. At the end
of the computation, after r rounds, each node outputs a color from Σ, and we treat the
corresponding mapping Φ from V to Σ as the coloring. Due to the probabilistic nature of
quantum computation, the output Φ is probabilistic, and we use the capital letter Φ instead
of φ to emphasize that we think of coloring Φ as a random variable taking values in ΣV.
3
Independent and Non-Signaling Random Colorings
Arfaoui and Fraigniaud [AF14] used the non-signaling property of quantum computation
when analyzing, along the lines of Ref. [GKM09], the hardness of 2-coloring the ring for
quantum distributed algorithms. Here we deﬁne non-signaling colorings and their special
case that we call independent colorings. Our deﬁnition of non-signaling colorings slightly
diﬀers from the deﬁnition of non-signaling distributions by Arfaoui and Fraigniaud. First of
all, our deﬁnition is speciﬁc to the ring graph, not a general graph, and we have also made
adaptations arising from the communication being one-way. In addition, in the distributed
model that we consider, nodes do not receive unique identiﬁers at the beginning of the
computation. However, aside from adaptations due to the communication being one-way,
3Here we take into account the one-wayness of the communication, and we also consider a special case
of non-signaling random colorings that we call independent colorings.
7

--- Page 8 ---
our deﬁnition would match that of Arfaoui and Fraigniaud if they assigned the unique
identiﬁers to the nodes uniformly at random.
We consider colorings Φ of the whole ring and colorings Ψ of segments of the ring, both
of which are random variables. Deﬁnitions and lemmas established here will let us prove
our main result, Theorem 1, in Section 4.
3.1
Frames, tableaux, and their collections
Let s ∈{1, 2, . . . , n −1}. We call the intervals of integers
{{s}} := (0, 1, . . . , s −1)
and
r{{s}} := (−r, −r + 1, . . . , s −1),
a sliding frame and a gapped sliding frame, respectively. See Figure 2 for illustrations. We
refer to s as the length of the frame and to r as the length (or width) of the gap. For nodes
v and v′ = v + s −1, we call the interval of nodes
[[v..v′]] := (v, v + 1, . . . , v′)
a ﬁxed frame of length s. Given a vertex v, let v + {{s}} := [[v..v + s −1]] and v + r{{s}} :=
[[v −r..v + s −1]] (here we assume s + r ≤n −1).
Intuitively, the goal of the above deﬁnition is to ensure the following regarding the
operation of r-round distributed algorithms. If v+ r{{s}} and v′ + r{{s′}} do not overlap, then
colors output by v + {{s}} and v′ + {{s′}} should be independent. We can think of a gap as
a buﬀer that keeps (non-gapped) sliding frames suﬃciently apart.
Given a coloring φ, let φ([[v..v′]]) be short for (φ(v), φ(v + 1), . . . , φ(v′)) ∈Σs, and we
call such a tuple of colors a tableau. We note that we cannot think of φ([[v..v′]]) as the
partial function that is the restriction of φ to the subdomain set[[v..v′]]. In particular, we
may have φ([[v..v′]]) = φ([[v + δ..v′ + δ]]) for some “shift” δ ∈Z.
Collections of frames and tableaux.
We call a t-tuple ({{s1}}, . . . , {{st}}) a collection
of sliding frames. Given a collection of sliding frames F = ({{s1}}, . . . , {{st}}), we say that
F is gap-r-placable if Pt
j=1(sj + r) ≤n. We say that a tuple ω ∈Vt is a gap-r placement
of F if for all distinct j, j′ ∈{1, . . . , t} we have
set
 ωj + r{{sj}}

∩set
 ωj′ + r{{sj′}}

= ∅.
Given a collection of sliding frames F = ({{s1}}, . . . , {{st}}) and a gap-r placement ω of
F, let
ω + F :=
 ω1 + {{s1}}, . . . , ωt + {{st}}

.
For a coloring φ, let
φ(ω + F) :=
 φ(ω1 + {{s1}}), . . . , φ(ωt + {{st}})

,
8

--- Page 9 ---
Figure 2: On the left, a sliding frame, a gap-2 gapped sliding frame, and a tableau, all of length 4,
are illustrated. Here Σ = {R, G, B}. We can think of gapped sliding frames as of something that we
can slide circularly on top of the ring (including jumping over one another), and we need to place
them so that they do not overlap. On the left, the ring of length n = 22, on which the collection
F = ({{3}}, {{3}}, {{2}}) of frames is placed by the gap-2 placement ω = (4, 16, 12). Assuming there
is some underlying coloring φ of the ring, we have revealed the colors corresponding to the sliding
frames, the (3, 3, 2)-collection of tableaux in this case being ((G, R, B), (B, B, R), (R, G)).
which is a t tuple of tableaux, with j-th tableau having length sj. We call such a tuple
an (s1, . . . , st)-collection of tableaux. We note that the order of tableaux in a collection is
ﬁxed. For example, given Σ = {R, G, B}, collections ((R, G), (G, B)) and ((G, B), (R, G))
are not the same.
3.2
Colorings of the ring
We consider random variables Φ whose values are colorings φ: V →Σ, and we refer to Φ
as a random coloring, or we might still just simply refer to it as a coloring. Let Prev: V →
V : v →v −1. We call a random coloring Φ cyclic if
Pr[Φ = φ ◦Prev] = Pr[Φ = φ],
where ◦denotes the composition.
Given a random coloring Φ, we deﬁne the random variable Φ(ω + F) accordingly:
Pr[Φ(ω + F) = (ζ1, . . . , ζt)] := Pr[Φ = φ such that φ(ω + F) = (ζ1, . . . , ζt)].
We can think of Φ(ω + F) inducing a marginal distribution over (ζ1, . . . , ζt) in the natural
way.
9

--- Page 10 ---
Deﬁnition 2. We say that a random coloring Φ is independent at distances beyond r if it is
cyclic and if for every s ≥1 there exists a probability distribution ps over Σs such that, for
every collection F = ({{s1}}, . . . , {{st}}) of sliding frames, a gap-r placement ω = (ω1, . . . , ωt)
of F, and ζj ∈Σsj for every j, we have
Pr[Φ(ω + F) = (ζ1, . . . , ζt)] = ps1(ζ1) · . . . · pst(ζt).
Deﬁnition 3. We call a random coloring Φ non-signaling at distances beyond r if it is cyclic
and if, for every gap-r-placable collection of frames F, the marginal distribution induced
by Φ(ω + F) is the same for all gap-r placements ω of F.
Note that, if Φ is non-signaling at distances beyond r1, then it is also non-signaling at
distances beyond r2 for r2 > r1. The following directly follows from Deﬁnitions 2 and 3.
Claim 2. A random coloring Φ that is independent at distances beyond r is also non-
signaling at distances beyond r.
We note that the reverse of Claim 2 is not true: there exist colorings that are non-
signaling beyond some distance but that are not independent beyond that same distance.
For example, suppose |Σ| = n, and consider Φ that is a uniform distribution over all n!
colorings φ that assign a unique color from Σ to every node. Φ is non-signaling already
beyond r = 0, but it becomes independent only beyond r ≥⌊n/2⌋.4
In Appendix A, we formalize the model of quantum distributed algorithms, adapted for
one-way communication on the ring, and we show that the output distributions of quantum
r-round one-way distributed algorithms are independent at distances beyond r.
Lemma 3. The coloring Φ produced by a quantum one-way r-round distributed algorithm
is independent at distances beyond r.
3.3
Colorings of line segments and exponential bounds
Let us consider colorings of line segments, where by a line segment we think of some interval
of nodes of the ring, not containing all of them (more precisely, at least r of them). Let
k ≥1, v ∈V, and consider interval of vertices v + {{k}} = [[v..v + k −1]]. We call a map
ψ: set[[v..v′]] →Σ a coloring of the line segment. Given a set of frames F = ({{s1}}, . . . , {{st}})
we say that a gap-r placement ω of F respects the interval [[v..v′]] if
set(ωj + {{s}}) ⊆set[[v..v′]]
for all j. Note that it is still allowed that set(ωj + r{{s}}) ̸⊆set[[v..v′]], for example, when
ωj = v.
Along the same lines as Deﬁnitions 2 and 3 for complete rings, we deﬁne independent
and non-signaling colorings for line segments.
4For r ≥⌊n/2⌋, only collections consisting of a single sliding frame are gap-r-placable.
10

--- Page 11 ---
Deﬁnition 4. We say that a random coloring Ψ of a line segment [[v..v′]] is independent
at distances beyond r if for every s ≥1 there exists a probability distribution ps over Σs
such that, for every collection F = ({{s1}}, . . . , {{st}}) of sliding frames, a gap-r placement
ω = (ω1, . . . , ωt) of F that respects [[v..v′]], and ζj ∈Σsj for every j, we have
Pr[Φ(ω + F) = (ζ1, . . . , ζt)] = ps1(ζ1) · . . . · pst(ζt).
Deﬁnition 5. We call a random coloring Ψ of a line segment [[v..v′]] non-signaling at
distances beyond r if, for every collection of frames F, the marginal distribution induced by
Ψ(ω + F) is the same for all gap-r placements ω of F that respect [[v..v′]].
Lemma 4. Suppose there exist a length k ≥2, a probability q < 1, and a node v ∈V such
that, for all random colorings Ψ of the interval [[v..v + k −1]] that are independent beyond
distance r, the success probability of Ψ is at most q. Then for every coloring Φ of the whole
ring that is independent beyond distance r the success probability of Φ is at most q⌊n/(k+r)⌋.
Proof. Suppose Φ is independent (beyond distance r), and let Ψ be its restriction to the
domain set[[v..v + k −1]]. Since Φ is independent, ﬁrst, so is Ψ, and, second, there is a
probability distribution pk over ψ ∈Σk such that
Pr[Φ([[v..v + k −1]]) = ψ] = pk(ψ).
From the assumptions of the lemma,
X
proper ψ∈Σk
pk(ψ) ≤q.
Let m := ⌊n/(k+r)⌋for brevity. Now consider the collection of frames F = ({{k}}, . . . , {{k}}),
consisting of m frames, each of length k, and consider their gap-r placement ω = (ω1, . . . , ωm)
where ωj := j(r + k). Since Φ is independent, we have
Pr[Φ(ω + F) = (ζ1, . . . , ζm)] = pk(ζ1) · . . . · pk(ζm).
As a result, the probability that for a random (ζ1, . . . , ζm) = Φ(ω + F) we have that ζj
is proper for all j ∈{1, . . . , m} is at most qm. Finally such a piece-wise properness is a
prerequisite for the whole Φ to be proper, and the probability of Φ being proper can be no
larger.
In Section 4.2, we instantiate this lemma with r = 1, k = 9, and q = 11/15, thus proving
Theorem 1.
11

--- Page 12 ---
4
Success Probability of Non-Signaling Colorings as a Linear
Program
If we inspect Deﬁnitions 3 and 5 of non-signaling colorings of the ring and the line segment,
respectively, we see that the maximum success probability among non-signaling colorings
can be computed via a linear program. In this section, we provide details of this claim by
stating the two linear programs. Using Wolfram Mathematica, we managed to symbolically
solve both linear programs for r = 1 and a large enough number of nodes so that the
maximum success probability is strictly less than 1. Here we also present those results and
their implications.
4.1
Optimal colorings for rings of up to 11 nodes
Let Φ be an arbitrary non-signaling coloring beyond distance r, and, for every coloring
φ ∈ΣV, let pφ be the probability that Φ = φ. Letting pφ ≥0 be variables that sum up to
1, the maximum success probability for 3-coloring among non-signaling colorings is given
by the linear program
maximize
X
proper φ∈ΣV
pφ
(1a)
subject to
pφ = pφ◦Prev
for all φ ∈ΣV,
(1b)
X
φ∈ΣV
∀j : φ(ωj+{{sj}})=ζj
pφ =
X
φ∈ΣV
∀j : φ(ω′
j+{{sj}})=ζj
pφ
for all F, ζ, ω, ω′,
(1c)
where the latter constraint is for all collections of gap-r-placable sliding frames F =
({{s1}}, . . . , {{st}}), all corresponding collections of tableaux ζ = (ζ1, . . . , ζt), and all pairs
of gap-r placements ω, ω′ of F. The linear program (1) is feasible for all r; for example,
consider pφ = 1/|Σ|n for all φ.
We symbolically solved (1) for r = 1 and n up to 11.5 While for n up to 9 we got
the optimal value of 1, for n = 10 and n = 11 we got 2/3 and 32/63, respectively. This
constitutes the proof that single-round one-way quantum distributed algorithms cannot
succeed with 3-coloring 10-node and 11-node rings with probabilities higher than 2/3 and
32/63, respectively. Note that, however, this by itself does not yet rule out the possibility
that for a larger number of nodes perfect coloring is again possible. For that, we have to
show a similar result for line segments.
5Our solution of the linear program was somewhat ad hoc. First, we solved the primal and the dual
problems numerically. Then, from those numerical results, we managed to get symbolic feasible solutions
for the primal and the dual with matching objective values, implying their optimality.
12

--- Page 13 ---
4.2
Impossibility of perfectly coloring the 9-node line segment
We can consider the equivalent of (1) for k-node line segments. Let us consider interval
[[w..w + k −1]], where w, the number of the initial node, is irrelevant.
The maximum
success probability among random colorings of this line segment that are non-signaling
beyond distance r can be computed via the linear program
maximize
X
proper ψ∈Σk
pψ
(2a)
subject to
X
ψ∈Σk
∀j : ψ(ωj+{{sj}})=ζj
pψ =
X
ψ∈Σk
∀j : ψ(ω′
j+{{sj}})=ζj
pψ
for all F, ζ, ω, ω′,
(2b)
where the maximization is over probability distributions p = (pψ)ψ∈Σk and where the con-
straint (2b) is for all collections of sliding frames F = ({{s1}}, . . . , {{st}}), all corresponding
collections of tableaux ζ = (ζ1, . . . , ζt), and all pairs of gap-r placements ω, ω′ of F that
respect [[w..w + k −1]].
Compared to the linear program (1) for the whole ring, now, in (2), we do not have
the symmetry introduced by the cyclicity condition (1b). This results in a less constrained
and, for the same number of nodes, slower-to-compute program. Because of the results
in Section 4.1 and the following claim, for r = 1 and for k up to 8, we do not need any
computation at all: the optimum is 1.
Claim 5. Suppose there is a random coloring of the n-node ring that is non-signaling beyond
distance r and whose success probability is q. Then its restriction to any line segment of
at most n −r nodes is a random coloring of that line segment that is non-signaling beyond
distance r and has the success probability at least q.
For r = 1 and k = 9, we symbolically solved the linear program (2) and found the
objective value to be 11/15 (Footnote 5 applies here too). Thus, as a result, since non-
signaling colorings are independent, Lemma 4 applies, and we obtain Theorem 1.
A couple of remarks are in place. First, we remark that our current results do not imply
that the maximum among success probabilities of random colorings of the n-node ring that
are non-signaling beyond distance 1 is exponentially small in n. Currently, we have such a
result only for independent colorings.
Second, while we have shown that, for r = 1 and k = 9, the success probability of (2)
is strictly below 1, it might be the case that, for any number of rounds r ≥1, there is a
length k such that the optimal solution of (2) is strictly below 1. Finding such a solution
numerically seems to be far beyond what is computationally possible. But the existence of
such a solution for every r would imply an ω(1) lower bound on the round complexity of
3-coloring via quantum distributed algorithms.
13

--- Page 14 ---
5
Impossibility of perfectly coloring the 4-node ring
Let us consider random colorings of the ring that are non-signaling beyond distance 1. If, in
addition to the non-signaling constraints, we impose that the colorings must be independent,
we can show stronger no-go results. In particular, while we managed to ﬁnd a perfect non-
signaling coloring for every n up to 9 (i.e., ﬁnd a solution of (1) of objective value 1), here we
show that a prefect independent coloring does not exist already for a much smaller number
of nodes n.
Theorem 6. There is no perfect random 3-coloring of the 4-node ring that is independent
beyond distance 1.
Proof. Let us assume the contrary: there is such a coloring Φ. There are a4 = 18 proper 3-
colorings φ of the 4-node ring, which we write below as (φ(0), φ(1), φ(2), φ(3)) ∈Σ4 where
we take Σ = {0, 1, 2} to be the set of colors.
Since Φ is cyclic, there are probabilities
p0,1, p0,2, p1,2, q0, q1, q2 such that Φ equals each
(0, 1, 0, 1), (1, 0, 1, 0)
w.p. p0,1,
(0, 2, 0, 2), (2, 0, 2, 0)
w.p. p0,2,
(1, 2, 1, 2), (2, 1, 2, 1)
w.p. p1,2,
(0, 1, 0, 2), (1, 0, 2, 0), (0, 2, 0, 1), (2, 0, 1, 0)
w.p. q0,
(1, 0, 1, 2), (0, 1, 2, 1), (1, 2, 1, 0), (2, 1, 0, 1)
w.p. q1,
(2, 0, 2, 1), (0, 2, 1, 2), (2, 1, 2, 0), (1, 2, 0, 2)
w.p. q2.
We have 2(p0,1 + p0,2 + p1,2) + 4(q0 + q1 + q2) = 1.
Given a node v and a color σ ∈Σ, let rσ be the probability that Φ(v) = σ. Note
that rσ is independent from the choice of v due to the cyclicity of Φ.
We have r0 =
p0,1 + p0,2 + 2q0 + q1 + q2, with analogous expressions for r1 and r2. From these three
expressions, we obtain
p0,1 = (r0 + r1 −r2)/2 −q0 −q1.
Given a node v, the probability that both Φ(v) = 1 and Φ(v + 2) = 2 is q0. On the other
hand, since Φ is independent beyond distance 1, Φ(v) and Φ(v +2) are independent, taking
colors 1 and 2 with probability r1 and r2, respectively. As a result, q0 = r1r2, and similarly
q1 = r0r2. Because r0 + r1 = 1 −r2, we get q0 + q1 = r2 −r2
2 and, further on,
p0,1 = (1 −r2 −r2)/2 −r2 + r2
2 =
 r2 −1 −1/
√
2
 r2 −1 + 1/
√
2

.
For p0,1 and r2 both to be probabilities, we must have r2 ≤1 −1/
√
2 < 1/3. The same
argument yields r0 < 1/3 and r1 < 1/3, which is a contradiction because r0+r1+r2 = 1.
14

--- Page 15 ---
Theorem 6 implies that already for n = 4, a single-round one-way quantum distributed
algorithm cannot 3-color perfectly. However, aside from stating that the maximum suc-
cess probability cannot be 1, the theorem does not place any other upper bound on the
probability. While, for non-signaling colorings, the maximum success probability can be
characterized by a linear program, it is likely not the case for independent colorings, making
its computation more diﬃcult.
In the next section, we brieﬂy discuss a more powerful model of quantum distributed
algorithms whose round complexity can be bounded by the maximum success probability
among non-signaling colorings, but not that among independent colorings.
6
Discussion of Future Work
Exponential bounds given unique indices.
In this paper we have considered the
model of quantum distributed algorithms where initially each node’s memory is in the
same state.
One could also consider a more powerful model where, at the start of the
computation, each node v ∈V is given a unique label i ∈Zn. Here v and i do not need
to be equal: v lets us reason about node’s location on the ring, but it is unknown to
the computation, while i can be used by the computation, but it does not reveal anything
about labels of other nodes in its vicinity. Let us suppose here that these labels are assigned
uniformly at random, there being n! diﬀerent assignments in total. In addition, we could
assume that there is an n-partite quantum state (generalizing an n-partite random bitstring
of the classical case) and that at the beginning of the computation the node labeled i receives
i-th part of this state.
Even if we give these extra resources to quantum r-round one-way distributed algo-
rithms, along the same lines as for Lemma 3, it can be shown that the resulting random
coloring Φ of the ring is non-signaling beyond distance r. Hence, the impossibility of per-
fect 3-coloring in a single-round proven for n ≥10 in Section 4 still applies to this stronger
model. However, unlike for independent colorings, it is not clear if Lemma 4 applies to
non-signaling colorings, and therefore it is not clear if the impossibility to perfectly color
constant-length line segments can be elevated to exponential bounds for coloring the whole
ring, as is done for Theorem 1. Showing that the success probability of quantum single-
round one-way distributed algorithms to 3-color when these algorithms are aided by unique
node labels and correspondingly shared quantum state is exponentially small is one problem
left opened by the current work.
Better understanding the diﬀerences between non-signaling and independent colorings
might provide a better understanding of capabilities of quantum distributed algorithms
with and without shared quantum states.
Generalization of round elimination.
The round elimination technique [Bra19], when
applied to prove the Ω(log∗n)-round lower bound for 3-coloring the ring by classical random-
15

--- Page 16 ---
ized distributed algorithms, is based essentially on the following observation. Informally
speaking, if there is an r-round randomized distributed algorithm that with high prob-
ability properly c-colors a line segment of length r + 1 (i.e., (r + 2)-node line segment),
then there is an (r −1)-round randomized distributed algorithm that with high probability
properly 2c-colors a line segment of length r. By repeatedly applying this observation, one
ﬁnally reaches the “base” case, where one reasons about the probability of properly coloring
two-node line segment without any communication.
This argument does not seem to work for non-signaling colorings because it reasons
about line segments whose length is only r+1, yet the limitations of non-signaling colorings
are due to long distance correlations. It would be interesting to see if a similar technique
to round elimination could be used for non-signaling colorings. In particular, one could
potentially seek a statement similar to the following.
Hypothesis 7 (informal). There exists an integer constant δ ≥1, representing the number
of rounds to be eliminated in one step, such that the following holds. Suppose there is a
line segment [[1..k]], a random c-coloring Ψ of this line segment that is proper with high
probability, a frame-length s, and a round-number r such that, for all gap-r placements ω of
the collection of frames F = ({{s}}, {{s}}) that respect the line segment [[1..k]], the marginal
distributions over (s, s)-collections of tableaux induced by Ψ(ω + F) are the same. Then
there exists a random 2c-coloring Ψ′ of the same line segment such that Ψ′ is proper with
high probability and, for all gap-(r −1) placements ω′ of the collection of frames F ′ =
({{s −δ}}, {{s −δ}}) that respect the line segment [[1..k]], the marginal distributions over (s−
δ, s −δ)-collections of tableaux induced by Ψ′(ω′ + F ′) are the same.
If the above hypothesis (or one similar to it) can be proven, we suspect that it might
lead to a proof that, if Φ is a random 3-coloring of an n-node ring that is both non-signaling
beyond distance r and that is proper with high probability, then r = Ω(log∗n). This would
imply the same lower bound on the round complexity of quantum distributed algorithms.
Better understanding of the linear program (2) for r = 1 and k = 9 and, in particular,
under what restricted sets of constraints its optimum is still strictly below 1, might yield
some insights towards the hypothesis above.
Acknowledgements
The authors are grateful to Sebastian Brandt for useful insights.
FLG and AR were
supported by JSPS KAKENHI Grant No. JP20H05966 and MEXT Quantum Leap Flag-
ship Program (MEXT Q-LEAP) Grants Nos. JPMXS0118067394 and JPMXS0120319794.
FLG was also supported by JSPS KAKENHI Grants Nos. JP19H04066, JP20H00579,
JP20H04139, JP21H04879.
16

--- Page 17 ---
References
[AF14]
Heger Arfaoui and Pierre Fraigniaud. What can be computed without communications?
SIGACT News, 45(3):82–104, 2014.
[BE13]
Leonid Barenboim and Michael Elkin. Distributed graph coloring: Fundamentals and
recent developments. Synthesis Lectures on Distributed Computing Theory, 4(1):1–171,
2013.
[Bra19]
Sebastian Brandt. An automatic speedup theorem for distributed problems. In Proceed-
ings of the 2019 ACM Symposium on Principles of Distributed Computing, PODC ’19,
page 379–388, New York, NY, USA, 2019. Association for Computing Machinery.
[CV86]
Richard Cole and Uzi Vishkin. Deterministic coin tossing with applications to optimal
parallel list ranking. Information and Control, 70(1):32–53, 1986.
[GKM09] Cyril Gavoille, Adrian Kosowski, and Marcin Markiewicz. What can be observed locally?
In Distributed Computing, pages 243–257, Berlin, Heidelberg, 2009. Springer Berlin Hei-
delberg.
[GPS88]
Andrew V. Goldberg, Serge A. Plotkin, and Gregory E. Shannon. Parallel symmetry-
breaking in sparse graphs. SIAM Journal on Discrete Mathematics, 1(4):434–446, 1988.
[HS21]
Juho Hirvonen and Jukka Suomela.
Distributed Algorithms 2020.
https://
jukkasuomela.fi/da2020/, 2021.
[LGR22]
François Le Gall and Ansis Rosmanis. On coloring the ring in the quantum LOCAL
model. http://rosmanis.com/research/3coloring/, 2022.
[Lin92]
Nathan Linial. Locality in distributed graph algorithms. SIAM Journal on Computing,
21(1):193–201, 1992.
[Nao91]
Moni Naor. A lower bound on probabilistic algorithms for distributive ring coloring.
SIAM Journal on Discrete Mathematics, 4(3):409–412, 1991.
[NC00]
Michael A. Nielsen and Isaac L. Chuang. Quantum Computation and Quantum Infor-
mation. Cambridge University Press, 2000.
[NS95]
Moni Naor and Larry Stockmeyer. What can be computed locally? SIAM Journal on
Computing, 24(6):1259–1277, 1995.
[Pel00]
David Peleg. Distributed Computing: A Locality-Sensitive Approach. Discrete mathe-
matics and applications. Society for Industrial and Applied Mathematics, 2000.
A
Quantum Distributed Algorithm
We assume that the reader of this section is familiar with the basics of quantum computation
(for an introductory textbook, see [NC00]).
17

--- Page 18 ---
A.1
Model of quantum one-way distributed algorithm
Let the memory of a node v ∈V be held in register Nv, which consists of two subregisters:
the workspace register Wv and the (forward) message register Mv. Let HWv, HMv, and
HNv = HWv ⊗HMv be complex Euclidean spaces corresponding to the registers Wv, Mv,
and Nv, respectively. We assume that each W0, W1, W2, . . . consists of the same number
of qubits, thus the dimensions of all HW0, HW1, HW2, . . . are the same, and similarly we
assume that each M0, M1, M2, . . . consists of the same number of qubits. We additionally
assume that all nodes run the same local computation. We may drop the subscript v when
convenient.
The collective memory of nodes is initialized to the state |0⟩⊗n, which is a pure state on
N
x∈[n] HNv; here |0⟩is the state of the register Nv with all individual qubits set to |0⟩. Let
V be the messaging unitary deﬁned by the linear extension of its action on product states
as
V :
O
v∈V
|bv, cv⟩Nv 7→
O
v∈V
|bv, cv−1⟩Nv,
where |bv⟩∈HWv and |cv⟩∈HMv. The unitary V implements one round of communication.
The local actions of every node between two communication rounds are described by a
unitary U, which acts on HN. It is the same for every node and, without loss of generality,
the same for every round.6 Likewise, the ﬁnal local projective measurement Π = {Πσ : σ ∈
Σ} is the same for every node. We permit this measurement not to be in the standard
computational basis, therefore there is no loss of generality in not applying any local unitary
after the last round of communication V .
An r-round protocol starts with the state |0⟩⊗n and then alternates between applications
of U for every node and V on the joint system. Thus, the overall ﬁnal state right before
the ﬁnal measurement is (V U⊗n)r|0⟩⊗n. Finally, each node performs the measurement Π
on its memory, outputting the result of the measurement. The joint result being random,
we treat it as a random variable Φ taking values in ΣV.
A.2
Proof of Lemma 3
Suppose we have a quantum r-round one-way distributed algorithm speciﬁed by U and Π.
Let the random coloring Φ be the output of the algorithm.
Consider s ≥1 and ζ = (σ0, . . . , σs−1) ∈Σs. Let us consider the space Ns−1
i=−r HNi,
where we label each individual instance of the space HN not with the number of a node but
with an index i in the gapped sliding frame r{{s}}. Let us deﬁne an orthogonal projector
Ξr(s, ζ) recursively for r ≥0 as follows. Intuitively, we will start with a ﬁnal measurement
6We can assume that the same unitary U is applied at every round because U can be designed so that
the node keeps a round counter in its memory and then controls its actions based on it.
18

--- Page 19 ---
operator Ξ0(s, ζ) and then run the computation in reverse for r rounds, seeing how that
operator evolves under this reverse computation. For r = 0, let
Ξ0(s, ζ) :=
s−1
O
i=0
(Πσi)Ni.
For r ≥1, ﬁrst, let
Vr+s :
s−1
O
i=−r
HNi →HW−r ⊗
s−1
O
i=−r+1
HNi ⊗HMs
be the linear isometry deﬁned as
Vr+s :
s−1
O
i=−r
|bi, ci⟩Ni 7→|b−r⟩W−r ⊗
s−1
O
i=−r+1
|bi, ci−1⟩Ni ⊗|cs−1⟩Ms.
Then, for r ≥1, we recursively deﬁne
Ξr(s, ζ) := (U−1)⊗(r+s)V−1
r+s

IW−r ⊗Ξr−1(s, ζ) ⊗IMs

Vr+sU⊗(r+s),
where I denotes the identity operator on the corresponding registers.
Given a ﬁxed s, projectors Ξr(s, ζ) are orthogonal for distinct ζ and the sum P
ζ∈Σs Ξr(s, ζ)
equals the identity operator on Ns−1
i=−r HNi. Deﬁne the probability distribution ps over Σs
as
ps(ζ) := ⟨0|⊗(r+s)Ξr(s, ζ)|0⟩⊗(r+s).
Now, given a node v, we can consider Ξr(s, ζ) to act on the space corresponding to the
interval of nodes v + r{{s}} = [[v −r..v + s −1]] by associating HNi, where i ∈r{{s}} is an
index, with HNv+i, where v + i is the number of a node. To specify that Ξr(s, ζ) acts on
the space corresponding to those nodes, we write it as (Ξr(s, ζ))Nv−r..Nv+s−1.
Consider a collection of sliding frames F = ({{s1}}, . . . , {{st}}) and, for every j ∈{1, . . . , t},
a tableau ζj ∈Σsj. Suppose ω is a gap-r placement of F. Because of the constraints on
gap-r placements, we can see that, for distinct j, the projectors (Ξr(sj, ζj))Nωj−r..Nωj+sj−1
act on spaces corresponding to disjoint sets of nodes.
Let use ﬁx ω and ζ, and let us write ζj = (ζj,0, . . . , ζj,sj−1) for every j. Let us deﬁne
p := Pr[Φ(ω + F) = (ζ1, . . . , ζt)],
that is, p is the probability that for every j ∈{1, . . . , t} and every i ∈{0, . . . , sj −1} the
node ωj + i outputs ζj,i. This probability equals
p = ∥Ξﬁnal(V U⊗n)r|0⟩⊗n∥2,
19

--- Page 20 ---
where
Ξﬁnal :=
t
O
j=1
sj−1
O
i=0
(Πζj,i)Nωj+i ⊗Irest =
t
O
j=1
(Ξ0(sj, ζj))Nωj ..Nωj+sj−1 ⊗Irest
and Irest is the identity on the joint space of the nodes not in any ωj + {{sj}}.
Let us start with the ﬁnal measurement operator Ξﬁnal and eﬀectively run the compu-
tation in reverse, obtaining the measurement operator
Ξinit := (V U⊗n)−rΞﬁnal(V U⊗n)r
on the initial state. We can write
Ξinit =
t
O
j=1
(Ξr(sj, ζj))Nωj−r..Nωj+sj−1 ⊗Irest′,
where Irest′ is the identity on the joint space of the nodes not in any ωj + r{{sj}}. The
correctness of the above expression for Ξinit can be seen inductively, using the recursive
deﬁnition of projectors Ξr.
Finally, since the initial state is a product state, we get the desired independence. More
precisely, because p = ∥Ξinit|0⟩⊗n∥2, we get that p = ps1(ζ1) · . . . · pst(ζt).
B
Bounds from Inspecting Pairs of Nodes
Here we consider single-round algorithms, and we consider probability distributions over
pairs of non-adjacent nodes, particularly focussing on whether the two nodes of the pair
have the same color. We will be interested in pairs (p, p′) of such probability distributions,
and we will be able to ﬁnd pairs that serve as witnesses that one cannot 3-color perfectly.
In Section B.1, we consider non-signaling colorings of the n-node ring and computation-
ally obtain witnesses for n = 11 and n = 13, 14, . . . , 22 that bound the success probability
strictly below 1. In Section B.2, we obtain a similar witness for the 15-node line segment,
showing that the probability of properly coloring this segment is less than 1382
1383, which then,
using Lemma 4, yields the following theorem, which is a weaker version of Theorem 1.
Theorem 8. The probability that a single-round one-way quantum distributed algorithm
properly 3-colors an n-node ring is at most (1382
1383)⌊n/16⌋.
Both sections take advantage of the fact that, since r = 1, the probability of two
non-adjacent nodes having the same color is independent from the distance between them.
Results presented here might be of an independent interest in combinatorics.
20

--- Page 21 ---
B.1
Constant bounds for certain small n
Suppose Φ is a random coloring that is non-signaling at distances beyond one.
Let us
consider the collection of frames F = ({{1}}, {{1}}). There are n(n −3) gap-one placements
ω = (v, v + d) of F, which we specify by a node v ∈V and a distance d ∈{2, 3, . . . , n −2}.
Since Φ is non-signaling, the marginal distribution induced by Φ(ω + F) = ((Φ(v)), (Φ(v +
d))) is the same for all such ω. In particular, the average probability
1
n
X
v∈V
Pr[σ1 = σ2 : σ1 = Φ(v) & σ2 = Φ(v + d)]
is some constant γ independent from d.
For every coloring φ ∈ΣV, deﬁne 1φ(v)=φ(v+d) to be 1 when φ(v) = φ(v + d) and 0
otherwise. Then deﬁne
βφ,d := 1
n
X
v∈V
1φ(v)=φ(v+d) ∈{0, 1
n, 2
n, . . . , 1},
and note that βφ,d is the probability that two randomly chosen nodes distance d apart have
the same color. Clearly βφ,d = βφ,n−d. Let us also deﬁne βφ := (βφ,2, βφ,3 . . . , βφ,n−2). We
have E[βΦ] = (γ, γ, . . . , γ).
For any probability distribution over distances p = (p2, p3, . . . , pn−2) we have
γ = p · E[βΦ] = E[p · βΦ].
Consider two such probability distributions p, p′ and a bias ∆≥0 such that p·βφ ≥∆+p′·βφ
for all proper colorings φ. Note that such p, p′, ∆always exist, as p = p′ and ∆= 0 jointly
satisfy the required condition.
The interesting cases, however, are when ∆> 0.
The
maximum value of ∆can be computed by the linear program
maximize
∆
(3a)
subject to
(p −p′) · βφ ≥∆
for all proper φ,
(3b)
where the optimization is over ∆≥0 and all probability distributions p and p′. Since
βφ,d = βφ,n−d, for the sake of aesthetics, without loss of generality we impose pd = pn−d and
p′
d = p′
n−d.7 Note that, whenever the maximum bias ∆is non-zero, probability distributions
p and p′ achieving it have disjoint supports.
We solved the linear program (3) for n up to 22 and we found the optimal ∆to be
strictly positive for n = 11 and n = 13, 14, . . . , 22. Before we elaborate on these solutions,
let us see how a non-zero ∆implies upper bounds on the success probability.
7The shapes of plots in Figure 4, representing optimal solutions of (3), are smoother this way. We could
alternatively impose pd = p′
d = 0 for d > ⌊n/2⌋, but then, for even n, the optimal solutions we found would
have p′
n/2−1 ≈2pn/2. We note that, however, when we implement (3) in Wolfram Mathematica, we do
indeed assume pd = p′
d = 0 for d > ⌊n/2⌋, because that approximately halves the number of variables.
21

--- Page 22 ---
Let −Γ ≤0 be the minimum of (p −p′) · βφ over improper colorings φ, and let εΦ :=
Pr[Φ is improper]. We have
0 = E[(p −p′) · βΦ]
=
X
proper φ∈ΣV
Pr[Φ = φ] (p −p′) · βφ +
X
improper φ∈ΣV
Pr[Φ = φ] (p −p′) · βφ
≥(1 −εΦ)∆−εΦΓ.
(4)
Hence, since Γ ≤1, we get
εΦ ≥
∆
∆+ Γ ≈∆
Γ ≥∆,
where the approximation assumes ∆≪Γ, which will be the case for the instances we
consider.
Solving the linear program.
We used Wolfram Mathematica to solve the linear pro-
gram (3) exactly (i.e., not in the ﬂoating-point arithmetic, but symbolically). The code for
this is relatively simple, only slightly building on top of the code given in Appendix C. We
have made the code available online [LGR22].
To ﬁnd the set of all distinct βφ, we run a brute force search over all proper φ ∈Σn.
For example, for n = 11, n = 16, n = 21, the number of such distinct βφ is, respectively,
21, 410, 8336.
Once we had found optimal p, p′, for values of n up to 19, we run the brute force search
over all improper colorings φ to compute Γ = −minφ (p −p′) · βφ for them. Since there are
approximately 2n proper colorings and approximately 3n improper colorings, ﬁnding Γ is
computationally slower than ﬁnding ∆.
Figure 3 shows lower bounds on the error probability of 3-coloring the ring using quan-
tum single-round one-way distributed algorithms for n = 11, 12, . . . , 22. For n = 12, this
lower bound is 0.
Figure 4 shows optimal solutions p, p′ of the linear program (3). We can see that p is
sharply concentrated around small distances (treating distances d and n−d as the minimum
between them), while p′ is more ﬂatly supported on long distances. In Figure 4 we have
plotted p, p′ for n = 13, 14, 15, 20, 21, 22, and similarly shaped plots were observed for other
values of n between 11 and 22.
We note that, if a non-zero bias could be achieved by some p and p′ that are supported
on {r +1, r +2, . . . , n−r −1}, then that would imply the impossibility of perfect 3-coloring
in r one-way rounds. However, we succeeded to ﬁnd such p and p′ only for r = 1.
B.2
Exponential bounds via Lemma 4
In a similarly fashion to the ring in Section B.1, let us now consider a line segment
[[w..w + k −1]] of k nodes. For notational convenience, let w = 1. Let Ψ be a random
22

--- Page 23 ---





















12
14
16
18
20
22
n
0.000
0.002
0.004
0.006
0.008
0.010
0.012
Figure 3: Maximum bias ∆for n = 11, 12, . . . , 22, represented by squares, as well as lower bounds
∆
∆+Γ on the error probability for n up to 19, represented by circles. (Since Γ ≤1, for n = 20, 21, 22,
we can take
∆
∆+1 ≈∆as the lower bound on the error probability.)
coloring of this segment that is independent beyond distance 1.
As before, let us con-
sider the collection of frames F = ({{1}}, {{1}}). There are (k −1)(k −2) gap-1 placements
ω = (u, v) of F that respect [[1..k]], but, due to symmetry, it suﬃces to consider only the
half of them that have u < v.
Similarly as before, for u, v ∈{1, 2, . . . , k} such that v ≥u + 2 and a coloring ψ ∈Σk
of the line segment, let βψ,u,v = 1 if ψ(u) = ψ(v), and βψ,u,v = 0 otherwise, and we extend
this deﬁnition to random Ψ. Since Ψ is non-signaling beyond distance 1, Pr[Ψ(u) = Ψ(v)]
is the same for all non-adjacent u, v, and let us denote this probability by γ. Let us consider
the vectors βψ := (βψ,u,v)u,v and probability distributions p := (pu,v)u,v over non-adjacent
nodes expressed as vectors, where the indexing is done in the same consistent manner. We
have E[βΨ] = (γ, γ, . . . , γ), and thus E[(p −p′) · βΨ] = 0.
Similarly as before, we deﬁne the maximum bias ∆as the optimal value of the linear
program
maximize
∆
(5a)
subject to
(p −p′) · βψ ≥∆
for all proper ψ.
(5b)
We note that solving the linear program (5) is more costly than (3), given the number of
nodes, k and n respectively, are equal. That is because (5) does not exploit symmetries
due to the cyclicity of the ring. In particular, up to color permutations, one can recover ψ
from βψ.
We solved the linear program (5) for increasing large values of k, and the smallest k for
which the optimum ∆is strictly positive is k = 15. For k = 15, the maximum bias is
∆=
569 800 825
2 362 818 191 739 ≈2.412 · 10−4.
23

--- Page 24 ---
p'd
pd
n=13
0
.1
.2
.3
.1
.2
p'd
pd
n=14
0
.1
.2
.3
.1
.2
p'd
pd
n=15
0
.1
.2
.3
.1
.2
p'd
pd
n=20
0
.1
.2
.3
.1
.2
p'd
pd
n=21
0
.1
.2
.3
.1
.2
p'd
pd
n=22
0
.1
.2
.3
.1
.2
Figure 4: Optimal solutions p, p′ of the linear program (3) for n = 13, 14, 15, 20, 21, 22. Probability
distributions p, p′ have disjoint supports, and we display only non-zero probabilities in them. The
horizontal axis corresponds to the distance d. The upward-pointing vertical axis corresponds to pd,
while the downward-pointing vertical axis corresponds to p′
d.
An optimal solution (p, p′) corresponding to this ∆is illustrated in Figure 5. As in Figure 4
for the whole ring, we see that p is supported on pairs (u, v) with shorter distances between
them, while p′ on pairs (u, v) with larger distances between them.
Then, for this solution (p, p′), we computed the minimum −Γ of (p −p′) · βψ over all
improper ψ, and we found
Γ = 218 333 768 903 290 121
655 639 517 480 121 198 ≈0.3330
(note that, since the solution (p, p′) is not necessarily unique, neither is Γ). Just like the
argument based on the inequality (4), this means that the success probability of Ψ is at
most
Γ
∆+Γ < 1382
1383. This together with Lemma 4 proves Theorem 8.
24

--- Page 25 ---
Figure 5: An optimal solution of (5) for the 15-node line segment. The blue dotted discs indicate
non-zero pu,v and the orange honeycombed discs indicate non-zero p′
u,v.
The probabilities are
proportional to the area of the disc, the scale being indicated by the ﬁve overlapping discs in gray.
C
Code for Witnessing Impossibility of Perfect Coloring
Here we consider the ring of n = 11 nodes, and we present a Wolfram Mathematica code
that veriﬁes that, according to arguments in Section B.1, it is impossible for a quantum
single-round one-way distributed algorithm to perfectly 3-color the ring.
Consider probability distributions p = (30
41, 11
41, 0, 0) and p′ = (0, 0, 14
41, 27
41) over distances
2, 3, 4, 5, respectively. As in Section B.1, for a coloring φ ∈ΣV, let βφ := (βφ,2, βφ,3, βφ,4, βφ,5),
where βφ,d := |{v ∈V : φ(v) = φ(v + d)}|/n. The following code returns minDelta of
1
451,
showing that (p −p′) · βφ ≥
1
451 for all proper colorings φ.
1
n = 11;
2
pp = {30, 11, -14, -27}/41;
3
minDelta = 1;
4
For[i = 0, i < 2^(n - 2), i++,
5
steps = 1 + IntegerDigits[i, 2, n - 2];
6
phi = {1, 0}~Join~Mod[Total[Take[steps, #]] & /@ Range[n - 2], 3];
7
If[Last[phi] == 1, Continue[]];
8
betaN = {};
25

--- Page 26 ---
9
For[d = 2, d <= Floor[n/2], d++, betaNd = 0;
10
For[v = 1, v <= n, v++,
11
betaNd += Boole[phi[[v]] == phi[[Mod[v + d, n, 1]]]]];
12
AppendTo[betaN, betaNd];];
13
If[pp . betaN < n minDelta, minDelta = pp . betaN/n];];
14
Print[minDelta]
Line 1 of the code is self-explanatory. In line 2, we deﬁne constant pp as p −p′. In line
3, we introduce variable minDelta that will track the minimum (p −p′) · βφ found so far,
which is clearly no more than 1. We consider the set of colors Σ = {0, 1, 2}. The For loop
of lines 4–13 goes over all proper colorings of the ring that, without loss of generality, colors
nodes v = 0 and v = 1 with colors 1 and 0, respectively. We note that not all counters i
correspond to proper colorings as about a third of them are discarded in line 7, which tests
if φ(n −1) = 1 = φ(0).
In line 5, we represent i as an n −2 bit string, and then we add 1 to all bits, getting a
string steps ∈{1, 2}n−2. After that, in line 6, we eﬀectively assign φ(j+1) := φ(j)+stepsj
mod 3 for all j from 1 to n −2. Thus φ is a proper coloring aside from, potentially, having
φ(n −1) = φ(0), which we check in line 7.
In lines 8–12, we compute βφn in the variable betaN. Here betaNd contains βφ,dn = |{v ∈
V : φ(v) = φ(v + d)}|, which is simply counted in line 11. Note that Wolfram Mathematica
indexes lists starting with index 1. Finally, in line 13, we update the minimum (p −p′) · βφ
if necessary, and print the result in line 14.
To implement the linear program (3), one only has to slightly extend the code above.
That code as well as all the other code that we have used for our computations is made
available online [LGR22].
26


=== 2403.01903v3.pdf ===

--- Page 1 ---
Online Locality Meets Distributed
Quantum Computing
Amirreza Akbari · Aalto University, Finland
Xavier Coiteux-Roy · School of Computation, Information and Technology, Technical
University of Munich, Germany · Munich Center for Quantum Science and Technology, Germany
Francesco d’Amore · Aalto University, Finland · Bocconi University, Italy · BIDSA, Italy
François Le Gall · Nagoya University, Japan
Henrik Lievonen · Aalto University, Finland
Darya Melnyk · Technische Universität Berlin, Germany
Augusto Modanese · Aalto University, Finland
Shreyas Pai · Aalto University, Finland
Marc-Olivier Renou · Inria, Université Paris-Saclay, Palaiseau, France · CPHT, Ecole
Polytechnique, Institut Polytechnique de Paris, Palaiseau, France
Václav Rozhoň · ETH Zurich, Switzerland
Jukka Suomela · Aalto University, Finland
Abstract. We connect three distinct lines of research that have recently explored extensions of the
classical LOCAL model of distributed computing:
A. distributed quantum computing and non-signaling distributions [e.g. STOC 2024],
B. finitely-dependent processes [e.g. Forum Math. Pi 2016], and
C. locality in online graph algorithms and dynamic graph algorithms [e.g. ICALP 2023].
We prove new results on the capabilities and limitations of all of these models of computing, for
locally checkable labeling problems (LCLs). We show that all these settings can be sandwiched
between the classical LOCAL model and what we call the randomized online-LOCAL model. Our
work implies limitations on the quantum advantage in the distributed setting, and we also exhibit a
new barrier for proving tighter bounds. Our main technical results are these:
1. All LCL problems solvable with locality O(log∗n) in the classical deterministic LOCAL model
admit a finitely-dependent distribution with locality O(1). This answers an open question by
Holroyd [2024], and also presents a new barrier for proving bounds on distributed quantum
advantage using causality-based arguments.
2. In rooted trees, if we can solve an LCL problem with locality o(log log log n) in the randomized
online-LOCAL model (or any of the weaker models, such as quantum-LOCAL), we can solve it
with locality O(log∗n) in the classical deterministic LOCAL model. One of many implications
is that in rooted trees, O(log∗n) locality in quantum-LOCAL is not stronger than O(log∗n)
locality in classical LOCAL.
arXiv:2403.01903v3  [cs.DC]  5 Nov 2024

--- Page 2 ---
1
Introduction
In this work, we connect three distinct lines of research that have recently explored extensions of the
classical LOCAL model of distributed computing:
A. Distributed quantum computing and non-signaling distributions [3, 27, 36].
B. Finitely-dependent processes [44, 45, 47].
C. Locality in online graph algorithms and dynamic graph algorithms [2, 22].
We prove new results on the capabilities and limitations of all of these models of computing, for
locally checkable labeling problems (LCLs), with the help of a unifying model that we call randomized
online-LOCAL. Our work implies limitations on the quantum advantage in the distributed setting,
and we also exhibit a new barrier for proving tighter bounds.
1.1
Highlights
Our main technical results are these:
1. All LCL problems solvable with locality O(log∗n) in the classical deterministic LOCAL
model admit a finitely-dependent distribution, i.e., a bounded-dependence distribution with
constant locality:
classical LOCAL algorithm, locality O(log∗n)
bounded-dependence distribution, locality O(1)
non-signaling distribution, locality O(1)
This answers an open question by Holroyd [44]. This also presents a new barrier for proving
bounds on distributed quantum advantage: all current quantum-LOCAL lower bounds are, in
essence, lower bounds for non-signaling distributions, and our result shows that fundamentally
different techniques will be needed to solve some of the biggest open questions in this area
(e.g., showing that there is no constant-round quantum-LOCAL algorithm for coloring cycles).
2. In rooted trees, if we can solve an LCL problem with locality o(log log log n) in the randomized
online-LOCAL model (or any of the weaker models, such as quantum-LOCAL), we can solve it
with locality O(log∗n) in the classical deterministic LOCAL model:
quantum-LOCAL algorithm, locality o(log log log n)
bounded-dependence distribution, locality o(log log log n)
randomized online-LOCAL algorithm, locality o(log log log n)
classical LOCAL algorithm, locality O(log∗n)
One of many implications is that in rooted trees, O(log∗n) locality in quantum-LOCAL is not
stronger than O(log∗n) locality in classical LOCAL, and also finitely-dependent distributions
are not stronger than O(log∗n) locality in classical LOCAL.
We will now proceed to explain what all of these terms and models mean, and how they are connected
with each others.
1

--- Page 3 ---
1.2
Roadmap
As our main goal is to unify and relate several distinct models studied in prior work, we will need to
introduce a fair number of models of computing. We recommend that the reader keep the roadmap
that we have in Fig. 10 (final page) at hand while reading the introduction, in order to maintain a
clear view of things, as well as to consult this overview again when needed.
We start our adventure in Section 1.3 by introducing the classical models that we have at the
very top of Fig. 10 and then relate these to the current landscape of LCLs in Section 1.4. Next, we
gradually work our way through the quantum as well as bounded-dependence and non-signaling
models in Section 1.5, after which we take our first break. At this point, we are familiar with the top
half of Fig. 10, and we are ready to state our first main contributions related to symmetry breaking
with finitely-dependent processes in Section 1.6.
In Section 1.7, we then turn to models that at first may seem completely unrelated. They deal
with locality in sequential, dynamic, and online settings. As we will see in Section 1.8, however, we
can connect all of these models into a single hierarchy, with seemingly orthogonal models sandwiched
between deterministic LOCAL and randomized online-LOCAL, and we can prove various strong
results that connect the complexity landscape between these two extremes.
1.3
Classical models
Let us first recall the definitions of the classical models of distributed graph algorithms [54, 61] that
form the foundation for our work; we keep it brief here and postpone formal definitions to Section 4.
• Deterministic LOCAL: Our input graph G = (V, E) represents a computer network; each
node v ∈V is a computer and each edge {u, v} ∈E is a communication link between two
computers. Each node is labeled with a unique identifier from {1, 2, . . . , poly(|V |)}. All nodes
follow the same distributed algorithm. Initially a node is only aware of its own identifier and
its own degree. Computation proceeds in synchronous rounds, and in each round a node can
send and receive a message to and from each neighbor and update its state. Eventually each
node must stop and announce its local output (its part of the solution, e.g. in graph coloring its
own color). The running time, round complexity, or locality of the algorithm is the (worst-case)
number of rounds T(n) until the algorithm stops in any n-node graph.
• Randomized LOCAL: As above, but each node also has a private source of random bits.
We also define the following variants (see e.g. [50] for more on the impact of shared global information):
• Deterministic LOCAL (shared): Deterministic LOCAL with shared global information. The
set of nodes and their unique identifiers is globally known, and hence we also know n = |V |.
• Randomized LOCAL (shared): Randomized LOCAL with shared global information and
shared randomness. The set of nodes and their unique identifiers is globally known, and in
addition to the private sources of random bits, there is also a shared source of random bits
that all nodes can access.
We can interpret the shared versions of the models so that we get to see the set of nodes V and
their unique identifiers in advance, and we can also initialize the nodes as we want based on this
information (and hence in the randomized model, we can also initialize all nodes with the same
shared random string), but the set of edges E is only revealed later. This interpretation will be
useful especially with the quantum models.
2

--- Page 4 ---
1.4
Landscape of LCL problems
There has been more than three decades of work on understanding the capabilities and limitations of
the classical deterministic and randomized LOCAL models, but for our purposes most interesting is
the recent line of work that has studied distributed algorithms for locally checkable labeling problems,
or LCLs. This is a family of problems first introduced by Naor and Stockmeyer [57]. LCL problems
are graph problems that can be defined by specifying a finite set of valid neighborhoods. Many
natural problems belong to this family: coloring graphs of maximum degree ∆with ∆+ 1 colors,
computing a maximal independent set, finding a maximal matching, etc.
Since 2016, we have seen a large body of work dedicated to understanding the computational
complexity of LCL problems in the deterministic and randomized LOCAL models [4–9, 11, 16, 17,
19, 20, 34, 37, 39, 40, 62], and nowadays there are even algorithms and computer tools available
for exploring such questions [9, 23, 59]. As a result of this large international research effort, a
landscape of the localities of LCL problems emerges [64]. We can classify LCL problems in discrete
classes based on their locality, and we also understand how much randomness helps in comparison
with deterministic algorithms. Our main goal in this work is to extend this understanding of LCL
problems far beyond the classical models, and especially explore what can be computed very fast in
models that are much stronger than deterministic or randomized LOCAL.
1.5
Quantum-LOCAL and finitely-dependent processes
We start our exploration of stronger models with distributed quantum computation. The key
question is understanding the distributed quantum advantage: what can we solve faster if our nodes
are quantum computers and our edges are quantum communication channels? There is a long line of
prior work exploring this theme in different models of distributed computing [3, 18, 27, 33, 35, 36,
43, 48, 49, 51, 52, 55, 66–68], but for our purposes these are the models of interest:
• Quantum-LOCAL: This model of computing is similar to the deterministic LOCAL model
above, but now with quantum computers and quantum communication links. More precisely,
the quantum computers manipulate local states consisting of an unbounded number of qubits
with arbitrary unitary transformations, the communication links are quantum communication
channels (adjacent nodes can exchange any number of qubits), and the local output can be the
result of any quantum measurement.
• Quantum-LOCAL (shared): Quantum-LOCAL with shared global information and a shared
quantum state. As above, but now the algorithm may inspect and manipulate the set of nodes
(before any edges are revealed). In particular, it may initialize the nodes with a globally shared
entangled state.
As quantum theory intrinsically involves randomness, quantum-LOCAL is at least as strong as
randomized LOCAL. There are some (artificial) problems that are known to be solvable much faster
in quantum-LOCAL than deterministic or randomized LOCAL [52]; however, whether any LCL admits
such a quantum advantage is a major open question in the field.
Directly analyzing quantum-LOCAL is beyond the scope of current techniques. In essence, the
only known technique for proving limitations of quantum-LOCAL is sandwiching it between the
classical randomized-LOCAL model and more powerful models than quantum-LOCAL that do not
explicitly refer to quantum information. These more powerful models are based on the physical
causality principle (a.k.a. non-signaling principle). The idea is perhaps easiest to understand with
the help of the following thought experiment:
3

--- Page 5 ---
Example 1.1. Fix a distributed algorithm A in the quantum-LOCAL model (with shared global
information and quantum state) that runs in T rounds on graphs with n nodes. Let G = (V, E) be
some n-node input graph. Apply A repeatedly to G to obtain some probability distribution Y (G)
of outputs. Now fix some subset of nodes U ⊆V , and consider the restriction of Y (G) to U, in
notation Y (G)↾U. Let G[U, T] be the radius-T neighborhood of set U in G. Now modify G outside
G[U, T] to obtain a different n-node graph G′ with G[U, T] = G′[U, T]. Apply A to G′ repeatedly,
and we obtain another probability distribution Y (G′) of outputs. If Y (G)↾U ̸= Y (G′)↾U, it would
be possible to use A to transmit information in T time steps between two parties, Alice and Bob,
that are within distance T + 1 from each other: Bob holds all nodes of U, and he can, therefore,
observe Y (G)↾U, while Alice controls the graph outside G[U, T] = G′[U, T], and she can, therefore,
instantiate either G or G′. This would enable Alice to send a signal to Bob even if no physical
communication occurred from Alice to Bob (as they are at distance T + 1 from each other and only
T communication steps occurred), and thus violate the non-signaling principle.
This thought experiment suggests the following definition, also known as the φ-LOCAL model
and the causal model [3, 36]:
• Non-signaling model: We can produce an arbitrary output distribution as long as it does
not violate the non-signaling principle: for any set of nodes U, modifying the structure of the
input graph at more than a distance T(n) from U does not affect the output distribution of U.
We also need to introduce the following definition to better connect our work with the study of
finitely-dependent processes and in particular finitely-dependent colorings [44, 45, 47]:
• Bounded-dependence model: We can produce an arbitrary output distribution as long as
it does not violate the non-signaling principle, and, furthermore, distant parts are independent:
if we fix any sets of nodes U1 and U2 such that their radius-T(n) neighborhoods are disjoint,
then the output labels of U1 are independent of the output labels of U2.
Now if we set T(n) = O(1), algorithms in the bounded-dependence model are in essence what is
usually called finitely-dependent processes.
Now we can connect all the above models with each others as follows, sandwiching the two
versions of quantum-LOCAL between other models (see Appendix A for details; the connection with
the non-signaling model is known [3, 36] but the connection with the bounded-dependence model is
to our knowledge new):
deterministic LOCAL
deterministic LOCAL (shared)
randomized LOCAL
randomized LOCAL (shared)
quantum-LOCAL
quantum-LOCAL (shared)
bounded-dependence
non-signaling
(1)
Here an arrow M1 →M2 indicates that an algorithm with locality (or round complexity) T(n) in
model M1 implies an algorithm with the same locality in M2. For some problems it is possible to
prove near-tight bounds for quantum-LOCAL by using diagram (1). For example, a very recent work
[27] used these connections to prove limits for the distributed quantum advantage in approximate
graph coloring: they prove an upper bound for the deterministic LOCAL model and a near-matching
lower bound for the non-signaling model.
4

--- Page 6 ---
1.6
Contribution 1: symmetry breaking with finitely-dependent processes
Now we are ready to state our first contribution. Recall the following gap result by Chang et al.
[21]: all LCL problems that can be solved with locality o(log n) in deterministic LOCAL or with
locality o(log log n) in randomized LOCAL can also be solved with locality O(log∗n) in deterministic
LOCAL. The class of problems with locality Θ(log∗n) contains in essence all symmetry-breaking
problems: these are problems that could be solved with constant locality if only we had some means
of breaking symmetry (e.g. distance-k coloring for some constant k would suffice). In Section 6 we
show the following result:
Theorem 1.2. Let Π be any LCL problem with locality O(log∗n) in the deterministic LOCAL
model. Then Π can be also solved with locality O(1) in the bounded-dependence model. Fur-
thermore, the resulting finitely-dependent processes are invariant under subgraph isomorphism.
Put otherwise, there is a finitely-dependent distribution over valid solutions of Π. Here the invariance
under subgraph isomorphisms implies that, for any two graphs G, H that share some isomorphic
subgraphs G′ and H′ such that their radius-O(1) neighborhoods are still isomorphic, the finitely-
dependent processes solving Π restricted to G′ and H′ are equal.
For any constant d, the task of coloring d-regular trees with d + 1 colors is a problem with
locality O(log∗n) in the deterministic LOCAL model. Hence, we can answer the open question
by Holroyd [44]:
Corollary 1.3. For each d ≥2, there is a finitely-dependent coloring with d + 1 colors in
d-regular trees. Furthermore, the resulting process is invariant over subgraph isomorphisms.
More specifically, there exists a finitely-dependent 4-coloring distribution of the infinite 3-regular
tree that is invariant under automorphisms.
Theorem 1.2 also introduces a formal barrier for proving limitations on distributed quantum
advantage. Recall that all current quantum-LOCAL lower bounds are, in essence, lower bounds in the
non-signaling model. Before our work, there was a hope that we could discover a symmetry-breaking
problem Π with the following properties: (1) its locality is O(log∗n) in deterministic LOCAL, and
(2) we can show that its locality is Ω(log∗n) in the non-signaling model, and therefore (3) Π cannot
admit any distributed quantum advantage. However, our work shows that no such problem Π
can exist. In particular, arguments related to non-signal distributions are not sufficient to exclude
distributed quantum advantage in this region.
1.7
Locality in online and dynamic settings
Let us now switch gears and consider a very different line of work. Ghaffari et al. [38] introduced a
sequential counterpart of the classical LOCAL model:
• Deterministic SLOCAL model: The nodes are processed in an adversarial order. When a
node v is processed, the algorithm gets to see all information in its radius-T(n) neighborhood
(including states and outputs of previously processed nodes). The algorithm has to label v
with its local output, and the algorithm can also record other information in v, which it can
exploit when other nodes near v are later processed.
• Randomized SLOCAL model: As above, with access to a source of random bits.
Clearly SLOCAL is stronger than LOCAL. One key feature is that the processing order naturally
breaks symmetry, and all symmetry-breaking LCLs can be solved with O(1) locality in SLOCAL.
5

--- Page 7 ---
One interpretation of our first contribution is that we also establish a new, unexpected similarity
between SLOCAL and the bounded-dependence model: both are able to solve any symmetry-breaking
LCL with constant locality.
A recent work [2] introduced the following models that capture the notion of locality also in the
context of centralized dynamic graph algorithms and centralized online graph algorithms:
• Deterministic dynamic-LOCAL model: The adversary constructs the graph one edge at a
time. The algorithm has a global view of the graph (including states and outputs of previously
processed nodes), but it has to maintain a feasible solution after each update. The algorithm
is restricted so that after a modification at node v, it can only update the solution within
distance T(n) from v.
• Deterministic online-LOCAL model: The adversary presents the input graph one node at
a time. When a node v is presented, the adversary also reveals the radius-T(n) neighborhood
of v. The algorithm has to then choose the output label of v. Crucially, the algorithm has
access to a global view of the graph (including states and outputs of previously processed
nodes). This model can be seen as a stronger version of the deterministic SLOCAL model
where all nodes have access to some global shared memory.
Both SLOCAL and dynamic-LOCAL can be sandwiched between LOCAL and online-LOCAL [2]:
deterministic LOCAL
deterministic SLOCAL
deterministic dynamic-LOCAL
deterministic online-LOCAL
(2)
There are also some problems in which deterministic online-LOCAL is much stronger than deterministic
LOCAL: 3-coloring in bipartite graphs has locality ˜Θ(√n) in deterministic LOCAL [17, 27] but O(log n)
in online-LOCAL [2]; very recently Chang et al. [22] also showed that this is tight for online-LOCAL.
1.8
Contribution 2: connecting all models for LCLs in rooted trees
At first sight, the models discussed in Sections 1.5 and 1.7 seem to have very little in common;
they seem to be orthogonal extensions of the classical deterministic LOCAL model. Furthermore,
we have already seen evidence that online-LOCAL can be much stronger than deterministic LOCAL.
Nevertheless, we can connect all these models in a unified manner, and prove strong limits on their
expressive power. To this end, we introduce yet another model:
• Randomized online-LOCAL model: Like deterministic online-LOCAL, but the algorithm
has access to a source of random bits, and we play against an oblivious adversary (the adversary
fixes the graph and the order of presenting nodes before the algorithm starts to flip coins).
Trivially, this is at least as strong as all models in diagram (2). However, the big surprise is that it
is also at least as strong as all models in diagram (1). In Section 5 we prove:
Theorem 1.4. Any LCL that can be solved in the non-signaling model with locality T(n) can
also be solved in the randomized online-LOCAL model with the same locality.
Then we zoom into the case of rooted trees in Section 7 and prove:
Theorem 1.5. Any LCL on rooted trees that can be solved in the randomized online-LOCAL
model with locality o(log log log n) can also be solved in the deterministic LOCAL model with
locality O(log∗n).
6

--- Page 8 ---
Together with Theorem 1.2 and previously-known results, we also obtain the following corollary:
Corollary 1.6. In rooted trees, the following families of LCLs are the same:
• locality O(log∗n) in deterministic or randomized LOCAL or quantum-LOCAL,
• locality O(1) in bounded-dependence model, non-signaling model, deterministic or ran-
domized SLOCAL, dynamic-LOCAL, or deterministic or randomized online-LOCAL.
In rooted trees, there is no LCL problem with locality between ω(log∗n) and o(log log log n)
in any of these models: deterministic and randomized LOCAL, quantum-LOCAL, bounded-
dependence model, non-signaling model, deterministic and randomized SLOCAL, dynamic-
LOCAL, and deterministic and randomized online-LOCAL.
In particular, when we look at LCLs in rooted trees, O(log∗n)-round quantum algorithms are not
any stronger than O(log∗n)-round classical algorithms. (However, it is still possible that there are
some LCLs in trees that can be solved in O(1) rounds in quantum-LOCAL and that require Θ(log∗n)
rounds in deterministic LOCAL; recall the discussion in Section 1.6.)
Theorem 1.5 can be seen as an extension of the result of Akbari et al. [2] that connects deterministic
online-LOCAL with LOCAL for LCLs on rooted regular trees without inputs. Our result is applicable
to the randomized online-LOCAL (and hence we can connect it with the non-signaling and quantum
models), and it holds for any LCLs on rooted trees (possibly with irregularities and inputs). Recall
that the presence of inputs makes a huge difference already in the case of directed paths [5, 23], and
we need fundamentally new ideas, as we can no longer build on the classification from [9, 11].
1.9
Big picture
By putting together all our contributions (including some auxiliary results that we discuss later
in Section 3), the landscape shown in Fig. 10 emerges. We can sandwich all models between
deterministic LOCAL and randomized online-LOCAL. Going downwards, we get symmetry breaking
for free (as indicated by the blue arrows). And in the case of rooted trees, for the low-locality region
o(log log log n), we can also navigate upwards (as indicated by the orange arrows). Table 1 gives
some concrete examples of localities for LCL problems across the landscape of models.
Model
Symmetry-breaking problems
3-coloring in bipartite graphs
Deterministic LOCAL
Θ(log∗n)
by definition
˜Θ(√n)
[27]
Randomized LOCAL
Θ(log∗n)
[19]
˜Θ(√n)
[27]
Quantum LOCAL
O(log∗n)
trivial
˜Θ(√n)
[27]
Bounded-dependence
O(1)
Theorem 6.16
˜Θ(√n)
[27]
Deterministic SLOCAL
O(1)
[38]
˜O(√n), nΩ(1)
[2, 27]
Randomized SLOCAL
O(1)
[38]
˜O(√n), nΩ(1)
[2, 27]
Deterministic dynamic-LOCAL
O(1)
Theorem 9.2
˜O(√n), Ω(log n)
[22, 27]
Deterministic online-LOCAL
O(1)
[2]
Θ(log n)
[2, 22]
Randomized online-LOCAL
O(1)
[2]
Θ(log n)
Theorem 8.1
Table 1: Examples of localities across the models. Here symmetry-breaking problems refer to LCL
problems with locality Θ(log∗n) in the deterministic LOCAL model; this includes many classical
problems such as maximal independent set, maximal matching, and (∆+ 1)-vertex coloring.
7

--- Page 9 ---
2
Overview of techniques and key ideas
In this section, we give an overview of the techniques and key ideas that we use to prove our main
results, and we also provide a roadmap to the rest of this paper. We note that our first contribution
is presented in Section 6, while the second contribution comes before it in Section 5—the proofs are
ordered this way since Section 5 also develops definitions that will be useful in Section 6.
2.1
Bounded-dependence model can break symmetry (Section 6)
Let us first present an overview of the proof of Theorem 1.2 from Section 1.6. We show that
the bounded-dependence model can break symmetry with constant locality; that is, there is a
finitely-dependent process for any symmetry-breaking LCL.
It is well known that any LCL problem Π that has complexity O(log∗n) in the LOCAL model has
the following property: there exists a constant k ∈N+ (that depends only on the hidden constant
in O(log∗n)) such that, if the graph is given a distance-k coloring (with sufficiently small number
of colors) as an input, then Π is solvable in time O(1) in the LOCAL model (using the distance-k
coloring as a local assignment of identifiers) [20].
We prove that for each bounded-degree graph, there is a finitely-dependent process providing a
distance-k coloring for constant k. Then, we can combine such a process with the LOCAL algorithm
that solves the problem with locality O(1) if a distance-k coloring is given, and we prove that
the resulting process is still a finitely-dependent distribution. Furthermore, we also prove that all
these processes are invariant under subgraph isomorphisms (even those that do not preserve node
identifiers), meaning that, for any two graphs G and H sharing two isomorphic subgraphs with
isomorphic radius-O(1) neighborhoods, the restrictions of the finitely-dependent processes solving Π
over G and H restricted to G′ and H′ are equal in law.
One of the key observations that we use is that LOCAL algorithms that do not exploit the specific
assignment of node identifiers and do not depend on the size of the graph provide finitely-dependent
distributions that are invariant under subgraph isomorphisms whenever the input labeling for the
graphs is invariant under subgraph isomorphisms.
Overview.
The cornerstone of our proof is a surprising result by Holroyd and Liggett [45] and
its follow-up in [47], that state that there exist k-dependent distributions giving a q-coloring of the
infinite path and of cycles for (k, q) ∈{(1, 4), (2, 3)} that are invariant under subgraph isomorphisms.
Recently, Holroyd has combined the finitely-dependent distributions of infinite paths to provide
a finitely-dependent 4-coloring of the d-dimensional lattice [44]. Getting a translation invariant
distribution is quite easy: First, use the distributions for the paths on each horizontal and vertical
path obtaining a distance-k coloring (with k being a large enough constant) of the lattice with
constantly many colors as shown in [45, Corollary 20]. Second, apply some LOCAL algorithm
that starts from a distance-k coloring and reduces the number of colors to 4 while keeping the
resulting distribution symmetric (e.g., the algorithms from [10, 17]). The major contribution of [44]
is transforming such a distribution into a process that is invariant under subgraph isomorphisms.
However, this symmetrization phase is quite specific to the considered topology.
We come up with a new approach that obtains similar results in all bounded-degree graphs
through the following steps:
1. We show that the finitely-dependent coloring of paths and cycles can be combined to obtain
finitely-dependent 3-coloring distributions of rooted pseudoforests of bounded-degree that are
invariant under subgraph isomorphisms.
8

--- Page 10 ---
2. We observe that all graphs of bounded-degree admit a random decomposition in rooted
pseudoforests that satisfies the required symmetry properties.
3. We prove that such a random decomposition can be combined with the finitely-dependent
3-coloring of rooted pseudoforests to obtain finitely-dependent distributions that give a (∆+1)-
coloring of graphs of maximum degree ∆that are invariant under subgraph isomorphism.
4. We show that we can use this finitely-dependent (∆+ 1)-coloring distributions to provide a
distance-k coloring for bounded-degree graphs, which is enough to simulate any O(log∗n)-
round LOCAL algorithms that solves an LCL Π. Such combinations result in finitely-dependent
processes that are invariant under subgraph-isomorphisms and solve Π.
Notice that, in spirit, steps 1 to 3 are similar to the steps needed to produce a (∆+ 1)-coloring
in time O(log∗n) in the LOCAL model [42, 60]: however, the detailed way these steps are obtained
in the bounded-dependence model is quite different and requires a careful analysis.
Step 1: Finitely-dependent 3-coloring distributions of rooted pseudoforests.
A rooted
pseudoforest is a directed graph in which each node has outdegree at most 1. Let us now fix any
rooted pseudoforest of maximum degree ∆. Consider the following process: each node v colors its
in-neighbors with a uniformly randomly permutation of {1, . . . , indeg(v)}. The graph Gi induced by
nodes colored with color i is a union of directed paths and cycles (see Fig. 1) and, hence, admits a
finitely-dependent 4-coloring given by [45] that is invariant under subgraph isomorphisms; if a node is
isolated, it can deterministically join any of the Gis, say G1. The sequence of graphs (G1, . . . , G∆in)
is said to be a random ∆in-decomposition of the rooted pseudoforest. Furthermore, if two graphs
G, H have isomorphic subgraphs G′, H′ (together with some constant-radius neighborhoods), the
decompositions in directed paths and cycles induced in G′ and H′ have the same distribution
(because node colors are locally chosen uniformly). We prove that the combination of the random
decomposition and the finitely-dependent coloring yields a finitely-dependent 4∆-coloring which
is invariant under subgraph isomorphisms: by further combining such distribution with the Cole–
Vishkin color reduction algorithm [29, 42, 60] (that has complexity O(log∗k) with k being the
size of the input coloring), we can obtain a finitely-dependent 3-coloring distribution for rooted
pseudoforests of maximum degree ∆that is invariant under subgraph isomorphisms.
Steps 2–3: Finitely-dependent (∆+ 1)-coloring distribution of bounded-degree graphs.
First, if the input graph is undirected, make it a directed graph by duplicating all edges and
assigning both orientations to duplicated edges. Since a coloring of the nodes can be given in
both cases equivalently, we focus on the directed case for simplicity. Second, consider the following
process: each node v labels its out-edges with a uniformly sampled permutation of the elements
of {1, . . . , outdeg(v)}; this way we obtain a random decomposition of the edges of the graph into
rooted pseudoforests, as each node has at most one out-edge with label i. Furthermore, if two
graphs G, H have isomorphic subgraphs G′, H′ (together with some constant-radius neighborhoods),
the decompositions induced in G′ and H′ have the same distribution (because edge labelings are
locally chosen uniformly). We prove that if we apply the finitely-dependent 3-coloring from step 1 to
each pseudoforest, we obtain a finitely-dependent 3∆-coloring of the input graph which is invariant
under subgraph isomorphisms. By further combining such a distribution with a variant of the
Cole–Vishkin color reduction algorithm, we obtain a finitely-dependent (∆+ 1)-coloring distribution
for bounded-degree graphs of maximum degree ∆that is invariant under subgraph isomorphisms.
Step 4: Finitely-dependent distribution solving Π.
Consider any graph G of maximum
degree ∆, and its k-th power graph defined as follows: simply add edges to G between each pair of
9

--- Page 11 ---
nodes at distance at most k, where k is some large enough constant. Observe that Gk is a graph of
maximum degree ∆k. Now, step 3 implies that there is a finitely-dependent (∆k + 1)-coloring of Gk
that is invariant under subgraph isomorphisms: such distribution yields a distance-k coloring of G.
For any LCL Π that has complexity O(log∗n) in LOCAL, we know that there exists a constant k
such that, if given a distance-k coloring in input (with a constant number of colors), then there is
an O(1)-round port-numbering algorithm solving Π [20]: the combination of the input distance-k
coloring of G given by step 2-3 with such an algorithm yields a finitely-dependent distribution solving
Π that is invariant under subgraph isomorphisms.
Random decomposition of a graph.
In steps 1 and 3 we proceed in an analogous way: First,
we construct a process that induces a random decomposition of a graph. Second, we consider
finitely-dependent distributions of output labelings over the outputs of the random decomposition.
The combination of the random decomposition and the finitely-dependent distributions gives rise to
a process over the whole graph. In Section 6, we derive a general result (Lemma 6.8) which gives
sufficient conditions on the random decomposition and the finitely-dependent distributions in order
to ensure the final process is still finitely-dependent (possibly with symmetry properties). Lemma 6.8
is then the tool used in practice in steps 1 and 3.
Independent related work.
Very recently, an independent and parallel work provided a finitely-
dependent coloring of bounded-degree graphs with exponentially many colors (in the degree of the
graph) [65]. The technique employed in [65] is very similar to ours: it exploits the decomposition of
graphs in rooted pseudoforests, and then colors rooted pseudoforests using the finitely-dependent
coloring of paths and cycles [45, 47]. However, [65] stops at the mere coloring problem and does
not make use of color reduction algorithms, which are the key ingredient for extending results to all
symmetry-breaking LCLs.
2.2
Simulating non-signaling in randomized online-LOCAL (Section 5)
Let us now give the intuition behind the proof of Theorem 1.4 from Section 1.8: we show that the
non-signaling model can be simulated in randomized online-LOCAL without any loss in the locality.
A randomized online-LOCAL algorithm is given in input the size of the input graph, and a
distribution that is non-signaling beyond distance T and that solves some problem Π over some
graph family F. When the adversary picks any node v1 and shows to the randomized online-LOCAL
algorithm its radius-T neighborhood, the randomized online-LOCAL algorithm simply goes over all
graphs of n nodes in F until it finds one, say H1, that includes the radius-T neighborhood of v1:
then, it samples an output according to the restriction of the non-signaling distribution in H1 to
v1. Notice that such distribution does not change if the topology of the graph changes outside the
radius-T neighborhood of v1. Recursively, when the adversary picks the i-th node vi, the randomized
online-LOCAL algorithm goes over all graphs of n nodes in F until it finds one, say Hi, that includes
the union of radius-T neighborhoods of v1, . . . , vi (it must necessarily exist as the graph chosen
by the adversary is a valid input): hence, it samples an output according to the restriction of the
non-signaling distributions in Hi to vi conditional on the outputs of v1, . . . , vi−1. We prove that
the non-signaling property ensures that the algorithm described above fails with at most the same
probability of failure of the non-signaling distribution.
10

--- Page 12 ---
2.3
Online-LOCAL can be simulated in SLOCAL for rooted trees (Section 7)
Next we give an overview of the proof of Theorem 1.5 from Section 1.8: we show that a randomized
online-LOCAL algorithm that solves an LCL problem in rooted trees with locality o(log log log n)
can be simulated in the deterministic SLOCAL model with locality O(1), and therefore also in the
deterministic LOCAL model with locality O(log∗n).
Online-LOCAL algorithms can be seen simply as SLOCAL algorithms with global memory. Notice
that SLOCAL algorithms instead only have a form of “incremental” memory, i.e., they keep track of
an incremental sequence of intersecting neighborhoods N1, N2. . . ., where Ni intersects Ni+1.
The new ingredient we use in this section are component-wise online-LOCAL algorithms. Roughly
speaking, a component-wise algorithm is a deterministic online-LOCAL algorithm that, when pro-
cessing a node v, uses information only coming from the connected component of the input graph
that has been revealed so far to which v belongs, and nothing else. (If two or more components are
merged, then the algorithm may use information it knows from any component.)
We prove Theorem 1.5 in three steps:
1. We first show that any randomized online-LOCAL algorithm solving an LCL with locality
T(n) can be turned into a deterministic component-wise online-LOCAL algorithm with locality
T(2O(2n2)).
2. We then prove that, for LCLs on rooted trees, we can simulate the component-wise algorithms
in SLOCAL.
3. Finally, we show that SLOCAL algorithms solving any LCL Π with locality o(log n) over rooted
trees can be turned into an O(log∗n)-round LOCAL algorithm solving Π over rooted trees.
Step 1: Constructing component-wise algorithms from deterministic online-LOCAL
algorithms.
To give some intuition, consider an LCL problem Π on a family F of graphs that is
closed under disjoint graph union and node and edge removals. Suppose there is a deterministic
online-LOCAL algorithm A solving Π with locality T(n) on n-node graphs. Note that the output
label A chooses for a node may depend arbitrarily on everything the algorithm has seen so far.
We show how to turn algorithm A into an algorithm whose output for isolated nodes depends
only on the local topology and inputs and is oblivious to any previously-processed nodes. We call
such algorithms 1-amnesiac. Here with isolated we mean the node v is such that all nodes belong to
the radius T-neighborhood around v are new to algorithm A, that is, A has no knowledge of how v
is connected (if at all) to the parts of the graph it has seen thus far.
Let N1 = |Σout| |Σin| n · 2n2 · n2, and let G1 be the set of all possible subgraphs of any n-node
graphs (from F) with inputs (up to isomorphisms) that are the radius-T(N1) neighborhood of some
node, which we call the center of the neighborhood. Let g1 = |G1| and notice that g1 ≤2n2|Σin| n.
Consider now the following experiment:
1. Construct a simulation graph H1 that consists of |Σout| · n copies of all graphs in G1. The size
of H1 is at most N1 = n2|Σout| · g1 ≤|Σout| |Σin| n · 2n2 · n2.
2. Reveal the center node of each of those neighborhood graphs to A in an arbitrary order with
locality T(N1). For each type of radius-T(N1) neighborhood T1 (i.e., any element of G1), there
exists some output label σT1 that occurs at least n times. We call such neighborhoods good
and such a label a canonical labeling of T1.
3. Continue labelling nodes of H1 using A under an arbitrary ordering of the nodes.
We describe a new online-LOCAL algorithm B that, using this experiment, produces a correct
labeling. Let G be an input graph n nodes, and let node v be revealed to B along with its radius-
T ′(n) neighborhood, where T ′(n) = T(N1). Whenever v is an isolated node, algorithm B finds
11

--- Page 13 ---
a “fresh” (i.e., not previously chosen) good neighborhood in the experiment graph matching the
radius-T(N1) neighborhood of v in G. It then takes that unused good neighborhood, identifies all
nodes with the revealed input neighborhood, and labels v accordingly. An unused good neighborhood
always exists since there are at least n good neighborhoods in the experiment graph matching the
radius-T(N1) neighborhood of v in G. Algorithm B effectively cuts and pastes the neighborhood
from the experiment graph to the actual input graph without algorithm A noticing. For non-isolated
nodes, B just simulates what A would do, following the adversarial order of the nodes presented to B.
This is always possible because the labels of isolated nodes come from valid online-LOCAL runs of A.
The correctness of algorithm B follows from that of A. Moreover, when labeling an isolated node,
B always labels it in the same way that depends only on the local structure and inputs of the graph;
hence B is 1-amnesiac. Clearly, there is an exponential overhead in the locality: the locality of B is
T ′(n) = T(N1) = T(2O(n2)).
Using the above, we now describe how to obtain a 2-amnesiac algorithm, that is, an algorithm
that always produces the same labels for the same types of connected components formed by the
union of intersecting neighborhoods of two distinct nodes. We modify the previous experiment as
follows:
1. First we must increase the size of the experiment graph. Let N2 = |Σout| 2|Σin| n · 2n · n2 and
redefine G1 with the radius-T(N2) neighborhoods.
2. Instead of considering |Σout| · n many disjoint copies of elements of G1, we now take |Σout| 2 · n
copies. By the same argument as before, there are at least n · |Σout| good neighborhoods.
3. Let G2 be the set of all possible unions of two non-disjoint radius-T(N2) neighborhoods of two
different nodes of any n-node graph (in F), with all possible input labelings and orderings of
the center nodes. Notice that the size of G2 is g2 ≤2n2|Σin| n. We take |Σout| · n many disjoint
copies of all graphs in G2, with the catch that the neighborhood of the center node that comes
first in the processing order is chosen arbitrarily among the good neighborhoods. The resulting
graph H2 is our new experiment graph, whose size is now N2 ≤|Σout| |Σin| n · 2n2 · n3.
4. Use A to label all nodes that come first in the input order in each graph, then all nodes that
come second in the same respective order.
5. Use A to label the second center node of each connected component. By the pigeonhole
principle, for all types of such connected components T2 there are at least n identical labelings.
These make out the canonical labelings σT2.
The 2-amnesiac algorithm B starts by running the above experiment. When given in input an
n-node graphs, it outputs the canonical labeling σT1 for isolated nodes whose radius-T ′(n) = T(N2)
neighborhood matches type T1. Similarly, B outputs the canonical labeling σT2 for nodes seeing a
connected component of type T2 when we look at their radius-T ′(n) = T(N2) neighborhood. The
correctness argument is the same as that for 1-amnesiac algorithms. For the remaining nodes, B just
simulates A using global memory as usual.
We can continue this process all the way up to n-amnesiac algorithms, which are simply
component-wise online-LOCAL algorithms. See Lemma 7.5 for the formal details. As a remark,
notice the restriction to LCLs is necessary to prove correctness: if the amnesiac algorithm fails,
it must fail locally; hence also the original online-LOCAL algorithm fails locally, contradicting its
correctness.
Dealing with randomness.
Let us now turn to the setting where A is randomized. For deter-
ministic online-LOCAL algorithms, we adaptively picked the good neighborhoods before processing
further; however, since in randomized online-LOCAL the adversary is oblivious, we must adapt our
strategy.
12

--- Page 14 ---
Our experiment graph Hn is now random. It is constructed exactly as before, though now
the good connected components have to be “guessed” uniformly at random each time. Clearly,
the probability that our guesses are good is incredibly small. Hence we would like to amplify the
success probability so that the probability that the guesses are good enough and the randomized
online-LOCAL algorithm works correctly is bounded away from zero. (Once we have this, we may
apply a standard derandomization argument.) The amplification is by replicating k times the
experiment graph Hn, guessing the good components for each copy of Hn independently. Since the
randomness of the algorithm and the randomness of these guesses are independent for each copy of
Hn, a simple union bound together with the inclusion-exclusion principle give a positive probability
that, in at least one copy of Hn, the guesses are correct and the algorithm works properly.
We now apply a standard derandomization argument: Since there exists an assignment of a
random bit string to the randomized online-LOCAL algorithm as well as for “guessing” the good
components in the k copies of the experiment graph, there is a fixed, deterministic realization of Hn
that yields a (correct) deterministic online-LOCAL algorithm. Hence our n-amnesiac algorithm B
goes over all possible definitions of Hn and of deterministic online-LOCAL algorithms (according
to an arbitrary order) until it finds this good combination. It must eventually succeed because,
when the size of the input graph is fixed, there are only finitely many combinations. The proof then
reduces to the previous case. See Lemma 7.6 for the formal details.
Step 2: From component-wise algorithms to SLOCAL algorithms on rooted trees.
We
heavily exploit the fact that, in rooted trees, there is a consistent orientation of the edges towards
the root. We adapt results from [23, Section 7] to the SLOCAL model to show how to “cluster” a
rooted tree in connected components (which are also rooted trees) in time O(α) and so that the
following properties are met:
1. All connected components have depth Θ(α).
2. All leaves of a connected component that are not at distance Θ(α) from the root of the
component are real leaves of the original rooted tree.
3. All other leaves are either real leaves or roots of other connected components.
The formal details can be found in Lemma 7.8.
Suppose now we are given an n-amnesiac (equivalently, component-wise) algorithm A solving
an LCL Π on rooted trees with locality T(n). We briefly describe how to construct an SLOCAL
algorithm B that solves Π with locality O(T(n)) on rooted trees. Recall that in SLOCAL we may
compose two algorithms with localities T1 and T2 and obtain an SLOCAL algorithm with locality
O(T1 + T2) [38]. Algorithm B is the composition of the following four algorithms with locality O(T):
1. B1 constructs a clustering with properties 1-3 above with α = O(T), where the hidden constant
is large enough.
2. B2 ensures each root of a connected component of the cluster precommits a solution in the
neighborhood of the leaves of the component using A. This can be done independently between
different components if the localities are appropriately chosen. The root of the original tree
also outputs a solution for itself.
3. B3 outputs the precommitments on the nodes designated by B2.
4. The fact that we used A independently on disjoint components of the graph (and A being
correct) ensures that a solution to the LCL exists and the “inner part” of all connected
components can be completed with a correct solution. Hence B4 simply brute-forces a solution
inside the clusters.
13

--- Page 15 ---
Since Π is an LCL, different components will have compatible solutions as B2 precommitted a
solution around leaf nodes, which are roots of other connected components.
Step 3: From SLOCAL algorithms to LOCAL algorithms on rooted trees.
Any o(log n)-
time SLOCAL algorithm A solving an LCL over rooted trees can be turned into an O(1)-time
SLOCAL algorithm B achieving the same. This is obtained by exploiting the same tree decomposition
described above and providing fake, repeating identifiers to each cluster so that two equal identifiers
are “far enough”. Then, we use A as a black-box and lie to A by providing the size of a cluster
as the input graph size. Once we have an O(1)-time SLOCAL algorithm B, how to turn it into an
O(log∗n)-time LOCAL algorithm is folklore.
3
Additional results
We will now discuss some additional results that help to establish the missing parts of the big picture
in Fig. 10, and provide further intuition and examples on these models and their key properties.
3.1
Lower bound on 3-coloring in randomized online-LOCAL (Section 8)
So far we have connected randomized online-LOCAL with other models through simulation arguments
that only work in rooted trees. Let us now put limitations on randomized online-LOCAL in a broader
setting. Recall that in deterministic online-LOCAL we can 3-color bipartite graphs with locality
O(log n) [2], and this is tight [22]. In Section 8 we show that randomness does not help:
Theorem 3.1. 3-coloring in bipartite graphs is not possible with locality o(log n) in the
randomized online-LOCAL model.
This demonstrates that even though randomized online-LOCAL is a very strong model, strong enough
to simulate e.g. any non-signaling distribution, it is nevertheless possible to prove strong lower
bounds in this model (which then imply lower bounds across the entire landscape of models).
Here it is important to assume that the adversary is oblivious, i.e., it cannot see the random
decisions of the randomized algorithm. This lower bound complements a recent result of Chang et al.
[22] showing the same bound for the deterministic online-LOCAL model.
In this proof, we use the notion of a b-value defined in [22] as a measure of the number of
incompatible boundaries present in a region of a grid. We start with the assumption that a grid can
be 3-colored with locality o(log n) and derive a contradiction. The high level idea is to construct
two path segments below each other, where one path segment has a large count of incompatible
boundaries (a high b-value) and the other segment has a low boundary count (incompatible b-value
to the upper path). This forces an algorithm to make boundaries escape on the side between the
two segments. We show that the boundary count is, however, too large compared to the distance
between the two segments and thus the boundaries “cannot escape”.
Two difficulties arise in the randomized case compared to the deterministic lower bound: (i) In
order to create a path with a large b-value we have to use a probabilistic construction that produces
a segment with a large b-value with high probability; (ii) Since the first construction is probabilistic
and the adversary oblivious, we cannot “see” the large b-value segment constructed in (i), that
is, we can neither predict its position nor its size. We therefore need to use another probabilistic
construction that positions the segment in a position that forces a contradiction (and which succeeds
with constant probability).
14

--- Page 16 ---
3.2
Deterministic dynamic-LOCAL can derandomize LOCAL (Section 9)
It is known that deterministic SLOCAL is strong enough to simulate randomized LOCAL. In Section 9
we show that the same holds also for dynamic-LOCAL, using the method of conditional expectation
in a manner similar to how the result is proved for SLOCAL:
Theorem 3.2. Deterministic dynamic-LOCAL can simulate randomized LOCAL.
We also show that dynamic-LOCAL can break symmetry for free, similar to SLOCAL and the
bounded-dependence model: if we can solve an LCL problem with O(log∗n) locality in LOCAL, we
can solve it with O(1) locality in dynamic-LOCAL.
3.3
Randomized online-LOCAL with adaptive adversary (Section 10)
The new model that we introduced, randomized online-LOCAL, is defined using an oblivious adversary.
In Section 10 we show that this is also necessary: if we defined randomized online-LOCAL with an
adaptive adversary, it would be as weak as the deterministic online-LOCAL model.
We show that an adaptive adversary in randomized online-LOCAL is so strong that a succeeding
randomized online-LOCAL algorithm of locality T would admit a single random-bit string that
outputs a good solution for all possible graphs of a given size: hence, a correct deterministic online-
LOCAL algorithm exists. Since deterministic online-LOCAL algorithms of locality T for graphs of n
nodes are only finitely many, the deterministic online-LOCAL algorithm in its initialization phase
can go over all of them until it finds the one working for all graphs of n nodes: it then uses that one.
3.4
Randomized online-LOCAL in paths and cycles (Section 11)
Our final technical part shows that LCL problems in paths and cycles have complexity either O(1)
or Θ(n) in the randomized online-LOCAL model; moreover the locality is O(1) in randomized online-
LOCAL if and only if it is O(log∗n) in the deterministic LOCAL model. Together with prior work,
this also shows that locality of an LCL problem in paths and cycles is decidable across all models [5]
(with the caveat that we cannot distinguish between O(1) and Θ(log∗n) for quantum-LOCAL). The
proof is a reworking of its deterministic variant from [2]. The main take-home message of this result
is the following: cycles are not a fundamental obstacle for simulating randomized online-LOCAL in
weaker models. Hence, there is hope for generalizing the simulation result of Section 7 from trees to
a broader class of graphs.
3.5
Quantum, bounded-dependence, and non-signaling (Appendix A)
Appendix A aims at serving a dual purpose. First, it aims at formally introducing the non-signaling
model based on the non-signaling principle, and at explaining why it is more powerful than the
quantum-LOCAL model. This is not a new result, but included for completeness and to clarify the
early works of Gavoille et al. [36] and Arfaoui and Fraigniaud [3]. Second, it formally introduces the
bounded-dependence model based on finitely-dependent processes and argues why the relations in
diagram (1) hold, and in particular why quantum-LOCAL without shared quantum state is contained
not only in the non-signaling model but also in the bounded-dependence model. While all the
ingredients are well-known, to our knowledge this relation between the quantum-LOCAL model and
the bounded-dependence model is not made explicit in the literature before.
15

--- Page 17 ---
3.6
Open questions
Our work suggests a number of open questions; here are the most prominent ones:
Question 1. Is quantum-LOCAL stronger than randomized LOCAL for any LCL problem? In
particular, is there any LCL problem with constant locality in quantum-LOCAL but super-constant
locality in LOCAL? We conjecture that such a problem does not exist. Our work proves that to
show this conjecture, new proof techniques are needed.
Question 2. Does shared global information or shared quantum state ever help with any LCL
problem (beyond the fact that shared quantum state can be used to generate shared randomness,
which is known to help [13])?
Question 3. Is it possible to simulate deterministic or randomized online-LOCAL in SLOCAL and
LOCAL also in a broader graph class than rooted trees? If we could extend the result to unrooted
trees, it would also imply new lower bounds for the widely-studied sinkless orientation problem
[12, 16] across all models.
3.7
Follow-up work
Since the first versions of this work originally appeared in arXiv earlier this year, this work has
already influenced at least two follow-up papers:
1. Dhar et al. [32] study the relation between online-LOCAL and deterministic LOCAL in much
greater depth, especially outside the o(log log log n) region. It turns out that e.g. in regular
rooted trees the complexity classes of LCL problems in randomized online-LOCAL and deter-
ministic LOCAL exactly coincide, and as a corollary all models in Fig. 10 are exactly as strong
for this graph family in the Ω(log∗n) region.
2. Balliu et al. [13] show that there are LCL problems in which shared randomness strictly helps.
This implies a number of new separations between the models in Fig. 10; for example, quantum-
LOCAL with shared quantum state is strictly stronger than quantum-LOCAL without shared
quantum state, the non-signaling model is strictly stronger than the bounded-dependence
model, and randomized online-LOCAL is strictly stronger than randomized SLOCAL.
Put together, these papers demonstrate that especially in restricted graph classes such as trees,
one can indeed often cover the entire hierarchy of models with a single theorem about randomized
online-LOCAL, while in general we are dealing with a large number of genuinely distinct models.
4
Preliminaries
We use the notation N = {0, 1, 2, . . . } and N+ = N \ {0}. For any positive integer n ∈N+, we denote
the set {1, . . . , n} by [n].
Graphs.
In this work, a graph G = (V, E) can be either directed (E ⊆V 2) or undirected (E ⊆
 V
2

).
If the set of nodes and the set of edges are not specified, we refer to them by V (G) and E(G),
respectively. For any edge e = (u, v) ∈E(G) we say that e is directed from u to v and is incident to
u and to v (the latter holds also for undirected edges). All graphs in this paper are simple graphs
without self-loops unless differently specified. The degree of a node v is the number of edges that
are incident to v and is denoted by degG(v), or simply by deg(v) when G is clear from the context.
The indegree of a node v is the number of directed edges that are directed towards v and is denoted
16

--- Page 18 ---
by indegG(v), while the outdegree of v is the number of directed edges that are incident to v but
directed to some other vertex and is denoted by outdegG(v). Again, we omit the suffix G if the
graph is clear from the context.
If G is a subgraph of H, we write G ⊆H. For any subset of nodes A ⊆V , we denote by
G[A] the subgraph induced by the nodes in A. For any nodes u, v ∈V , distG(u, v) denotes the
distance between u and v in G (i.e., the number of edges of any shortest path between u and v
in G—it doesn’t need to be a directed path); if u and v are disconnected, then distG(u, v) = +∞.
If G is clear from the context, we may also simply write dist(u, v) = distG(u, v). Also, for subset
of nodes A, B ⊆V and any node v ∈V , we can define distG(v, A) = minu∈A distG(u, v) and, by
extension, distG(A, B) = minu∈A distG(u, B). We assume that distG(A, ∅) = +∞. Similarly, for
subgraphs G1, G2 ⊆G, we define distG(G1, G2) = distG(V (G1), V (G2)): here, we also assume
distG(G1, ∅) = +∞where ∅is now the empty graph. For T ∈[n], the T-neighborhood of a node
u ∈V of a graph G is the set NT (u, G) = {v ∈V | distG(u, v) ≤T}. The T-neighborhood of a subset
A ⊆V is the set NT (A, G) = {v ∈V | ∃u ∈A : distG(u, v) ≤T}. Similarly, the T-neighborhood of
a subgraph H ⊆G is the set NT (H, G) = {v ∈V | ∃u ∈V (H) : distG(u, v) ≤T}. If G is clear from
the context, we just write NT (u), NT (A), and NT (H). If u /∈V , A∩V = ∅, or V (H)∩V (G) = ∅, then
the neighborhood NT (u) = ∅, NT (A) = ∅, or NT (H) = ∅, respectively. We make use of some graph
operations: For any two graphs G, H, we denote by G∩H the intersection graph defined by G∩H =
(V (G)∩V (H), E(G)∩E(H)). The graph union is defined by G∪H = (V (G)∪V (H), E(G)∪E(H)).
Moreover, the graph difference is the graph G \ H = (V (G) \ V (H), E(G) \ E(H)).
Finally, for any two graphs G and H, we write G ∼f H to denote that G and H are isomorphic
and f : V (G) →V (H) is an isomorphism.
Labeling problems.
We start with the notion of labeling problem.
Definition 4.1 (Labeling problem). Let Σin and Σout two sets of input and output labels, respectively.
A labeling problem Π is a mapping (G, λin) 7→{λ(out,i)}i∈I, with I being a discrete set of indexes,
that assigns to every graph G with any input labeling λin : V (G) →Σin a set of permissible
output vectors λ(out,i) : V (G) →Σout that might depend on (G, λin). The mapping must be closed
under graph isomorphism, i.e., if φ : V (G) →V (G′) is an isomorphism between G and G′, and
λ(out,i) ∈Π((G′, λin)), then λ(out,i) ◦φ ∈Π((G, λin ◦φ)).
A labeling problem can be thought as defined for any input graph of any number of nodes. If
the set of permissible output vectors is empty for some input (G, λin), we say that the problem
is not solvable on the input (G, λin): accordingly, the problem is solvable on the input (G, λin) if
Π(G, λin) ̸= ∅.
One observation on the generality of definition of labeling problem follows: one can actually
consider problems that require to output labels on edges.
We actually focus on labeling problems where, for any input graph, an output vector λout is
permissible if and only if the restrictions of the problem on any local neighborhoods can be solved
and there exist compatible local permissible output vectors whose combination provides λout. This
concept is grasped by the notion of locally checkable labeling (LCL) problems, first introduced by
Naor and Stockmeyer [57]. For any function f : A →B and any subset A′ ⊆A, let us denote the
restriction of f to A′ by f ↾A′. Furthermore, we define a centered graph to be a pair (H, vH) where
H is a graph and vH ∈V (H) is a vertex of H that we name the center of H. The radius of a
centered graph is the maximum distance from vH to any other node in H.
Definition 4.2 (Locally checkable labeling problem). Let r, ∆∈N. Let Σin and Σout two finite
sets of input and output labels, respectively, and Π a labeling problem. Π is locally checkable with
17

--- Page 19 ---
checking radius r if there exists a family S = {((H, vH), ¯λin, ¯λout)i}i∈I of tuples, where (H, vH) is a
centered graph of radius at most r and maximum degree at most ∆, ¯λin : V (H) →Σin is an input
labeling for H, ¯λout : V (H) →Σout is an output labeling for H (which can depend on ¯λin) with the
following property
• for any input (G, λin) to Π with deg(G) ≤∆, an output vector λout : V (G) →Σout is
permissible (i.e., λout ∈Π((G, λin))) if and only if, for each node v ∈V (G), the tuple
((G[Nr(v)]), λin ↾Nr(v), λout ↾Nr(v)) belongs to S (up to graph isomorphisms).
Notice that the family S can be always thought to be finite up to graph isomorphisms, as r and
∆are fixed and the set of input/output labels are finite. We now define the computational models
we work in.
The port-numbering model.
A port-numbered network is a triple N = (V, P, p) where V is the
set of nodes, P is the set of ports, and p : P →P is a function specifying connections between ports.
Each element x ∈P is a pair (v, i) where v ∈V , i ∈N+. The connection function p between ports
is an involution, that is, p(p(x)) = x for all x ∈P. If (v, i) ∈P, we say that (v, i) is port number i
in node v. The degree of a node v in the network N is degN(v) is the number of ports in v, that
is, degN(v) = |{i ∈N : (v, i) ∈P}|. Unless otherwise mentioned, we assume that port numbers are
consecutive, i.e., the ports of any node v ∈V are (v, 1), . . . , (v, degN(v)). Clearly, a port-numbered
network identifies an underlying graph G = (V, E) where, for any two nodes u, v ∈V , {u, v} ∈E if
and only if there exists ports xu, xv ∈P such that p(xu) = xv. Clearly, the degree of a node degN(v)
corresponds to degG(v).
In the port-numbering model we are given distributed system consisting of a port-numbered
network of |V | = n processors (or nodes) that operates in a sequence of synchronous rounds. In each
round the processors may perform unbounded computations on their respective local state variables
and subsequently exchange of messages of arbitrary size along the links given by the underlying
input graph. Nodes identify their neighbors by using ports as defined before, where port assignment
may be done adversarially. Barring their degree, all nodes are identical and operate according to the
same local computation procedures. Initially all local state variables have the same value for all
processors; the sole exception is a distinguished local variable x(v) of each processor v that encodes
input data.
Let Σin be a set of input labels. The input of a problem is defined in the form of a labeled graph
(G, x) where G = (V, E) is the system graph, V is the set of processors (hence it is specified as part
of the input), and x: V →Σin is an assignment of an input label λin(v) ∈Σin to each processor v.
The output of the algorithm is given in the form of a vector of local output labels λout : V →Σout,
and the algorithm is assumed to terminate once all labels λout(v) are definitely fixed. We assume
that nodes and their links are fault-free. The local computation procedures may be randomized by
giving each processor access to its own set of random variables; in this case, we are in the randomized
port-numbering model as opposed to the deterministic port-numbering model.
The running time of an algorithm is the number of synchronous rounds required by all nodes to
produce output labels. If an algorithm running time is T, we also say that the algorithm has locality
T. Notice that T can be a function of the size of the input graph. We say that a problem Π over
some graph family F has complexity T in the port-numbering model if there is a port-numbering
algorithm running in time T that solves Π over F, and T = T(n) is the minimum running time
(among all possible algorithms that solve Π over F) in the worst case instance of size n. If the
algorithm is randomized, we also require that the failure probability is at most 1/n, where n is the
size of the input graph.
18

--- Page 20 ---
We remark that the notion of an (LCL) problem is a graph problem, and does not depend on
the specific model of computation we consider (hence, the problem cannot depend on, e.g., port
numbers).
The LOCAL model.
The LOCAL model was first introduced by Linial [53]: it is just the port-
numbering model augmented with an assignment of unique identifiers to nodes. Let c ≥1 be a
constant, and let Σin be a set of input labels. The input of a problem is defined in the form of a
labeled graph (G, x) where G = (V, E) is the system graph, V is the set of processors (hence it
is specified as part of the input), and x: V →[nc] × Σin is an assignment of a unique identifier
id(v) ∈[nc] and of an input label λin(v) ∈Σin to each processor v. The output of the algorithm is
given in the form of a vector of local output labels λout : V →Σout, and the algorithm is assumed
to terminate once all labels λout(v) are definitely fixed. We assume that nodes and their links are
fault-free. The local computation procedures may be randomized by giving each processor access to
its own set of random variables; in this case, we are in the randomized LOCAL (randomized LOCAL)
model as opposed to deterministic LOCAL (deterministic LOCAL). Notice that the knowledge of n
makes the randomized port-numbering model roughly equivalent to the randomized LOCAL model,
as unique identifiers can be produced with high probability. We say that a problem Π over some
graph family F has complexity T in the LOCAL model if there is a LOCAL algorithm running in time
T that solves Π over F, and T = T(n) is the minimum running time (among all possible algorithms
that solve Π over F) in the worst case instance of size n. If the algorithm is randomized, we also
require that the failure probability is at most 1/n, where n is the size of the input graph.
The sequential LOCAL model.
The sequential LOCAL model was first introduced by [38]: it is
a sequential version of the LOCAL model. Nodes are processed according to an adversarial order
σ = v1, . . . , vn. When processing a node vi, a T-round algorithm collects all inputs in the radius-T
neighborhood of vi (including the states and the outputs of previously processed nodes in NT (Vi), i.e.,
vj ∈NT (Vi) for j < i): we say that such an algorithm has complexity T. Note that the algorithm
might store all inputs in NT (vi) in the state of vi: hence, when processing vi, it can see the input of vj,
j < i, if and only if there is a subsequence of nodes {vhk}k∈[m] with j = hk < hk+1 < · · · < hkm = i
such that vhk ∈NT (vhk+1) for all k ∈[m].
If the algorithm is given an infinite random bit string, we talk about the randomized SLOCAL
model, as opposed to the deterministic SLOCAL model. We assume that the adversarial order
according to which nodes are processed is oblivious to the random bit string, as in the original
definition of the model. We say that a problem Π over some graph family F has complexity T in
the SLOCAL model if there is an SLOCAL algorithm running in time T that solves Π over F, and
T = T(n) is the minimum running time (among all possible algorithms that solve Π over F) in
the worst case instance of size n. If the algorithm is randomized, we also require that the failure
probability is at most 1/n, where n is the size of the input graph.
The dynamic-LOCAL model.
The deterministic dynamic-LOCAL was introduced in [2]. It is
a centralized model of computing where the adversary constructs the graph one edge at a time.
An adversary construct the input graph by adding one edge at a time (with an ordering of the
nodes). The algorithm has a global view of the current state of the graph and has to commit for
the newly added nodes (according to the ordering), but it has to maintain a feasible solution after
each update. The algorithm is restricted so that after a modification at node v, it can only update
the solution within distance T(n) from v. We say that a problem Π over some graph family F has
complexity T(n) in the dynamic-LOCAL model if T(n) is the minimum function such that there
19

--- Page 21 ---
is a dynamic-LOCAL algorithm running in time T(n) that solves Π over F, and T = T(n) is the
minimum running time (among all possible algorithms that solve Π over F) in the worst case instance
of size n.
The online-LOCAL model.
The (deterministic) online-LOCAL model was introduced in [2]. It is
basically equivalent to the SLOCAL model with global memory. More specifically, the online-LOCAL
model is a centralized model of computing where the algorithm initially knows only the set of
nodes of the input graph G. The nodes are processed with respect to an adversarial input sequence
σ = v1, v2, . . . , vn. The output of vi depends on Gi = G[Si
j=1 NT (vj)], i.e., the subgraph induced
by the radius-T neighborhoods of v1, v2, . . . , vi (including all input data), plus all the outputs of
previously processed nodes (in order).
We define the randomized online-LOCAL model as a randomized variant of the online-LOCAL
model where the label assigned by the algorithm to vi is a random outcome.
Note that this
model is oblivious to the randomness used by the algorithm. In particular this means that the
graph G \ Gi cannot be changed depending on the label assigned to vi. One could also define the
randomized online-LOCAL model in an adaptive manner, but it turns out that this is equivalent to
the deterministic online-LOCAL model as we show in Section 10. We say that a problem Π over
some graph family F has complexity T in the online-LOCAL (randomized online-LOCAL) model if
there is an online-LOCAL (randomized online-LOCAL) algorithm running in time T that solves Π
over F, and T = T(n) is the minimum running time (among all possible algorithms that solve Π
over F) in the worst case instance of size n. If the algorithm is randomized, we also require that the
failure probability is at most 1/n, where n is the size of the input graph.
5
Simulating non-signaling in randomized online-LOCAL
5.1
Framework
In this section we give the necessary framework to define the non-signaling model and is largely
inspired by the definitions given in [27, 36]. Next definition introduces the concept of outcome.
Definition 5.1 (Outcome). Let Σin and Σout be two sets of input and output labels, respectively,
and let F be a family of graphs. An outcome O over F is a mapping (G, x) 7→{(λ(out,i), pi)}i∈I,
with I being a discrete set of indexes, assigning to every input graph G ∈F with any input data
x = (id : V (G) →[|V (G)|c], λin : V (G) →Σin), a discrete probability distribution {pi}i∈I over
output vectors λ(out,i) : V (G) →Σout such that:
1. for all i ∈I, pi > 0;
2. P
i∈I pi = 1;
3. pi represents the probability of obtaining λ(out,i) as the output vector of the distributed system.
We say that an outcome O over some graph family F solves problem Π over F with probability p
if, for every G ∈F and any input data x = (id, λin), it holds that
X
(λ(out,i),pi)∈O((G,x)) :
λ(out,i)∈Π((G,λin))
pi ≥p.
When p = 1, we will just say that O solves problem Π over the graph family F.
The next computational model tries to capture the fundamental properties of any physical
computational model (in which one can run either deterministic, random, or quantum algorithms)
20

--- Page 22 ---
that respects causality. The defining property of such a model is that, for any two (labeled) graphs
(G1, x1) and (G2, x2) that share some identical subgraph (H, y), every node u in H must exhibit
identical behavior in G1 and G2 as long as its local view, that is, the set of nodes up to distance T
away from u together with input data and port numbering, is fully contained in H. As the port
numbering can be computed with one round of communication through a fixed procedure (e.g.,
assigning port numbers 1, 2, . . . , deg(v) based on neighbor identifiers in ascending order) and we care
about asymptotic bounds, we will omit port numbering from the definition of local view.
The model we consider has been introduced by [36]. In order to proceed, we first define the
non-signaling property of an outcome. Let T ≥0 be an integer, and I a set of indices. For any set
of nodes V , subset S ⊆V , and for any input (G = (V, E), x), we define its T-local view as the set
vT (G, x, S) = {(u, x(u)) | ∃u ∈V, v ∈S such that distG(u, v) ≤T} ,
where distG(u, v) is the distance in G. Furthermore, for any subset of nodes S ⊆V and any output
distribution {λ(out,i), pi}i∈I, we define the marginal distribution of {λ(out,i), pi}i∈I on set S as the
unique output distribution defined as follows: for any λout : V (G) →Σout, the probability of λout ↾S
on S is given by
p(λout, S) =
X
i∈I : λout↾S=λ(out,i)↾S
pi,
where λout ↾S and λ(out,i) ↾S are the restrictions of λout and λ(out,i) on S, respectively.
Definition 5.2 (Non-signaling outcome). Let F be a family of graphs. An outcome O : (G, x) 7→
{(λ(out,i), pi)}i∈I over F is non-signaling beyond distance T = T(G, x) if for any pair of inputs (G1 =
(V1, E1), x1), (G2 = (V2, E2), x2), with the same number of nodes, such that vT(G1,x1)(G1, x1, S) is
isomorphic to vT(G1,x1)(G2, x2, S) and G1, G2 ∈F, the output distributions corresponding to these
inputs have identical marginal distributions on the set S.
Definition 5.2 is also the more general definition for the locality of an outcome: an outcome O
has locality T if it is non-signaling beyond distance T.
The φ-LOCAL model.
The φ-LOCAL model is a computational model that produces non-signaling
outcomes over some family of graphs F. Let p ∈[0, 1]. A problem Π over some graph family F has
complexity T (and success probability p) if there exists an outcome O that is non-signaling beyond
distance T which solves Π over F (with probability at least p), and T = T(n) is the minimum
“non-signaling distance” (among all possible outcomes that solve Π over F) in the worst case instance
of size n.
As every (deterministic or randomized) algorithm running in time at most T in the LOCAL model
produces an outcome which has locality T, we can provide lower bounds for the LOCAL model by
proving them in the φ-LOCAL model.
Notice that algorithms in the LOCAL model can be always thought as producing outputs for any
input graph: when the computation at any round is not defined for some node, we can make the node
output some garbage label, say ⊥. If we require that also outcomes are defined for every possible
graph, then we are restricting the power of φ-LOCAL because outcomes must be defined accordingly.
This gives rise to a slightly weaker model, the non-signaling model, which was considered in other
works such as [27] and is still stronger than any classical or quantum variation of the LOCAL model.
Theorem 5.3. Let Π be any LCL problem over any family of graphs F. Let O : (G, λin) 7→
{(λ(out,h), pi)}h∈H be an outcome over F which solves Π with failure probability at most ε and is
non-signaling at distance greater than T. There exists a randomized online-LOCAL algorithm A with
complexity T that solves Π over F and has failure probability at most ε.
21

--- Page 23 ---
We want to design a randomized online-LOCAL algorithm A with complexity T that solves Π
over F and has failure probability at most ε that somehow simulates O. We need to assume that
the number of nodes of the input graph is known by A.
Fix any graph G ∈F of n nodes and any input labeling λin, and fix any sequence of nodes
v1, . . . , vn the adversary might choose to reveal to the algorithm.
The adversary initially shows G[NT (v1)] to the algorithm (including input labels and identifiers)
and asks it to label v1. In order for the algorithm to choose an appropriate output, it can arbitrarily
choose a graph H1 ∈F with n nodes that contains a subgraph isomorphic to G[NT (v1)] (again,
including input labels and identifiers). Notice that H1 necessarily exists since G itself is such a
graph. We stress that the arbitrariness in the choice of H1 is thanks to the non-signaling property,
which ensures that the restriction of the output distribution O(H1, λin) over NT (v1) does not change
if the topology of the graph outside G[NT (v1)] differs (i.e., no matter how the adversary chooses it).
Indeed, if O did not have the non-signaling property, then it would be impossible to sample from it
correctly since the marginal output distribution on G[NT (v1)] would depend on the topology of the
graph beyond it, which the algorithm still has no knowledge of.
For any λout : V (G) →Σout, the probability that A labels v1 with λout(v1) is
p(λout, v1) =
X
k: λout↾{v1}=λ(out,k)↾{v1}
pk,
where {(λ(out,k), pk)}k∈K1 = O(H1, λin).
Let Λi be the random variable yielding the label assigned to vi by A. In general, for any
λout : V (G) →Σout let p(λout, vi) denote the probability that Λi = λout(vi). Assume now that
G[NT (vi+1)] is shown to the algorithm. Conditional on Λ1, . . . , Λi, for any λout : V (G) →Σout such
that λout(vj) = Λj for all j = 1, . . . , i, the probability that Λi+1 = λout(vi+1) is
p(λout, vi+1) =
X
k: λout↾{vj}=λ(out,k)↾{vj}
∀1≤j≤i+1
pk
Q
1≤l≤i p(λout, vl),
where {(λ(out,k), pk)}k∈Ki+1 = O(Hi+1, λin) for any graph Hi+1 ∈F of n nodes that contains a
subgraph isomorphic to G[∪i+1
i=1NT (vj)] (including input labels and identifiers). As before, Hi+1 may
be chosen arbitrarily due to the non-signaling property.
Now consider O(G, λin) = {(λ(out,h), ph)}h∈H for the right input graph G, and take any
(λ(out,h⋆), ph⋆) ∈O(G, λin).
The probability that the outcomes of Λ1, . . . , Λn give exactly λ(out,h⋆) is
Pr

Λ1 = λ(out,h⋆)(v1), . . . , Λn = λ(out,h⋆)(vn)

= Pr

Λn = λ(out,h⋆)(vn)
Λ1 = λ(out,h⋆)(v1), . . . , Λn−1 = λ(out,h⋆)(vn−1)

· Pr

Λn−1 = λ(out,h⋆)(vn−1)
Λ1 = λ(out,h⋆)(v1), . . . , Λn−2 = λ(out,h⋆)(vn−2)

. . .
· Pr

Λ1 = λ(out,h⋆)(v1)

= p(λ(out,h⋆), v1) · . . . · p(λ(out,h⋆), vn)
=
Y
1≤l≤n−1
p(λout, vl) ·
X
kn: λ(out,h⋆)↾{vj}=λ(out,kj)↾{vj}
∀1≤j≤n
pkn
Q
1≤l≤n−1 p(λout, vl)
22

--- Page 24 ---
=
X
kn: λ(out,h⋆)↾{vj}=λ(out,kj)↾{vj}
∀1≤j≤n
pkn.
Notice that
X
kn: λ(out,h⋆)↾{vj}=λ(out,kj)↾{vj}
∀1≤j≤n
pkn = ph⋆
as Hn is necessarily isomorphic to G. By the hypothesis,
X
h: λ(out,h) is valid for (G,λin)
ph ≥1 −ε,
implying that A succeeds with probability at least 1 −ε.
6
Bounded-dependence model can break symmetry
For any graph G = (V, E), a random process (or distribution) on the vertices of G is a family of
random variables {Xv}v∈V , indexed by V , while a random process on the edges of G is a family of
random variables {Xe}e∈E indexed by E. More generally, a random process on G is a family of
random variables {Xy}y∈V ∪E indexed by V ∪E. The variables of a random process live in the same
probability space and take values in some label set Σ. In general, we will consider random processes
over vertices of graphs unless otherwise specified.
We now introduce the notion of T-dependent distribution. To do so, we extend the definition
of distance to edges as follows: For any two edges e = {v1, v2}, e′ = {u1, u2} ∈E, distG(e, e′) =
mini,j∈[2] distG(vi, uj). Similarly, the distance between any edge e = (v1, v2) and a vertex v is
distG(e, v) = mini∈[2] distG(vi, v). The definition extends easily to subsets containing vertices and
edges.
Definition 6.1 (T-dependent distribution). Let T ∈N be a natural number and G = (V, E) be
any graph. A random process {Xv}v∈V on the vertices G is said to be a T-dependent distribution
if, for all subsets S, S′ ⊆V such that distG(S, S′) > T, the two processes {Xv}v∈S and {Xv}v∈S′
are independent. Analogous definitions hold for random processes on the edges of a graph and for
random processes on the whole graph.
A way to define T-dependent distributions that uses the same notation of Section 5.1 is by
describing the output probability of global labelings: Let I be a discrete set of indices, and G = (V, E)
some graph. A distribution {(λi, pi)}i∈I over output labelings, where λi : V →Σ is an output
labeling, is T-dependent if the following holds: for all output labelings λ in {(λi, pi)}, for every two
subsets of nodes S1, S2 ⊆V (G) such that distG(S1, S2) > T, we have that
p(λ, S1 ∪S2) = p(λ, S1) · p(λ, S2).
Notice that outcomes, as defined in Definition 5.1, output a random process for every input. Often,
we have a family of graphs of arbitrarily large size n on which a T(n)-dependent distribution is
defined.1
Now we define the hypothetical computational model that outputs T-dependent distributions on
some input graph.
1Note that the dependency T might depend on other graph parameters such as the maximum degree ∆, the
chromatic number χ, etc.
23

--- Page 25 ---
The bounded-dependence model.
The bounded-dependence model is a computational model
that, for a given family of graphs F, produces an outcome (as defined in Definition 5.1) over F
that is non-signaling beyond distance T = T(G, x) (as defined in Definition 5.2), where G ∈F
and x represents the input, which, in turn, produces T(G, x)-dependent distributions. The random
processes produced by an outcome are said to be finitely-dependent if T = O(1) for all graphs in
F and all input data. If an outcome with the aforementioned properties solves a problem Π over
a graph family F with probability at least p, we say that the pair (Π, F) has complexity T (with
success probability p), and T = T(n) is the minimum dependence (among all possible distributions
solving Π over F) in the worst case instance of size n. We remark that T is also called the locality
or the complexity of the corresponding output distributions.
We are particularly interested in T-dependent distributions that satisfy invariance properties:
We say that a random process {Xv}v∈V over vertices of a graph G = (V, E) is invariant under
automorphisms if, for all automorphisms f : V →V of G = (V, E), the two processes {Xv}v∈V and
{Yv = Xf(v)}v∈V are equal in law. The definition is easily extendable to random processes on edges
and random processes on the whole graph.
A stronger requirement is the invariance under subgraph isomorphism: Suppose we have an
outcome O : (G, x) 7→{Xv}v∈V (G) that maps each input graph G from family of graphs F and any
input data x to a T = T(G, x)-dependent distribution over G from a family of random process R. We
say that the random process over vertices in R are invariant under subgraph isomorphisms if, given
any two graphs G1, G2 ∈F of size n1, n2 with associated process {X(1)
v }v∈V (G1) and {X(2)
v }v∈V (G2),
and any two subgraphs H1 ⊆G1, H2 ⊆G2 such that G1[NT(n1)(H1)] and G2[NT(n2)(H2)] are
isomorphic (with the isomorphism that brings H1 into H2), then {X(1)
v }v∈V (H1) and {X(2)
v }v∈V (H2)
are equal in law.2 Trivially, invariance under subgraph isomorphisms implies invariance under
automorphisms and the non-signaling property. This definition is again easily extendable to the case
of families of random processes over edges or over graphs in general.
The baseline of our result is a finitely-dependent distribution provided by [45, 47] on paths and
cycles.
Theorem 6.2 (Finitely-dependent coloring of the integers and of cycles [45, 47]). Let G = (V, E) be
a graph that is either a cycle with at least 2 nodes or has V = Z and E = {{i, i + 1} : i ∈Z}. For
(k, q) ∈{(1, 4), (2, 3)}, there exists a k-dependent distribution {X(G)
v
}v∈V (G) that gives a q-coloring
of G. Furthermore, such distributions can be chosen to meet the following properties: If {Xi}i∈[n] is
the k-dependent q-coloring of the n-cycle and {Yi}i∈Z is the k-dependent q-coloring of the integers,
then {Xi}i∈[n−k] is equal in law to {Yi}i∈[n−k]. If n = 2, then the finitely-dependent colorings on the
2-cycle and on a path of 2 nodes are identical in distribution.
It is immediate that the disjoint union of any number of paths and cycles (even countably many)
admits such distributions as well.
Corollary 6.3. Let F be the family of graphs formed by the disjoint union (possibly uncountably
many) paths with countably many nodes and cycles of any finite length. For all G ∈F and for
(k, q) ∈{(1, 4), (2, 3)}, there exists a k-dependent distribution {X(G)
v
}v∈V (G) that gives a q-coloring
of G. Furthermore, such distributions can be chosen to meet all the following properties:
1. On each connected component H ⊆G, {X(G)
v
}v∈V (H) is given by Theorem 6.2.
2. {{X(G)
v
}v∈V (G)}G∈F is invariant under subgraph isomorphisms.
2We remark that, as opposed to Definition 5.2, the isomorphism must preserve the input but not the node identifiers.
24

--- Page 26 ---
We will use this result to provide “fake local identifiers” to the nodes of the graph to simulate an
O(log∗n)-round LOCAL algorithm through a random process with constant dependency. In order
to do that, we introduce some results on the composition of T-dependent distributions.
Trivially, every T-round (deterministic or randomized) port-numbering algorithm defines a 2T-
dependent distribution over the input graph. Furthermore, if the underlying port-numbering model
has access to random bits, the distribution can be made invariant under subgraph isomorphisms
(provided that, whenever a distribution over input labelings is given together with the input graph,
such distribution is also invariant under subgraph isomorphisms). The composition of the T2-
dependent distribution obtained by a T2-round port-numbering algorithm and any T1-dependent
distribution yields a (2T2 + T1)-dependent distribution.
Lemma 6.4. Let Σ(1) and Σ(2) be two label sets with countably many labels. Let F be any family of
graphs, and let R = {{Xv}v∈V (G) : G ∈F} be a family of T1-dependent distributions taking values in
Σ(1), where T1 might depend on parameters of G. Consider any T2-round port-numbering algorithm
A that takes as an input G ∈F labelled by {Xv}v∈V (G): it defines another distribution {Yv}v∈V (G)
taking values in some label set Σ(2). Then, the following properties hold:
1. {Yv}v∈V (G) is a (2T2 + T1)-dependent distribution on G.
2. If the processes in R are invariant under subgraph isomorphisms, T2 is constant, and A does
not depend on the size of the input graph and permutes port numbers locally u.a.r. at round 0,
then the processes in {{Yv}v∈V (G) : G ∈F} are invariant under subgraph isomorphisms.
Proof. We prove the claim 1 first. Fix any G = (V, E) ∈F, and the corresponding T2-dependent
distribution {Xv}v∈V ∈R. Fix any two subsets S, S′ ⊆V such that distG(S, S′) > 2T2 + T1.
Consider any output labeling λ(2) : V →Σ(2). Then,
Pr
h
∩v∈S∪S′{Yv = λ(2)(v)}
i
=
X
λ(1) : V →Σ(1)
Pr
h
∩v∈S∪S′{Yv = λ(2)(v)}
∩v∈V {Xv = λ(1)(v)}
i
· Pr
h
∩v∈V {Xv = λ(1)(v)}
i
=
X
λ(1) : V →Σ(1)
Pr
h
∩v∈S∪S′{Yv = λ(2)(v)}
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
(3)
· Pr
h
∩v∈V {Xv = λ(1)(v)}
i
=
X
λ(1) : NT2(S∪S′)→Σ(1)
Pr
h
∩v∈S∪S′{Yv = λ(2)(v)}
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
· Pr
h
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
,
where Eq. (3) holds because the output of {Yv}v∈S∪S′ is independent of {Xv}v /∈NT2(S∪S′). Since
distG(S, S′) > 2T2,
X
λ(1) : NT2(S∪S′)→Σ(1)
Pr
h
∩v∈S∪S′{Yv = λ(2)(v)}
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
· Pr
h
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
25

--- Page 27 ---
=
X
λ(1) : NT2(S∪S′)→Σ(1)
Pr
h
∩v∈S{Yv = λ(2)(v)}
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
· Pr
h
∩v∈S′{Yv = λ(2)(v)}
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
· Pr
h
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
=
X
λ(1) : NT2(S∪S′)→Σ(1)
Pr
h
∩v∈S{Yv = λ(2)(v)}
∩v∈NT2(S){Xv = λ(1)(v)}
i
· Pr
h
∩v∈S′{Yv = λ(2)(v)}
∩v∈NT2(S′){Xv = λ(1)(v)}
i
· Pr
h
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
.
Now observe that distG(NT2(S), NT2(S′)) > T1. Since {Xv}v∈V is a T1-dependent distribution, it
holds that
X
λ(1) : NT2(S∪S′)→Σ(1)
Pr
h
∩v∈S{Yv = λ(2)(v)}
∩v∈NT2(S){Xv = λ(1)(v)}
i
· Pr
h
∩v∈S′{Yv = λ(2)(v)}
∩v∈NT2(S′){Xv = λ(1)(v)}
i
· Pr
h
∩v∈NT2(S∪S′){Xv = λ(1)(v)}
i
=
X
λ(1) : NT2(S∪S′)→Σ(1)
Pr
h
∩v∈S{Yv = λ(2)(v)}
∩v∈NT2(S){Xv = λ(1)(v)}
i
· Pr
h
∩v∈S′{Yv = λ(2)(v)}
∩v∈NT2(S′){Xv = λ(1)(v)}
i
· Pr
h
∩v∈NT2(S){Xv = λ(1)(v)}
i
Pr
h
∩v∈NT2(S′){Xv = λ(1)(v)}
i
= Pr
h
∩v∈S{Yv = λ(2)(v)}
i
· Pr
h
∩v∈S′{Yv = λ(2)(v)}
i
.
We now prove claim 2. Given any G, H ∈F of size nG and nH, respectively, consider any
subgraph isomorphism f : N2T2+T1(nG)(G′, G) →N2T2+T1(nH)(H′, H) for any two G′ ⊆G, H′ ⊆H
such that f restricted to G′ is an isomorphism to H′. Let {X(G)
v
}v∈V (G) and {X(H)
v
}v∈V (H), and
{Y (G)
v
}v∈V (G) and {Y (H)
v
}v∈V (H) be the corresponding distributions of interest before and after the
combination with the port-numbering algorithm, respectively. Fix any subset of nodes U ⊆V (G′)
and consider any family of labels {λu}u∈U indexed by U. In order to prove property 1, it is sufficient
to show that
Pr
h
∩u∈U{Y (G)
u
= λu}
i
= Pr
h
∩u∈U{Y (H)
f(u) = λu}
i
.
Notice that Pr [∩u∈U{Yu = λu}] depends solely on the graph G[NT2(U, G)] = ∪u∈UG[NT2(u, G)],
the distribution of the port numbers in G[NT2(U, G)], and the random process {Xu}u∈NT2(U). By
hypothesis, {X(G)
u
}u∈NT2(U,G) is equal in law to {X(H)
f(u)}u∈NT2(U,G). Furthermore, the restriction
of f to G[NT2(U, G)] defines an isomorphism from G[NT2(U, G)] to H[NT2(f(U), H)], hence the
distribution of the port numbers in G[NT2(U, G)] is the same as that in H[NT2(f(U), H)] because
each node permutes the port numbers locally u.a.r. Thus, Pr
h
∩u∈U{Y (G)
u
= λu}
i
must be the same
as Pr
h
∩u∈U{Y (H)
f(u) = λu}
i
.
26

--- Page 28 ---
T-dependent distributions over different graphs can be combined to obtain a T-dependent
distribution over the graph union.
Lemma 6.5. Let {Xv}v∈V1 and {Yv}v∈V2 be a T1-dependent distribution over a graph G1 = (V1, E1)
taking values in Σ(1) and a T2-dependent distribution over a graph G2 = (V2, E2) taking values
in Σ(2), respectively. Assume {Xv}v∈V1 and {Yv}v∈V2 to be independent processes. Consider the
graph H = (V = V1 ∪V2, E = E1 ∪E2) and a distribution {Zv}v∈V over H taking values in
Σ = (Σ(1) ∪{0}) × (Σ(2) ∪{0}) defined by
Zv =





(Xv, 0)
if v ∈V1 \ V2,
(Xv, Yv)
if v ∈V1 ∩V2,
(0, Yv)
if v ∈V2 \ V1.
Then, {Zv}v∈V is max(T1, T2)-dependent.
Proof. For any vector v ∈Σ1 × · · · × Σn, we write v[i] to denote its i-th entry. Fix any output
labeling λ : V →Σ such that λ(v)[2] = 0 for all v ∈V1 \ V2 and λ(v)[1] = 0 for all v ∈V2 \ V1.
Observe that for any subset S ⊆V it holds that
Pr [∩v∈S{Zv = λ(v)}]
= Pr [(∩v∈S∩V1{Xv = λ(v)[1]}) ∩(∩v∈S∩V2{Yv = λ(v)[2]})]
= Pr [∩v∈S∩V1{Xv = λ(v)[1]}] · Pr [∩v∈S∩V2{Yv = λ(v)[2]}] ,
(4)
where the latter equality follows by independence between {Xv}v inV1 and {Yv}v inV2. W.l.o.g.,
suppose T1 ≥T2. Consider two subsets S, S′ ⊆V such that distG(S, S′) > T1. Fix any output
labeling λ : V →Σ such that λ(v)[2] = 0 for all v ∈V1 \ V2 and λ(v)[1] = 0 for all v ∈V2 \ V1. Using
Eq. (4), we have that
Pr [∩v∈S∪S′{Zv = λ(v)}]
= Pr

∩v∈(S∪S′)∩V1{Xv = λ(v)[1]}

· Pr

∩v∈(S∪S′)∩V2{Yv = λ(v)[2]}

= Pr

∩v∈(S∩V1)∪(S′∩V1){Xv = λ(v)[1]}

· Pr

∩v∈(S∩V2)∪(S′∩V2){Yv = λ(v)[2]}

= Pr [∩S∩V1{Xv = λ(v)[1]}] · Pr [∩S′∩V1{Xv = λ(v)[1]}]
(5)
· Pr [∩S∩V2{Yv = λ(v)[2]}] · Pr [∩S′∩V2{Yv = λ(v)[2]}]
= Pr [(∩v∈S∩V1{Xv = λ(v)[1]}) ∩(∩v∈S∩V2{Yv = λ(v)[2]})]
(6)
· Pr [(∩v∈S′∩V1{Xv = λ(v)[1]}) ∩(∩v∈S′∩V2{Yv = λ(v)[2]})]
= Pr [∩v∈S{Zv = λ(v)}] · Pr [∩v∈S′{Zv = λ(v)}] ,
where Eq. (5) holds because {Xv}v∈V1 is T1-dependent and {Yv}v∈V2 is T2-dependent, while Eq. (6)
holds because {Xv}v∈V1 and {Yv}v∈V2 are independent.
Now we present a final lemma on the composition of random processes. To do so, we first
introduce the notation of random decomposition of a graph.
Definition 6.6 (Random decomposition). Let G = (V, E) be any graph and P a family of subgraphs
of G. For any k ∈N, let Γ(G) be a random variable taking values in Pk that is sampled according
to any probability distribution. We say that Γ(G) is a random k-decomposition of G in P.
27

--- Page 29 ---
Given a random k-decomposition Γ(G) of G in P, for any y ∈V ∪E, we define the random
variable Γ(G)y ∈{0, 1}k as follows: Γ(G)y[i] = 1 if y belongs to Γ(G)[i] and 0 otherwise. Notice that
{Γ(G)y}y∈V ∪E is a random process on G. If {Γ(G)y}y∈V ∪E is invariant under automorphisms, then
we say that the random k-decomposition Γ(G) is invariant under automorphisms. If, for a family
of graphs F and any graph G ∈F, {Γ(G)y}y∈V (G)∪E(G) is T-dependent (with T being a function
of the size of G) and the processes in {{Γ(G)y}y∈V (G)∪E(G) : G ∈F} are invariant under subgraph
isomorphisms, then we say that the random k-decompositions in {Γ(G) : G ∈F} are T-dependent
and invariant under subgraph isomorphisms.
For a random decomposition, we define the notion of induced random process.
Definition 6.7 (Induced process). Let G = (V, E) be a graph that admits a family of subgraphs P.
Suppose there exists a random process {Xv}v∈V (H(P)) with H(P) being the graph obtained by the
disjoint union of all elements of P. Let Γ(G) be a random k-decomposition of G in P. For all v ∈V
and G′ ∈P, define the random process {X(G′)
v
}v∈V by setting X(G′)
v
= XfG′(v) for all v ∈V (G′),
where fG′ : V (G′) →V (H(P)) is the natural immersion of G′ into H(P) otherwise set X(G′)
v
= 0.
Let {Y (Γ(G))
v
}v∈V be a random process that we define conditional on the output of Γ(G): for all
G ∈Pk, conditional on Γ(G) = G,
Y (Γ(G))
v
= Y (G)
v
= (X(G[1])
v
, . . . , X(G[k])
v
).
The random process {Y (Γ(G))
v
}v∈V on G is said to be induced by the action of {Xv}v∈V (H(P)) over
the random k-decomposition Γ(G).
Now we present a result on the induced random process whenever the random decomposition
and the family of random processes that acts on the random decomposition meet some invariance
properties.
Lemma 6.8. Let F be a family of graphs. For any G = (V, E) ∈F, let PG be any family of
subgraphs of G that is closed under node removal and disjoint graph union, that is, if G1, G2 ∈
PG and V (G1) ∩V (G2) = ∅, then G1 ∪G2 ∈PG. Furthermore, suppose that, for each pair of
isomorphic subgraphs G1, G2 ⊆, G1 ∈PG
=⇒
G2 ∈PG.
Moreover, let Γ(G) be a random
k-decomposition of G in PG that is T1-dependent, and suppose that the random decompositions
in {Γ(G) : G ∈F} are invariant under subgraph isomorphism. Suppose there is T2-dependent
distribution {Xv}v∈V (H(PG)), taking values in a finite set Σ, such that {{Xv}v∈V (H(PG)) : G ∈F} is
invariant under subgraph isomorphism, where H(PG) is obtained by the disjoint union of a copy of each
element of PG. Let {Y (Γ(G))
v
}v∈V (G) be the random process induced by the action of {Xv}v∈V (H(PG))
over Γ(G). Then, {Y (Γ(G))
v
}v∈V (G) is a (T1 +2T2)-dependent distribution. Furthermore, the processes
in {{Xv}v∈V (H(PG)) : G ∈F} are invariant under subgraph isomorphism.
Proof. Fix G ∈F and let Γ = Γ(G), P = PG. Since Pk might be uncountable, we consider the
density function fΓ and the probability measure P associated to Γ. Consider two subsets of nodes
S, S′ ⊆V at distance at least max(T1, T2) + 1. Fix any labeling λ : V →Σk. It holds that
Pr
h
∩v∈S∪S′{Y (Γ)
v
= λ(v)}
i
=
Z
Pk Pr
h
∩v∈S∪S′{Y (Γ)
v
= λ(v)}
 Γ = G
i
fΓ(G) dP
(7)
=
Z
Pk Pr
h
∩v∈S∪S′{Y (G)
v
= λ(v)}
i
fΓ(G) dP
28

--- Page 30 ---
=
Z
Pk Pr

∩v∈S{Y G
v
= λ(v)}

Pr

∩v∈S′{Y G = λ(v)}

fΓ(G) dP
(8)
=
Z
Pk
Y
i∈[k]
Pr
h
∩v∈S{XG[i]
v
= λ(v)[i]}
i
Pr
h
∩v∈S′{XG[i]
v
= λ(v)[i]}
i
fΓ(G) dP ,
(9)
where Eq. (7) holds by the law of total probability, Eq. (8) holds since {Y (G)
v
}v∈V is T2-dependent
for all G ∈Pk by Lemma 6.5, and Eq. (9) holds since {XG[i]
v
}v∈V and {XG[j]
v
}v∈V are independent
if i ̸= j. Notice that, for any set S ⊆V , G′ = G[i][NT2(S, G[i])] ∈P and the event ∩v∈S{XG[i]
v
=
λ(v)[i]} has the same probability as ∩v∈S{XG′
v
= λ(v)[i]} because {Xv}v∈V (H(P)) is invariant under
subgraph isomorphisms.
For any subset U ⊆V and any integer T ≥0, let
H(T, U) =
n
(G[1][NT (U, G[1])], . . . , G[k][NT (U, G[k])])
 G ∈Pko
⊆Pk,
and let P[H(T, U)] be the restriction of P to H(T, U) defined as follows: for any event E,
P[H(T, U)](E) = P(E ∩H(T, U))/P(H(T, U)).
Finally, define the random variable Γ(T,U) to be a k-dimensional vector, taking values in H(T, U),
whose i-th entry is Γ[i][NT (U, Γ[i])], and let fΓ(T,U) be its density function. Define U = S ∪S′:
Eq. (9) becomes
Z
Pk
Y
i∈[k]
Pr
h
∩v∈S{XG[i]
v
= λ(v)[i]}
i
Pr
h
∩v∈S′{XG[i]
v
= λ(v)[i]}
i
fΓ(G) dP
(10)
=
Z
H(T2,U)
Y
i∈[k]
Pr
h
∩v∈S{XH[i]
v
= λ(v)[i]}
i
Pr
h
∩v∈S′{XH[i]
v
= λ(v)[i]}
i
fΓ(T2,U)(H) dP[H(T2, U)] .
Now notice that, since the random decomposition Γ is T1-dependent and distG(S, S′) > T1 + 2T2,
the probability space H(T2, U) (with measure P[H(T2, U)]) is isomorphic to the product space
H(T2, S) × H(T2, S′) (with product measure P[H(T2, S)] × P[H(T2, S′)]). The isomorphism brings
any element
(G[1][NT2(U, G[1])], . . . , G[k][NT2(U, G[k])])
of H(T2, U) into
 (G[1][NT2(S, G[1])], . . . , G[k][NT2(S, G[k])]), (G[1][NT2(S′, G[1])], . . . , G[k][NT2(S′, G[k])])

which belongs to H(T2, S) × H(T2, S′). Hence, we get
Z
H(T2,U)
Y
i∈[k]
Pr
h
∩v∈S{XH[i]
v
= λ(v)[i]}
i
Pr
h
∩v∈S′{XH[i]
v
= λ(v)[i]}
i
fΓ(T2,U)(H) dP[H(T2, S)]
=
Z
H(T2,S)
Z
H(T2,S′)
Y
i∈[k]
Pr
h
∩v∈S{XH[i]
v
= λ(v)[i]}
i
Pr
h
∩v∈S′{XH[i]
v
= λ(v)[i]}
i
· fΓ(T2,S)(H1)fΓ(T2,S′)(H2) dP[H(T2, S)] dP[H(T2, S′)] .
The latter becomes
Z
H(T2,S)
Z
H(T2,S′)
Y
i∈[k]
Pr
h
∩v∈S{XH[i]
v
= λ(v)[i]}
i
Pr
h
∩v∈S′{XH[i]
v
= λ(v)[i]}
i
29

--- Page 31 ---
· fΓ(T2,S)(H1)fΓ(T2,S′)(H2) dP[H(T2, S)] dP[H(T2, S′)]
=
Z
H(T2,S)
Y
i∈[k]
Pr
h
∩v∈S{XH[i]
v
= λ(v)[i]}
i
fΓ(T2,S)(H1) dP[H(T2, S)]
·
Z
H(T2,S′)
Y
i∈[k]
Pr
h
∩v∈S′{XH[i]
v
= λ(v)[i]}
i
fΓ(T2,S′)(H2) dP[H(T2, S′)]
=
Z
Pk
Y
i∈[k]
Pr
h
∩v∈S{XG[i]
v
= λ(v)[i]}
i
fΓ(G) dP
(11)
·
Z
Pk
Y
i∈[k]
Pr
h
∩v∈S′{XG[i]
v
= λ(v)[i]}
i
fΓ(G) dP
= Pr
h
∩v∈S{Y (Γ(G))
v
= λ(v)}
i
Pr
h
∩v∈S′{Y (Γ(G))
v
= λ(v)}
i
,
where Eq. (11) follows by the same reasoning as for Eq. (10) but in reverse.
Now we want to prove that {{Y (Γ(G))
v
}v∈V : G ∈F} is invariant under subgraph isomorphism.
Fix any two graphs G, H ∈F of sizes nG and nH, respectively. Consider any isomorphism α
between the radius-(T1(nG) + 2T2(nG)) neighborhoods of any subgraph G′ ⊆G and the radius-
(T1(nH)+2T2(nH)) neighborhoods of any subgraph H′ ⊆H, such that the restriction of α to G′ is an
isomorphism to H′. With an abuse of notation, for any subgraph K ⊆G′, let us denote α(K) ⊆H′
its isomorphic image in H′ through α. Let TG = T1(nG) + 2T2(nG) and TH = T1(nH) + 2T2(nH).
Fix any labeling λ : V →Σk. We have that
Pr
h
∩v∈V (G′){Y (Γ(G))
v
= λ(v)}
i
=
Z
Pk
G
Pr
h
∩v∈V (G′){Y (Γ(G))
v
= λ(v)}
 Γ(G) = G
i
fΓ(G)(G) dPG .
=
Z
Pk
G
Pr
h
∩v∈V (G′){Y (G)
v
= λ(v)}
i
fΓ(G)(G) dPG
=
Z
Pk
G
Y
i∈[k]
Pr
h
∩v∈V (G′){X(G[i])
v
= λ(v)[i]}
i
fΓ(G)(G) dPG
=
Z
HG(TG,V (G′))
Y
i∈[k]
Pr
h
∩v∈V (G′){X(H[i])
v
= λ(v)[i]}
i
fΓ(G)(TG,V (G′))(H) dPG(HG(TG, V (G′)))
=
Z
HG(TG,V (G′))
Y
i∈[k]
Pr
h
∩v∈V (G′){X(α(H[i]))
α(v)
= λ(v)[i]}
i
fΓ(G)(TG,V (G′))(H) dPG(HG(TG, V (G′))) ,
where the latter holds because
Pr
h
∩v∈V (G′){X(H[i])
v
= λ(v)[i]}
i
= Pr
h
∩v∈V (G′){X(α(H[i]))
α(v)
= λ(v)[i]}
i
as {{Xv}v∈V (H(PG)) : G ∈F} is T2-dependent and invariant under subgraph isomorphism. Further-
more, since the processes in {Γ(G) : G ∈F} are T1-dependent and invariant under subgraph isomor-
phism, we have that fΓ(G)(TG,V (G′))(H) = fΓ(H)(TH ,V (H′))((α(H[1]), . . . , α(H[k]))) almost everywhere
in HG(TG, V (G′)), and that the probability space HG(TG, V (G′)) with measure dPG(HG(TG, V (G′)))
is isomorphic to HH(TH, V (H′)) with measure dPH(HH(TH, V (H′))), where the isomorphism brings
30

--- Page 32 ---
H into (α(H[1]), . . . , α(H[k])). Hence,
Z
HG(TG,V (G′))
Y
i∈[k]
Pr
h
∩v∈V (G′){X(α(H[i]))
α(v)
= λ(v)[i]}
i
fΓ(G)(TG,V (G′))(H) dPG(HG(TG, V (G′)))
=
Z
HH(TH,V (H′))
Y
i∈[k]
Pr
h
∩v∈V (H′){X(H[i])
v
= λ(v)[i]}
i
fΓ(H)(TH ,V (H′))(H) dPH(HH(TH, V (H′)))
= Pr
h
∩v∈V (H′){Y (Γ(H))
v
= λ(v)}
i
,
concluding the proof.
Remark 6.9. When the underlying graph is a directed graph, Lemma 6.8 guarantees invariance
under subgraph isomorphisms that keep edge orientation.
We are going to work on rooted pseudotrees and pseudoforests. A pseudotree is a graph that
is connected and contains at most one cycle. A pseudoforest is a graph obtained by the disjoint
union of pseudotrees; an equivalent definition of pseudoforest is a graph in which each connected
component has no more edges than vertices. Note that a pseudotree might contain multiple edges:
however, we assume it does not contain self-loops as self-loops are useless communication links in
the LOCAL model. A rooted tree is a tree where each edge is oriented and all nodes have outdegree
at most 1: it follows that all but one node have outdegree exactly 1 and one node (the root) has
outdegree 0. Trivially, a tree can be rooted by selecting one node and orienting all edges towards
it. A rooted pseudotree is a pseudotree where each edge is oriented and each node has outdegree at
most 1: if the pseudotree contains a cycle, then all nodes necessarily have outdegree exactly 1. Any
pseudotree can be oriented so that it becomes rooted: just orient the cycle first (if it exists) in a
consistent way, then remove it, and make the remaining trees rooted at nodes that belonged to the
cycle. A rooted pseudoforest is the union of rooted pseudotrees.
We will show that pseudoforests of maximum degree ∆admit a O(log∗∆)-dependent 3-coloring
distributions. In order to do so, we use a color reduction technique that follows by known revisions
of the Cole–Vishkin technique [29, 42].
Lemma 6.10 (port-numbering algorithm for color reduction in pseudoforests [29, 42]). Let G be
a pseudoforest with countably many nodes. Assume G is given as an input a k-coloring for some
k ≥3. There exists a deterministic port-numbering algorithm that does not depend on the size of G
and outputs a 3-coloring of G in time O(log∗k).
Now we are ready to prove our result on pseudoforests.
Lemma 6.11 (Finitely-dependent coloring of rooted pseudoforests). Let F be a family of rooted
pseudoforests of countably many nodes of maximum degree ∆. Then, there exists an outcome that
associates to each graph G ∈F a O(log∗∆)-dependent distribution on the vertices of G that gives
a 3-coloring of G. Furthermore, the family of distributions outputted by the outcome are invariant
under subgraph isomorphisms.
Proof. Let us fix the rooted pseudoforest G ∈F. Let PG be the family of all subgraphs of G formed
by the disjoint union of directed paths and cycles. Notice that PG is closed under node removal
and disjoint graph union. Furthermore, for any two pair of isomorphic subgraphs G1, G2 ⊆G,
G1 ∈PG =⇒G2 ∈PG. Let H(PG) be the graph formed by the disjoint union of a copy of each
element of PG. By Corollary 6.3, H(PG) admits a 1-dependent 4-coloring distribution {Xv}v∈H(PG)
(with colors in [4]), such that {{Xv}v∈H(PG) : G ∈F} is invariant under subgraph isomorphism.
31

--- Page 33 ---
Figure 1: A decomposition of rooted pseudoforests in directed paths and cycles: each node v colors
its indegree neighbors with a uniformly sampled permutation of the elements in [indeg(v)]. The
graph induced by nodes colored with color i is a disjoint union of directed paths and cycles.
Consider now a (non-proper) coloring of the pseudoforest in which each node u colors its indegree
neighbors with a permutation of {1, . . . , indeg(u)} sampled uniformly at random: if a node has
outdegree zero, then it is deterministically colored with color 1. Such a coloring is described by a
2-dependent distribution {Zv}v∈V that is (trivially) invariant under subgraph isomorphisms that
keep edge orientation. Also, {Zv}v∈V identifies ∆in disjoint random subset of nodes V1, . . . , V∆in,
where nodes in Vi are colored with the color i, and ∆in is the maximum indegree of the graph.
Let Γ(G) = (G[V1], . . . , G[V∆in]), where Γ(G)[i] is the random graph induced by Vi. Furthermore,
observe that, the output of Γ(G)[i] is the disjoint union of oriented paths and/or oriented cycles,
with Γ(G)[i] being the i-th entry of the ∆in-tuple Γ(G) (see Fig. 1). Notice that process Γ(G) is
2-dependent and is a random ∆in-decomposition of G in PG (according to Definition 6.6), such
that the random decompositions in {Γ(G) : G ∈F} are invariant under subgraph isomorphism. By
Lemma 6.8, the random process {Y (Γ(G))
v
}v∈V , that is induced by the action of {Xv}v∈H(PG) over
the random ∆in-decomposition Γ(G) (according to Definition 6.7), is a 4-dependent distribution that
gives a 4∆in-coloring of G: in fact, Γ(G)[i] and Γ(G)[j] are disjoint if i ̸= j, hence only one entry of
Y (Γ(G))
v
is non-zero, for all v ∈V .
We then combine {Y (Γ(G))
v
}v∈V and a modified version of the port-numbering algorithm from
Lemma 6.10 where at round 0 each node permutes port numbers locally u.a.r.: by Lemma 6.4, we
obtain an O(log∗∆)-dependent 3-coloring distribution {Q(G)
v
}v∈V (G) of G such that processes in
{{Q(G)
v
}v∈V (G) : G ∈F} are invariant under subgraph isomorphisms.
Our finitely-dependent coloring of pseudoforests can be used as a baseline to provide a (∆+ 1)-
coloring of graphs with maximum degree ∆.
The tool we use is again an application of the
Cole–Vishkin color reduction technique [56].
Lemma 6.12 (port-numbering algorithm for color reduction of general graphs [56]). Let G = (V, E)
be a graph with maximum degree ∆and countably many nodes. Suppose G is given in input a k-coloring
32

--- Page 34 ---
1
2
5
4
3
6
7
1
2
5
4
3
6
7
1
1
1
1
1
1
1
2
2
2
2
2
2
2
3
3
3
3
3
4
4
5
(a) Each node v rearranges its port numbers uniformly at random.
1
2
5
4
3
6
7
1
2
5
4
3
6
7
1
2
5
4
3
6
7
1
2
5
4
3
6
7
1
2
5
4
3
6
7
H!
H"
H#
H$
H%
(b) The ∆= 5 rooted pseudoforests that we take by considering port numbers i ∈[∆].
Figure 2: A decomposition of a graph of maximum degree ∆= 5 in rooted pseudoforests: for the sake
of image clarity, we focus on the undirected case. In Fig. 2a, each node v rearranges its port-numbers
with a uniformly sampled permutation of the elements in [deg(v)]. As shown in Fig. 2b, edges
hosting port number i at some endpoint are oriented away from that port (in case both endpoints
host port number i, the edge is duplicated) and form a rooted pseudoforest.
33

--- Page 35 ---
for some k ≥∆+ 1. There exists a deterministic port-numbering algorithm that does not depend on
the size of the input graph and outputs a (∆+ 1)-coloring of G in time O
 log∗k + √∆log ∆

.
We first present a corollary of Lemma 6.12 where we characterize the combination of an input
finitely-dependent coloring distribution and the port-numbering color-reduction algorithm.
Corollary 6.13. Let G = (V, E) be a graph with maximum degree ∆and countably many nodes. Let
{Xv}v∈V be a T-dependent distribution that gives a k-coloring of G, with k ≥∆+1. Then there exists
a distribution Yvv∈V that gives a (∆+ 1)-coloring of G and is O
 log∗k + √∆log ∆+ T

-dependent.
Furthermore, if {Xv}v∈V is invariant under subgraph isomorphism, then so it is {Yv}v∈V .
Proof. We combine the distribution {Xv}v∈V with a modified version of the port-numbering algorithm
from Lemma 6.12 where at round 0 each node permutes port numbers locally u.a.r.: Lemma 6.4
implies the existence of an O
 log∗k + √∆log ∆+ T

-dependent (∆+ 1)-coloring distribution of G.
If {Xv}v∈V is invariant under subgraph isomorphism, Lemma 6.4 implies that {Yv}v∈V has the same
property.
Lemma 6.14 (Finitely-dependent coloring of bounded-degree graphs). Let F be a family of graphs
of countably many nodes and maximum degree ∆. Then, there exists an outcome that associates
to each graph G ∈F an O(√∆log ∆)-dependent distribution on the vertices of G that gives a
(∆+1)-coloring of G. Furthermore, the family of distributions outputted by the outcome are invariant
under subgraph isomorphisms.
Proof. Let us fix G = (V, E) ∈F First, if G is not directed, then duplicate each edge and give
to each pair of duplicates different orientations. Since a coloring of the original graph is a proper
coloring if and only if the same coloring is proper in the directed version, w.l.o.g., we can assume G
to be directed.
Let PG be a family of all subgraphs of G formed by rooted pseudotrees and disjoint union of rooted
pseudotrees. Notice that PG is closed under node removal and disjoint graph union. Furthermore,
for any two pair of isomorphic subgraphs G1, G2 ⊆G, G1 ∈PG =⇒G2 ∈PG. The graph H(PG)
that is the disjoint union of all elements of copies of each PG is a rooted pseudoforest of maximum
degree ∆and, by Lemma 6.11, admits a 3-coloring O(log∗∆)-dependent distribution {Xv}v∈H(PG)
such that processes in {{Xv}v∈H(PG) : G ∈F} are invariant under subgraph isomorphism.
Now, consider a process in which each node v samples uniformly at random a permutation of
a port numbering from {1, . . . , outdeg(v)} for its outgoing edges. For each i ∈[∆out], consider the
graph Gi induced by edges that host port i: notice that Gi is a rooted pseudoforest as each node
has at most one out-edge with port i. If a node has degree 0, it deterministically joins G1, which
remains a pseudoforest. The random choice of port numbering defines a random variable Γ ∈Pk
G,
where Γ[i] is the graph induced by port number i: according to Definition 6.6, we obtain a random
∆out -decomposition Γ(G) of G in PG which is 2-dependent (by construction): also, the random
decompositions in {Γ(G) : G ∈F} are invariant under subgraph isomorphisms. For an example of a
possible output of the random decomposition, see Fig. 2.
Hence, the random process {Y (Γ(G))
v
}v∈V from Definition 6.7 is well defined, and provides a
proper 3∆-coloring of G. By Lemma 6.8, the random process {Y (Γ(G))
v
}v∈V is O(log∗∆)-dependent
and, when G ∈F varies, the processes {Y (Γ(G))
v
}v∈V are invariant under subgraph isomorphisms.
By Corollary 6.13 we obtain an O(√∆log ∆)-dependent (∆+ 1)-coloring distribution on G that
is invariant under subgraph isomorphism (as G ∈F varies).
Lemma 6.14 answers an open question posed by Holroyd [44]. (See also Corollary 1.3 and the
discussion around it.)
34

--- Page 36 ---
Corollary 6.15. Let G = (V, E) be the infinite d-regular tree. There exists a finitely-dependent
distribution giving a (d + 1)-coloring of G that is invariant under automorphisms.
Proof. Finding a (d + 1)-coloring of any d-regular tree has complexity O(1) in SLOCAL; the coloring
can just be performed greedily. Lemma 6.14 yields the desired result.
Consider any graph G = (V, E). For any k ∈N+, a distance-k coloring of G is an assignment of
colors c : V →Σ such that, for each node v ∈V , all nodes in Nk(v) \ {v} = {u ∈V : distG(u, v) ≤
k} \ {v} have colors that are different from c(v).
It is well known that any LCL problem Π that has complexity O(log∗n) in the LOCAL model has
the following property: there exists a constant k ∈N+ (that depends only on the hidden constant in
O(log∗n)) such that, if the input graph is given a distance-k coloring, then Π is solvable in time
O(1) in the port-numbering model [20]. Furthermore, no knowledge of the size of the input graph is
required.
Theorem 6.16. Consider any LCL problem Π with checking radius r that has complexity T ≥r in
the LOCAL model over a family F of graphs with maximum degree ∆, where T = O(log∗n) for input
graphs of size n. For each G ∈F, there exists an O(f(∆))-dependent distribution {Y (G)
v
}v∈V (G)
that solves Π over G. Furthermore, the processes in {{Y (G)
v
}v∈V (G) : G ∈F} are invariant under
subgraph isomorphisms.
Proof. Fix G ∈F of size n. As said before, there exists a constant k ∈N+ (that depends only on the
description of the Π) such that, if the input graph is given a distance-k coloring, then Π is solvable
in time O(1) (hiding some dependence on ∆) in the port-numbering model [20]. Furthermore, no
knowledge of the size of the input graph is required. Consider the power graph Gk, where k ≥T,
defined by Gk = {V, Ek} with Ek = {{u, v} : u, v ∈V, distG(u, v) ≤k}. The maximum degree of
Gk is ∆k. By Lemma 6.14, Gk admits an O
p
k∆k log ∆

-dependent (∆k + 1)-coloring distribution
{Xv}v∈V that is invariant under subgraph isomorphisms (as G ∈F varies). Notice that such a
coloring provides a distance-k coloring for G.
Let A be the algorithm in port-numbering model that solves Π in time O(1) while given the
distance-k coloring in input. Consider a port-numbering algorithm A′ that simulates A and is defined
as follows: At round 0, A′ permutes ports locally u.a.r. Then, A′ simply simulates A using identifiers
given by the distance-k coloring and properly solves Π by the hypotheses. Notice that {Yv}v∈V , that
is, the random process induced by combining {Xv}v∈V and A′ is a O(f(∆))-dependent distribution
on G by Lemma 6.4 with the required invariance properties, and we get the thesis by choosing
k = T.
7
Simulation of online-LOCAL in SLOCAL for rooted trees
In this section, we show how to turn an online-LOCAL algorithm solving an LCL problem in rooted
forests into a deterministic SLOCAL algorithm solving the same problem. More concretely, we prove
the following theorems:
Theorem 7.1. Let Π be an LCL problem with degree constraint ∆, input label set Σin, output label
set Σout, and checking radius r > 0. In addition, let A be an online-LOCAL algorithm solving Π with
locality T(n) over rooted forests. Then the following holds:
1. If A is deterministic, then there exists a deterministic SLOCAL algorithm solving Π with locality
O(r) + T(2O(n3)).
35

--- Page 37 ---
2. If A is randomized and has success probability p(n) > 0, then there exists a deterministic
SLOCAL algorithm solving Π with locality O(r) + T(2O(n3) + 2O(2n2) · log
1
p(n)).
Theorem 7.1 implies that any randomized online-LOCAL algorithm with locality o(log log log n)
solving an LCL Π over rooted trees can be turned into an SLOCAL algorithm solving Π with locality
o(log n). Next theorem shows that, over rooted trees, the class of LCL problems with complexity
o(log n) is the same as that of LCL problems with complexity O(1).
Theorem 7.2. Let A be an SLOCAL algorithm solving an LCL problem Π that runs with locality
o(log∆n) over rooted forests of maximum degree ∆and n nodes. Then, there exists an SLOCAL
algorithm B solving Π with locality O(1).
It is folklore that any O(1)-round SLOCAL algorithm solving an LCL can be turned into an
O(log∗n)-round LOCAL algorithm solving the same LCL, implying the thesis of Theorem 1.5.
7.1
Amnesiac online-LOCAL algorithms
We start by formalizing what an online-LOCAL algorithm sees when run for a fixed number of steps
on a graph. We then define formally what we mean by amnesiac algorithms:
Definition 7.3 (Partial online-LOCAL run of length ℓ). Let G be a graph with an ordering of nodes
v1, v2, . . . , vn. Consider the subgraph Gℓ⊆G induced by the radius-T neighborhoods of the first ℓ
nodes v1, . . . , vℓ. We call (Gℓ, (v1, . . . , vℓ)) the partial online-LOCAL run of length ℓof G as this is
exactly the information that an online-LOCAL algorithm would know about G when deciding the
output for node vℓ.
We denote by the pair ( ¯Gℓ, (w1, . . . , wk)) where ¯Gℓ⊆Gℓis the connected component containing
vℓ, and (w1, . . . , wk) is the maximal subsequence of (v1, . . . , vℓ) of nodes that belong to ¯Gℓ. In such
case, k is the length of (Gℓ, (v1, . . . , vℓ))[vℓ].
Trivially, wk = vℓ.
If (Gℓ, (v1, . . . , vℓ))[vℓ] = (Gℓ, (v1, . . . , vℓ)), then we say that (Gℓ, (v1, . . . , vℓ)) is a partial one-
component online-LOCAL run of length ℓof G. In such case, we call vℓthe center of the neighborhood.
Finally, we denote by G−
ℓthe disjoint set of partial one-component online-LOCAL runs formed
by v1, . . . , vℓ−1, that is, one step shorter than Gℓ; this is exactly the information that an online-
LOCAL algorithm knows before labeling node vℓwhen (Gℓ, (v1, . . . , vℓ)) is a partial one-component
online-LOCAL run.
Definition 7.4 (Amnesiac algorithm). Let A be a deterministic online-LOCAL algorithm, and let
us fix the number of nodes to be n. We say that A is amnesiac if the following condition is met:
Consider any two graphs G, H of n nodes and any adversarial orderings of the nodes
(v1, . . . , vn) (for G) and (u1, . . . , un) (for H). Fix any pair (i, j) ∈[n]2 of indices such
that
(Gi, (v1, . . . , vi))[vi] = ( ¯Gi, (v′
1, . . . , v′
k)) and
(Hj, (u1, . . . , uj))[uj] = ( ¯Hi, (u′
1, . . . , u′
k))
and are isomorphic (with the isomorphism being order-preserving, i.e., bringing v′
h into
u′
h, for all h ∈[k]). Then the outputs of ui and vj coincide.
Intuitively, A is amnesiac if the output of A for some node v depends only on the local connected
component of the partial online local run and not anything else the algorithm has seen.
In general, an online-LOCAL algorithm uses global memory and hence it is not amnesiac.
36

--- Page 38 ---
7.2
Online to amnesiac
We are now ready to generalize the intuition we provided in Section 2.3 for turning any online-LOCAL
algorithm into an amnesiac algorithm with the cost of blowing up its locality.
Lemma 7.5. Let Π be an LCL problem with degree constraint ∆, input label set Σin and output
label set Σout. Let A be a deterministic online-LOCAL algorithm solving Π over a family F of graphs
that is closed under disjoint graph union and node/edge removal. Assume A has locality T(n) for
an n-node graph. Then there exists an amnesiac online-LOCAL algorithm A′ that solves Π on an
n-node graph in F with locality T(2O(n3)).
Proof. Let T = T(N) be the locality of the following experiment; we determine the size N of
the experiment graph later. Let Gℓbe the set of all partial one-component online-LOCAL runs
of length ℓfor n-node graphs in F (up to isomorphisms). We denote gℓ= |Gℓ| and remark that
gℓ≤g = 2n2|Σin| n. Notice that the term 22n takes into accounts not only all possible topologies (up
to isomorphisms), but also all possible orderings of the nodes: indeed, there are at most 22n directed
graphs of n nodes where the vertices are labelled with elements of [n] (which defines an ordering).
We set Nℓ= (3|Σout| ng)n−ℓ+1n.
We now adaptively construct an experiment graph H in n phases. In the first phase, we construct
N1 copies of all graphs in G1, that is, we construct N1g1 disjoint components describing all possible
isolated neighborhoods an online-LOCAL algorithm might see. We then show the centers of these
regions to A and let it label them. As there are N1 copies of each partial online local run of length
1, for each of these, say T , there exists a canonical label σT that appears at least N1/|Σout| times,
by the pigeonhole principle. We say that such online-LOCAL runs of length 1 are good, and ignore
the rest.
In each subsequent phase ℓ, we again construct Nℓcopies of all graphs in Gℓ, with the catch
that, for each graph (G, (v1, . . . , vℓ)) ∈Gℓand for each component of G−, we take the corresponding
good partial one-component online-LOCAL run from a previous phase; we defer arguing why such
good runs exist for now. Next we show node vℓto A and let it label the node. Finally, again by the
pigeonhole principle, for each partial one-component online-LOCAL run T (of length ℓ) we find a
canonical label σT that appears at least Nℓ/|Σout| times, and mark the corresponding runs as good.
Now our new online-LOCAL algorithm B works as follows: Before even processing the first node
of the input, B runs the above-described experiment by simulating A on H with locality T. Notice
that the nodes of the experiment graph will be processed according to a global ordering which is
locally consistent with that of the nodes in the single partial one-component online-LOCAL runs. We
do not care about the specific global ordering of the nodes.
When processing node v, algorithm B looks at partial one-component online-LOCAL run around
v and finds a corresponding good and unused run from the experiment graph H. Algorithm B labels
v with the good label that it found in H and marks the neighborhood in H used.
In each step, algorithm B can find such unused good neighborhoods as after the whole input
has been processed, what the algorithm has seen corresponds to a partial online-LOCAL run, and in
particular each component of this run corresponds to a partial one-component online-LOCAL run
in H. There are at most n such component. By construction, there are at least Nn copies of each
type of partial one-component runs in H. At least Nn/|Σout| ≫n of those are good, and hence
the algorithm can find good and unused neighborhoods for each of the final partial one-component
online-LOCAL runs. But as each good run in H is formed by combining only good components in
H, there must also be a good and unused partial one-component online-LOCAL run corresponding
to each processed node v. This construction ensures that B is amnesiac.
37

--- Page 39 ---
Now, by contradiction, assume that B doesn’t solve Π. Since Π is an LCL, there must be a node
v of the input graph such that the whole output in its radius-r neighborhood, with r being the
checking radius, is not admissible. However, the output of B in this neighborhood is the output of A
from the experiment graph in a partial one-component online-LOCAL run, which must be correct by
the hypothesis.
The only thing left to do is to argue that we can always find a good online-LOCAL run in the
construction and to compute the final size of the experiment graph, and hence the locality of B. We
start with the former: Consider phase ℓ. All subsequent phases contain Pn
k=ℓ+1 Nkgk graphs, the
simulation uses at most n graphs, and each of those may use at most n previously-used components.
Hence, nodes from phase ℓcan be used at most
n + n
n
X
k=ℓ+1
Nkgk ≤n + ng
n
X
k=ℓ+1
Nk ≤n +
Nℓ
2|Σout|
As n ≪Nℓ, we get that
Nℓ
|Σout| ≥n + n
n
X
k=ℓ+1
Nkgk,
that is the future phases won’t run out of components.
Finally, the size of the experiment graph is
N = n
n
X
ℓ=1
Nℓgℓ≤N0 = n(3|Σout| gn)n+1 = n2O(n3) = 2O(n3),
and it belongs to F as F is closed under disjoint graph union and node/edge removal.
The next lemma shows how to generalize the idea behind Lemma 7.5 all the way up to randomized
online-LOCAL.
Lemma 7.6. Let Π be an LCL problem with degree constraint ∆, input label set Σin and output
label set Σout. Let A be a randomized online-LOCAL algorithm solving Π over a family Fof graphs
that is closed under disjoint graph union and node and edge removals. Assume A has locality T(n)
and success probability p(n) > 0 for an n-node graph. Then there exists an amnesiac online-LOCAL
algorithm A′ that solves Π on a graph in F with n nodes with locality T(2O(n3) + 2O(2n2) · log
1
p(n)).
Note the locality is such that, if p(n) converges to 1 fast enough, then we only have a 2poly(n)
blowup in the locality (instead of a doubly-exponential one).
Proof. The main idea is to adapt the proof of Lemma 7.5. The main challenge is that the construction
of the simulation graph in the proof of Lemma 7.5 was adaptive to the output of the deterministic
online-LOCAL algorithm; however, the adversary in the randomized online-LOCAL model is oblivious
to the randomness of the algorithm. In fact only a q′ = 1/|Σout| fraction of components in each
phase of the proof of Lemma 7.5 are good, and we cannot adaptively choose to use only those.
To combat this, we modify the experiment: instead of adaptively choosing only the good
components and discarding the rest, we sample the components from the previous phases uniformly
at random without replacement. We later show that the sampled component is good with probability
at least q = q′/2. In the worst case, each component at layer Nℓmay use up to n partial one-
component online-LOCAL runs from the previous layers N1, . . . , Nℓ−1, each of which is sampled to be
good with probability only q. As the construction is n levels deep (i.e., there are n layers N1, . . . , Nn)
38

--- Page 40 ---
and the whole construction needs to work for all up to g = 2n2|Σin| n different partial one-component
online-LOCAL runs, the total probability of finding a good label in all Nℓ, ℓ∈[n], is at least qgn2.
This probability is minuscule, but we can boost it by increasing the size of the construction by
considering
k = 1 +

q−2n2|Σin|nn2 log
1
p(n)

disjoint copies of the simulation graph independently. Letting N be the size of a single simulation
graph, kN is then the size of the whole experiment. Since N = 2O(n3) in Lemma 7.5, we have
kN = 2O(n3) + 2O(2n2) log
1
p(n).
The probability that each simulation graph does not contain all the necessary good labels in all
layers is at most

1 −qgn2k
≤e−kqgn2
= e−kq2n2
|Σin|nn2
< p(n).
Since the success probability of A is p(n), by the inclusion-exclusion principle, we get positive
probability that least one simulation graph in the experiment contains all the necessary good labels
and, in addition, A does not fail on it.
We show that the probability of sampling a good component is indeed at least q = 1/(2|Σout| ).
Consider the components in phase ℓ. For each component type, there are at least Nℓ/|Σout| that are
good. By the calculations in the proof of Lemma 7.5, future layers will use at most Nℓ/(2|Σout| ) of
them. Hence, after each step, at least 1/(2|Σout| ) = q fraction of the components are still good and
unused, as desired.
We finish the proof by showing that there indeed exists an amnesiac algorithm A′ as in the claim.
As argued above, our experiment succeeds with positive probability. After fixing the randomness
f : V (H) →{0, 1}N of the algorithm A, we obtain a uniquely defined deterministic online-LOCAL
algorithm A[f] that behaves exactly as A when given the random bit string f as input. In particular,
for such f, the following holds:
1. There exists a simulation graph with the necessary number of good labels in all layers.
2. A[f] does not fail on the aforementioned simulation graph.
Now the amnesiac algorithm B works as follows: Since there are finitely many possible simulation
graphs and finitely many behaviors of A[f] (for all possible f), B executes a preprocessing phase in
which it goes over all possible simulation graphs and tries all possible deterministic online-LOCAL
algorithms (according to some ordering, e.g., lexicographical in the description) until it finds the
pair with the properties 1 and 2 above. We take such pair and use the labeling for that component
as the base for our amnesiac algorithm. Proceeding as in the proof of Theorem 7.1, we then obtain
an amnesiac algorithm that has locality
T

2O(n3) + 2O(2n2) log
1
p(n)

.
7.3
From online-LOCAL to SLOCAL
We first show how the SLOCAL model can nicely “partition” a rooted forest. The idea is not new
and comes from [23, Section 7] where it is directly applied to the LOCAL model; we present here
an adaptation to SLOCAL. The definition of rooted forest is given in Section 6. For a rooted forest
39

--- Page 41 ---
Figure 3: A (3, 4)-clustering of a rooted tree. The leader nodes are colored and their closed clusters
marked with their respective color.
G = (V, E) and each node v ∈V , we denote by Gv the subtree of G that is rooted at v. A root-to-leaf
path v0v1 . . . vk, where vi ∈V for all i ∈{0, 1, . . . , k}, is a path of a rooted tree such that (vi, vi−1)
is an edge for all i ∈[k]: we say that the path starts at v0 and ends at vk.
Definition 7.7 ((α, β)-clustering of rooted trees). Let G = (V, E) be a rooted forest. An (α, β)-
clustering of G is a subset L ⊆V of leader nodes that contains the root and is such that, for each
v ∈L, the following properties are met:
1. Gv does not contain elements of L at levels 1, . . . , α −1.
2. Each maximal oriented path in Gv contains exactly one element u ∈L such that distGv(u, v) ∈
[α, β], unless the length of the maximal oriented path is at most β −1, in which case there is
at most one element of L in the path (and possibly none).
A cluster is a maximally connected component of non-leader nodes. A closed cluster is a cluster
together with its adjacent leader nodes. See Fig. 3 for an example.
We will combine many SLOCAL algorithms: it is easy to prove that the combination of two
SLOCAL algorithms with localities T1, T2 gives an SLOCAL algorithm with locality O(T1 + T2) [38,
Lemma 2.3].
Lemma 7.8. Let α ∈N+, and let G = (V, E) be a rooted forest. There is an SLOCAL algorithm
with locality O(α) that produces an (α −1, 2α + 1)-clustering of G.
Proof. We combine some SLOCAL algorithms. Consider first the following algorithm A1: Suppose a
node v ∈V is picked by the adversary and asked to commit to something. For each root-to-leaf path
v0v1 . . . v2α−1 (with v0 = v) that v can distinguish using locality 2α −1, in parallel, v precommits
40

--- Page 42 ---
that the node vα−1 is the leader of the path vα−1vα . . . v2α−1 unless there is another precommitment
on the path within distance α from v.
Next we define an algorithm A2 that takes as input a rooted forest labelled by A1: Each node v
looks at its radius-α neighborhood and checks if there is some other (unique) node that precommitted
for v in the neighborhood. If so, it becomes a leader and stores the path that is under its leadership,
otherwise it does nothing.
The final algorithm A3 takes as input a rooted forest labelled by A2 and is defined as follows:
Each node v becomes a leader if and only if it belongs to an oriented root-to-leaf path v0v1 . . . vα−1,
with vα−1 = v lead by v0. All other nodes do not output anything, except the root, that becomes a
leader.
We now prove that the SLOCAL algorithm A providing the clustering is the composition of A1,
A2, and A3, and has locality O(α).
Notice that the root is a leader thanks to A3. Property 1 in Definition 7.7 is satisfied due to A3
as well. Furthermore, for each maximal root-to-leaf path, consecutive leader nodes must be within
distance at most 2α + 1 between each other, unless the path ends with a leaf at distance at most 2α
from the last leader. In fact, if the distance between consecutive leaders is at least 2α + 2, or there
is only one leader and the path is longer than 2α from the last leader, there would be at least one
non-leader node that does not see any leader within distance α in the path, which is impossible due
to how precommitments are done in A1.
We can now prove Theorem 7.1, which we restate here for the reader’s convenience:
Theorem 7.1. Let Π be an LCL problem with degree constraint ∆, input label set Σin, output label
set Σout, and checking radius r > 0. In addition, let A be an online-LOCAL algorithm solving Π with
locality T(n) over rooted forests. Then the following holds:
1. If A is deterministic, then there exists a deterministic SLOCAL algorithm solving Π with locality
O(r) + T(2O(n3)).
2. If A is randomized and has success probability p(n) > 0, then there exists a deterministic
SLOCAL algorithm solving Π with locality O(r) + T(2O(n3) + 2O(2n2) · log
1
p(n)).
Proof. Let G denote the input graph, which is a rooted forest, and assume A is a deterministic
online-LOCAL algorithm. We can apply Lemma 7.5 to get an amnesiac algorithm A′ that solves
Π with locality T ′(n) = T(2O(n3)). We now show how to get an SLOCAL algorithm B solving the
problem with roughly the same locality. B is the composition of four different SLOCAL algorithms
B1, B3, B3, B4, each of them having locality O(T ′):
1. We first use Lemma 7.8 with α = 10T ′ + 4r, where r is the checking radius of Π, and obtain
an algorithm B1 that outputs an (α −1, 2α + 1)-clustering of G with locality O(α).
2. Now consider an algorithm B2 with locality 2α + 4r that takes as input G as labelled by B1
and works as follows: When processing a leader node v, it collects the topology of the radius-2r
neighborhood of the set composed of the closest leaders v sees in each root-to-leaf path. Then,
v runs A′ in this neighborhood and precommits a solution to the LCL for the nodes in such
neighborhood. If v is the root, it also presents its own radius-2r neighborhood to A′ and
precommits a solution for the whole neighborhood. Observe that all such neighborhoods are
disjoint by construction of the (α −1, 2α + 1)-clustering.
3. B3 also has locality 2α + 4r and just makes all nodes whose label has been precommitted by
some other node actually output the precommitted label. (The output of B2 guarantees there
are no conflicts to be resolved.)
41

--- Page 43 ---
4. Finally, B4 has again locality 2α + 4r and just brute-forces a solution in each cluster. The
solution is guaranteed to exist because A′ was run in all disjoint neighborhoods and works
correctly. In fact, B4 can just continue calling A′ on each cluster it sees.
The combination of B1, B2, B3, and B4 yields a deterministic SLOCAL algorithm B that has
locality O(α) = O(r) + O(T ′(n)).
The same argument applies to a randomized online-LOCAL algorithm, the only change is that
now T ′ is T ′(n) = T(2O(n3) + 2O(2n2) · log
1
p(n)).
7.4
From SLOCAL to LOCAL
It is folklore that all LCL problems that have complexity O(1) in SLOCAL belong to the complexity
class O(log∗n) in LOCAL. Then, to obtain Theorem 1.5, it suffices to show that all LCLs with
complexity o(log n) in SLOCAL in rooted trees actually belong to the complexity class O(1). We
restate Theorem 7.2.
Theorem 7.2. Let A be an SLOCAL algorithm solving an LCL problem Π that runs with locality
o(log∆n) over rooted forests of maximum degree ∆and n nodes. Then, there exists an SLOCAL
algorithm B solving Π with locality O(1).
Proof. Assume Π has checking radius r ≥0, and T(n) = o(log∆n) to be the locality of A. Further-
more, w.l.o.g., suppose T(n) ≥r for all n large enough. Let N be a large enough integer such that
T(N) = k ≥r. Let G be a rooted tree of maximum degree ∆with n nodes. We now construct a
new SLOCAL algorithm B which is the composition of many SLOCAL algorithms.
For the first SLOCAL algorithm B1, we make use of Lemma 7.8 where α = ⌊(log∆N −2)/4⌋.
Hence, B1 yields an (α −1, 2α + 1)-clustering of G in time O(α), with α −1 ≥(log∆N −10)/4 and
2α + 1 ≤(log∆N)/2. Hence, any closed cluster will have at most ∆2α+1 ≤
√
N nodes (including
the adjacent leader nodes).
Then, we consider a second SLOCAL algorithm B2 that takes G and the (α −1, 2α + 1)-clustering
of G in input and reassigns identifiers from the set [N] “locally”. To better describe how B2 works,
let us define some notation. For each leader node v, let Cv denote the closed cluster where v is the
leader node of minimum level, and let Lv be the set of leader nodes in Cv except for v. Consider a
partition of the nodes in (Cv \ Nk(v)) ∪Nk(Lv) according to their distance from v. More specifically,
C(1)
v
contains all nodes that have distance between k + 1 and ⌊(α −1)/4⌋from v, while, for i ∈{2, 3},
C(i)
v
contains nodes that have distance between ⌊(α −1)/(6 −i)⌋+ 1 and ⌊(α −1)/(5 −i)⌋from v.
Finally, C(4)
v
contains all the other nodes in Cv, which have distance at least ⌊(α −1)/2⌋+ 1 from v.
Notice that |(Cv \ Nk(v)) ∪Nk(Lv)| ≤∆2α+1+k ≤∆(log∆N)/2+o(log∆N) ≤N2/3 for N large enough.
Then, B2 works as follows: When a non-leader node is picked by the adversary, nothing happens.
When a leader node v is selected, it precommits identifiers for the nodes in (Cv \ Nk(v)) ∪Nk(Lv). In
details, it assigns identifiers from 1 to ⌊N/4⌋to nodes in C(1)
v , from ⌊N/4⌋+ 1 to ⌊N/2⌋to C(3)
v , from
⌊N/2⌋+ 1 to ⌊3N/4⌋to C(2)
v , from ⌊3N/4⌋+ 1 to N to C(4)
v . Notice that, since
C(i)
v
 ≤N2/4, then
even ⌊N/5⌋distinct identifiers are enough to cover the whole region C(i)
v
when N is large enough.
Furthermore, if v is the root of the whole graph, it precommits distinct identifiers from the set
{⌊3N/4⌋+ 1, . . . , N} for the nodes that have distance at most k from v (v itself included).
The third and last SLOCAL algorithm B3 takes as input the whole rooted tree with the clustering
given by B1 and the output of leader nodes given by B2, and computes the solution to the problem
as follows: Every node u (that does not belong to Cv where v is the root of the graph) looks at its
two closest leader nodes v(1)
u
(the closest one) and v(2)
u
(the second closest one) that are ancestors
42

--- Page 44 ---
(if u is a leader, it still looks up in the tree for two different leader ancestor), and collects all the
information regarding identifiers for G[Nk(Cv(1)
u )]. In this way, u can locally simulate A on a “virtual
graph” Gu = G[Nk(Cv(1)
u )] with
Nk(Cv(1)
u )
 ≤N nodes. The adversarial ordering according to which
A processes Gu = G[Nk(Cv(1)
u )] is induced by the ordering of the identifiers. Notice that it might
still be that A processes two nodes at the same time but, due to the assignment of identifiers done
by B2, the outputs of these nodes can be determined independently of each other. Then, u outputs
whatever A outputs on u according to this simulation. If u is the root of the whole graph, then it
knows already the all the identifiers needed to run A in G[Nk(Cu)]. If u is in Cv and Cv is the cluster
of the root node of the graph, then by accessing the memory of v it gets access to all the information
it needs to compute its output.
Notice that each Bi has locality O(α), hence the whole algorithm B obtained by the composition of
B1, B2, and B3 has locality O(α) by [38, Lemma 2.3]. Observe also that O(α) = O(log∆N) = O(1).
Also, the final output of B is correct: Suppose, by contradiction, that there is a failure somewhere,
that is, a node v could detect its neighborhood Nr(v) as non-admissible. Suppose v does not belong
Cu where u is the root of the graph, and denote its two closest ancestors that are leader nodes by
v(1)
u
(the closest one) and v(2)
u
(the second closest one). We have two cases. If u ∈C(4)
v(2)
u ∪C(1)
v(1)
u ∪C(2)
v(1)
u ,
then its output must be correct: it is completely determined by G[Nk(Cv(1)
u ∩(C(4)
v(2)
u ∪C(1)
v(1)
u ∪C(2)
v(1)
u ))]
which contains only distinct identifiers (because it is a subgraph of G[C(4)
v(2)
u
∪C(1)
v(1)
u
∪C(2)
v(1)
u
∪C(3)
v(1)
u ])
and hence can be extended to a valid input for A with N nodes (choosing identifiers arbitrarily
in [N2] \ [N] and extending the adversarial processing order respecting the ordering induced by
identifiers). In the second case, u ∈C(3)
v(1)
u ∪C(4)
v(1)
u . Also in this case the output of u must be correct:
it is completely determined by G[Nk(Cv(1)
u ∩(C(3)
v(1)
u ∪C(4)
v(1)
u ))] which contains only distinct identifiers
(because it is a subgraph of G[C(2)
v(1)
u ∪C(3)
v(1)
u ∪C(4)
v(1)
u ]) and hence can be extended to a valid input for A
with N nodes (choosing identifiers arbitrarily in [N2] and extending the adversarial processing order
respecting the ordering induced by identifiers). An analogous argument holds for nodes in Cv where
v is the root node of the graph.
8
Lower bound for 3-coloring grids in randomized online-LOCAL
In this section, we will show that 3-coloring (√n × √n)-grids in randomized online-LOCAL requires
Ω(log n)-locality:
Theorem 8.1. The locality of a randomized online-LOCAL algorithm for solving 3-coloring in
(√n × √n)-grids is Ω(log n).
We will base our proof on the recent result of Chang et al. [22], where the authors show a similar
lower bound for the deterministic online-LOCAL model. We will start with a brief overview of the
techniques used in [22].
8.1
Relevant ideas from Chang et al. [22]
The lower bound in [22] is based on the idea that any coloring of a grid G with the three colors
{1, 2, 3} can be partitioned into regions with colors 1 and 2 that are separated by boundaries of
color 3. Formally, a region is a maximal connected component that is colored only with colors 1 and
2, while a boundary is a maximal connected component in G2 that is colored only with color 3. It
43

--- Page 45 ---
B1
B2
1
1
1
1
1
2
2
2
2
2
2
2
2
3
3
3
3
3
u
v
Figure 4: Example of a 3-colored grid with two boundaries B1 and B2 that have different parities.
As one can see, b(u, v) = 2: No matter if we take the blue or the red path from u to v, we always
cross B1 and then B2.
is crucial to observe that the boundaries of color 3 are not always compatible and that they have
parities of their own (see Fig. 4). Indeed, the core idea of the proof is to constrict many incompatible
boundaries of color 3 to a small space, thus requiring a view of Ω(log n) to resolve them.
Using the same terminology as [22], we count incompatible boundaries between two points by
using so-called a- and b-values. The a-value is defined as an edge weight between any two nodes and
captures the change of colors 1 and 2.
Definition 8.2 (a-value [22]). Given a directed edge (u, v) and a 3-coloring of the nodes c : V 7→
{1, 2, 3}, we define
a(u, v) =
(
c(u) −c(v),
if c(u) ̸= 3 and c(v) ̸= 3
0,
otherwise.
Observe that the a-value of any directed 4-cycle in a grid is equal to 0. Using the a-value, we
define the b-value of a path.
Definition 8.3 (b-value [22]). For a directed path P, its b-value is defined as
b(P) =
X
(u,v)∈H
a(u, v).
On a high level, the b-value of a path describes the cumulative total of incompatible boundaries
along this path. Note we say “cumulative” because in this count boundaries of the same parity cancel
each other out. Indeed, if we consider the b-value of a simple directed cycle in a grid, then it must
be equal to 0:
Lemma 8.4 (b-value of a cycle is zero [22]). Let C be a directed cycle in G. Then b(C) = 0.
As an example, observe that a path that starts and ends with color 3 and otherwise is colored
with colors 1 and 2 always has a b-value of 0 or 1. In particular, the b-value is 1 if the distance
between the nodes of color 3 is even (and thus the boundaries are incompatible). Meanwhile, a path
that goes through two incompatible regions has a total b-value of 2. Nevertheless, a path going
through two boundaries that are compatible has a total b-value of 0.
44

--- Page 46 ---
Lemma 8.5 (Parity of the b-value [22]). Let P denote any directed path of length ℓthat starts in
node u and ends in node v in a grid. Then, the parity of b(P) is
b(P) ≡β(u) + β(v) + ℓ(mod 2)
where β is an indicator variable stating whether a node is of color 3 or not:
β(u) =
(
1,
if c(u) = 3
0,
otherwise.
Observe that the parity of the b-value of a path is determined by the colors of the endpoints of
this path.
8.2
From deterministic to randomized online-LOCAL
Suppose that we are given a randomized online-LOCAL algorithm with visibility radius T = o(log n).
Our goal is to prove the algorithm fails to solve the 3-coloring problem. Using Yao’s minimax
principle, we show how to construct an (oblivious) adversarial distribution of inputs so that any
deterministic online-LOCAL algorithm fails with noticeable probability.
As in [22], the lower bound consists of two main steps:
1. First we show how to force paths to have an arbitrarily large b-value. Generally we cannot
force a large b-value between the path’s endpoints (or in fact between any two fixed nodes),
but we do get the guarantee that it contains two nodes v1 and v2 where b(v1, v2) is large. Note
the location of v1 and v2 is completely unknown to us since we are working with an oblivious
adversary. The construction is inductive: Given a procedure that generates a path with b-value
≥k −1 with probability ≥1/2, we show how to generate a path with b-value ≥k also with
probability ≥1/2. (Cf. the construction in [22] with an adaptive adversary, which succeeds
every time.) Since we invoke the construction for k −1 a constant number of times, we are
able to obtain any desired b-value of k = o(log n) with high probability. Note it is logical that
we cannot do much better than this as it would contradict the existing O(log n) deterministic
online-LOCAL algorithm.
2. The second step is to actually obtain a contradiction. (See Fig. 5.) First we construct a path
P1 with large b-value, say ≫4T, between nodes us and vt. To get the contradiction, we wish
to place two nodes ws and wt next to us and vt, respectively, so that the four node cycle has
positive b-value (which is impossible due to Lemma 8.4). If we had an adaptive adversary as
in [22], this would be relatively simple: Since the adaptive adversary knows the location of
us and vt, it just constructs an arbitrary path P2 with the same size as P1, picks any two ws
and wt that are at the same distance from each other as us and vt, mirrors P2 if needed to
obtain a non-negative b-value, and then places this at minimal distance to P1. We show that,
allowing for some failure probability, we do not need any information about us and vt (i.e., nor
their location nor the distance between them) in order to obtain the same contradiction.
We now proceed with the proof as outlined above. Accordingly, the first step is the following:
Lemma 8.6. Given any k = o(log n), there is an adversarial strategy to construct a directed path of
length no(1) with a b-value of at least k against any online-LOCAL algorithm with locality T = o(log n).
Moreover, this strategy succeeds with high probability.
Proof. Consider the following recursive construction:
45

--- Page 47 ---
• If k = 0, create a single node with previously unrevealed nodes all around it (inside the visibility
radius T).
• Otherwise, repeat the following steps four times in total:
– Create four distinct paths P1, P2, P3, P4 by following the procedure for k −1.
– Toss independent fair coins c1, c2, c3 ∈{0, 1}.
– Connect the Pi’s horizontally aligned and in order while placing ci + 1 nodes between
paths Pi and Pi+1.
Let Q1, Q2, Q3, Q4 be the four paths created by this procedure (each having their own four
Pi’s coming from the procedure in the previous iteration k −1). Next, we connect the Qi’s
horizontally aligned with each other and in arbitrary order. Note that we need to place an
additional node between each pair of Qi’s. Otherwise, we would have to have revealed the
edge between the two endpoints too early to the algorithm.
Thus, for k ≥1 we have 16 invocations of the procedure for k −1 in total. We argue that, with
probability at least 1/2, the path yielded by this procedure contains a segment with b-value at least
k. By repeating this procedure O(log n) times independently, we obtain at least one path with the
desired property with high probability.
To prove that the recursive construction works, we proceed by induction. Fix k ≥1 and suppose
that the procedure for k −1 succeeds with probability p ≥1/2 at yielding a segment with b-value at
least k −1. Let us first consider Q1. Let Xi be a random variable that is 1 if this occurs for path Pi
and 0 otherwise. Then we have
Pr
" 4
X
i=1
Xi < 2
#
= Pr
" 4
X
i=1
Xi = 0
#
+ Pr
" 4
X
i=1
Xi = 1
#
= (1 −p)4 + 4p(1 −p)3
= (1 −p)3(1 + 3p)
≤1
2.
Hence, with probability at least 1/2 there are at least two paths Pi and Pj, i < j, for which the
construction succeeds.
Since we are dealing with paths, we may simplify the notation and write b(u, v) for the b-value
of the (unique) segment that starts at u and ends at v. Let thus ui, vi, uj, vj appear in this order in
Q1 and |b(ui, vi)|, |b(uj, vj)| ≥k −1. Next we will show that, conditioned on this assumption, the
probability that Q1 contains a segment with b-value at least k is at least 1/2. Hence, a priori, Q1
contains such a segment with probability at least 1/4. Since all Qi’s are constructed the in the same
way and independently of one another, the probability that at least one of the Qi’s contains such a
segment is at least 1 −(1 −1/4)4 > 1 −1/e > 1/2.
Let us write σ(x) for the sign function of x (i.e., σ(x) = 1 if x > 0, σ(x) = −1 if x < 0, and
σ(0) = 0). To see why the above holds for Q1, consider the two following cases:
Case 1: σ(b(ui, vi)) = σ(b(uj, vj)). Using Lemma 8.5, we have that b(vi, uj) ≡β(vi) + β(uj) +
ci + · · · + cj−1 (mod 2). Since β(vi) and β(uj) are fixed, and the coin tosses are independent,
we have |b(vi, uj)| ̸≡k −1 (mod 2) with probability 1/2. Assuming this holds, we have either
46

--- Page 48 ---
|b(vi, uj)| ≥k, in which case we are done, or |b(vi, uj)| ≤k −2. Since b(ui, vi) and b(uj, vj)
have the same sign, we have
|b(ui, vj)| = |b(ui, vi) + b(vi, uj) + b(uj, vj)|
≥|b(ui, vi) + b(uj, vj)| −|b(vi, uj)|
≥2(k −1) −(k −2)
= k.
Case 2: σ(b(ui, vi)) ̸= σ(b(uj, vj)). Arguing by using Lemma 8.5 as before, we obtain that
|b(vi, uj)| ̸≡0 (mod 2) holds with probability 1/2. Assuming this is the case, we have thus
|b(vi, uj)| ≥1. Without restriction, let σ(b(ui, vi)) = σ(b(vi, uj)). Then
|b(ui, uj)| = |b(ui, vi) + b(vi, uj)| ≥k −1 + 1 = k.
Finally, let us confirm that the construction fits into the (√n × √n)-grid. We only reveal at
most 2T + 1 = o(√n) in a column, so we need to only consider nodes along a row. The initial path
contains m0 = 2T + 1 visible nodes and in the i-th recursive step we have mi ≤16pi−1 + 27 visible
nodes in total for i ≥1. (Inside each Qi we need at most 2(4 −1) = 6 additional nodes to join the
four Pi’s, and to join the four Qi’s we need an additional 3 nodes.) Solving the recursion, in the
k-th step we have thus
mk = 1
5

24k+1(5T + 7) −9

= no(1)
visible nodes along the path since k, T = o(log n).
We now illustrate the idea for getting the contradiction previously described. (See Fig. 5.)
Invoking Lemma 8.6, we obtain a path P1 with a b-value of 4T + 4 between two nodes us and vt
(whose positions are unknown to us). Letting L be the length of P1, we (arbitrarily) create a second
path P2 of length 10L and then randomly choose how to align P1 and P2. More specifically, letting
u be the first node in P1, we choose some node w of P2 uniformly at random and align u and w;
then we mirror P2 with probability 1/2 and reveal it at distance 2T + 2 to P1 (which is consistent
with all previously revealed nodes).
The reason why this works is the following: Since P1 has length L and P2 length 10L, with at least
4/5 we align the paths so that each node in P1 has a matching node underneath it in P2. Let ws and
wt be the nodes matching us and vt, respectively. Then because we mirror P2 with probability 1/2,
we get that b(ws, . . . , wt) is at least zero in expectation (conditioned on having properly aligned the
two paths). Hence, with probability at least 2/5 we obtain a cycle (us, . . . , vt, . . . , wt, . . . , ws, . . . , us)
where b(us, . . . , vt) > 4T + 4, b(wt, . . . , ws) ≥0, and b(vt, . . . , wt), b(ws, . . . , us) ≥−2T −2 (due to
the distance between the two paths).
Proof of Theorem 8.1. Observe that, using Lemma 8.6, we can construct a path P1 = (u0, . . . , uL)
of length L = no(1) where some segment (us, . . . , ut) of P1 has a b-value of k > 4T + 4. Next we
construct a path P2 = (v0, . . . , v10L) of length 10L that will be placed below P1. We assume that
the points of the path are revealed to the algorithm in some predefined order.
The position and orientation of P2 are chosen as follows:
1. Choose a node vr ∈[L, 9L] of P2 uniformly at random. This node is placed below the node u0
of P1 at 2T + 2 distance from it.
2. Throw a fair coin m ∈{0, 1}. If m = 1, mirror P2 along the vertical axis that goes through u0
and vr.
47

--- Page 49 ---
v0
vr
ws
wt
v10L
u0
us
ut
uL
P2
P1
b(us, . . . , ut) ≥k
b(wt, . . . , ws) ≥0
T
T
2T + 1
Figure 5: How to turn paths with large b-value into a contradiction. Here the blue area includes
the nodes revealed so far around the path segments (u0, . . . , uL) and the corresponding part of P2
underneath it. The green segments are the two segments we consider in the proof. A cycle going
through both paths leads to a contradiction.
The nodes of P2 are revealed to the algorithm in the same predefined and possibly mirrored order.
See Fig. 5 for an example.
We next prove that we obtain the desired lower bound. First notice that, since we pick vr ∈[L, 9L],
every node in P1 has a counterpart in P2 whether we mirror P2 or not. Let (ws, . . . , wt) denote the
segment matched to (us, . . . , ut). Consider the case where either of the following is true:
• m = 0 and r ∈[L, 9L −s −t]
• m = 1 and r ∈[L + s + t, 9L]
Denoting by E the event in which this occurs, note we have
Pr[E] = 1
2 Pr[r ∈[L, 9L −s −t]] + 1
2 Pr[r ∈[L + s + t, 9L]] = 8L −s −t + 1
9L + 1
≥6L + 1
9L + 1 > 2
3.
Now conditioned on E, notice that every segment (vx, . . . , vy) where x ∈[L + s, 9L −s] and
y ∈[L + t, 9L −t] has equal probability of being matched with (us, . . . , ut) either in the same
direction (i.e., ws = vx and ut = vy) or reversed (i.e., ws = vy and wt = vx). Hence,
Pr[b(wt, . . . , ws) ≥0 | E] ≥1
2.
(In fact, the probability is exactly 1/2 if b(wt, . . . , ws) > 0 and 1 if b(wt, . . . , ws) = 0.) Thus, the
probability that b(wt, . . . , ws) ≥0 is > (2/3) · (1/2) = 1/3.
From here on, we proceed as in [22]. By Lemma 8.4, the cycle (us, . . . , ut, . . . , wt, . . . , ws, . . . , us)
must have a b-value of 0. However, recall that the b-value of a path is bounded by its length by
definition. In our case, −2T −2 < b(ut, . . . , wt) < 2T + 2, −2T −2 < b(ws, . . . , us) < 2T + 2,
b(us, . . . , ut) ≥k, and b(wt, . . . , ws) ≥0. In order for the b-value of the cycle to be 0, we would need
to have 2(2T + 2) ≥k, which is a contradiction. Since this occurs with noticeable probability (i.e.,
> 1/3), the claim follows.
9
Dynamic-LOCAL derandomizes LOCAL and breaks symmetry
This section presents a derandomization result for the dynamic-LOCAL model: we show that not
only dynamic-LOCAL can simulate randomized LOCAL with no overhead in the locality, but actually
it brings the complexity class O(log∗n) in randomized LOCAL down to O(1).
48

--- Page 50 ---
We make use of the method of conditional expectations from [39] to derandomize the model of
dynamic-LOCAL computation. We note that while the following theorems are proven for the class of
all graphs, they can be extended to any subclass of graphs.
Theorem 9.1. Let Π be an LCL problem, and let A be a randomized LOCAL algorithm solving Π
with locality T(n) and probability p > 1 −1/n. Then there exists a deterministic dynamic-LOCAL
algorithm A′ solving Π with locality O(T(n)).
Proof. The randomized LOCAL algorithm A can be viewed as a deterministic LOCAL algorithm
which is given i.i.d. random variables Rv locally for each node v. We show that there exists a
dynamic-LOCAL algorithm with locality O(T(n)) that assigns fixed values ρv for each Rv such
that when A is run on these values as Rv, it produces a correct output for problem Π. Such
dynamic-LOCAL clearly implies an O(T(n))-locality dynamic-LOCAL algorithm for problem Π as
one can compose it with A. The proof uses a technique similar to that of derandomizing LOCAL
algorithms in SLOCAL [39].
We use the method of conditional expectation. Let Fv be a flag that is 1 when the output around
node v is invalid, and 0 otherwise. Note that Fv depends only on the radius-r neighborhood of
node v. Let F = P
v∈V Fv. As Π is an LCL problem, F = 0 iff the labeling is correct for the whole
graph, and otherwise F ≥1. By definition, E[F] = P
v∈V E[Fv] ≤n(1 −p) < 1.
Let σ = e1, e2, . . . , em be the order of edges in which the adversary dynamically modifies the
graph, and let Gi be the graph after modification i. Note that any edge can appear multiple times
in the sequence if the adversary also removes edges.
Now algorithm A′ sets the randomness as follows: In step i, algorithm A′ first clears ρu for all
nodes u with dist(u, ei) ≤T(n) + r. Then
E[F |
^
u,dist(u,ei)>T(n)+r
Ru = ρu] < 1
as
E[F |
^
u
Ru = ρu] < 1
in the previous step. Hence, there exists some concrete values for ρu for dist(u, ei) ≤T(n) + r such
that E[F | V
u Ru = ρu] < 1. Algorithm A′ sets all ρu to such values. Finally, algorithm A′ simulates
A for all nodes within radius T(n) + r from ei with randomness fixed at ρ.
This produces a correct labeling for all nodes as E[F | V
u Ru = ρu] < 1, and hence
E[F |
^
u
Ru = ρu] = 0.
Theorem 9.2. Let Π be an LCL problem, and let there exist a randomized LOCAL algorithm solving
it with locality O(log∗n). Then there exists a dynamic-LOCAL algorithm solving Π with locality O(1).
Proof. Using [21], a randomized LOCAL algorithm for solving Π with locality O(log∗n) implies the
existence of a deterministic LOCAL algorithm solving Π with locality O(log∗n). Moreover, the
deterministic LOCAL algorithm can be normalized into an algorithm that first finds a distance-k
coloring with O(∆k) colors for some constant k, and then applies an O(k)-locality LOCAL algorithm
A on this coloring.
The dynamic-LOCAL algorithm for solving Π maintains a distance-k coloring with O(∆k) colors
on the graph, and then applies A on these colors. When the dynamic-LOCAL algorithm encounters
an update, it first clears the colors of all nodes within distance k from the update, and greedily
49

--- Page 51 ---
assigns new colors for those nodes. The greedy assignment always succeeds since each node can
have at most ∆k neighbors within distance k hence they can use at most ∆k of the available colors.
Finally, the algorithm applies A on all nodes of the graph. As A is a deterministic LOCAL algorithm
with locality O(k), and only the colors of nodes within distance k of the update have changed, we
have that only the output of nodes within distance O(k) = O(1) from the update change.
10
Randomized online-LOCAL with an adaptive adversary
This section aims at showing that randomized online-LOCAL with an adaptive adversary is as strong
as its deterministic counterpart. The proof is very similar to the proof of Theorem 9.1 and uses,
again, the method of conditional expectations. Also, as in the previous section, the results can be
extended to any subclass of graphs.
Theorem 10.1. Let Π be an LCL problem, and let A be an online-LOCAL algorithm with an adaptive
adversary solving Π with locality T(n) and probability p > 1 −1/n. Then there exists a deterministic
online-LOCAL algorithm A′ solving Π with locality T(n).
Proof. Let A be an algorithm in the online-LOCAL model with an adaptive adversary and with round
complexity T(n). We construct a deterministic online-LOCAL algorithm A′ with the same round
complexity T(n) as follows: The algorithm A′ simulates A with certain fixed random-bit-strings. In
particular, whenever new nodes arrive at the input, the algorithm A′ fixes the random bits in all
newly arrived nodes in the way we describe below.
We view a run of an online-LOCAL algorithm with an adaptive adversary as a game between an
algorithm A and an adversary. In each step of that game, first the adversary chooses a set of nodes
that arrive at the input (one special node and its neighborhood). Then the algorithm A samples the
random bits of the newly arrived nodes and fixes the label of the arrived node. After i steps of this
game, we use F to denote the event that the adversary wins the game, that is algorithm A produces
an invalid output according to problem Π. By definition, we have Pr [F] ≤1/n. Here and from now
on, the probability expressions assume that the adversary maximizes the probability of F happening.
Our algorithm A′ in each i-th step fixes the random bits of the newly arrived nodes in a way
that guarantees that
Pr [F|B1 = b1, . . . , Bi = bi] ≤Pr [F|B1 = b1, . . . , Bi−1 = bi−1] .
Here, Bj = bj stands for fixing the values of random bits of nodes that arrived in the j-th step to bj.
We note that this can always be done since, by definition, we have
Pr [F|B1 = b1, . . . , Bi−1 = bi−1] = EBi [Pr [F|B1 = b1, . . . , Bi = bi]] .
Moreover, the online-LOCAL algorithm importantly both knows all the past arrived nodes and their
randomness, and can also consider all the different choices of the adversary in the future, and hence
can compute the above conditional probabilities.
At the end of the simulation of A, we have Pr [F|B1 = b1, . . . , Bn = bn] < 1, and hence the bad
event F does not occur. This implies that the algorithm A′ is always correct.
Remark 10.2. This proof assumes that we have white-box access to the randomized online-LOCAL
algorithm and that it uses finitely many random bits. If either of these assumptions does not hold,
we can use a more inefficient derandomization along the lines of [30]. Here, we just observe that an
online-LOCAL algorithm working against an adaptive adversary implies the existence of a function f
that maps all possible input sequences on all possible n-node graphs that can be produced by the
adversary to a valid output of the problem Π. The deterministic online-LOCAL algorithm finds such
a function f at the beginning of its execution and produces the output according to f.
50

--- Page 52 ---
11
LCL problems in paths and cycles in randomized online-LOCAL
In this section, we show that the complexity of LCLs in paths and cycles is either O(1) or Θ(n) in
randomized online-LOCAL (with an oblivious adversary).
Theorem 11.1. Let Π be an LCL problem on paths and cycles (possibly with inputs). If the locality
of Π is T in the randomized online-LOCAL model, then its locality is O(T + log∗n) in the LOCAL
model.
This theorem is a simple corollary of the following two lemmas:
Lemma 11.2. Let Π be an LCL problem on paths and cycles (possibly with inputs), and let A be a
randomized online-LOCAL algorithm solving Π with locality o(n). Then there exists a randomized
online-LOCAL algorithm A′ solving Π with locality O(1).
Lemma 11.3. Let Π be an LCL problem on paths and cycles (possibly with inputs), and let A be
a randomized online-LOCAL algorithm solving Π with locality O(1). Then there exists a LOCAL
algorithm A′ solving Π with locality O(log∗n).
By previous results [2], it is known that, in the case of paths and cycles, any (deterministic)
online-LOCAL algorithm with sublinear locality can be sped up to an online-LOCAL algorithm with
constant locality. We show how to extend [2, Lemma 5.5]. We start by constructing a large virtual
graph P ′ such that, when the original algorithm runs on the virtual graph P ′, the labeling produced
by the algorithm is locally compatible with the labeling in the original graph P.
Proof of Lemma 11.2. Let Π be an LCL problem in paths or cycles with checking-radius r, let P
be a path or a cycle with n nodes, and let A be a randomized online-LOCAL algorithm solving Π
with locality T(n) = o(n). In the proof of [2, Lemma 5.5], the authors use three phases to speed
up (deterministic) online-LOCAL with sublinear locality to only constant locality. We use the same
strategy to construct a randomized online-LOCAL algorithm A′ for solving Π with constant locality.
The phases for constructing randomized online-LOCAL algorithm A′ are as follows:
1. In the first phase, the algorithm deterministically creates an (α, α)-ruling set R for the path
P, mirroring the approach outlined in the proof of [2, Lemma 5.5].
2. In the second phase, the algorithm constructs a larger virtual path P ′ with N nodes and
simulates algorithm A on P ′ in the neighborhoods of nodes in R. Intuitively this path P ′
is constructed based on the pumping-lemma-style argument on LCL problems presented by
Chang and Pettie [19], and it only relies on (the definition of) problem Π, not the algorithm
A. During this simulation, the algorithm encounters a failure only if A fails within specific
neighborhoods of P ′. Consequently, the algorithm’s success in this phase aligns with the
success rate of A, ensuring a high probability of success.
3. The third phase is also as in [2, Lemma 5.5]: The algorithm extends the fixed labels around R
to the entire path P by applying brute force for nodes outside the neighborhood of R. Note that
this extending is feasible because of the way the path P ′ is created and the pumping-lemma-style
argument as discussed in [2].
In the end, we compose these three phases together to obtain the randomized online-LOCAL algorithm
A′ for solving Π with constant locality.
51

--- Page 53 ---
Proof of Lemma 11.3. This proof closely follows the argument presented in [2, Lemma 5.6]. Let
Π denote an LCL problem with a constant checking-radius r, and suppose A is a randomized
online-LOCAL algorithm solving Π with constant locality T. Define β = T + r + 1. As in [2, Lemma
5.6], we consider an input-labeled graph P formed by many copies of all feasible input neighborhoods
with a radius of β. We can depict P as a collection of disjoint path fragments that we later connect
to each other and create a long path with. Each of these path fragments has size 2β + 1, so the node
in the center of each segment (i.e., the (β + 1)-th node in the segment) has the same view (up to
radius β) as in the final path. Let V be the set of central nodes within these fragments.
We apply A to each node within the radius-r neighborhood of the nodes in V following an
arbitrary order and then terminate. These nodes have the same view as in the final path because
their distance to the endpoints is at most β −r = T + 1. We iterate the process multiple times,
yielding a distribution of output labels around the central nodes. Given that the size of P is constant,
there exists an output labeling L of the nodes occurring with probability p = Ω(1). If needed, we
can augment P with (constantly many) additional nodes such that |P| > 1/p.
We set this labeling L as the deterministic output for graph P and proceed similarly to the
deterministic case by constructing the canonical labeling f from L. Then, we use the function f
to construct a LOCAL algorithm with O(log∗n) locality following the same steps as in the proof of
[2, Lemma 5.6]. It is important to highlight that it is feasible to fill any gap of sufficient length
between parts labeled with the canonical labeling: If the algorithm A would never produce a valid
labeling for this gap, then the algorithm would fail to label P with probability at least p and, since
p ≥1/|P|, the algorithm A would not succeed with high probability.
Acknowledgments
We thank anonymous reviewers for their helpful feedback on previous versions of this work. This
work was supported in part by the Research Council of Finland, Grant 333837. Xavier Coiteux-
Roy is supported by the Swiss National Science Foundation. Francesco d’Amore is supported
by MUR FARE 2020 - Project PAReCoDi CUP J43C22000970001. Darya Melnyk is supported
by the European Research Council (ERC), grant agreement No. 864228 (AdjustNet), Horizon
2020, 2020-2025. Augusto Modanese and Shreyas Pai are supported by the Helsinki Institute for
Information Technology (HIIT). Marc-Olivier Renou acknowledges funding by INRIA through the
Action Exploratoire project DEPARTURE, and by the ANR for the JCJC grant LINKS (ANR-23-
CE47-0003).
Errata.
An earlier version of this manuscript (arXiv:2403.01903v1, posted on 2024-03-04) had
a mistake: we claimed a result analogous to Theorem 1.5 for unrooted trees (which would also
have implications on the complexity of the sinkless orientation problem). However, the proof had a
missing step, and we do not know if the proof can be fixed.
References
[1] Jon Aaronson, David Gilat, Michael Keane, and Vincent de Valk. An algebraic construction of
a class of one-dependent processes. The Annals of Probability, 17(1):128–143, 1989.
[2] Amirreza Akbari, Navid Eslami, Henrik Lievonen, Darya Melnyk, Joona Särkijärvi, and Jukka
Suomela. Locality in online, dynamic, sequential, and distributed graph algorithms. In Kousha
Etessami, Uriel Feige, and Gabriele Puppis, editors, 50th International Colloquium on Automata,
52

--- Page 54 ---
Languages, and Programming, ICALP 2023, July 10-14, 2023, Paderborn, Germany, volume
261 of LIPIcs, pages 10:1–10:20. Schloss Dagstuhl - Leibniz-Zentrum für Informatik, 2023.
doi:10.4230/LIPICS.ICALP.2023.10.
[3] Heger Arfaoui and Pierre Fraigniaud.
What can be computed without communications?
SIGACT News, 45(3):82–104, 2014. doi:10.1145/2670418.2670440.
[4] Alkida Balliu, Juho Hirvonen, Janne H. Korhonen, Tuomo Lempiäinen, Dennis Olivetti, and
Jukka Suomela. New classes of distributed time complexity. In Ilias Diakonikolas, David Kempe,
and Monika Henzinger, editors, Proceedings of the 50th Annual ACM SIGACT Symposium on
Theory of Computing, STOC 2018, Los Angeles, CA, USA, June 25-29, 2018, pages 1307–1318.
ACM, 2018. doi:10.1145/3188745.3188860.
[5] Alkida Balliu, Sebastian Brandt, Yi-Jun Chang, Dennis Olivetti, Mikaël Rabie, and Jukka
Suomela. The distributed complexity of locally checkable problems on paths is decidable. In
Peter Robinson and Faith Ellen, editors, Proceedings of the 2019 ACM Symposium on Principles
of Distributed Computing, PODC 2019, Toronto, ON, Canada, July 29 - August 2, 2019, pages
262–271. ACM, 2019. doi:10.1145/3293611.3331606.
[6] Alkida Balliu, Sebastian Brandt, Dennis Olivetti, and Jukka Suomela. How much does ran-
domness help with locally checkable problems? In Yuval Emek and Christian Cachin, editors,
PODC ’20: ACM Symposium on Principles of Distributed Computing, Virtual Event, Italy,
August 3-7, 2020, pages 299–308. ACM, 2020. doi:10.1145/3382734.3405715.
[7] Alkida Balliu, Sebastian Brandt, Juho Hirvonen, Dennis Olivetti, Mikaël Rabie, and Jukka
Suomela. Lower bounds for maximal matchings and maximal independent sets. Journal of the
ACM, 68(5):39:1–39:30, 2021. doi:10.1145/3461458.
[8] Alkida Balliu, Sebastian Brandt, Dennis Olivetti, and Jukka Suomela. Almost global problems
in the LOCAL model. Distributed Computing, 34(4):259–281, 2021. doi:10.1007/S00446-020-
00375-2.
[9] Alkida Balliu, Sebastian Brandt, Yi-Jun Chang, Dennis Olivetti, Jan Studený, and Jukka
Suomela. Efficient classification of locally checkable problems in regular trees. In Christian
Scheideler, editor, 36th International Symposium on Distributed Computing, DISC 2022, October
25-27, 2022, Augusta, Georgia, USA, volume 246 of LIPIcs, pages 8:1–8:19. Schloss Dagstuhl -
Leibniz-Zentrum für Informatik, 2022. doi:10.4230/LIPICS.DISC.2022.8.
[10] Alkida Balliu, Juho Hirvonen, Darya Melnyk, Dennis Olivetti, Joel Rybicki, and Jukka Suomela.
Local mending. In Merav Parter, editor, Structural Information and Communication Complexity
- 29th International Colloquium, SIROCCO 2022, Paderborn, Germany, June 27-29, 2022,
Proceedings, volume 13298 of Lecture Notes in Computer Science, pages 1–20. Springer, 2022.
doi:10.1007/978-3-031-09993-9_1.
[11] Alkida Balliu, Sebastian Brandt, Yi-Jun Chang, Dennis Olivetti, Jan Studený, Jukka Suomela,
and Aleksandr Tereshchenko. Locally checkable problems in rooted trees. Distributed Computing,
36(3):277–311, 2023. doi:10.1007/S00446-022-00435-9.
[12] Alkida Balliu, Janne H. Korhonen, Fabian Kuhn, Henrik Lievonen, Dennis Olivetti, Shreyas Pai,
Ami Paz, Joel Rybicki, Stefan Schmid, Jan Studený, Jukka Suomela, and Jara Uitto. Sinkless
orientation made simple. In Telikepalli Kavitha and Kurt Mehlhorn, editors, 2023 Symposium
53

--- Page 55 ---
on Simplicity in Algorithms, SOSA 2023, Florence, Italy, January 23-25, 2023, pages 175–191.
SIAM, 2023. doi:10.1137/1.9781611977585.CH17.
[13] Alkida Balliu, Mohsen Ghaffari, Fabian Kuhn, Augusto Modanese, Dennis Olivetti, Mikaël
Rabie, Jukka Suomela, and Jara Uitto. Shared randomness helps with local distributed problems,
2024. URL https://arxiv.org/abs/2407.05445.
[14] Salman Beigi and Marc-Olivier Renou. Covariance decomposition as a universal limit on
correlations in networks. IEEE Transactions on Information Theory, 68(1):384–394, 2021.
[15] Max Born. Quantenmechanik der Stoßvorgänge. Zeitschrift für Physik, 38(11-12):803–827, 1926.
doi:10.1007/bf01397184.
[16] Sebastian Brandt, Orr Fischer, Juho Hirvonen, Barbara Keller, Tuomo Lempiäinen, Joel Rybicki,
Jukka Suomela, and Jara Uitto. A lower bound for the distributed Lovász local lemma. In
Daniel Wichs and Yishay Mansour, editors, Proceedings of the 48th Annual ACM SIGACT
Symposium on Theory of Computing, STOC 2016, Cambridge, MA, USA, June 18-21, 2016,
pages 479–488. ACM, 2016. doi:10.1145/2897518.2897570.
[17] Sebastian Brandt, Juho Hirvonen, Janne H. Korhonen, Tuomo Lempiäinen, Patric R. J.
Östergård, Christopher Purcell, Joel Rybicki, Jukka Suomela, and Przemyslaw Uznanski. LCL
problems on grids. In Elad Michael Schiller and Alexander A. Schwarzmann, editors, Proceedings
of the ACM Symposium on Principles of Distributed Computing, PODC 2017, Washington, DC,
USA, July 25-27, 2017, pages 101–110. ACM, 2017. doi:10.1145/3087801.3087833.
[18] Keren Censor-Hillel, Orr Fischer, François Le Gall, Dean Leitersdorf, and Rotem Oshman.
Quantum distributed algorithms for detection of cliques. In Mark Braverman, editor, 13th
Innovations in Theoretical Computer Science Conference, ITCS 2022, January 31 - February
3, 2022, Berkeley, CA, USA, volume 215 of LIPIcs, pages 35:1–35:25. Schloss Dagstuhl -
Leibniz-Zentrum für Informatik, 2022. doi:10.4230/LIPICS.ITCS.2022.35.
[19] Yi-Jun Chang and Seth Pettie. A time hierarchy theorem for the LOCAL model. SIAM Journal
on Computing, 48(1):33–69, 2019. doi:10.1137/17M1157957.
[20] Yi-Jun Chang, Tsvi Kopelowitz, and Seth Pettie. An exponential separation between randomized
and deterministic complexity in the LOCAL model. In Irit Dinur, editor, IEEE 57th Annual
Symposium on Foundations of Computer Science, FOCS 2016, 9-11 October 2016, Hyatt
Regency, New Brunswick, New Jersey, USA, pages 615–624. IEEE Computer Society, 2016.
doi:10.1109/FOCS.2016.72.
[21] Yi-Jun Chang, Tsvi Kopelowitz, and Seth Pettie. An exponential separation between randomized
and deterministic complexity in the LOCAL model. SIAM Journal on Computing, 48(1):122–143,
2019. doi:10.1137/17M1117537.
[22] Yi-Jun Chang, Gopinath Mishra, Hung Thuan Nguyen, Mingyang Yang, and Yu-Cheng Yeh.
A tight lower bound for 3-coloring grids in the online-LOCAL model. CoRR, abs/2312.01384,
2023. doi:10.48550/ARXIV.2312.01384.
[23] Yi-Jun
Chang,
Jan
Studený,
and
Jukka
Suomela.
Distributed
graph
problems
through an automata-theoretic lens.
Theoretical Computer Science, 951:113710, 2023.
doi:10.1016/J.TCS.2023.113710.
54

--- Page 56 ---
[24] Giulio Chiribella and Robert W. Spekkens, editors. Quantum Theory: Informational Foundations
and Foils. Springer Netherlands, 2016. doi:10.1007/978-94-017-7303-4.
[25] Xavier Coiteux-Roy, Elie Wolfe, and Marc-Olivier Renou. Any physical theory of nature must
be boundlessly multipartite nonlocal. Physical Review A, 104(5):052207, 2021.
[26] Xavier Coiteux-Roy, Elie Wolfe, and Marc-Olivier Renou.
No Bipartite-Nonlocal Causal
Theory Can Explain Nature’s Correlations. Physical Review Letters, 127(20):200401, 2021.
doi:10.1103/physrevlett.127.200401.
[27] Xavier Coiteux-Roy, Francesco d’Amore, Rishikesh Gajjala, Fabian Kuhn, François Le Gall,
Henrik Lievonen, Augusto Modanese, Marc-Olivier Renou, Gustav Schmid, and Jukka Suomela.
No distributed quantum advantage for approximate graph coloring. In Proc. 56th Annual ACM
Symposium on Theory of Computing (STOC 2024). ACM Press, 2024.
[28] Xavier Coiteux-Roy, Owidiusz Makuta, Fionnuala Curran, Remigiusz Augusiak, and Marc-
Olivier Renou. The genuinely multipartite nonlocality of graph states is model-dependent, 2024.
In preparation.
[29] Richard Cole and Uzi Vishkin. Deterministic coin tossing with applications to optimal parallel
list ranking. Information and Control, 70(1):32–53, 1986. doi:10.1016/S0019-9958(86)80023-7.
[30] Sameep Dahal, Francesco D’Amore, Henrik Lievonen, Timothé Picavet, and Jukka Suomela.
Brief announcement: Distributed derandomization revisited. In Rotem Oshman, editor, 37th
International Symposium on Distributed Computing, DISC 2023, October 10-12, 2023, L’Aquila,
Italy, volume 281 of LIPIcs, pages 40:1–40:5. Schloss Dagstuhl - Leibniz-Zentrum für Informatik,
2023. doi:10.4230/LIPICS.DISC.2023.40.
[31] Giacomo Mauro D’Ariano, Giulio Chiribella, and Paolo Perinotti.
Quantum Theory
from First Principles:
An Informational Approach.
Cambridge University Press, 2016.
doi:10.1017/9781107338340.
[32] Anubhav Dhar, Eli Kujawa, Henrik Lievonen, Augusto Modanese, Mikail Muftuoglu, Jan
Studený, and Jukka Suomela. Local problems in trees across a wide range of distributed models.
In Proc. 28th International Conference on Principles of Distributed Systems (OPODIS 2024),
Leibniz International Proceedings in Informatics (LIPIcs). Schloss Dagstuhl–Leibniz-Zentrum
für Informatik, 2024.
[33] Michael Elkin, Hartmut Klauck, Danupon Nanongkai, and Gopal Pandurangan. Can quantum
communication speed up distributed computation? In Magnús M. Halldórsson and Shlomi
Dolev, editors, ACM Symposium on Principles of Distributed Computing, PODC ’14, Paris,
France, July 15-18, 2014, pages 166–175. ACM, 2014. doi:10.1145/2611462.2611488.
[34] Manuela Fischer and Mohsen Ghaffari.
Sublogarithmic distributed algorithms for Lovász
local lemma, and the complexity hierarchy. In Andréa W. Richa, editor, 31st International
Symposium on Distributed Computing, DISC 2017, October 16-20, 2017, Vienna, Austria,
volume 91 of LIPIcs, pages 18:1–18:16. Schloss Dagstuhl - Leibniz-Zentrum für Informatik, 2017.
doi:10.4230/LIPICS.DISC.2017.18.
[35] Pierre Fraigniaud, Maël Luce, Frédéric Magniez, and Ioan Todinca. Even-cycle detection in
the randomized and quantum CONGEST model. In Ran Gelles, Dennis Olivetti, and Petr
Kuznetsov, editors, Proceedings of the 43rd ACM Symposium on Principles of Distributed
55

--- Page 57 ---
Computing, PODC 2024, Nantes, France, June 17-21, 2024, pages 209–219. ACM, 2024.
doi:10.1145/3662158.3662767.
[36] Cyril Gavoille, Adrian Kosowski, and Marcin Markiewicz. What can be observed locally? In
Idit Keidar, editor, Distributed Computing, 23rd International Symposium, DISC 2009, Elche,
Spain, September 23-25, 2009. Proceedings, volume 5805 of Lecture Notes in Computer Science,
pages 243–257. Springer, 2009. doi:10.1007/978-3-642-04355-0_26.
[37] Mohsen Ghaffari and Hsin-Hao Su. Distributed degree splitting, edge coloring, and orientations.
In Philip N. Klein, editor, Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on
Discrete Algorithms, SODA 2017, Barcelona, Spain, Hotel Porta Fira, January 16-19, pages
2505–2523. SIAM, 2017. doi:10.1137/1.9781611974782.166.
[38] Mohsen Ghaffari, Fabian Kuhn, and Yannic Maus. On the complexity of local distributed graph
problems. In Hamed Hatami, Pierre McKenzie, and Valerie King, editors, Proceedings of the
49th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2017, Montreal, QC,
Canada, June 19-23, 2017, pages 784–797. ACM, 2017. doi:10.1145/3055399.3055471.
[39] Mohsen Ghaffari, David G. Harris, and Fabian Kuhn. On derandomizing local distributed algo-
rithms. In Mikkel Thorup, editor, 59th IEEE Annual Symposium on Foundations of Computer
Science, FOCS 2018, Paris, France, October 7-9, 2018, pages 662–673. IEEE Computer Society,
2018. doi:10.1109/FOCS.2018.00069.
[40] Mohsen Ghaffari, Juho Hirvonen, Fabian Kuhn, Yannic Maus, Jukka Suomela, and Jara Uitto.
Improved distributed degree splitting and edge coloring. Distributed Computing, 33(3-4):293–310,
2020. doi:10.1007/S00446-018-00346-8.
[41] Nicolas Gisin, Jean-Daniel Bancal, Yu Cai, Patrick Remy, Armin Tavakoli, Emmanuel Zambrini
Cruzeiro, Sandu Popescu, and Nicolas Brunner. Constraints on nonlocality in networks from
no-signaling and independence. Nature Communications, 11(1):2378, 2020. doi:10.1038/s41467-
020-16137-4.
[42] Andrew V. Goldberg, Serge A. Plotkin, and Gregory E. Shannon. Parallel symmetry-breaking in
sparse graphs. SIAM Journal on Discrete Mathematics, 1(4):434–446, 1988. doi:10.1137/0401044.
[43] Atsuya Hasegawa, Srijita Kundu, and Harumichi Nishimura.
On the power of quantum
distributed proofs. In Ran Gelles, Dennis Olivetti, and Petr Kuznetsov, editors, Proceedings
of the 43rd ACM Symposium on Principles of Distributed Computing, PODC 2024, Nantes,
France, June 17-21, 2024, pages 220–230. ACM, 2024. doi:10.1145/3662158.3662788.
[44] Alexander E. Holroyd. Symmetrization for finitely dependent colouring. Electronic Communi-
cations in Probability, 29, 2024. doi:10.1214/24-ecp600.
[45] Alexander E. Holroyd and Thomas M. Liggett.
Finitely Dependent Coloring.
Forum of
Mathematics, Pi, 4:e9, 2016. doi:10.1017/fmp.2016.7.
[46] Alexander E. Holroyd, Oded Schramm, and David B. Wilson. Finitary coloring. The Annals of
Probability, 45(5):2867–2898, 2017. doi:10.1214/16-aop1127.
[47] Alexander E. Holroyd, Tom Hutchcroft, and Avi Levy. Finitely dependent cycle coloring.
Electronic Communications in Probability, 23, 2018. doi:10.1214/18-ecp118.
56

--- Page 58 ---
[48] Taisuke Izumi and François Le Gall. Quantum distributed algorithm for the all-pairs short-
est path problem in the CONGEST-CLIQUE model. In Peter Robinson and Faith Ellen,
editors, Proceedings of the 2019 ACM Symposium on Principles of Distributed Computing,
PODC 2019, Toronto, ON, Canada, July 29 - August 2, 2019, pages 84–93. ACM, 2019.
doi:10.1145/3293611.3331628.
[49] Taisuke Izumi, François Le Gall, and Frédéric Magniez. Quantum distributed algorithm for
triangle finding in the CONGEST model. In Christophe Paul and Markus Bläser, editors, 37th
International Symposium on Theoretical Aspects of Computer Science, STACS 2020, March
10-13, 2020, Montpellier, France, volume 154 of LIPIcs, pages 23:1–23:13. Schloss Dagstuhl -
Leibniz-Zentrum für Informatik, 2020. doi:10.4230/LIPICS.STACS.2020.23.
[50] Amos Korman, Jean-Sébastien Sereni, and Laurent Viennot. Toward more localized local
algorithms: removing assumptions concerning global knowledge. Distributed Computing, 26
(5-6):289–308, 2013. doi:10.1007/S00446-012-0174-8.
[51] François Le Gall and Frédéric Magniez. Sublinear-time quantum computation of the diameter in
CONGEST networks. In Proceedings of the 2018 ACM Symposium on Principles of Distributed
Computing, pages 337–346. ACM, 2018. doi:10.1145/3212734.3212744.
[52] François Le Gall, Harumichi Nishimura, and Ansis Rosmanis. Quantum advantage for the
LOCAL model in distributed computing. In Rolf Niedermeier and Christophe Paul, editors,
36th International Symposium on Theoretical Aspects of Computer Science, STACS 2019, March
13-16, 2019, Berlin, Germany, volume 126 of LIPIcs, pages 49:1–49:14. Schloss Dagstuhl -
Leibniz-Zentrum für Informatik, 2019. doi:10.4230/LIPICS.STACS.2019.49.
[53] Nathan Linial. Distributive graph algorithms-global solutions from local data. In 28th Annual
Symposium on Foundations of Computer Science, Los Angeles, California, USA, 27-29 October
1987, pages 331–335. IEEE Computer Society, 1987. doi:10.1109/SFCS.1987.20.
[54] Nathan Linial. Locality in distributed graph algorithms. SIAM Journal on Computing, 21(1):
193–201, 1992. doi:10.1137/0221015.
[55] Frédéric Magniez and Ashwin Nayak. Quantum distributed complexity of set disjointness on a
line. ACM Transactions on Computation Theory, 14(1):5:1–5:22, 2022. doi:10.1145/3512751.
[56] Yannic Maus and Tigran Tonoyan. Linial for lists. Distributed Computing, 35(6):533–546, 2022.
doi:10.1007/S00446-022-00424-Y.
[57] Moni Naor and Larry J. Stockmeyer. What can be computed locally?
SIAM Journal on
Computing, 24(6):1259–1277, 1995. doi:10.1137/S0097539793254571.
[58] Michael A. Nielsen and Isaac L. Chuang. Quantum Computation and Quantum Information:
10th Anniversary Edition. Cambridge University Press, 2012. doi:10.1017/cbo9780511976667.
[59] Dennis Olivetti. Round eliminator: a tool for automatic speedup simulation, 2019. URL
https://github.com/olidennis/round-eliminator.
[60] Alessandro Panconesi and Romeo Rizzi. Some simple distributed algorithms for sparse networks.
Distributed Computing, 14(2):97–100, 2001. doi:10.1007/PL00008932.
[61] David Peleg. Distributed Computing: A Locality-Sensitive Approach. Society for Industrial and
Applied Mathematics, 2000. doi:10.1137/1.9780898719772.
57

--- Page 59 ---
[62] Václav Rozhon and Mohsen Ghaffari. Polylogarithmic-time deterministic network decomposition
and distributed derandomization. In Konstantin Makarychev, Yury Makarychev, Madhur
Tulsiani, Gautam Kamath, and Julia Chuzhoy, editors, Proceedings of the 52nd Annual ACM
SIGACT Symposium on Theory of Computing, STOC 2020, Chicago, IL, USA, June 22-26,
2020, pages 350–363. ACM, 2020. doi:10.1145/3357713.3384298.
[63] Yinon Spinka. Finitely dependent processes are finitary. The Annals of Probability, 48(4):
2088–2117, 2020. doi:10.1214/19-aop1417.
[64] Jukka Suomela. Landscape of locality (invited talk). In Susanne Albers, editor, 17th Scandinavian
Symposium and Workshops on Algorithm Theory, SWAT 2020, June 22-24, 2020, Tórshavn,
Faroe Islands, volume 162 of LIPIcs, pages 2:1–2:1. Schloss Dagstuhl - Leibniz-Zentrum für
Informatik, 2020. doi:10.4230/LIPICS.SWAT.2020.2.
[65] Ádám Timár.
Finitely dependent random colorings of bounded degree graphs.
CoRR,
abs/2402.17068, 2024. doi:10.48550/arXiv.2402.17068.
[66] Joran van Apeldoorn and Tijn de Vos. A framework for distributed quantum queries in the
CONGEST model. In Alessia Milani and Philipp Woelfel, editors, PODC ’22: ACM Symposium
on Principles of Distributed Computing, Salerno, Italy, July 25 - 29, 2022, pages 109–119. ACM,
2022. doi:10.1145/3519270.3538413.
[67] ChengSheng Wang, Xudong Wu, and Penghui Yao.
Complexity of eccentricities and all-
pairs shortest paths in the quantum CONGEST model.
CoRR, abs/2206.02766, 2022.
doi:10.48550/ARXIV.2206.02766.
[68] Xudong Wu and Penghui Yao.
Quantum complexity of weighted diameter and radius in
CONGEST networks.
In Alessia Milani and Philipp Woelfel, editors, PODC ’22: ACM
Symposium on Principles of Distributed Computing, Salerno, Italy, July 25 - 29, 2022, pages
120–130. ACM, 2022. doi:10.1145/3519270.3538441.
58

--- Page 60 ---
A
Quantum, bounded-dependence, and non-signaling
This appendix introduces both the non-signaling model and the bounded-dependence model, which
are the most powerful models that satisfy physical causality, and thus they generalize the quantum-
LOCAL model. The distinction between the non-signaling model and the bounded-dependence
depends on whether shared states are available (in the non-signaling model) or not (in the bounded-
dependence model). We illustrate the difference between these models by analyzing the problem of
c = 2-coloring a lifebuoy-shaped graph (see Fig. 6 and Fig. 7b) with locality T = 2.
We first introduce a circuit formalism which allows us to clarify the early works of Arfaoui and
Fraigniaud [3], and Gavoille et al. [36], by re-expressing the randomized LOCAL and quantum-LOCAL
models in this formalism (see Appendix A.1). Second, we introduce the concept of light-cones and
the principle of non-signaling, explaining how (together with the symmetries of the graph) they define
the non-signaling model (see Appendices A.1.3 and A.1.4). Third, we show in Appendix A.2 that
lifebuoy-shaped graphs are not 2-colorable in the non-signaling model with locality T = 2 through a
reduction from the 2-colorability of the cheating graph H shown in Fig. 7a. At last, we define the
bounded-dependence model based on our circuit formalism and on the following three principles:
device replication; non-signaling and independence [14, 25, 26, 41]; and invariance under symmetries
of the graph (see Appendix A.3). We stress its connection to the concept of finitely-dependent
distributions [1, 44, 45, 47, 63].
Figure 6: An example of a lifebuoy-shaped graph G. The lifebuoy-shaped graphs are defined by the
set G of graphs that are isomorphic to the above. Notice that their chromatic number is 2. In our
case, the node labels required by the LOCAL model are unique and go from 1 to 12. Granting this
extra power is not restrictive as we are proving a lower bound.
A.1
Randomized LOCAL, quantum-LOCAL, and non-signaling models
In the next two sections, we re-introduce the randomized LOCAL model and the quantum-LOCAL
model for coloring lifebuoy-shaped graphs in a circuit formalism. This will later enable us to clarify
the definitions of the non-signaling and bounded-dependence models.
A.1.1
Randomized LOCAL model
We consider twelve nodes with unique identifiers ranging from 1 to 12 and that are connected in
a lifebuoy-shaped graph that is a priori unknown to the nodes3 (an example of such graph is the
labeled graph G0 ∈G illustrated in Fig. 7b). The nodes try to color this graph in the randomized
3A reader used to standard quantum nonlocality should see the graph — H or G ∈G — as an input of the problem,
split and distributed among the local parties.
59

--- Page 61 ---
(a) H has chromatic number 3.
(b) A distributed algorithm that finds a 2-
coloring of the lifebuoy-shaped graphs G ∈
G would by definition 2-color the particular
instance G = G0.
Figure 7: The joint view of the couple of nodes u, v = 1, 2 after T = 2 rounds of communication
is limited to the gray area. In this region the graphs G0 and H are identical. The non-signaling
principle implies that the outputs (c1, c2) must therefore be identically distributed in both G0 and H.
LOCAL model within T = 2 steps of synchronous communication. The difficulty is that a given
node ignore which G ∈G connects the set of labelled nodes: it can only discover a local part of the
structure of G by communicating to its neighbors. The most general (T = 2)-round strategy for the
node 1 consists of the following procedure, which alternates between randomized processing steps
and communication steps (the computational power and size of exchanged messages are unbounded):
Processing 0: Sample a random real number and store it locally.
Communication 1: Send all stored information, including the sampled random number, to all
neighbors. Receive information from all neighbors and store it for subsequent rounds (in G0,
the neighbors are 2, 3, 5).
Processing 1: Process all stored information (possibly in a randomized way) and store the result.4
Communication 2: Send all stored information, including all received messages and the outputs
of processing steps, to all neighbors. Receive information from neighbors and store it.
Processing 2: Process all stored information (possibly in a randomized way) to output a color.
Such T-round strategy on the graph G can be represented formally as a circuit CG,T , such as in
Fig. 8a where semicircles, line wires, and squares respectively represent the sampling of a random
number, the transfer (or storage) of information, and the processing of information. Once the
concrete operations performed by the nodes (i.e. randomness sampling and processing) are made
explicit, it is possible to compute (using classical information theory) the exact output distribution
of the strategy on graph G, that is, the probability distribution Pr [c1, . . . , cn | CG,T ] of observing
that the set of nodes {1, . . . , n} outputs the colors {c1, . . . , cn} when connected as per one of the
lifebuoy-shaped graphs G ∈G. Importantly, in our model, the operations performed by the nodes
cannot depend on the connection graph G.
4In classical information theory, it is known that intermediate processing gates can be taken as identity gates, that
is, any strategy can be simulated by a two-layer circuit where the parties send their first random number to all parties
up to a distance T, and then make a unique processing step after all the communication has taken place. In quantum
and non-signaling theories, this is not the case anymore [28].
60

--- Page 62 ---
A generic classical strategy with shared randomness can be in the same way represented by the
general circuit of Fig. 8b, by initializing the circuit with a source of randomness common to all nodes
(the large semicircle).
A.1.2
Quantum-LOCAL model
Any quantum strategy can also be represented by the circuit formalism of Fig. 8 by using resources
and processing operations that are quantum rather than classical. Quantum information theory
provides a concrete mathematical formalism (based on the tensor product of Hilbert spaces) with
rules to represent the potential operations performed by each of the gates of the circuit. Semicircles,
line wires, and squares now respectively represent the creation of a quantum state (a density matrix),
the transfer (or storage) of quantum information, and the processing of quantum information with
quantum channels (or quantum measurements in the last layer) represented by completely positive
operators. Once the quantum states and channels are made explicit, the Born rule of quantum
information theory [15, 58] allows computing Pr [c1, . . . , cn |CG,T ], the output distribution of the
strategy on graph G.
However, analyzing the quantum-LOCAL model directly is complicated. Instead, we employ the
fact that it is possible to bound the time complexity of the quantum-LOCAL model by analyzing
models that do not depend on the mathematical formalism of quantum information theory (and which
are, therefore, arguably simpler). In the present appendix, we utilize the fact that quantum-LOCAL is
sandwiched between the randomized LOCAL model (less powerful) and the non-signaling model (the
most powerful model satisfying the information-theoretic principles of non-signaling, independence
and device replication we introduce bellow). We next introduce the non-signaling model.
A.1.3
The non-signaling model (with unique identifiers)
The non-signaling model is the most powerful model of synchronous distributed computing that does
not violate physical causality, when a pre-established shared resource exists.
The formulation of the non-signaling model is radically different from the randomized LOCAL
and quantum-LOCAL models. The randomized LOCAL and quantum-LOCAL models are based
on classical (randomized) and quantum information theory which both provide a mathematical
formalism to describe information processing gates and to compute the probability distribution of
outputs when these gates are placed in a circuit. To show that some probability distribution is
feasible in these models, one needs to propose a valid strategy in these mathematical formalisms.
The non-signaling model does not rely on any underlying mathematical formalism, but on some
information-theoretical principles which should not be violated. More precisely, to show that some
probability distribution is feasible in the non-signaling model, one needs to explain how to obtain
it, but only to make sure that this probability distribution is compatible with the non-signaling
principle in a way we now explain.
Before introducing this principle, we state the following definition of light-cones:
Definition A.1 (Past light-cone). Consider a circuit. Consider a subset of gates R, and another
gate s /∈R in that circuit. We say that s is in the past light-cone of R if starting from s, one can
reach a gate in R by traveling down the circuit. For instance, in Fig. 8b, the past light-cone of the
second processing gates of nodes {1, 2} is composed of all gates in red.
Remark A.2. Light-cones allow to formalize the fact that, in a circuit, the precise time ordering in
which the gates process information has no influence over the result, as long as physical causality
(that is, information can be transferred only through communication) is preserved. For instance, in
61

--- Page 63 ---
12
c12
10
c10
8
c8
6
c6
4
c4
2
c2
1
c1
3
c3
5
c5
7
c7
9
c9
11
c11
11
9
12
10
Processing 0
Communication 1
Processing 1
Communication 2
Processing 2
Output
(a) Circuit representation of a
non-signaling strategy on graph
G0 of Fig. 7b, without a shared
resource. Note the cyclicity of
the circuit. Highlighted in red
is the past-light-cone of the joint
output (c1, c2), that is the set of
gates which connects to the out-
put gates producing (c1, c2).
12
c12
10
c10
8
c8
6
c6
4
c4
2
c2
1
c1
3
c3
5
c5
7
c7
9
c9
11
c11
11
9
12
10
Processing 0
Communication 1
Processing 1
Communication 2
Processing 2
Output
(b) Circuit representation of a
non-signaling strategy on graph
G0 of Fig. 7b, with an arbitrary
shared resource. The joint out-
put (c1, c2) remain, after T = 2
rounds of communication, inde-
pendent of the graph structure
around nodes 11 and 12, because
the difference lies outside their
joint past light-cones.
12
c12
10
c10
8
c8
6
c6
4
c4
2
c2
1
c1
3
c3
5
c5
7
c7
9
c9
11
c11
11
9
12
10
Processing 0
Communication 1
Processing 1
Communication 2
Processing 2
Output
(c) Circuit representation of a
non-signaling strategy on graph
H of Fig. 7a, with an arbitrary
shared resource. Note the differ-
ence between this circuit and the
one of Fig. 8b (namely, the differ-
ent connections between the top
layer and bottom layer of the cir-
cuit) is only manifested outside
the joint past light-cone of the
outputs (c1, c2).
Figure 8: The above circuits represent non-signaling strategies (it includes as special cases the
classical strategies and quantum strategies) executed by the nodes 1 and 2 in various scenarios. The
semicircles represent private (Fig. 8a) or shared (Fig. 8b and Fig. 8c) arbitrary-but-non-signaling
resources; the wires depict communication (or storage), and the squares are local operations (using
possibly private resources). The last layer of gates (or measurements) outputs the individual colors
of the nodes (i.e. classical variables). Since the nodes start with no knowledge about the identity of
their neighbors, the operations of the gates are a priori independent of the graph structure (as long
as the nodes have the right degree). For the special cases of classical and quantum strategies, the
output distribution can be computed directly from those circuits, which define it uniquely.
62

--- Page 64 ---
Fig. 8a, our drawing of the circuit represents the processing-1 gate of node 8 as being in the past of
the processing-2 gate of node 2. However, by stretching the communication lines, another drawing
in which this time ordering is exchanged exists, and this is possible as long as one node is not in the
past light cone of another. The name “light-cone” refers to relativity, where physical causality is
bounded by the speed of light. Circuits provide an abstracted representation of physical causality
that is not based on any notion of spacetime.
We now state the non-signaling principle5, which is essentially the only constraint in the non-
signaling model.
Definition A.3 (Non-signaling principle). Consider a set of gates, two different circuits C, C′
connecting them, and corresponding distributions Pr [c1, . . . , cn | C], Pr [c1, . . . , cn | C′]. Let U be a
subset of measurement gates whose past light-cones in C and C′ coincide (i.e. they are composed of
the same gates which are connected in the same way). Then Pr [{ci}i∈U | C] = Pr [{ci}i∈U |C′].
Implicitly, a non-signaling theory assumes that, given a set of gates and a valid way to connect
them in a circuit C, one obtains a corresponding distribution Pr [c1, . . . , cn | C]6 (here the alphabet
of the outputs ci is not limited: e.g., in case of unexpected circuits, the measurement gates can
produce failure outputs).
We are now ready to define the non-signaling model, which is associated to circuits with a
pre-shared non-signaling resource such as in Fig. 8b:
Definition A.4 (Non-signaling model, with unique identifiers). The distribution
Pr [c1, . . . , cn | CG,T ]
is feasible in the non-signaling model (with unique identifiers) with locality T on graph G if and
only if, for all possible alternative connecting graphs H of the nodes, there exists a distribution
P = Pr [c1, . . . , cn | CH,T ] such that the no-signaling principle is respected.7
Note that H might not be a lifebuoy-shaped graph: in the case a gate ‘discovers’ this unexpected
situation, it has the possibility to produce a new output from a set of error outputs (i.e. it crashes
and no further useful constraint can be derived).
A.1.4
The non-signaling model without unique identifiers
We have up until now considered N = 12 nodes with unique identifiers ranging from 1 to N = 12.
When the nodes do not start with unique identifiers, the situation is slightly more complicated. In
that case, the resulting distribution should be invariant under subgraph isomorphism, as all nodes
are running identical programs and the circuit is thus completely symmetric under permutations of
nodes8. For instance, if the nodes were to color the graph of Fig. 7b without being a priori assigned
5Chiribella and Spekkens [24] call this principle no-signaling from the future.
6Note that the gates have “types” and can only be connected to other gates of matching types: For instance, in
our case, the inputs of gates from the second processing step must correspond to the outputs of gates from the first
processing step. The theory of circuits can be formalized using category theory — see, e.g. [31].
7Note that considering scenarios with more than one copies of each node does not allow us to derive additional
constraints, since the pre-shared non-signaling resource cannot by definition be cloned and extended to more than one
copy of each of its original recipient.
8Note that while a shared classical resource is inherently symmetric, because it can be without a loss of generality
taken to be distributed identically to each party, a non-signaling resource is not a priori symmetric under permutation
of the parties that it connects. The absence of identifiers thus forces the non-signaling model to pre-share only a
subset of all possible non-signaling resources, namely the subset that respects such symmetry.
63

--- Page 65 ---
unique identifiers, the resulting circuit CG,T would have some symmetries (as all processing gates
would be the same in any layer of the respective steps 0, 1 and 2), implying that the distribution
should be invariant by several non-trivial graph isomorphisms cyclically permuting the nodes, or
inverting the inner and outer cycle of 6 nodes.
Definition A.5 (Non-signaling model, without unique identifiers). The distribution
Pr [c1, . . . , cn | CG,T ]
is feasible in the non-signaling model (without unique identifiers) in T communication steps on
graph G if and only if the following two conditions are respected: for all possible alternative
connecting graphs H of the nodes, there exists a distribution P = Pr [c1, . . . , cn | CH,T ] such that the
no-signaling principle is respected; and the distributions in G and H are invariant under subgraph
isomorphism.
This definition can also be generalized to the case where several nodes with the same identifiers
are present in G, or were the number of identifiers ranges from 1 to M ̸= N.
A.2
Graph G is not 2-colorable in T = 2 rounds
We now show by contradiction that the nodes 1, . . . , 12 cannot 2-color the set G of lifebuoy-shaped
graphs with a non-signaling strategy (including pre-shared non-signaling resources) in T = 2 rounds
of communication. More precisely, we prove that if there existed such a non-signaling algorithm able
to color any G ∈G, then the same algorithm would also color the cheating graph H with 2 colors,
which is impossible.
Proof. Assume by contradiction that there exists such a non-signaling algorithm, that is, there exist
gates as in Fig. 8b such that the resulting probability distribution Pr [c1, . . . , c12 | CG,T ] is a proper
coloring for all lifebuoy-shaped graphs G ∈G. Such proper coloring means that for all G ∈G, and
for all nodes u, v that are neighbors in G, it holds that Pr [cu ̸= cv | CG,T ] = 1.
We consider the same nodes performing the same gates, but we change the edges so that the
connected nodes now form the graph H in Fig. 7b. Let Pr [c1, . . . , c12 | CH,T ] be the distribution
of output colors in that new configuration9. Consider two nodes connected by an edge in H: by
symmetry of H, we can without a loss of generality assume that these are nodes 1 and 2. We
introduce the lifebuoy-shaped graph G0 of Fig. 7b (G0 ∈G depends on our choice of nodes, here
1, 2, in H). Then, we observe that the common past light-cones of the two nodes is the same when
connected through H or through G0 (compare the circuit of Fig. 8b with the circuit of Fig. 8c). It
hence holds that Pr [c1 ̸= c2 | CH,T ] = 1 = Pr [c1 ̸= c2 | CG0,T ] due to the non-signaling principle.
We conclude that the non-signaling distributed algorithm outputs a 2-coloring for H, which is
impossible.
A.3
Bounded-dependence model
The bounded-dependence model is similar to the non-signaling model, but the former does not allow
pre-shared non-signaling resources between the nodes. The following two new principles are needed
to define feasible distributions in the bounded-dependence model.
9While we are deceiving the nodes by promising a lifebuoy-shaped connecting graph but imposing instead H, the
nodes cannot locally detect the fraud in T = 2 communication steps or less. (More formally, the past light-cone in H
of any node is then compatible with a lifebuoy-shaped graph — an individual node cannot detect the difference and
must therefore, according to the non-signaling principle, output a color as if it were in a lifebuoy-shaped graph.)
64

--- Page 66 ---
Figure 9: In the bounded-dependence model, one can find non-trivial subgraph isomorphisms even
when the nodes are provided with unique identifiers.
Definition A.6 (Independence principle). Consider a set of gates connected in a circuit C, and
the corresponding distribution Pr [c1, . . . , cn | C]. Let U, V be two subsets of measurement gates
producing the outputs {cu}u∈U and {cv}v∈V , respectively. If the past light-cones of U and V do
not intersect, then Pr [{cw}w∈U∪V | C] = Pr [{cu}u∈U | C] · Pr [{cv}v∈V | C], that is their output
distributions are independent.
Definition A.7 (Device-replication principle). Identical and independent copies of non-signaling
gates and non-signaling resources can be prepared10.
Then, we obtain the following definition:
Definition A.8 (Bounded-dependence model, with unique identifiers). The distribution
Pr [c1, . . . , cn | CG,T ]
with unique identifiers has bounded dependence with locality T on graph G (without pre-shared
non-signaling resources) if and only if for all possible alternative connecting graph H of the nodes
and their replicates, there exists a distribution Pr [c1, . . . , cm | CH,T ] such as the non-signaling and
independence principles are respected, and such that the distribution is invariant under subgraph
isomorphisms.
Note a subtlety related to subgraph isomorphisms in the bounded-dependence model. There
is the variant where the nodes have identifiers in G, and the one where they do not. When the
nodes do not have any identifiers, the class of subgraph isomorphisms of all alternative graphs H
created out of the nodes in G and their replicates is obviously larger than with identifiers, because
the subgraph isomorphisms must respect the identifiers. However, even if the nodes of G do have
distinct identifiers, as H is created out of possibly many copies of the original nodes of G, H might
contain several nodes with the same identifiers. Hence, the group of subgraph isomorphism of H
might be nontrivial even if all nodes in G have distinct identifiers. For instance, in lifebuoy-shaped
graphs, one could consider the case represented in Fig. 9, which starts from the graph G0 in Fig. 7b,
duplicates all nodes, and constructs a new graph H of 24 nodes with identifiers ranging from 1 to 12
with one non-trivial graph isomorphism cyclically permuting the nodes.
10Note that this principle does not imply that one can duplicate unknown non-signaling resources: device-replication
compatible with the quantum no-cloning theorem.
65

--- Page 67 ---
A.3.1
Relation with finitely-dependent distributions
Our bounded-dependence model is directly connected to the concept of finitely-dependent distri-
butions introduced in mathematics [1, 44–47, 63]. In this framework, in a graph H, the color ci
produced by each node i is seen as the result of a random process Ci. The set of all random
processes {Ci}i is said to be k-dependent in graph H if, for any two subsets U, V of the nodes of
H which are at least at distance k + 1, the two sets of processes {Cu}u∈U and Cvv∈V are inde-
pendent. In our notation, assuming even k and taking T = k/2, this is equivalent to asking that
Pr [{cw}w∈U∪V | CH,T ] = Pr [{cu}u∈U | C] · Pr [{cv}v∈V | CH,T ].
Hence, the question of the existence of distributions with bounded dependence that solve some
problem can directly be formulated in terms of the existence of finitely dependent distributions over
a family of graphs that satisfy additional constraints of compatibility (to satisfy the non-signaling
principle) and symmetries (to cope with subgraph isomorphisms).
66

--- Page 68 ---
Distributed,
parallel,
message-
passing
models
Probability
distributions
Distributed
sequential
models
Centralized
sequential
models
New result
New result
New result
New result
Simulation
of stronger
models in
weaker
models
(for rooted
trees)
Free symmetry
breaking in
stronger models
deterministic
LOCAL
randomized
LOCAL
quantum-
LOCAL
bounded-
dependence
deterministic
LOCAL
(shared)
randomized
LOCAL
(shared)
quantum-
LOCAL
(shared)
non-signaling
deterministic
SLOCAL
randomized
SLOCAL
deterministic
dynamic-
LOCAL
deterministic
online-
LOCAL
randomized
online-
LOCAL
Figure 10: Landscape of models and their relations for LCL problems. A black arrow X →Y
indicates that model Y is at least as strong as model X and can simulate any algorithm designed
there. A blue arrow X →Y indicates that we additionally get symmetry-breaking for free: locality
O(log∗n) in model X implies locality O(1) in model Y . An orange arrow X →Y indicates that at
least in rooted trees we can simulate highly-localized algorithms in model X using the weaker model
Y so that e.g. locality O(log∗n) in model X implies locality O(log∗n) in model Y (see Theorem 7.1
and [38] for details).
67


=== 2406.19430v2.pdf ===

--- Page 1 ---
Invitation to Local Algorithms
Václav Rozhoň
December 2023
Abstract
This text provides an introduction to the field of distributed local algorithms – an area at the in-
tersection of theoretical computer science and discrete mathematics. We collect many recent results in
the area and demonstrate how they lead to a clean theory. We also discuss many connections of local
algorithms to areas such as parallel, distributed, and sublinear algorithms, or descriptive combinatorics.
Contents
1
Local Complexity Fundamentals
2
1.1
First Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.2
Formal Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.3
Sequential vs Distributed Local Complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.4
Derandomization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.5
Network Decompositions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
1.6
Bounds for Concrete Problems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
1.6.1
Maximal Independent Set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
2
The Bounded-Degree Regime
15
2.1
The Symmetry-Breaking Regime . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
2.1.1
Fast Coloring Algorithm and its Implications . . . . . . . . . . . . . . . . . . . . . . .
16
2.1.2
Lower bound for coloring via round elimination . . . . . . . . . . . . . . . . . . . . . .
18
2.2
The Lovász Local Lemma Regime . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
2.2.1
Fast Algorithms for the Local Lemma . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
2.2.2
Lower Bound via Round Elimination . . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
2.3
Speedups and Slowdowns
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
2.3.1
Slowdowns
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
2.3.2
Speedups
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
2.4
Classification of Local Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
32
2.4.1
Sequential local complexities
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
2.4.2
Classification of Local Problems for Concrete Graph Classes . . . . . . . . . . . . . . .
34
3
Applications
36
3.1
Distributed Computing (CONGEST) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
3.2
Local Computation Algorithms and the Volume Model . . . . . . . . . . . . . . . . . . . . . .
37
3.3
PRAM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
3.4
Massively Parallel Computing (MPC)
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
3.5
Descriptive Combinatorics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
3.6
Other Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
1
arXiv:2406.19430v2  [cs.DC]  21 Nov 2024

--- Page 2 ---
1
Local Complexity Fundamentals
The field of local algorithms is an area on the border of theoretical computer science and discrete mathematics
where a lot of progress has happened in the past decade. This text is trying to serve as an introductory
material presenting a certain view of the field. It aims to be helpful to beginning researchers in the area or
researchers working in adjacent areas.
There are already many resources on various aspects of local algorithms: the classical book of Peleg
[Pel00], survey of Suomela [Suo13], book of Barenboim and Elkin [BE13], lecture notes by Ghaffari, Mohsen
[Gha20], introductory text of Suomela [Suo20], or a recent book by Hirvonen and Suomela [HS20]. Unlike
other texts, this one primarily explores the field’s conceptual framework and complexity-theoretical aspects,
rather than delving into individual problems. If you find errors in the text, please let me know – this is the
first version of it so there will be many! Several researchers generously gave me feedback on a preliminary
version of this text; my thanks go to Anton Bernshteyn, Yi-Jun Chang, Jan Grebík, Yannic Maus, Seth
Pettie, Jukka Suomela, and Goran Zuzic, and especially to Mohsen Ghaffari and Seri Khoury.
In the first section, we introduce local algorithms and local problems in Section 1.1. We then carefully
discuss the appropriate formal definitions in Section 1.2. The following sections Sections 1.3 to 1.5 discuss
the basic theory of local algorithms and aim to convey that we are after a very clean, fundamental, and
robust concept. Finally, Section 1.6 surveys some known results for concrete local problems.
1.1
First Example
Consider a very long oriented cycle that we want to properly color with as few colors as possible (see Figure 1).
Two colors are enough if the number of vertices n is even, otherwise we need three colors. However, there is
something uneasy about the 2-coloring solution even when it is possible – the solution lacks any flexibility.
A decision to color any particular vertex with one of the two colors already implies how all the other vertices
are going to be colored.
This lack of flexibility can be undesirable for all kinds of reasons, typically when we want to design a
coloring algorithm that is in some way parallel or distributed. If we enlarge our palette to three colors, the
problem seems to go away though: Now, coloring one vertex red still implies that its neighbors are not red,
but other vertices can have an arbitrary color.
Imagine that there is a computer in every vertex of the cycle and neighboring computers can communicate.
The computers are trying to solve the coloring problem together. How many rounds of communication are
needed until each computer outputs its color? A message-passing algorithm of this sort is known as a local
algorithm and we define it formally in Section 1.2.
It is possible to convince oneself that in the case of the 2-coloring problem, at least around n{4 rounds
are necessary to solve it, even if n is divisible by two.1 But what about the 3-coloring scenario? Can we
solve that problem in 10 rounds of communication? Or Oplog nq? Or is it similarly hard to 2-coloring?
There indeed is a simple randomized local algorithm that solves our 3-coloring problem after Oplog nq
rounds of exchanging messages. Let’s describe it next. The algorithm should serve as an example that
nontrivial local algorithms are indeed possible, though we will later see a better algorithm for the coloring
problem.
The 3-coloring algorithm has two phases. In the first phase, every computer flips a coin and selects itself
with probability 1/2 (top picture in Figure 1). Subsequently, the vertex asks its neighbors whether they are
also selected. If at least one neighbor is selected, the vertex unselects itself (middle picture in Figure 1).
In the second phase of the algorithm, every selected vertex first colors itself red. Then, it is responsible for
coloring the yet uncolored vertices until the next red vertex. The red node sends a message in the direction
of edges, asking the subsequent vertices to color themselves by alternating the two remaining colors (see the
bottom picture in Figure 1). This algorithm properly colors the oriented cycle with 3 colors and the number
of communication rounds that it needs is asymptotically at most as large as the length of the longest run of
non-red vertices in our coloring.
1Consider two opposing nodes u, v in the cycle graph: In less than n{4 rounds of communication, there is no third node that
could send a message to both u and v. Intuitively, the two vertices then cannot know whether their distance is even or odd.
This argument can be made into a rigorous lower bound after the model of local algorithms is properly defined in Section 1.2.
2

--- Page 3 ---
Random selection
Unselect if you have neighbors
Fill in the gap to the next selected node
Figure 1: An example local algorithm that uses three colors to color a long cycle, a small part of which is shown.
First, every vertex flips a coin and selects itself with probability 1{2. Second, a vertex unselects itself whenever a
neighbor is selected. Third, selected vertices color themselves red and each selected vertex is then responsible for
coloring the subsequent vertices until the next selected one with alternating colors.
To understand this quantity, consider any run of ℓconsecutive nodes and let us upper bound the proba-
bility that the run does not contain any red node. This is done by splitting the run into consecutive triples
of vertices. For every triple, we know that with probability 1{8, its middle node is initially selected, while its
two neighbors are not. The selected middle node then remains selected after the end of the first phase and is
colored red. Making this argument for every triple and using that the appropriate events are independent,
we conclude that the probability of no red node in the run is at most p7{8qtℓ{3u. Taking ℓ“ Oplog nq and
union bounding over all n different runs of vertices of length ℓ, we conclude that all of them contain at least
one red node with 1 ´ 1{ polypnq probability. We will call this guarantee “with high probability” later on.
That is, our algorithm finishes after Oplog nq communication rounds, with high probability.
Surprisingly, the fastest local algorithm for the 3-coloring problem has a much better, albeit not constant
complexity of Oplog˚ nq.2 However, instead of focusing on specific algorithms, this text is trying to give a
bit more general understanding of what is going on here. For example, it turns out that if we come up with
any local algorithm with complexity Oplog nq for any reasonable problem defined on the cycle as we just did,
there is a general theory that can turn this algorithm into a faster, Oplog˚ nq-round, algorithm for the very
same problem (see Theorem 2.30). Clearly, something interesting is going on here!
1.2
Formal Definitions
In this section, we formally define local problems and algorithms.
Local problems: We will be mostly interested in the so-called local problems. Informally speaking, these
are the problems on graphs such that if the solution is incorrect, we can find out by looking at a small
neighborhood of one vertex.
Given a graph G and its node u P V pGq, the ball BGpu, rq3 around u of radius r is the subgraph of nodes
around u up to distance r. More generally, an r-hop neighborhood is a graph with one highlighted node v
such that the radius of that graph measured from v is at most r.
Definition 1.1 (A local problem). Local problem4 Π with checkability radius r is formally a triplet pS, r, Pq.
Here, S is a finite set of allowed labels and each P is a set of allowed S-colored r-hop neighborhoods. A
solution to Π in a graph G is an assignment of color from S to every vertex of G such that for every u P V pGq
we have BGpu, rq P P.
2The function log˚ n measures how many times we need to take the logarithm of n until we get a value of size at most 2,
i.e., log˚ 22 “ 1, log˚ 222 “ 2 and so on.
3We write Bpu, rq when G is clear from the context.
4Our definition is a simplified variant of the definition of the so-called locally checkable labeling problem by Naor and
Stockmeyer [NS95], discussed later in Section 2.4.2.
3

--- Page 4 ---
42
69
73
47
3
42
77
43
12
3
...
Function from local neighborhoods to output labels
Message-passing distributed algorithm
42
77
43
8
42
77
43
12
3
8
Figure 2: This picture shows the two fundamentally different ways of understanding local algorithms.
Left: A tpnq-round local algorithm can be seen as a distributed protocol where in each round, each node can send
any message to any of its neighbors. The computers start with the knowledge of their unique identifier (or a random
string).
Right: A local algorithm with round complexity tpnq can be seen as a function that maps each possible tpnq-hop
neighborhood to an output label. Applying this function to every vertex of the input graph always has to solve our
problem: For example, if our problem is a coloring problem, the first two local neighborhoods in the above table need
to map the two vertices with labels 77 and 43 to different colors, since the two labeled 2-hop neighborhoods could be
a part of the same graph (which is, in fact, shown on the left).
For example, 3-coloring is a local problem for S “ tR, G, Bu, r “ 1, and P containing all properly colored
1-hop neighborhoods. On the other hand, a non-example of a local problem is coloring an input graph
on n vertices with n colors: the local problem should not have different constraints for graphs of different
sizes. Of course, while the theory of local algorithms is simplest for local problems as we defined them, the
applications of local algorithms are not limited to local problems.
Local algorithms: There are two equivalent ways of thinking about local algorithms5 and both of them
are important (see Figure 2). An intuitive, algorithmic definition was already sketched in Section 1.1: We
assume that there is a computing device at every node. For simplicity, these devices are assumed to have
unbounded computational power, thus excluding Turing machines from the definitions. A tpnq-round local
algorithm is a protocol where these devices communicate for tpnq synchronous message-passing rounds using
the edges of the input graph to send messages. At the beginning, the device in each node starts only with
the information about its identifier/random string and the size of the graph, n. When the protocol finishes,
each device outputs its part of the solution (e.g., its color).
It will also be helpful to understand an alternative and equivalent definition that extracts the essence of
what we are measuring with local algorithms. In this alternative definition, a local algorithm with round
complexity tpnq is simply a function that we can apply to every ball Bpu, tpnqq of the input graph to compute
the output at a given node u. Let us state it formally.
Definition 1.2 (Local algorithm). A local algorithm A with a round complexity of tpnq is a function that
accepts two inputs: firstly, the value n, and secondly, a labeled tpnq-hop neighborhood.
5In the literature, these algorithms are often referred to as “distributed algorithms in the LOCAL model of computing”. We
use the shorter and less formal term “local algorithm” for better readability.
4

--- Page 5 ---
When we use this second definition, running a local algorithm on an input graph G simply means
coloring each node u P V pGq with the output of AnpBGpu, tpnqqq where we used the first parameter of a local
algorithm, the size of the underlying graph n “ |V pGq|, as a subscript. Solving a problem Π on G simply
means that after running An on G, the output colors satisfy constraints P on all vertices of G.
Moreover, in the case of deterministic local algorithms, we assume that the nodes of the input graph
are additionally labeled with unique identifiers from the range rnOp1qs “ t1, 2, . . . , nOp1qu.6 In the case of
randomized local algorithms, we assume that the nodes of the input graph are labeled with infinite bit
strings. Solving a problem then means solving it with overall error probability at most 1{nOp1q, if the bit
strings are sampled independently randomly.7
We notice that if there is a deterministic local algorithm solving some problem with round complexity
tpnq, there is also a randomized local algorithm solving the same problem with the same round complexity.
This is because any randomized algorithm can start by each node generating a random identifier from
the range rnCs: The probability that these identifiers are not unique, i.e., some two nodes have the same
identifier, is at most n2 ¨
1
nC . Choosing C large enough, this error probability can be made as small as any
polynomial function of n.
Finally, we remark that we can talk about local algorithms solving problems on graphs with additional
structure (e.g. directed graphs) or on concrete graph classes. For example, in our introductory example from
Section 1.1, it makes sense to think of all definitions relative not to the class of all graphs but to the class
of graphs that are oriented paths. One interesting setup that we discuss mostly in Section 2 is the class of
bounded-degree graphs where we fix some constant ∆and analyze the class of graphs of degree at most ∆.
Notice that on these graphs, the set P from the definition of local problems, as well as the support of the
function A from the definition of local algorithms, are finite.
Equivalence of the two definitions: Let’s see a proof sketch of why the two definitions are equivalent.
On the one hand, let’s say we are given a function A that maps tpnq-hop neighborhoods to output labels and
we want to construct a tpnq-round message-passing protocol. Consider the protocol where in the i-th round,
each vertex u sends its neighbors everything there is to know about the ball Bpu, iq: How the graph looks
like and the values of identifiers/random strings at every node of Bpu, iq. Each node v can then internally
use this information from its neighbors to learn everything there is to know about the ball Bpu, i ` 1q. After
tpnq rounds of communication, each vertex v thus knows its whole tpnq-hop neighborhood Bpv, tpnqq. At this
point, the vertices stop communicating and each one applies the function A locally to its ball which solves
the problem solved by A.
On the other hand, assume that we have a tpnq-round communication protocol and want to turn it into a
function A that takes tpnq-hop neighborhood as inputs. We notice that if we know the tpnq-hop neighborhood
Bpu, tpnqq of a node u, we can simulate the first round of the protocol in that ball and get to know the state
of all vertices in Bpu, tpnq ´ 1q after the first round. Continuing like this inductively, we conclude that
starting with the knowledge of Bpu, tpnqq, we can learn the state of the protocol at the center node u after
tpnq rounds.
There are two different but equivalent ways of understanding local algorithms.
1. They are message-passing protocols running for some number of rounds.
2. The output at each node is a function of its local neighborhood.
Importantly, it will be very helpful for us to keep both definitions in mind: When we design local
algorithms, the message-passing definition is more helpful as it is natural to think as “first, we run the
protocol A1, then the protocol A2”. On the other hand, when we prove lower bounds, the formal definition of
Definition 1.2 is easier to use. When we think of applications to distributed/parallel algorithms, the protocol-
design definition is preferable since this is how the actual parallel/distributed algorithms are implemented.
6While assuming polynomial-range identifiers may look a bit arbitrary, we will see in Section 2 that the notion of deterministic
algorithms is very robust. We simply need a way of breaking the potential symmetry of the input graph – think of what happens
when you run a local algorithm on a vertex-transitive graph such as a cycle without any identifiers or randomness!
7Formally-minded readers may feel uneasy about the definitions not specifying the constant in the nOp1q expressions. We
will see later in Theorem 2.20 that the exact constant in the definition typically does not matter. Formally, when we say that
there is a local algorithm, it means that for every C there is an algorithm in the setup where we require the size of identifiers
to be at most nC (or the error probability to be at most 1{nC).
5

--- Page 6 ---
In some other applications, like applications to descriptive combinatorics, the formal definition is perhaps a
bit more natural.
1.3
Sequential vs Distributed Local Complexity
This section presents one of the most fundamental results in the area of local algorithms. Currently, it may be
very unclear what kind of problems can be solved with a local algorithm of round complexity, say, poly log n.
This will become much clearer, since we will next see that, up to poly log n, the model of local algorithms is
the same as the model of so-called sequential local algorithms that are much easier to understand.
The case of maximal independent set: As an example, let’s think of a concrete local problem known
as the maximal independent set problem. In this problem, every node must be labeled either selected or
unselected. The constraint is that each selected node should not neighbor any other selected node,
while each unselected node should neighbor at least one selected node8.
Is there a local algorithm constructing a maximal independent set in a polylogarithmic number of rounds?
This is not clear at all! The answer to this question is positive, and perhaps the simplest algorithm is the
randomized algorithm of Luby [Lub86; ABI86]. This algorithm in fact served as the foundational example
that later led Linial [Lin92] to define local algorithms. But Luby’s algorithm is a non-trivial algorithm9 and
just by staring at the maximal independent set problem, it is quite unclear whether a fast local algorithm
exists, or not.
This stands in stark contrast with the “sequential” world: If we do not care about all vertices outputting
the answer “at once”, we can compute a maximal independent set with the following simple algorithm: We
choose any order of vertices and iterate over them in that order. Whenever we consider a vertex u, we look
at its neighbors, and if at least one of them is already selected, we mark u as unselected. Otherwise, we
mark u as selected.
Here is a curious property of the above algorithm: We can still think of it as a “local” algorithm. Indeed,
each node makes its decision by examining its 1-hop neighborhood. The only difference is that the algorithm
is a sequential local algorithm where we iterate over nodes in an arbitrary order, not a distributed local
algorithm10 as we defined it in Definition 1.2 where all nodes have to output their answer at once.
A fundamental result of local complexity is the fact that these two definitions are equally powerful, up
to polylogarithmic factors. Hence, in the concrete example of the maximal independent set, we can think of
this problem as being “easy” not because of a clever algorithm like Luby’s, but because of the above simple
sequential algorithm.
The distributed round complexity of any local problem equals its sequential local complexity,
up to poly logpnq.
Formal definition of sequential local algorithms: We next make this principle formal. We need to
start by defining a general sequential local algorithm. Here is a definition of a deterministic sequential local
algorithm, made slightly more powerful than the maximal-independent-set algorithm by allowing the output
of each node to be not just the final color, but the node can also keep additional information that future
vertices can read from that node.
Definition 1.3 (Sequential local algorithms). A sequential local algorithm of local complexity tpnq is a
function A that takes two inputs, n and a labeled tpnq-hop neighborhood.
Its output for a neighborhood
Bpu, tpnqq around a node u is a pair ps, tq, with s being the output at u and t being additional information
stored at u. An input neighborhood to A has some nodes labeled by these pairs.
8This is a much easier problem than the maximum independent set problem where we additionally maximize the number
of selected nodes.
9We can briefly describe the algorithm: It runs in Oplog nq rounds and in each round, every vertex chooses a random number
from r0, 1s. If its number is the largest among its neighbors, the vertex goes in the independent set and is removed from future
iterations, together with its neighbors. After Oplog nq rounds, all vertices are removed with high probability and the algorithm
terminates.
10We sometimes use the name distributed local algorithm to stress that we are talking about a local algorithm and not a
sequential local one.
6

--- Page 7 ---
Running a sequential local algorithm on a graph means iterating over its vertices in some order and each
time applying A to produce the answer at the particular vertex. When we run A on a node v, the algorithm
has access to all already produced pairs ps, tq at the vertices in Bpu, tpnqq on which A has already been run.
Solving a problem with a sequential local algorithm means that regardless of the order in which we choose
the vertices, this process results in a solution to the problem.
Notice that we do not require unique identifiers in the definition; we will see later in Theorem 2.7 that
they are not needed for local problems. We can also define (oblivious) randomized algorithms where first an
adversary chooses an order in which we iterate over vertices; then we sample random bits in each vertex and
run our sequential local algorithm.
We will next prove the following theorem by Ghaffari, Kuhn, and Maus [GKM17].
Theorem 1.4 (Ghaffari, Kuhn, and Maus [GKM17]). Let A be a deterministic (randomized) sequential local
algorithm with local complexity tpnq. Then, there is a deterministic (or randomized, respectively) distributed
local algorithm simulating A with round complexity tpnq ¨ rOplog3pnqq.11
We note that it is known that there are local problems such that their sequential and distributed local
complexity differ by a factor of Ωplog n{ log log nq. [Gav+09]
Network decompositions: A crucial tool that we will rely on in this section and the next one is the
concept of a network decomposition. Network decomposition is a clustering of the input graph into clusters
of small diameter12 (see Figure 3).
Definition 1.5 (Network decomposition). A pc, dq-network decomposition of a graph G is a coloring of G
with c colors. We require that vertices of each color induce a graph such that each of its connected components
(that we call clusters) has diameter at most d.
We defer the discussion about the existence of network decompositions to Section 1.5. For now, we will
simply state the guarantees of the currently best deterministic network decomposition construction.
Theorem 1.6 ([GG24]). There is a deterministic local algorithm that outputs a (Oplog nq, Oplog nq)-network
decomposition in rOplog2 nq rounds.
Proof of Theorem 1.4: Armed with the algorithm for network decomposition, from Theorem 1.6, let us
prove Theorem 1.4.
Proof of Theorem 1.4. An important concept employed throughout this text is working within the power
graph: Given a graph G and a parameter r, we define the power graph Gr to be the graph with V pGrq “ V pGq
where two vertices are connected whenever their distance in Gr is at most r.
We start with a sequential local algorithm A of complexity tpnq.
We will work in the power graph
Gtpnq and construct a network decomposition in it with c “ Oplog nq colors and diameter d1 “ rOplog nq in
Gtpnq via Theorem 1.6. Consider this network decomposition in the context of the original graph G: We
constructed clusters of actual diameter d ď tpnq ¨ d1 “ tpnq ¨ rOplog nq in G. Moreover, two clusters from the
same color class have distance at least tpnq ` 1 in G. Finally, since every communication round in Gr can be
simulated in r communication rounds in G, the round complexity of constructing our network decomposition
is tpnq ¨ rOplog3 nq by Theorem 1.6.
We will now use our clustering to simulate A. We will simulate an order of iterating over the vertices
where we first iterate over all the vertices in the first color class, then all the vertices in the second color
class, and so on. For a fixed color class, we will arbitrarily simulate the algorithm A in each cluster C
independently of all other clusters of the same color (see Figure 3).
Notice that every two clusters C1, C2 of the same color i are far enough so that the tpnq-hop neighborhood
of any vertex u P C1 never contains a vertex u1 P C2. Hence, simulations in different clusters of the i-th color
do not interact and our simulation is a faithful simulation of iterating over all the vertices of G in a certain
order and applying the sequential algorithm A to them.
11We use rOptpnqq to denote the complexity Optpnq ¨ logOp1q tpnqq.
12A diameter of a graph G is defined as maxu,v dGpu, vq where dGpu, vq is the distance between u and v in G.
7

--- Page 8 ---
1.
2.
11.
12.
1.
13.
4.
7.
2.
5.
14.
8.
9.
15.
3.
6.
1.
2.
1.
1.
1.
1.
2.
2.
2.
2.
3.
3.
3.
3.
4.
10.
Figure 3: This picture shows a network decomposition with c “ 2 color classes and d “ 2 diameter. It also shows how
network decomposition is used to convert an input sequential local algorithm (of local complexity 1) into a distributed
local algorithm in Theorem 1.4.
Left: The color classes of the network decompositions are ordered as (red, blue). We iterate over the color classes
and in one iteration, we consider each cluster separately and simulate an input sequential local algorithm in it (see
the node ordering inside each cluster). When the algorithm is simulated in blue clusters, it has access to the output
of neighboring red vertices.
Right: The partial simulations of the sequential local algorithm in each cluster are consistent with a single run of
that algorithm over all vertices.
Finally, let us discuss how the simulation of A is implemented with a local algorithm. Our local algorithm
simulating A is a message-passing protocol with c phases where in the i-th phase, each cluster C of color
i first chooses a leader node, e.g., the node with the smallest identifier. This node collects all information
about the output of A so far up to the distance tpnq from C. Then, the leader node internally simulates A
on C and sends the result of that simulation back to all nodes in C. All this can be done in a number of
rounds proportional to the diameter of C and tpnq. Thus, the overall round complexity of the simulation is
c ¨ tpnq ¨ rOplog nq “ tpnq ¨ rOplog2 nq.
1.4
Derandomization
By now, we understand that the sequential local complexity is closely related to the distributed round
complexity. However, we still do not understand the power of randomness. There might be scenarios where a
problem’s randomized (sequential or distributed) local complexity is significantly lower than its deterministic
(sequential or distributed) complexity. Interestingly, this never happens for local problems. Distributed local
algorithms for them can be derandomized with poly logpnq slowdown in round complexity.13
Any local problem has the same deterministic and randomized round complexity,
up to poly logpnq.
Before proving this result, let us contemplate how it fits into the big picture. Thus far, we have seen
six plausible definitions of how to measure the local complexity of a problem. There are the following three
different ways of thinking about it, and for each one of them, we can define both the deterministic and the
randomized complexity:
1. (distributed protocol) There are computers at nodes, we design a message-passing protocol, and we
measure the number of rounds of this protocol.
2. (distributed local complexity) Output at each node is a function of its local neighborhood.
3. (sequential local complexity) We iterate over the nodes in an arbitrary order and settle each output at
a node by looking at its local neighborhood.
13It is important to restrict ourselves to local problems. Otherwise, consider the following silly counterexample problem: We
are to mark some vertices of the input graph so that at least n{3 but at most 2n{3 vertices are marked. Using randomness,
this problem can be solved in 0 round complexity: every vertex simply flips a coin. But imagine trying to solve the problem
deterministically: If the input graph has no edges, we are pretty screwed!
8

--- Page 9 ---
We now understand that all of these definitions are equivalent, up to poly logpnq and for local problems.
Formal statement of derandomization: Formally, we will prove the following statement by Ghaffari,
Harris, and Kuhn [GHK18], using the derandomization method of conditional expectations.
Theorem 1.7 (Ghaffari, Harris, and Kuhn [GHK18]). Let Π be any local problem of randomized round
complexity tpnq. Then, its deterministic sequential local complexity is Optpnqq.
Proof. We are given a randomized local algorithm A with round complexity tpnq for a local problem Π “
pS, Pq with checkability radius r. We will next describe a deterministic sequential local algorithm that writes
an infinite sequence of bits into each node u of the input graph G so that if we then simulate A with these
bits, it solves Π.
For a vertex u P V pGq, define the failure indicator Xpuq as the indicator random variable for the event
that if we run A with random bits, it fails at u at solving the local problem Π “ pS, Pq. By failure at u we
mean that Bpu, rq R P. We notice that Xpuq depends only on the output of A at an r-hop neighborhood of
u, and thus it ultimately depends only on random bits in the pr ` tpnqq-hop neighborhood of u. Moreover,
the probability of failure at u is less than 1{n by A being a randomized algorithm solving Π. This implies
that E
”ř
uPV pGq Xpuq
ı
ă 1.
Next, we will consider the following sequential local algorithm. We iterate over the nodes in an arbitrary
order, and whenever it is a node uk’s turn, we fix the random bits Bpukq at this node to a value bpukq such
that
E
»
–
ÿ
vPV pGq
Xpvq
ˇˇˇ @i P rks : Bpuiq “ bi
fi
fl
ď E
»
–
ÿ
vPV pGq
Xpvq
ˇˇˇ @i P rk ´ 1s : Bpuiq “ bi
fi
fl .
In words, we set the random bits so that the expected number of errors does not increase.
First, such a value bpukq of random bits at uk definitely exists, since the right-hand side of the above
inequality simply averages over many possible instantiations of Bpukq (that is, we rely on the law of total
expectation).
Second, we can compute this value of random bits by looking only at the pr ` tpnqq-hop
neighborhood of uk, since the values Xv for v outside of Bpuk, r ` tpnqq are independent of the choice of
random bits at uk.
After this sequential algorithm with local complexity pr ` tpnqq finishes, we have set the random bits at
every vertex u P V pGq in a way that makes
E
»
–
ÿ
uPV pGq
Xpuq
ˇˇˇ @i P rns : Bpuiq “ bi
fi
fl ă 1.
But all values Xpuq are now deterministic, so we conclude that no failure occurs if we run A with these bits.
Finally, after this derandomization procedure is run, we also have to run A. We will defer the discussion
of how to combine two sequential local algorithms into one to Lemma 1.9. This lemma implies that there
exists a single sequential local algorithm with local complexity Optpnqq that simulates first running the
derandomization procedure and then running A with the bits computed by that procedure.
Putting Theorems 1.4 and 1.8 together, we get the following derandomization theorem for (distributed)
local algorithms.
Theorem 1.8 (Ghaffari, Harris, and Kuhn [GHK18]). Let Π be any local problem of checkability r and
randomized round complexity tpnq. Then, its deterministic round complexity is tpnq ¨ rOplog3 nq.
Conversely, it’s known that for some local problems, the gap between randomized and deterministic local
complexity can be as large as Ωplog n{ log log nq [Bal+20c].
Leftover: composing sequential algorithms: We will briefly discuss how two sequential local algorithms
run one after the other can be composed into a single one of larger local complexity.
9

--- Page 10 ---
Lemma 1.9 (Ghaffari, Kuhn, and Maus [GKM17, Observation 2.1, Lemma 2.2]). Let A1, A2 be two deter-
ministic (randomized) sequential local algorithms with local complexities t1pnq, t2pnq. Then, there is a single
deterministic (randomized, respectively) sequential local algorithm A of complexity 2pt1pnq ` t2pnqq14 that
simulates the output of first running A1, and then running A2 on the output of A1.
Proof. We would like A to work as follows: We iterate over the nodes and when it is the turn of a node u,
we first simulate A1 for all nodes in Bpu, t2pnqq. Then, we use the computed information to simulate A2 at
u to compute the final output at u.
The only difficulty is that once u simulates A1 for a node v P Bpu, t2pnqq, we cannot simulate A1 at v
again in the future since we want to have the guarantee that all simulations of A1 taken together correspond
to a consistent iteration over the nodes of the input graph and running A1 on them.
Thus, our algorithm A will additionally store at u the output of simulations of A1 within Bpu, t2pnqq.
When it is the turn of a vertex u, A starts by looking at its 2t2pnq-hop neighborhood and fixing the answers
of A1 for nodes v P Bpu, t2pnqq at which A1 was already simulated in the past. Only then we simulate
A1 for the rest of the nodes in Bpu, t2pnqq and run A2 after that.
The final local complexity of A is
max pt1pnq ` t2pnq, 2t2pnqq.
1.5
Network Decompositions
Let us recall the definition of a network decomposition:
Definition 1.5 (Network decomposition). A pc, dq-network decomposition of a graph G is a coloring of G
with c colors. We require that vertices of each color induce a graph such that each of its connected components
(that we call clusters) has diameter at most d.
We will next discuss constructions of network decompositions15: the missing piece in proof of Theo-
rems 1.4 and 1.8.
Existence of network decompositions: First of all, it is unclear whether network decomposition of the
input graph, say with parameters c, d “ Oplog nq always exists. Let’s confirm this by constructing it using
the folklore sequential ball-carving algorithm.
Theorem 1.10 (Ball-carving algorithm). An pOplog nq, Oplog nqq-network decomposition exists for any
graph G.
Proof. We will show how to construct the first color class of the network decomposition. In particular, we
will find a family of vertex-sets C “ tC1, C2, . . . , Ctu, where we call each Ci Ď V pGq a cluster, such that:
1. The clusters are not adjacent; i.e., there is no edge uv P EpGq with u P Ci, v P Cj, i ­“ j,
2. each cluster Ci has diameter Oplog nq,
3. at least n{2 vertices are clustered, i.e.,
ˇˇˇŤt
i“1 Ci
ˇˇˇ ě n{2.
To construct the clustering C, we iterate over the vertices of G in an arbitrary order. Each time we are
at a vertex u, we consider the balls Bpu, 0q, Bpu, 1q, . . . of increasing radii around it. In particular, think of
gradually growing larger and larger balls around u, and once the size of the ball does not at least double, i.e.,
once we have |Bpu, i`1q| ď 2¨|Bpu, iq| for the first time, we let Bpu, iq be the next cluster of C. Additionally,
we remove all vertices from the boundary Bpu, i ` 1qzBpu, iq from G. After the ball around u is grown, we
continue this procedure with an arbitrary next vertex of G that was not explored yet.
To analyze this algorithm, first notice that no two clusters are adjacent (Item 1), since after growing each
cluster, we delete its boundary.
Moreover, we claim that all balls have diameter Oplog nq (Item 2). To see this, note that the volume of
each ball Bpu, iq grows as |Bpu, iq| ě 2i until we finish growing. This implies that if we are not finished in
iteration 1 ` log2 n, the ball Bpu, 1 ` log2 nq has to contain more than n vertices, a contradiction.
14In general, k local sequential algorithms can be simulated with complexity 2 řk
i“1 tipnq.
15In the literature, one can very often encounter numerous variants of network decompositions with names like low-diameter
clusterings, padded decompositions, or sparse neighborhood covers.
10

--- Page 11 ---
Finally, we cluster at least half of the vertices (Item 3), because by definition, whenever a ball stops
growing, we have |Bpu, i ` 1qzBpu, iq| ď |Bpu, iq|, so the number of vertices unclustered because of the ball
around u can be charged to the number of vertices clustered around u.
We construct the desired network decomposition by simply repeating the above process log2 n times:
The clustered vertices in the i-th step are removed from the graph and form the i-th color class of the final
decomposition. After log2 n rounds, every vertex gets clustered.
Deterministic distributed algorithms: There is a long line of work on deterministic algorithms for
constructing network decompositions [Awe+89; PS92; RG20; GGR21; CG21; Roz+22a; RHG23; Gha+23;
GG24]. The currently fastest deterministic algorithm for network decomposition is the algorithm by Ghaffari
and Grunau [GG24]. We stated its guarantees in Theorem 1.6.
Perhaps the simplest poly log n-round algorithm is the algorithm of Rozhoň and Ghaffari [RG20] and
its variant by Rozhoň, Haeupler, and Grunau [RHG23]. They both need Oplog7 nq rounds and construct
clusters with diameter Oplog3 nq. We will next explain the construction from [RG20] that in fact outputs
clusters that only have a weaker guarantee of small weak-diameter. A weak-diameter of a cluster C is defined
as maxu,vPC dGpu, vq, as opposed to the (strong-) diameter which is defined as maxu,vPC dGrCspu, vq. That
is, a cluster with a small weak diameter can be even disconnected, we only require that its vertices are close
in the underlying graph G. A small weak-diameter is sufficient for our applications such as the proof of
Theorem 1.4 and we will discuss at the end of this section how one can convert the weak-diameter guarantee
to the strong-diameter one in a black-box way.
Theorem 1.11 (Distributed ball-carving algorithm). There is a local algorithm with round complexity
Oplog7 nq that constructs a network decomposition with c “ Oplog nq colors and d “ Oplog3 nq weak-diameter.
Proof. Similarly to Theorem 1.10, we show how to construct a family of clusters C “ tC1, C2, . . . , Ctu such
that:
1. No two clusters are adjacent,
2. each cluster Ci has weak-diameter Oplog3 nq,
3. at least n{2 vertices are clustered.
Recall that in deterministic local algorithms, every vertex starts with a unique b “ Oplog nq-bit identifier.
Our algorithm has b phases. At the beginning of the algorithm, we start with a clustering C0 that contains
each node of G as a trivial one-vertex cluster. Each cluster C in our clustering is assigned a unique identifier
idpCq – in particular, the identifier of a cluster is set to be the identifier of its unique vertex.
The clustering Ci evolves during the following b phases, with some vertices changing which cluster they
belong to and some vertices being deleted from Ci. We will prove that after each phase i P rbs, the clustering
Ci has the following guarantees:
1. Consider the graph Gi “ GrŤ
CPCi Cs, i.e., the graph induced by vertices that were not deleted yet.
Consider any connected component K of Gi. All clusters present in K have the same first i bits in
their unique identifier.
2. Each cluster C P Ci has weak-diameter i ¨ Oplog2 nq.
3. |V pGiq| ě n ´ i ¨ n
2b.
Plugging i “ b, the inductive guarantees of Items 1 to 3 reduce to the final desired guarantees of Items 1
to 3 from the beginning of the proof. Thus, we only need to show how one phase of the algorithm makes
sure that if we start with the guarantees for some i, they also hold for i ` 1.
At the beginning of each phase i`1 P rbs, we classify each cluster in Ci as either active or inactive, where
a cluster C is active if and only if the pi ` 1q-th bit in idpCq is equal to zero.
Next, we run a variant of the ball-carving algorithm from Theorem 1.7 with t “ 10b log2 n steps. In
each step of this algorithm, each vertex u from some inactive cluster first checks whether it neighbors with
11

--- Page 12 ---
0001
0111
0101
1011
1001
1101
1111
1110
1100
Figure 4: This picture illustrates the second phase of the algorithm from Theorem 1.11, in a simple example graph.
Left: At the beginning of the second phase, the clusters are already separated according to their first bit. In particular,
if the identifier starts with 1, the cluster is in the top connected component, while if the identifier starts with 0, the
corresponding cluster is in one of the two bottom connected components. In the second phase, a cluster is active
(blue) if its second bit in the identifier is 0, and inactive (red) otherwise. In the first step of this phase, each red
vertex proposes to join an arbitrary neighboring blue cluster, provided that there is one (the arrows in the picture).
The active cluster then either decides to grow (cluster 1001) or the vertices that proposed to it are deleted (cluster
1011). Note that if a cluster decides to delete its boundary, it does not neighbor any red nodes from that point on.
Middle: After one step of our algorithm, the inactive cluster with identifier 1111 became disconnected but its weak-
diameter remains the same as at the beginning of the phase. In the second step of this phase, each red vertex again
proposes to join an arbitrary neighboring blue cluster.
Right: The picture shows the resulting clustering after the second phase is finished. Note that the only two adjacent
clusters with identifiers 1011 and 1001 will be separated in the following, third, phase, as their identifiers differ on
the third position.
12

--- Page 13 ---
a vertex that is currently present in an active cluster. If there are more such neighboring vertices, u chooses
an arbitrary such vertex in C and then u proposes to join C.
Next, each cluster C collects how many vertices proposed to join C. If there are at least |C|{p2bq such
vertices, then C decides to grow: All the vertices that proposed to join C leave their original cluster and join
C. On the other hand, if less than |C|{p2bq proposed to join C, all these vertices are deleted; they will not be
present in Ci`1 and they will not participate in the rest of the algorithm. Note that after an active cluster
C decides to delete the proposing vertices, it is neighboring only with nodes from other active clusters and
thus it does not grow anymore in the rest of the phase. This finishes the description of one phase of the
algorithm (see Figure 4 for an illustration).
To analyze the phase, we first check that each cluster stops growing during the phase.
This is true
because otherwise, at the end of the phase, the cluster would have to contain more than
p1 ` 1{p2bqq10b log2 n ą n
nodes. In particular, the weak-diameter of each active cluster grows additively by at most 2 ¨ 10b log2 n “
Oplog2 nq, while the weak-diameter of each inactive cluster does not increase. This proves Item 2.
Next, consider any connected component K of Gi. The clusters in K already agree on the first i bits of
their identifier at the beginning of the phase i`1 by our inductive assumption. Recall that all active clusters
stop growing during the phase and delete the inactive nodes on their boundary; in particular no active and
inactive cluster neighbor at the end of the algorithm. Therefore, in Gi`1 the component K further splits into
connected components K1, K2, . . . such that for each component Ki we have that either all of its clusters
are active or all are inactive. We conclude that clusters in each connected component of Gi`1 agree on the
first i ` 1 bits in their identifier as needed in Item 1.
Finally, whenever a cluster C stops growing, we delete at most |C|{p2bq nodes. Thus, during the phase,
we delete at most n{p2bq nodes which proves Item 3.
Let us discuss the round complexity of the algorithm. The clusters have weak-diameter Oplog3 nq. Hence,
each growing step can be implemented with that round complexity. There are t “ Oplog2 nq steps in one
phase, b “ Oplog nq phases, and we need to repeat the overall algorithm c “ log2 n times. We conclude that
the overall round complexity is Oplog7 nq.
Next, let us show how we can use our current knowledge of local algorithms to construct a local algorithm
for network decomposition with c, d “ Oplog nq.
Corollary 1.12. There is a local algorithm with Oplog9 nq round complexity that constructs a network
decomposition with c “ Oplog nq colors and d “ Oplog nq diameter.
Proof. We observe that the algorithm from Theorem 1.10 can be seen as a sequence of Oplog nq sequential
local algorithms per Definition 1.3, each one with local complexity Oplog nq. Using Lemma 1.9, we can thus
view it as a single sequential local algorithm of local complexity Oplog2 nq.
Thus, we can use Theorem 1.4 to convert this algorithm into a local algorithm.
While we phrased
the guarantees of Theorem 1.4 using the best available network decomposition algorithm, we can plug
in the network decomposition from Theorem 1.11 instead; the reduction holds even if we use a network
decomposition with a weak-diameter guarantee.
Let us briefly go back to the observation from the proof of Corollary 1.12 that the algorithm from
Theorem 1.10 can be viewed as a sequential local algorithm. This observation helps us to appreciate network
decomposition as the “complete” problem for turning sequential local algorithms into distributed ones: On
the one hand, network decomposition allows us to do this task via Theorem 1.4; on the other hand, any
way of proving that theorem leads to a distributed algorithm for network decomposition via the proof of
Corollary 1.12.
Randomized distributed algorithms: There is a classic randomized algorithm by Linial and Saks [LS93]
that constructs an pOplog nq, Oplog nqq-network decomposition in Oplog2 nq distributed rounds. Let us sketch
its beautiful variant by Miller, Peng, and Xu [MPX13] also known as the MPX algorithm:
In their algorithm, every vertex independently chooses a random head start sampled from an exponential
distribution; that is, a head start of each node is 0 with probability 1{2, 1 with probability 1{4, and so
on. Next, we run the breadth-first-search algorithm from all nodes at once with those head starts. That is,
13

--- Page 14 ---
we first choose some number T “ Oplog nq such that with high probability, no node samples a head start
larger than T. Then, we simulate a run of breadth-first search from an additional virtual node u0 which is
connected to every other node u with an oriented edge of length T ´ head startpuq. All vertices reached by
the breadth-first search from the same starting node u form one cluster. The output of the algorithm are
only those vertices such that all their neighbors are from the same cluster.
One can prove that the output clustering from this algorithm contains at least a constant fraction of
all vertices and uses disjoint clusters of diameter Oplog nq, with high probability. We repeat this process
c “ Oplog nq times to construct a network decomposition.
1.6
Bounds for Concrete Problems
This survey emphasizes the general properties of local algorithms, but it is crucial to remember that their
study is rooted in understanding specific local problems. One of the most significant problems that has
driven much of the development in this field is the maximal independent set problem. This problem belongs
to the group of four classical symmetry-breaking problems, along with maximal matching, vertex coloring,
and edge coloring that we discuss later in this section.
1.6.1
Maximal Independent Set
Recall that the maximal independent set problem involves finding a subset of vertices in a graph that
is both independent (no two vertices are adjacent) and maximal (adding any other vertex would violate
independence). The first algorithms for this problem were the randomized algorithms by Luby [Lub86] and
Alon, Babai, and Itai [ABI86], which find a solution in Oplog nq rounds with high probability.16 Around the
same time, Linial introduced the model of local algorithms [Lin92], perhaps influenced by those algorithms.
One of the most important open questions in this area is whether a sublogarithmic-round randomized
algorithm exists for the maximal independent set problem.
Problem 1.13. Is there a randomized oplog nq-round algorithm for the maximal independent set problem?
Is there an rOp?log nq-round algorithm?17
Note that this problem specifically asks for a randomized algorithm. We discuss the deterministic case
shortly.
The second part of the question is motivated by the celebrated lower bound by Kuhn, Moscibroda, and
Wattenhofer [KMW16], which shows that the complexity of the problem is Ω
´b
log n
log log n
¯
. More precisely,
they show that for any maximum degree ∆, we can derive a lower bound of Ω
´
min
´b
log n
log log n,
log ∆
log log ∆
¯¯
for the maximal independent set problem. This motivates analyzing the complexity of the problem both as
a function of n and ∆.
Algorithms for small ∆: An important related question is to understand the complexity of the problem
as a function of the maximum degree, ∆. In this context, remarkable progress has been made using the so-
called shattering framework. The main idea is to develop fast randomized algorithms that solve the problem
for most vertices, leaving only small “islands” of unsolved vertices to be resolved later by an appropriate
deterministic local algorithm (see Section 2.2 for an example usage of the technique).
This technique,
developed in several papers [Bar+16; FG17; CLP18], culminated in an algorithm by Ghaffari [Gha16] that
solves the problem in Oplog ∆` poly log log nq rounds.
On the lower bound side, the aforementioned bound by Kuhn, Moscibroda, and Wattenhofer [KMW16]
shows that Oplog ∆q complexity cannot be substantially improved for certain ranges of ∆.
Moreover, the celebrated round elimination technique developed over the past decade [Bra19; Bra+16;
Bal+19b; Bal+21a; BO20; Bal+22c; BBO20] (see Sections 2.1 and 2.2 or the survey by Suomela [Suo13])
shows that this complexity is nearly optimal. In particular, Balliu, Brandt, Hirvonen, Olivetti, Rabie, and
Suomela [Bal+19b] use round elimination to establish a lower bound of Ω
´
min
´
∆,
log log n
log log log n
¯¯
. We con-
clude that no algorithm can achieve round complexity Oplog ∆q`o
´
log log n
log log log n
¯
or even op∆q`o
´
log log n
log log log n
¯
.
16Section 1.3 contains additional discussion related to maximal independent set and Luby’s algorithm.
17This text lists some open problems in the area. For a different list, see [Suo23].
14

--- Page 15 ---
Interestingly, a deterministic algorithm by Barenboim, Elkin, and Kuhn [BEK15; BE09; Kuh09] for the
maximal independent set problem runs in Op∆` log˚ nq rounds, which is also tight under this lower bound.
Deterministic algorithms: For deterministic algorithms, the most significant open question is whether
their complexity can match that of Luby’s algorithm.
Problem 1.14. Is there a deterministic rΘplog nq-round algorithm for the maximal independent set problem?
For a long time, the deterministic complexity of the maximal independent set problem paralleled the best-
known algorithms for network decompositions (discussed in Section 1.5), which implies a polylogarithmic
round complexity. Recently, a number of papers developed techniques such as local rounding and distributed
derandomization [HKP01; FGK17; Har19; GK22; Fao+23; GG23]; this lead to decoupling of the complexity
of the maximal independent set from network decomposition.
Currently, the best-known algorithm by
Ghaffari and Grunau [GG24] achieves a complexity of rOplog5{3 nq rounds.
On the lower bound side, Balliu, Brandt, Hirvonen, Olivetti, Rabie, and Suomela [Bal+19b] used
round elimination to show that the deterministic local complexity of finding a maximal independent set
is Ωplog n{ log log nq.
2
The Bounded-Degree Regime
In the previous section, we gained a good understanding of the fundamentals of local complexity – in essence,
if we care about the complexities up to poly log n, there are several equivalent definitions of it with sequential
local algorithms being a particularly helpful model for designing algorithms.
In this section, we will restrict our attention to bounded degree graphs and local problems of subloga-
rithmic complexity. Something surprising is going to happen: We will see that while, a priori, we would
expect all kinds of problem complexities, there are only three distinctive classes of local problems. This
sharp threshold phenomenon is a consequence of remarkable results known as speedup theorems.
As a rough roadmap for the rest of the section, we are going to give a more or less self-contained proof of
the following Theorem 2.1, with Section 2.1 focusing on the symmetry-breaking regime, Section 2.2 focusing
on the Lovász-local-lemma regime, and Section 2.3 focusing on showing that there are gaps in between the
regimes.
Theorem 2.1 (Classification of local problems with oplog nq complexity on bounded degree graphs). Let
us fix any ∆and the class of graphs of degree at most ∆. Then, any local problem with randomized round
complexity oplog nq has one of the following three round complexities.
1. Order-invariant regime: The problem has Op1q deterministic and randomized round complexity.
2. Symmetry-breaking regime: The deterministic and randomized round complexity of the problem lies
between Ωplog log˚ nq and Oplog˚ nq (both the deterministic and the randomized complexity is the same
function).
3. Lovász-local-lemma regime: The problem has deterministic round complexity between Ωplog nq and
rOplog4 nq. Its randomized round complexity is between Ωplog log nq and rOplog4 log nq.
2.1
The Symmetry-Breaking Regime
In the bounded-degree regime, the problems of maximal independent set or the closely related problem of
p∆` 1q-coloring play a bit similar role to network decomposition, as we will see in Theorem 2.5. These
problems are known as basic symmetry-breaking problems. This section shows that the round complexity of
these problems is Θplog˚ nq on bounded-degree graphs.
Basic symmetry breaking problems like maximal independent set and ∆` 1 coloring are
closely related. Their round complexity on bounded degree graphs is Θplog˚ nq.
15

--- Page 16 ---
2.1.1
Fast Coloring Algorithm and its Implications
We will first discuss a classical local coloring algorithm of Linial [Lin92] improving upon earlier work from
[CV86; GPS88]. This algorithm colors a graph of degree at most ∆with Op∆2q many colors in Oplog˚ nq
rounds. We will later see in Theorem 2.5 that this implies that on bounded-degree graphs, the local com-
plexity of constructing the maximal independent set and ∆` 1 coloring is Oplog˚ nq.
The main idea behind Linial’s algorithm is as follows: At the beginning of the algorithm, we will think
of the unique identifiers at the vertices as an input proper coloring with colors from the (very large) range
rnOp1qs. The heart of the proof is to provide a 1-round local algorithm that takes as input a coloring with
colors from a large range rks, and outputs a coloring with colors from a much smaller range rOp∆2 log kqs.
Repeating this process for Oplog˚ nq many rounds, we end up with a coloring with ∆Op1q many colors.
It remains to construct a suitable 1-round algorithm. To do this, we will use the so-called cover-free
families defined below.
Definition 2.2. Given a ground set rk1s, a family of sets S1, . . . , Sk Ď rk1s is called a ∆-cover free family if
for each set of indices i0, i1, . . . , i∆P rks, we have Si0z
´Ť∆
j“1 Sij
¯
­“ H. That is, no set in the family is a
subset of the union of some ∆other sets.
Such families can be constructed with the following parameters.
Lemma 2.3 ([KSS81; EFF82] or see [Gha20, Lemma 1.19, 1.20]). For any k, ∆, there exists a ∆-cover free
family of size k on a ground set of size k1 “ Op∆2 log kq. Moreover, if k ď ∆3, it exists for k1 “ Op∆2q.
We can now state and analyze Linial’s algorithm.
Theorem 2.4 (Linial [Lin92]). The deterministic round complexity of constructing a coloring with Op∆2q
many colors is Oplog˚ nq.
Proof. We will show a one-round algorithm that turns an input proper k-coloring into a proper Op∆2 log kq
coloring. Moreover, in case k ď ∆3, we can turn the k-coloring into an Op∆2q coloring.
The one-round algorithm simply interprets each input color from rks as a set in a ∆-cover free family
over the ground set rk1s for k1 “ Op∆2 log kq (and k1 “ Op∆2q in case k ď ∆3). Such a family exists by
Lemma 2.3. After each vertex u with a color Su learns the colors Sv1, . . . , Svd of its neighbors, it simply
chooses any color in the set Suz
´Ťd
i“1 Svi
¯
as its new color. This set is non-empty by the definition of a
cover-free family, and the new coloring is proper. This finishes the description of our one-round algorithm.
We interpret the input unique identifiers as proper coloring and apply the one-round algorithm Oplog˚ nq
many times. A quick calculation shows that the number of colors then drops to Op∆2 log ∆q. After one more
round and using the case k ď ∆3, the number of colors becomes Op∆2q, as needed. 18
Simulation of sequential local algorithms: We notice that graph coloring can be seen as a special case of
network decomposition discussed in Section 1 where each cluster has diameter 0. In particular, coloring with
a small number of colors allows us to turn sequential local algorithms into distributed local ones similarly to
Theorem 1.4.
Theorem 2.5. Let A be a sequential local algorithm with local complexity tpnq. Then, we can turn it into
a distributed local algorithm of round complexity Op∆Optpnqq ` tpnq ¨ log˚ nq. If the sequential algorithm is
deterministic, so is the distributed one.
18If we do not care about how the resulting number of colors depends on ∆, there is a more self-contained one-round algorithm
going back to Cole and Vishkin [CV86] that does not rely on cover-free families and leads to a coloring with 2Op∆log ∆q many
colors in Oplog˚ nq rounds. The algorithm turns a coloring with 2k colors into a coloring with 2Op∆log kq colors as follows:
Think of the input color of each vertex u as a k-bit string su. The vertex sends this color to all its neighbors. After u receives
d ď ∆strings of its neighbors, s1, s2, . . . , sd, it does the following. For each received si, the node u identifies an index ji where
si differs from its own bit string su. Such an index exists since we assumed that we started with proper coloring. The new color
of u is defined as the concatenation s1
u “ j1 ˝ surj1s ˝ ¨ ¨ ¨ ˝ jd ˝ surjds. That is, the vertex u simply remembers only the values
of bits of su on the positions where those values reveal that su differs from its neighbors. We observe that no two neighboring
vertices can end up with the same string. Moreover, if we write s1
u in binary, it has only Op∆¨ log kq many bits.
16

--- Page 17 ---
Proof. We follow the outline of the proof of Theorem 1.4 that simulated sequential local algorithms using
network decompositions.
To simulate a sequential local algorithm A of local complexity tpnq, we first
construct a coloring of Gtpnq with O
`
∆2pGtpnqq
˘
colors19 using Linial’s algorithm from Theorem 2.4. That
algorithm needs O
`
tpnq ¨ log˚ n
˘
rounds where we multiply by tpnq because one round of communication in
Gtpnq can be simulated in tpnq rounds in G. Subsequently, we iterate over all colors and simulate the sequential
algorithm A as in Theorem 1.4. That simulation takes additional Op∆2pGtpnqqq “ ∆Optpnqq rounds.
As a corollary of Theorem 2.5, we get that maximal independent set or ∆`1-coloring can be constructed
in Oplog˚ nq rounds on bounded-degree graphs.
Corollary 2.6. Sequential local algorithms with local complexity Op1q (such as algorithms for the maximal
independent set or ∆` 1 coloring) can be simulated with round complexity Oplog˚ nq on bounded degree
graphs.
Understanding unique identifiers: Let us now discuss the unique identifiers from the range rnOp1qs in
the definition of deterministic algorithms. We will use our understanding of coloring to see that the strength
of the model of deterministic algorithms remains the same even if the identifiers come from a much larger
range like r2ns or r22ns. Moreover, we will understand why identifiers are not needed in the definition of
sequential local algorithms.
The following theorem will use an instance of a fooling argument, variants of which we will enjoy employing
later on. To motivate it, notice that it is a bit awkward that the definition of a local algorithm talks about
globally unique identifiers. We will next “fool” a given deterministic local algorithm solving a local problem
by supplying to it a distance coloring (i.e., coloring of the power graph) with nOp1q many colors instead of
unique identifiers. The algorithm still has to work since a failure of the algorithm for input distance coloring
would imply a failure for input unique identifiers.
Theorem 2.7. Let A be a deterministic local algorithm of round complexity tpnq for a local problem Π.
Then, given any s “ nωp1q, there is a deterministic local algorithm A1 solving Π in Optpnq¨log˚
npsqq rounds20
and assumes that the identifiers are from range rss.
Similarly, let A be a sequential local algorithm of local complexity tpnq for a local problem Π in a model of
sequential local algorithms where each node has additionally a unique identifier from rnOp1qs. Then there is a
sequential local algorithm A1 for Π of complexity Optpnqq in the standard model of sequential local algorithms
without any identifiers.
Proof. Let A be a deterministic algorithm of round complexity tpnq solving a local problem Π with local
checkability r in the model where the unique identifiers are from rnOp1qs (the constant in the exponent is
assumed to be large enough). We construct a new algorithm A1 that works in the less powerful model with
identifiers from rss as follows. We first compute a coloring of the power graph G2ptpnq`rq with nOp1q many
colors, then we simulate A with that coloring as identifiers.
In particular, the coloring is constructed by iterating color reductions of Linial’s algorithm of Theorem 2.4.
Recall that each color reduction reduces the range of color exponentially, thus after log˚
npsq rounds, we reduce
the input coloring with colors from rss to a coloring with colors of size at most Op∆2pG2ptpnq`rqqq “ nOp1q.
Next, we prove that A1 is correct. Assume that A1 fails to solve Π at a node u. Notice that this failure
depends only on the ptpnq`rq-hop neighborhood of u where the coloring constructed by A1 uses unique colors.
In particular, we can extend this coloring of Bpu, tpnq ` rq to a labeling of every node of the input graph
with unique identifiers. The original algorithm A fails to solve Π at u for these identifiers, a contradiction
with A being correct.
The proof of the second claim in the theorem is very similar and, in fact, easier, since ∆` 1-coloring has
constant sequential local complexity and thus Linial’s color reductions are not needed.
As a helpful corollary of the second part of Theorem 2.7, we can now see that any deterministic local
algorithm A solving some local problem can be converted into a deterministic sequential algorithm of the
same asymptotic local complexity. This was actually not clear until now since our definition of deterministic
sequential algorithms in Definition 1.3 did not contain input unique identifiers.
19The notation ∆pGq stands for the maximum degree of G.
20Here, log˚
npsq returns how many times we need to take the logarithm of s, until its value drops below n, i.e., log˚
np2nq “
1, log˚
np22nq “ 2 and so on.
17

--- Page 18 ---
2.1.2
Lower bound for coloring via round elimination
Finally, let us prove that the log˚ n dependency for constructing maximal independent sets or colorings is
necessary.
Theorem 2.8 (Naor [Nao91] and Linial [Lin92]). The local complexity of computing ∆` 1 coloring is
Ωplog˚ nq, even on graphs that are oriented paths.
There are several known proofs of this theorem [Nao91; Lin92]; we will use the proof of Linial [Lin92]
framed in the language of a powerful technique known as the round elimination (see [Suo13] for an introduc-
tion to it). In essence, given a local problem Π, round elimination is an automated technique that defines a
problem Π1 such that the round complexity of the fastest algorithm for Π1 is exactly one round smaller than
the round complexity of the fastest algorithm for Π (unless the complexity of Π was already zero). This is
very helpful for proving lower bounds: If we start with some problem Π and argue that even after t rounds
of round elimination, the problem Πptq that we end up with is not solvable in zero rounds, we infer that the
local complexity of Π is at least t.
Preparations for the lower bound: We will prove the lower bound in the extremely simple setup where
we are promised that the input graph is an oriented path, i.e., the setup from Section 1.1. The lower bound
will be for deterministic algorithms, so each node starts with a unique identifier. We will make a further
restriction on the identifiers, we require that the input labeling with identifiers is increasing; that is, if for
every oriented edge e “ uv going from u to v, we have IDpuq ă IDpvq.
Next, let us discuss local algorithms. It will be helpful to think about them as functions in the spirit of
Definition 1.2. A subtlety we need to be careful about is that in one step of round elimination, we don’t
want to directly convert a t-round local algorithm (that sees 2t ` 1 vertices) to a t ´ 1 round algorithm (that
sees 2t ´ 1 vertices). Instead, we want to convert an algorithm that sees t vertices to an algorithm that sees
t ´ 1 vertices. To this end, we define an edge-centered pt ` 1{2q-round algorithm A to be a local algorithm
such that for an edge e “ uv, the input to A is the ball Bpuv, t ´ 1q defined as Bpu, t ´ 1q Y Bpv, t ´ 1q. The
output of A is a label for the edge e. For example, 1{2-round local algorithm run on e has access to the two
identifiers IDpuq and IDpvq and it maps the two identifiers to a label of e.
One half-round reduction: Here comes the heart of the proof; we will show that any given t-round local
algorithm for coloring vertices with k colors can be converted to a ppt ´ 1{2qq-round algorithm for coloring
edges with 2k colors.
Lemma 2.9. Assume that for t ą 0 we are given a node-centered t-round deterministic local algorithm A
that outputs a proper coloring with k colors on oriented paths with increasing unique identifiers. Then, there
is an edge-centered ppt ´ 1{2qq-round algorithm A1 that properly colors the edges with 2k colors in the same
setup. Similarly, edge-centered pt ` 1{2q-round algorithms for k-coloring can be converted into node-centered
t-round algorithms for 2k-coloring.
Proof. We will only discuss the conversion of a node-centered algorithm into an edge-centered one, the other
case is very similar.
Given a t-round algorithm A, we define a pt ´ 1{2q-round edge-centered algorithm A1 as follows (see
Figure 5): Given an edge e “ uv so that A1 has access to Bpuv, t ´ 1q, we let A1 to consider all possible
identifiers of the unique node x P Bpv, tqzBpuv, t ´ 1q, i.e., the only node that A sees but A1 doesn’t. For
each possible value of the identifier IDpxq of x (we also consider the option that we are at the end of the
path and the vertex x does not exist), the algorithm A1 simulates A on Bpv, tq and records the color that
A outputs. The final output of A1 is a subset of rks that contains each color c P rks whenever there is an
identifier that makes A output c. Note that we can encode the set with k bits – that is, we view this set of
colors from the range rks itself as a new color from the range r2ks. This finishes the description of A1.
Our task is to prove that A1 returns a proper coloring of edges. Here is what this question reduces to:
Consider any increasing labeling of the oriented path with identifiers and consider any three consecutive
nodes u, v, w (see Figure 6). We again let x be the unique node in Bpv, tqzBpuv, t ´ 1q and y the subsequent
neighbor of x. Consider the new colors C1, C2 P r2ks that A1 outputs on the two edges uv and vw. We need
to prove that the two colors C1, C2 are different. We do that by focusing on the original color c P rks that
A outputs at v.
18

--- Page 19 ---
A′
2
3
5
9
10
11
15
17
18
5
9
10
11
13
A
5
9
10
11
12
A
...
{
}
Figure 5: The definition of the 1.5-round algorithm A1 derived from a 2-round algorithm A: The algorithm A1
considers all compatible one-node extensions of its neighborhood containing 4 nodes to 5-node-neighborhoods (in the
picture, this corresponds to the following node having the identifier 12, 13, . . . , nOp1q, and the possibility that the node
does not exist). The algorithm considers all possible answers that A returns for those neighborhoods (the picture
shows that the red and the blue color are two of those possible answers). The color that A1 uses to color the edge it
is centered on is simply the set of all colors that A returns for some extension (in the picture, it is the set containing
the red and the blue color).
A′
2
3
5
9
10
11
15
17
18
u
v
w
x
y
A′
C1
C2
Figure 6: The situation from the proof of correctness of A1: We need to argue that the two colors C1, C2 are
different. To do so, we define c to be the color that A outputs on the input p5, 9, 10, 11, 15q. By definition, we have
c P C1. On the other hand, if c P C2, we get an existence of an identifier ID1pyq such that A returns c on the
input p9, 10, 11, 15, ID1pyqq. But then we consider the input p5, 9, 10, 11, 15, ID1pyqq and notice that A colors two
consecutive vertices with the same color c, a contradiction with its correctness.
19

--- Page 20 ---
On one hand, notice that c P C1 because the edge-centered algorithm A1 run at uv considers the actual
identifier IDpxq as a possibility and thus includes c in C1.
On the other hand, assume for contradiction that c P C2. That would imply that there is a certain
identifier ID1pyq that makes the output of A at w to be the color c. But now consider changing the valid
increasing labeling of identifiers that we started with by letting the identifier of y be equal to ID1pyq. Let’s
look at all the nodes in Bpvw, tq. The identifiers on them are still a valid increasing identifier sequence.21
But after extending Bpvw, tq and its identifiers to a path on n vertices labeled with increasing identifiers,
A fails to solve k-coloring on that graph since it outputs the same color c at both v and w, a contradiction
with our assumption that A is correct.
We can now prove Theorem 2.8 as follows: Assuming the existence of a t “ oplog˚ nq-round algorithm
for 3-coloring of oriented paths, we apply Lemma 2.9 2t times until we end up with a 0-round algorithm
A0 that colors oriented paths with 22. . .23
ă n colors where the inequality holds because the height of the
exponentiation tower is 2t “ oplog˚ nq. But such A0 is simply a function mapping an input identifier from
the range rnOp1qs to a color in the smaller range rns.
Using the pigeonhole principle, we can find two
identifiers that A0 maps to the same color and argue that if these two identifiers happen to be present at
two neighboring nodes, A0 fails to output proper coloring. 22
2.2
The Lovász Local Lemma Regime
We will next discuss Lovász local lemma, a very expressible local problem closely related to the third regime
of problems from Theorem 2.1.
Definition of Lovász local lemma: Lovász local lemma is the following very general local problem 23. The
problem is formally defined for bipartite graphs in which nodes of one part are labeled as random variables
and the nodes of the other part are labeled as bad events.
We denote the maximum degree of random
variable nodes as ∆r.v. and the maximum degree of bad event nodes as ∆b.e.. Each node u labeled as a
random variable is additionally labeled with a probability space Ωu. To simplify discussions, we will without
loss of generality assume that each probability space is an infinite list of random bits (i.e., it is the uniform
distribution on r0, 1s). Next, each node v labeled as a bad event that neighbors with nodes u1, . . . , ud with
d ď ∆b.e. is additionally labeled with an event Ev on the space śd
i“1 Ωui.
Often, it is useful to work only with a graph induced by bad-event nodes where two bad-event nodes
are connected if they share a common random variable. In that case, we will talk about the dependency-
graph formulation of Lovász local lemma and use ∆to denote its maximum degree. On the other hand, the
setup with a bipartite graph with both bad-event nodes and random-variable nodes will be denoted as the
variable-event-graph.
The crucial ingredient to the Lovász local lemma is a requirement on the bad events that, roughly
speaking, says that we can use the union bound in the dependency-graph neighborhood of every bad event
Ev and conclude that with positive probability, neither Ev, nor its neighboring bad events occur. Namely, in
the tight version of Lovász local lemma, we are given a promise that each bad event Ev has probability at
most p where p is defined by the following Lovász local lemma criterion:
p ¨ p∆` 1q ď 1{e.
(1)
A foundational result of Erdős and Lovász [EL75] is that even in the tight formulation, it is always
possible to solve any instance of the local lemma problem, by which we mean that one can instantiate
random variables so that no bad event occurs.
21This is the place in the argument where we need increasing and not just unique identifiers: With unique identifiers, the
leftmost and the rightmost node of Bpvw, tq could now have the same identifier.
22Round elimination may used both to prove lower bounds and to construct algorithms. In particular, it can be used to
derive that the round complexity of 3-coloring paths in 1
2 log˚ n ˘ Op1q [RS15].
23The Lovász-local-lemma problem does not quite satisfy the requirements for the local problem as we defined it in Defini-
tion 1.1, but, morally speaking, it can be seen as such.
20

--- Page 21 ---
A C-relaxed (or just polynomially-relaxed) version of Lovász local lemma, which is a bit more relevant
to our applications, only requires that
p ¨ ∆C ď 1
(2)
This section will show both fast algorithms and lower bounds for the polynomially-relaxed Lovász local
lemma.
Lovász local lemma is a very versatile and expressible local problem.
Its deterministic
round complexity on bounded degree graphs is Θppoly log nq, and its randomized complexity
Θppoly log log nq.
2.2.1
Fast Algorithms for the Local Lemma
We first discuss how to solve any instance of the local lemma with a fast deterministic local algorithm.
To this end, we will start with a randomized algorithm that we later derandomize by Theorem 1.8. In a
breakthrough result in the area of constructive algorithms for the local lemma, Moser and Tardos [MT10]
presented an algorithm for it in the tight formulation. Moreover, they presented a parallel variant of their
algorithm that can be interpreted as a local algorithm with round complexity Oplog2 nq. This complexity was
later improved by Chung, Pettie, and Su [CPS17b] to Oplog nq rounds on bounded degree graphs. Plugging
their result to Theorem 1.8, we obtain the following theorem.
Theorem 2.10. The deterministic round complexity of solving any instance of the tight version of Lovász
local lemma on bounded degree graphs is rO
`
log4pnq
˘
.
Even faster randomized algorithm: Next, we will show that there is an even exponentially faster
randomized algorithm for the relaxed version of the local lemma. We will discuss the algorithm of Fischer
and Ghaffari [FG17] with round complexity poly log log n which uses shattering, a successful technique (cf.
Section 1.6) that goes back to the work on algorithmic local lemma by Beck [Bec91].
The main idea goes as follows. Our algorithm will have two phases. In the first phase, we use a sequential
local algorithm with constant complexity to do the following. Given an instance of the local lemma, the
algorithm fixes most of the random variables in such a way that most bad events are satisfied (i.e., all random
variables relevant for that bad event are fixed and the event does not occur). More concretely, the fraction
of fixed random variables and satisfied events is 1 ´ 1{∆Op1q. The price for this outcome is that remaining,
unfixed, bad events have their probability slightly increased from 1{∆C to 1{∆C1 for some C1 ă C.
Fortunately, we have an additional guarantee on the unfixed bad events. Due to the very small locality
of the algorithm in the first phase, we can use an independence-like argument to show that the size of the
connected components of unfixed bad events is Op∆Op1q log nq, with high probability (see Figure 7). We also
say that the graph shatters into small components. We can thus run the best deterministic algorithm from
Theorem 2.10 as the second phase of the algorithm, to solve the remaining instance of the C1-relaxed local
lemma. This second phase takes poly log p∆log nq rounds which is also the round complexity of the overall
algorithm.24 We will now make the above discussion formal.
Theorem 2.11 (First phase of Fischer and Ghaffari [FG17]). There is a randomized sequential local algo-
rithm A of constant local complexity that gets as input a variable-event graph of an instance of C-relaxed
Lovász local lemma for some large enough C. The algorithm fixes some bits of each random variable to
concrete values so that conditioned on those fixed bits, we have the following two properties:
1. Each bad event has probability at most 1{p3∆q.
2. Up to 1{ polypnq error probability, the residual dependency graph induced by bad events with non-zero
probability has connected components of size Op∆3 log nq.
24Our example algorithm from Section 1.1 can be seen as a simple shattering algorithm.
21

--- Page 22 ---
Figure 7: This picture shows an example variable-event graph corresponding to an instance of Lovász local lemma; the
circles represent bad events and squares represent random variables. The picture shows the situation after the first
phase of Fischer-Ghaffari algorithm (Theorem 2.11). Most random variables are set to a fixed value (grey squares). A
small proportion of the random variables remains unset (red squares) and the bad events neighboring with an unset
random variable (red circles) form connected components of diameter Oplog nq.
Proof. 25 The algorithm A is defined as follows. We iterate over the random variables and for each random-
variable node u with neighboring bad-event nodes v1, . . . , vd, we perform the following process. We sample
the random bits of Ωu one by one. While we do that, we consider the probabilities of neighboring bad events
PpEi|sampled bitsq for each 1 ď i ď d. The first time it happens that for some i we have PpEi|sampled bitsq ą
1{p6∆q, i.e., the bad-event probability crosses the dangerous threshold of 1{p6∆q, we stop sampling and do
the following.
We label u, together with all other random variables neighboring vi as frozen (if more vi’s jumped over
the dangerous threshold at the same time, we do this to all of them). We never sample bits of frozen random
variables in the future.
In particular, we stop sampling bits of u and continue with the next unfrozen
random variable in the arbitrary order of our sequential local algorithm. This finishes the description of the
algorithm.
To see that each bad event has probability at most 1{p3∆q (the first item in the theorem statement)
during any point throughout the algorithm, we notice that if an event E of probability PpEq “ p depends
on a single bit of randomness b, we have, by Markov’s inequality, that PpE|b “ 0q, PpE|b “ 1q ď 2p. That
is, the bad event probability in our process never increases multiplicatively by a factor larger than 2, which
together with the definition of the dangerous threshold implies the desired bound.
To understand the size of connected components in the residual dependency graph (i.e., components of
bad-event nodes of non-zero probability after we set the random bits), consider any fixed set S of bad-event
nodes with the following two properties:
1. (independence) no two nodes v1, v2 P S are neighboring in the dependency graph G,
2. (connectivity) S is connected in G6.
We will next prove that with high probability, no such set S of size Ωplog nq survives to the residual graph.
First, we use the independence property to prove that the probability that all nodes in a fixed set S
crossed the dangerous threshold during our process is exponentially small in the number of nodes |S|. Let
us contemplate the behavior of the algorithm A with respect to any bad-event node v P S and the random
variables u1, . . . , ud neighboring v in the variable-event graph. We note that if bits b1, . . . , bk´1 were already
sampled and bk is sampled next, we have Ebk rPpEv|b1, . . . , bkqs “ PpEv|b1, . . . , bk´1q. Hence, viewing PpEvq
as a random variable that depends on bits sampled from Ωu, u P V pGq, we conclude that its expectation is
at most 1{∆C and we can thus use Markov’s inequality to conclude that the probability of PpEvq crossing
the dangerous threshold is at most
6∆
∆C “ 6{∆C´1. Moreover, we notice that if we first set the randomness
25The original algorithm and its analysis by Fischer and Ghaffari [FG17] contains subtle flaws. Here, we follow the proof by
Maus [Mau].
22

--- Page 23 ---
of nodes in V 1 “ V pGqzpu1 Y ¨ ¨ ¨ Y udq to whatever values, we can still make above argument and conclude
that for all ways of setting Ωu “ ωu for all u P V 1 we have
PpEv|@u P V 1 : Ωu “ ωuq ď 6{∆C´1.
Since we assumed that S is an independent set of bad-event nodes in the dependency graph, we can thus
inductively prove that the probability of all nodes in S crossing the dangerous threshold is at most
`
6
∆C´1
˘|S|.
We next count the number of possible sets S of size t that satisfy the connectivity property: Each such
S can be specified by fixing any node u P S, and then specifying how one can walk for 2p|S| ´ 1q steps
in G6 so that the walk defines a spanning tree of G6rSs. Hence, the number of sets S of size t is at most
n ¨ p2∆6q2pt´1q. We can thus upper bound the existence of some connected surviving set S of size t as
n ¨ p2∆q12t ¨
ˆ
6
∆C´1
˙t
.
Choosing C “ Op1q and t “ Oplog nq large enough, we conclude that the size of this expression is at most
1{nOp1q.
Finally, for t “ Oplog nq from the above argument, consider any connected subset S of G of size at least
p2∆q3 ¨ t and assume that S survived to the residual dependency graph. Then, we can find its subset S1 Ď S
of size at least |S1| ě t where S1 is independent in G3, yet S1 is connected in G4. To see this, consider a
greedy algorithm that starts with S1 “ tuu for arbitrary u P S, iterates through vertices of S and while
we still can add at least one node v P S to S1 and keep the independence property, we choose any v with
distance 4 to S1 and add it to S1. One can see that the final set S1 has to be connected in G4. Also, |S1| ě t
because adding a vertex to S1 disqualifies at most p2∆3q vertices to be added to S1 in the future.
If all nodes of S survived to the residual dependency graph, it means that every node in S1 has to have
a neighboring node that crossed the dangerous threshold. The set S1 thus gives rise to a set S2 of size
|S2| “ |S1| ě t of nodes that all crossed the dangerous threshold. Moreover, by S1 being independent in G3,
we conclude that S2 is independent in G. Since S1 was connected in G4, S2 is connected in G6. The set S2
thus satisfies the requirements of a set that, as we have proven, does not occur in the residual graph with
high probability and we can thus conclude the same for the original connected set S.
Putting Theorem 2.11 (simulated as a distributed algorithm by Theorem 2.5) together with Theorem 2.10,
we conclude that the following result holds.
Theorem 2.12 (Fischer and Ghaffari [FG17]). There exists a constant C such that the randomized round
complexity of any instance of the C-relaxed Lovász local lemma on bounded-degree graphs is rO
`
log4 log n
˘
.
The dependency on ∆in the round complexity of Fischer-Ghaffari algorithm is polynomial. It is unknown
whether this polynomial dependency can be improved to logarithmic.
Problem 2.13. Is there a randomized local algorithm for relaxed Lovász local lemma with round complexity
Oppoly log ∆` poly log log nq?
Conjecture of Chang and Pettie [CP19]: We note that Chang and Pettie [CP19, Conjecture 1] conjec-
ture that any instance of the relaxed local lemma can be solved with randomized Oplog log nq complexity.
Problem 2.14 (Chang-Pettie Conjecture). Is it true that the randomized round complexity of C-relaxed
Lovász Local Lemma for some large enough C is Θplog log nq on bounded degree graphs?
We will see later in Section 2.3.2 that the randomized round complexity Oplog log nq implies the deter-
ministic round complexity of Oplog nq via Theorem 2.21.
Self-contained algorithm: A bit unfortunate property of Theorem 2.12 is that it relies on the random-
ized entropy-compression algorithms from Moser and Tardos [MT10] or Chung, Pettie, and Su [CPS17b].
However, we can prove Theorem 2.12 also in a self-contained way: First, we observe that after the first
23

--- Page 24 ---
phase of the Fischer-Ghaffari algorithm finished, each surviving bad event simply collects the whole con-
nected component of the residual graph; then we solve the problem in each residual component by applying
the standard, existential, Lovász local lemma. This new randomized algorithm has complexity Oplog nq on
bounded degree graphs since this is the maximum diameter of residual components, with high probability.
We can derandomize this algorithm using Theorem 1.8 and use the resulting deterministic algorithm instead
of the algorithm of Chung, Pettie, and Su [CPS17b] in the second phase of our shattering algorithm. This
way, we get a simpler and more self-contained algorithm. Its downside is a worse value of C and a worse
dependence of round complexity on ∆.
2.2.2
Lower Bound via Round Elimination
Next, we will show that the deterministic local complexity of solving a certain specific instance of Lovász local
lemma is Ωplog nq. Later, we will prove in Theorem 2.21 that this also implies a randomized lower bound
of Ωplog log nq, thus showing that the round complexity of Fischer-Ghaffari algorithm from Theorem 2.12 is
close to tight.
The problem we choose for the lower bound is sinkless orientation. We will define the problem only on
trees of degree at most ∆where it is already hard. The task is to orient all the edges of the input tree so
that no node is a sink, which is defined as a node such that all ∆neighboring edges point towards it (nodes
of degree less than ∆are not constrained in any way).
Sinkless orientation can be seen as a specific instance of the local lemma: orienting each edge randomly
corresponds to a random variable at each edge. Then, a vertex becoming a sink corresponds to a bad event
of probability 2´∆. For large enough ∆, this is much smaller than the polynomial criterion 1{∆C from
Equation (2) which makes this problem a valid instance of the local lemma. We will next prove the following
theorem.
Theorem 2.15 (Brandt, Fischer, Hirvonen, Keller, Lempiäinen, Rybicki, Suomela, and Uitto [Bra+16]).
For any constant ∆, the sinkless orientation problem has deterministic round complexity Ωplog nq on the
class of trees of degree at most ∆.
Preparations: As in Theorem 2.8, we will want to replace the uniqueness of identifiers with local con-
straints that imply that they are unique. In the proof of Theorem 2.8, we worked with identifiers that were
monotonically increasing (which implied they were unique), this time we will work with identifiers that are
consistent with a so-called ID graph [Kor+21; Bal+23b; Bra+22]. 26
Definition 2.16 (ID graph). Given a parameter ∆, an ID graph H is a graph on a set rns that we associate
with unique identifiers. Every edge of the graph is colored with one of ∆many colors and we write Hi for
the graph induced by the i-th color. We require that:
1. The girth of H, i.e., the length of the shortest cycle in H, is at least γ log∆n for some fixed γ ą 0.
2. Each independent set of each Hi has less than n{∆vertices.
Such a graph exists, which can be proven using the same argument as how one proves that high-girth
high-chromatic graphs exist [Bra+22; Kor+21].
We will fix any ID graph and work in a model relative to that ID graph. Here is what that means. First,
we will assume that the input graph G is always a tree of degree at most ∆such that its edges are, moreover,
properly ∆-colored on the input (i.e., each vertex is incident to edges of different colors). Additionally, we
require that if two nodes u, v neighbor in G with an edge of color i, then their identifiers IDpuq, IDpvq
neighbor in Hi.
We notice that this is a local constraint on input identifiers that does not imply they are unique. However,
notice that whenever two vertices u, v P V pGq have the same identifier, we can consider the path between u
and v in G and how it maps to a walk in H that starts in IDpuq and finishes in IDpvq “ IDpuq. The proper
edge-coloring of G implies that the walk never goes from x P V pHq to y P V pHq and then back to x in the
subsequent step. This implies that the walk contains a cycle, thus the distance of u and v is at least as large
26The usual usage of round elimination is for randomized algorithms instead of using the ID graph, but this would require
a longer setup and more calculations.
24

--- Page 25 ---
as the girth of H. That is, the identifiers are unique up to a large distance which is pretty much the same
as them being unique (cf. Theorem 2.7).
Similarly to the lower bound of Theorem 2.8, we will work with node-centered and edge-centered algo-
rithms. For node-centered algorithms, solving sinkless orientation means that the algorithm outputs one of
∆many input edge colors at each node. Outputting a color i means that u decides that the edge of the
color i goes outwards from u. The local constraint on this output vertex-coloring is that no two neighboring
nodes should select the same edge going in between. We will call this variant of the problem edge-grabbing.
On the other hand, edge-centered algorithms will solve the sinkless orientation as we described the problem:
Each edge simply outputs how it is oriented and we have a local constraint at each vertex, requiring that it
has at least one outgoing edge.
Round elimination: We proceed with performing the actual round elimination. Notice that the spirit of
the following proof is very similar to the proof of Lemma 2.9.
Lemma 2.17. Assume that we are given a node-centered deterministic t-round local algorithm A of round
complexity at most t ď log∆n ´ 1 that solves the edge-grabbing problem on trees of degree at most ∆relative
to some fixed ID graph H. Then, there is a t ´ 1{2-round edge-centered deterministic local algorithm A1 that
solves sinkless orientation in the same setup.
Similarly, t ` 1{2-round edge-centered algorithm for sinkless orientation implies a t-round node-centered
algorithm for edge-grabbing.
Proof. We prove just the first part of the statement, the proof of the second part is similar, and doing it is
a good exercise.
We start with any node-centered algorithm A with round complexity t that solves the edge-grabbing
problem. We define the edge-centered algorithm A1 of round complexity t ´ 1{2 as follows. For an edge
e “ uv, the algorithm first considers all the possible extensions of the (known) ball Bpuv, t ´ 1q to the ball
Bpu, tq that is known to A when it is run on u. By an extension, we mean first how the graph looks like
(e.g., maybe some vertices on the boundary of Bpuv, t ´ 1q turn out to be leaves), and second, what the
identifiers are (they have to be consistent with H). We consider all valid extensions and if at least one of
them leads to A grabbing the edge uv from u, then A1 orients the edge uv from u to v. After this is done,
the algorithm makes an analogous reasoning for v; again, whenever at least one extension of Bpuv, t ´ 1q
to Bpv, tq decides to grab the edge uv, A1 orients it from v to u. If no vertex ever decides to grab uv, A1
decides to orient it arbitrarily. This finishes the description of A1 (see Figure 8).
To make sure that A1 is well-defined, we need to prove that it never happens that there is an extension
of Bpuv, t ´ 1q to both Bpu, tq and Bpv, tq such that A run on Bpu, tq decides to grab the edge uv and run
on Bpv, tq, it decides to grab the edge vu. To see this, notice that putting the two extensions Bpu, tq, Bpv, tq
together, the graph Bpuv, tq has at most n nodes and its identifiers respect H.27 We observe that in case A1
is not well-defined, A fails to solve edge-grabbing on Bpuv, tq, a contradiction with the assumed correctness
of A.
Moreover, the algorithm A1 solves sinkless orientation: For any node u of full degree ∆, the original
algorithm A decided to grab a certain edge uv. When we run A1 on uv, A1 will by definition orient this edge
from u to v, thus u cannot be a sink.
Finishing the proof: Let us finish the proof of Theorem 2.15.
Proof of Theorem 2.15. Consider an input graph G which is a branching tree with ε log n layers and every
non-leaf vertex has degree ∆. Note that for small enough ε ą 0, the girth property of the ID graph implies
that any labeling of G with identifiers from rns that respects a fixed ID graph H has unique identifiers. On
the other hand, G has O
`
∆ε log n˘
nodes, so the range from which the identifiers are coming is |V pGq|Op1q.
Therefore, a deterministic local algorithm for sinkless orientation on G implies a local algorithm for that
problem on G with identifiers consistent with H.
But Lemma 2.17 shows that any oplog nq-round algorithm that works relative to H can be sped up to 0
round complexity. A 0-round algorithm A0 is simply a function that maps an input identifier to one of ∆
many colors, i.e., which edge the vertex decides to grab. We can thus think of A0 as a coloring of H with ∆
27This part of the argument needs to work with the ID graph instead of unique identifiers.
25

--- Page 26 ---
u
v
A
A
A′
B(u, t)
B(v, t)
B(uv, t −1)
Figure 8: The picture shows the definition of the algorithm A1 for t “ 2. Notice that our setup is a large ∆-regular
tree with edges colored with ∆colors.
The algorithm A1 has access only to the identifiers in Bpuv, t ´ 1q (the
intersection of the red and the blue ball). To decide on the orientation of the edge uv, the algorithm considers all
possible identifier extensions of Bpuv, t ´ 1q to Bpu, tq (the red ball), and if at least one such extension makes A run
at u grab the edge uv, A1 orients that edge towards v. We analogously orient this edge towards u if at least one
extension of Bpuv, t ´ 1q to Bpv, tq (the blue ball) makes A run at v grab the edge uv.
We notice that it cannot happen that A1 wants to orient the edge uv in both directions: that would imply the
existence of an identifier-labeling of Bpuv, tq on which A is incorrect.
many colors. But notice that for any such vertex coloring, we can consider the largest color class i that has
at least n{∆colors. Then, we use the independence property of ID graphs from Definition 2.16 to infer that
the set of vertices of color i cannot be independent in Hi, i.e., there is an edge uv in H where both u and
v, as well as the edge uv are colored by the color i. We thus found two vertices that may be neighboring in
the input graph G and the algorithm A0 decides to grab the edge connecting them from both endpoints of
that edge, a contradiction with A0 being correct.
Sinkless orientation as the “simplest hard problem”: Notice that if we formulate sinkless orientation as
an instance of Lovász local lemma, the bad event probability is equal to 2´∆, that is, the bad event probability
is exponentially small compared to the polynomial guarantee in the relaxed criterion of Equation (2). It
turns out that this is the threshold where an instance of the local lemma is still “hard”.
Theorem 2.18 ([Bra+16; BMU19; BGR20]). On one hand, there is an instance of Lovász local lemma
(namely sinkless orientation) with the criterion p ¨ 2∆ď 1 that has deterministic round complexity Ωplog nq.
On the other hand, any instance of Lovász local lemma with the criterion p ¨ 2∆ă 1 has deterministic round
complexity Oplog˚ nq.
A similar threshold phenomenon holds also if we work in the variable-event graph.
Theorem 2.19 ([FG17, Theorem 3.5], [Ber23b, Corollary 1.8]). On one hand, there is an instance of Lovász
local lemma28 with the criterion p ¨ ∆∆b.e.
r.v.
ď 1 has deterministic round complexity Ωplog nq. On the other
hand, any instance of Lovász local lemma with the criterion p¨∆∆b.e.
r.v.
ă 1 has deterministic round complexity
Oplog˚ nq.
28The instance is sinkless orientation on trees where one color class has degree ∆r.v. and the other has degree ∆b.e.. One
formulates it as an instance of the local lemma by letting each vertex of one color class grab a random outgoing edge. The
proof that this variant of sinkless orientation is still hard seems to be missing in the literature.
26

--- Page 27 ---
2.3
Speedups and Slowdowns
The following section covers speedup and slowdown theorems which are at the heart of why we understand
that there are sharp thresholds in the local complexities in Theorem 2.1.
The elegant idea behind speedups and slowdowns is that we can simply “lie” to algorithms about the
size of the input graph, an idea closely related to the fooling argument we have already seen in the proof
of Theorem 2.7. To understand this technique, it may be useful to briefly recall that in Definition 1.2, we
defined a local algorithm as a function that takes two inputs. Firstly, it is n, the size of the input graph,
and secondly, it is a tpnq-hop neighborhood of a vertex that is additionally labeled by unique identifiers or
random strings. We will use the notation An to denote the algorithm A when the first input is n, i.e., we
will view A as a sequence of functions A1, A2, . . . In this section, we will contemplate what happens if we
run An on a graph of size n1 ­“ n. If n1 ą n, we are “speeding up” A, while if n1 ă n, we are “slowing it
down”.
2.3.1
Slowdowns
Let’s first see why slowdowns may be useful. As a first application, let us recall that we defined deterministic
and randomized round complexities in Definition 1.1 by requiring unique identifiers from the range rnOp1qs
or error probability at most 1{nOp1q. We will next see that for algorithms with sufficiently small round
complexity, we can replace nOp1q by n in the definition without changing its strength. For deterministic
algorithms, this complements Theorem 2.7 that shows how to replace very large identifiers with polynomially-
sized ones. This follows by plugging in fpnq “ nOp1q into the following slowdown theorem.
Theorem 2.20 (Chang, Kopelowitz, and Pettie [CKP19]). Let f be any increasing function with fpnq ě n,
let Π be any local problem, and let us use tfpnqpnq to denote the deterministic (randomized) round complexity
of solving Π if the input identifiers are from the range rfpnqs (the error probability is required to be 1{fpnq,
respectively). Then,
tnpnq ď tfpnqpnq ď tnpfpnqq.
The theorem holds for local complexities defined with respect to any subclass of graphs closed on adding
isolated vertices. 29
Proof. We will prove just the deterministic version of the theorem. Notice that tnpnq ď tfpnqpnq follows
directly from our assumption fpnq ě n and the definition: any algorithm expecting identifiers from the
range rfpnqs certainly works if they happen to be from the smaller range rns.
Next, consider any deterministic algorithm A that solves Π if the identifiers are from rns in round
complexity tpnq. Our goal is to turn it into an algorithm A1 with round complexity t1pnq that works if the
identifiers are from rfpnqs. Think of A as a sequence A1, A2, . . . for each n P N. We define A1 by setting for
each n that A1
n :“ Afpnq. That is, we “lie” to the algorithm A, telling it that the size of the graph is larger
(namely fpnq) than what it actually is (namely n). Since the round complexity of A on fpnq-sized instances
is tpfpnqq, for the complexity of A1 on n-sized instances we have t1pnq “ tpfpnqq.
Moreover, since Afpnq assumes that the unique identifiers are from rfpnqs, A1
n also assumes that the
unique identifiers from rfpnqs, making it a well-defined algorithm for the definition of local algorithm where
identifiers are supposed to be from rfpnqs on instances of size n.
Finally, we claim that A1 is a correct algorithm. To see this, suppose that A1
n fails to solve Π on some
graph G with n vertices labeled with unique identifiers from rfpnqs. Then, we go back to A and run it on a
graph G1 defined as G together with fpnq ´ n additional isolated vertices, all labeled with unique identifiers
from rfpnqs. We notice that since Π is a local problem, a failure in G implies a failure in G1, and we get a
contradiction with A being correct.
As an example of a non-local problem where the range of identifiers matters, consider the leader-election
problem30 where exactly one node of the input graph is to be selected. If the identifiers are from rns, we
can simply select the node with identifier 1. Otherwise, there is no local algorithm for it if the input graph
is empty.
29Looking at the proof, it is hard to come up with a reasonable class of graphs where the theorem does not apply.
30This is a fundamental problem in the broader area of distributed computing. The maximal independent set problem can
be seen as a local variant of this problem.
27

--- Page 28 ---
A similar argument to the proof of Theorem 2.20 can be used to prove another sleep-well-at-night result:
any local algorithm A with round complexity tpnq solving some local problem can be turned into an algorithm
A1 of round complexity t1pnq ď tpnq which is a non-decreasing function of n.
The randomized version of Theorem 2.20 turns out to be particularly interesting. Chang, Kopelowitz,
and Pettie [CKP19] used it to show that any randomized algorithm can be derandomized, if we appropriately
slow down its complexity. 31
Theorem 2.21 (Chang, Kopelowitz, and Pettie [CKP19]). If a local problem Π has randomized round
complexity tpnq, its deterministic round complexity is t
´
2Opn2q¯
.
The theorem holds for any class of graphs closed on adding isolated vertices.
Proof. Let A be a randomized local algorithm with error 1{nOp1q and round complexity tpnq solving Π. We
start by applying Theorem 2.20 with fpnq “ 2Opn2q to slow down A to complexity t
´
2Opn2q¯
while pushing
the error probability down to 2´Ωpn2q. We still call this new algorithm A.
The deterministic algorithm A1 for Π will work as follows. Let C be such that the unique identifiers
are coming from rnCs. We will use a certain function h (a hash function that we soon specify) that maps
each identifier from rnCs to an infinite bit string. We define A1 as follows: It first uses h to map each input
identifier to an infinite bit string, and next it simulates A using each bit string as the string of random bits.
To construct the function h that makes A1 correct, we simply choose a random one and notice that on
any concrete graph, A1 fails to solve Π with probability at most 2´Ωpn2q with the randomness over the choice
of h. This is because on any concrete graph, A1 with random h is equivalent to running A. But notice that
the number of distinct graphs on n vertices labeled with polynomial identifiers is 2Opn2q ¨ pnCqn “ 2Opn2q.
Hence, choosing the failure probability small enough, we can union-bound over all distinct labeled graphs
and still get that random h works, with positive probability. We thus conclude that for some h, A1 is a valid
deterministic algorithm for Π, as needed.
As a nice corollary, we are getting a very precise understanding of what is happening for the random-
ized round complexity of Lovász local lemma: On one hand, we have seen a randomized algorithm with
round complexity poly log logpnq (Theorem 2.12) that used a deterministic algorithm with round complexity
poly logpnq (Theorem 2.10) as a subroutine. But we can now see that any poly log logpnq round randomized
algorithm would imply a poly logpnq-round deterministic one via Theorem 2.21. A similar observation applies
not just for the local lemma, but for many other problems with randomized algorithms based on shattering
(see Section 1.6). This explains why in local complexity deterministic algorithms are a big deal – not only
they are used as subroutines of randomized algorithms, but we in fact understand that to make progress in
the randomized world, progress in the deterministic world is often necessary.
2.3.2
Speedups
While slowdowns are very useful, the real fun starts when we try to speed up algorithms by lying to them
that the size of the graph is smaller than it actually is. In fact, what can possibly go wrong if we tell an
algorithm that the size of the graph is constant, i.e., we claim that n “ Op1q? As it turns out, not much!
One potential problem is that the algorithm may find out that its tpnq-hop neighborhood contains more
than n nodes and “crash”. The other problem is that the algorithm now requires very small identifiers (if we
started with a deterministic algorithm) or that the failure probability of the algorithm increased to constant
(if we started with a randomized one). This is where our story connects with our discussions of coloring and
Lovász local lemma.
Theorem 2.22 (Chang and Pettie [CP19] and Chang, Kopelowitz, and Pettie [CKP19]). Let A be a local
algorithm for a local problem Π with round complexity tpnq “ oplog nq. Then there is a local algorithm A1
solving Π such that
1. If A was deterministic, so is A1 and its round complexity is Oplog˚ nq.
31Their technique is similar to Adelman’s theorem that proves that BPP Ď P{poly. See [AB09, Theorem 7.14].
28

--- Page 29 ---
A
The size of the graph is n0.
3
1
1
14
33
15
15
2
14
4
4
5
18
6
7
7
8
8
20
11
13
11
1
3
2
4
16
17
5
6
19
8
9
10
21
Figure 9: To speed up an algorithm A, we tell it that the size of the graph is some constant n0, whatever the true
size n is. In this case, the round complexity of the algorithm becomes 2 (see the smaller ball in the picture) and we
assume that the checkability radius of the local problem solved by A is 1.
The algorithm A assumes that the identifiers are unique numbers of size up to nOp1q
0
. Since n " n0, we cannot supply
such identifiers. However, we notice that if A is supplied with nOp1q
0
-sized identifiers that are unique only in every
ball of radius 3 (see the larger ball in the picture), the algorithm still has to work. This is because a failure of A
around some node u implies a failure of A on the graph Bpu, 3q which has size at most n0 and is labeled with unique
identifiers.
2. If A was randomized, so is A1 and its round complexity is the same as the randomized complexity of
solving relaxed Lovász local lemma, i.e., it is rO
`
log4 logpnq
˘
.
The theorem holds for the class of bounded degree graphs and any of its subclasses closed on taking
subgraphs and adding isolated vertices. More generally, for round complexities defined relative to a subclass
of bounded degree graphs of restricted growth, the complexity tpnq needs to be such that we always have
|Bpu, tpnqq| “ opnq for any node u.
Proof. Let Π be a local problem with a checkability radius of r and A be a deterministic (randomized) local
algorithm for Π. We will assume that the identifiers are coming from a range rnCs (alternatively, the failure
probability is 1{nC) for sufficiently large C. We will view A as a sequence A1, A2, . . . , and we start by
choosing n0 to be a large enough constant so that
∆0 ` ∆1 ` ¨ ¨ ¨ ` ∆tpn0q`r ď n0.
(3)
We notice that such an n0 exists by the requirement tpnq “ oplog nq. Our algorithm A1 will simulate An0
for any input n (for n ă n0 we define A1
n “ An).
Let us first handle the case of deterministic algorithms (see Figure 9). There, A1 needs to supply identifiers
to its simulation of An0. This is done as follows. We compute a p∆pG1q ` 1q-coloring of the power graph
G1 “ G2ptpn0q`rq such that the number of colors used is ∆pG1q ` 1 “ ∆Optpn0q`rq ď nC
0 where we used that
C is large enough. We use those colors as identifiers for our simulation of An0. This finishes the description
of A1.
On one hand, the round complexity of the overall algorithm is Oplog˚ nq on bounded-degree graphs. On
the other hand, suppose that A1 fails to solve the problem Π at some node u. We notice that Equation (3)
yields that the ptpn0q ` rq-hop neighborhood of u contains at most n0 nodes. Moreover, this neighborhood
is colored by A1 with unique colors from the range rnC
0 s. Recall that An0 is defined on neighborhoods with
at most n0 nodes labeled with identifiers from rnC
0 s. Thus the algorithm A1 is well-defined. Additionally,
a failure of A1 at u would imply a failure of A on a neighborhood of size at most n0 labeled with some
29

--- Page 30 ---
unique identifiers from rnC
0 s. Adding isolated vertices to that neighborhood to make its size n0, we reach a
contradiction with An0 being correct on n0-sized instances.
We handle the case of randomized algorithms similarly: We again try to simulate An0 for large enough
n0. We notice that we do not need to supply any identifiers in the simulation. However, if we simply simulate
A, we fail to solve Π at any fixed vertex u with probability 1{nC
0 as this is the failure probability of An0.
Thus, we instead formulate the process of simulating A as an instance of Lovász local lemma on a new
variable-event graph G1 as follows. Any original vertex u of the input graph G will be thought of as two
new vertices in G1. One vertex, ur.v, is a random-variable vertex, and it corresponds to the random string
at u. The other vertex, ub.e., corresponds to the event that if we run An0 at u and use the random strings
sampled from the random-variable vertices vr.v. P Bpub.e., tpn0qq, An0 fails to solve Π at u.
We notice that the event at ub.e. depends only on the ptpn0q ` rq-hop neighborhood of u in G. Thus the
degree of this local-lemma instance (in the sense of its dependency-graph formulation) is at most ∆0 ` ∆1 `
¨ ¨ ¨ ` ∆tpn0q`r which is in turn at most n0 by Equation (3). On the other hand, the probability of each bad
event is at most 1{nC
0 . We can thus formulate the simulation of An0 as an instance of a C-relaxed local
lemma. For large enough C, we can then apply Theorem 2.12 to solve that instance.
Finally, we notice that both in the deterministic and the randomize case, we can generalize the requirement
tpnq “ oplog nq to requiring that t satisfies for each u that |Bpu, tpnqq| “ opnq.
We note that in the statement of Theorem 2.22, we do not literally require tpnq “ oplog nq (or |Bpu, tpnqq| “
opnq), it should just be that for some large enough n0, we have tpn0q ď ε log n0, where ε is some small constant
which is a function of ∆, r, and C.
Additional intuition yielded by the proof: The proof of Theorem 2.22 tells us a bit more: Basically, it
allows us to think of local problems with deterministic round complexity oplog nq or, equivalently, Oplog˚ nq,
as “those problems that can be solved in a constant number of rounds, after we compute a distance coloring”.
Moreover, the problems with randomized round complexity oplog nq or, equivalently poly log log n, can be
thought of as “those problems that we can view as an instance of the local lemma”.
Problems with deterministic round complexity oplog nq can be, in fact, solved in constantly
many rounds, after a suitable coloring used as “fake identifiers” is computed.
Problems with randomized round complexity oplog nq can be formulated as instances of poly-
nomially relaxed Lovász local lemma.
Speedup below log˚ n: We will next sketch how one can speed up algorithms with round complexity
oplog log˚ nq to complexity Op1q. Why the weird complexity oplog log˚ nq? The following speedup argument
relies more on the volume than on the radius32, so the importance of radius oplog log˚ nq is that the number
of nodes the algorithm sees is ∆oplog log˚ nq “ oplog˚ nq. The log˚ n volume is then the right threshold for
which we can argue that any deterministic algorithm can be turned into a drastically simpler order-invariant
algorithm. 33
An order-invariant algorithm is a deterministic local algorithm with an additional restriction: it does
not have direct access to the identifiers written on the nodes; it only knows their order, meaning that it
can only compare their relative size. A bit more formally, while an input to a classical local algorithm is a
graph G together with a map f : V pGq Ñ rnOp1qs that maps vertices to unique identifiers, an input to an
order-invariant algorithm is G together with a function f 1 : V pGq ˆ V pGq Ñ tă, ąu that is consistent with
a total linear order on V pGq and that can tell the algorithm for each pair of nodes which one is larger. Of
course, tpnq-round algorithm run at u only has access to f 1 restricted to Bpu, tpnqq ˆ Bpu, tpnqq.
For example, in the setup of Theorem 2.8 where we worked with an oriented path with increasing labels,
an order-invariant algorithm would see the same input order at every vertex.
This already shows that
order-invariant algorithms struggle to solve interesting local problems on graphs that are paths.
32Compare with Theorem 3.2 classifying volume complexities where we have oplog˚ nq speedup instead.
33While the name order-invariant suggests that the algorithm may not care about the order of identifiers in some way, it is
the other way around, the algorithm cares only about the order of the identifiers in its neighborhood. That is, the algorithm
is comparison-based.
30

--- Page 31 ---
Theorem 2.23 (Naor and Stockmeyer [NS95] and Chang, Kopelowitz, and Pettie [CKP19]). Let A be a
deterministic local algorithm for a local problem Π with round complexity oplog log˚ nq. Then, there is a
deterministic local algorithm A1 solving Π with local complexity Op1q.
The theorem holds for any subclass of bounded-degree graphs closed on taking subgraphs and adding isolated
nodes.
Proof Sketch. We will sketch how any deterministic local algorithm A with round complexity tpnq “ oplog log˚ nq
can be turned into an order-invariant algorithm A1, using the hypergraph Ramsey theorem34. Fix an algo-
rithm A and consider the set B “ rnOp1qs of identifiers that A expects on input. Next, consider any subset
S Ď B of size p2∆qtpnq “ oplog˚ nq. Here, we have chosen the function p2∆qtpnq because it upper-bounds the
maximum number of nodes in any tpnq-hop neighborhood that A can see as its input.
Next, let us define the color of S. To do so, first consider the set H of all possible tpnq-hop neighborhoods.
Moreover, for each (unlabeled) neighborhood H P H, consider all of at most |S|! ways in which the identifiers
from S can be assigned to the vertices of H. For each labeled neighborhood, we record the output of A when
it is run on it, and the color of S is defined to be the complete list of all such outputs.
We note that the number of possible colors of a set S Ď B is relatively small, and in particular it can be
upper-bounded by 22Oplog˚ nq2
. Recalling that we use r to denote the checkability radius of Π, we aim to find
a medium-sized set M Ď B of size p2∆qtpnq`r “ oplog˚ nq such that all subsets S Ď M have the same color.
The known bounds for hypergraph Ramsey numbers [GRS91, §1, Theorem 2] allow us to conclude that B is
large enough to always contain such a set M.
We notice that the algorithm A behaves in the order-invariant way if the input identifiers are coming
from the set M. This allows us to define an order-invariant tpnq-round algorithm A1 for Π as follows. Given
an input order on the vertices of Bpu, tpnqq, the algorithm A1 chooses an arbitrary subset S Ď M and maps
the identifiers in S to vertices of Bpu, tpnqq in the unique order-preserving way. Concretely, whenever v1 ă v2
according to the input order, we also have IDpv1q ă IDpv2q. Our algorithm then simply outputs what A
would output on this input. This finishes the description of A1.
To see that we are on the right track, we first notice that it does not matter which subset S Ď M we
choose above; since all subsets S have the same color, they all lead to the same output.
Next, to see that A1 is valid, we assume for contradiction that it fails at a vertex u in some graph G
equipped with some input order. We consider the ball Bpu, tpnq`rq and the restriction of the input order to
this ball. Consider the following thought experiment: In the ball Bpu, tpnq ` rq, we replace the input order
with identifiers from M. We do it in the unique way that preserves the original order; that is, if v1 ă v2 in
the original order, then IDpv1q ă IDpv2q. We observe that for any vertex v P Bpu, rq, the algorithm A1 run
on v with access to the original input order returns the same as A run on v with access to the identifiers
from M. This is because A1 returns the same answer, whatever identifiers from M are chosen to replace the
input order.
But this means that the original algorithm A also fails at the node u for the specific choice of identifiers
from M above. After adding isolated nodes to the ball Bpu, tpnqq equipped with these identifiers, we find a
graph on n vertices where A fails and we thus reach a contradiction.
Finally, let us contemplate the proof of Theorem 2.22 again. The only reason why we could speedup
oplog nq-round deterministic algorithm only to Oplog˚ nq instead of Op1q was the necessity to compute a
coloring that served as “fake” identifiers supplied to the simulation of an algorithm An0. But for order-
invariant algorithms, this is not necessary. We can simply give An0 exactly the same order as the order that
appears on input; thus order-invariant algorithms can be sped up to complexity Op1q and this finishes the
proof.
Tower-sized identifiers: We can wonder what would happen if we wanted to make the above proof
of Theorem 2.23 work for all deterministic local algorithms, not just those that encounter only oplog˚ nq
vertices.
This would force us to change the small-set size from oplog˚ nq to n in the proof.
Since the
hypergraph Ramsey numbers grow roughly as a tower function of the small-set size, this means that to make
the proof work, we would have to start with unique identifiers from the range which is contains numbers
34Recall that in hypergraph Ramsey theorem we have a big set B, we color its small subsets S and we want to find a
medium-sized set M such that all its small subsets S Ď M have the same color.
31

--- Page 32 ---
as large as the tower function of n. The rest of the proof then goes through and allows us to speed up
oplog nq-round algorithms to Op1q-round order-invariant algorithms.
This observation nicely complements Theorem 2.7: While it is true that exponentially-, doubly-exponentially-
, etc. sized identifiers have the same power as polynomially-sized ones, there is a transition somewhere
around tower-function-sized identifiers. From then on, deterministic algorithms of oplog nq complexity with
such huge identifiers can be turned into order-invariant ones. In other words, the identifiers are so large that
no oplog nq-round algorithm can extract any meaningful information from them other than their relative
order.
2.4
Classification of Local Problems
We can now put all the pieces together and prove Theorem 2.1. Let’s restate it here for convenience.
Theorem 2.1 (Classification of local problems with oplog nq complexity on bounded degree graphs). Let
us fix any ∆and the class of graphs of degree at most ∆. Then, any local problem with randomized round
complexity oplog nq has one of the following three round complexities.
1. Order-invariant regime: The problem has Op1q deterministic and randomized round complexity.
2. Symmetry-breaking regime: The deterministic and randomized round complexity of the problem lies
between Ωplog log˚ nq and Oplog˚ nq (both the deterministic and the randomized complexity is the same
function).
3. Lovász-local-lemma regime: The problem has deterministic round complexity between Ωplog nq and
rOplog4 nq. Its randomized round complexity is between Ωplog log nq and rOplog4 log nq.
Proof. Let Π be any local problem of randomized local complexity tpnq “ oplog nq. We can use Theorem 2.22
to formulate Π as an instance of Lovász local lemma. This instance is then solved either with the determin-
istic rOplog4 nq-round algorithm from Theorem 2.10, or the randomized rOplog4 log nq-round algorithm from
Theorem 2.12.
Next, let us assume that the randomized round complexity of Π is even oplog log nq. Then, we can use
the derandomization of Theorem 2.21 to conclude that the deterministic round complexity is oplog nq. This
allows us to use the speedup theorem of Theorem 2.23 to conclude that the deterministic round complexity
of Π is Oplog˚ nq. Moreover, we notice that for any increasing function tpnq “ Oplog˚ nq, we have tp2Opn2qq “
Optpnqq; this means that the derandomization from Theorem 2.21 tells us that randomized and deterministic
round complexities of Π are the same.
Finally, assume that the randomized local complexity of Π is even oplog log˚ nq.
Then, we can use
Theorem 2.23 to find an order-invariant constant-round local algorithm for Π via Theorem 2.23.
Local problems with complexities below oplog nq are of three types:
1. Those that can be solved in constant rounds by order-invariant algorithms,
2. those that are roughly as hard as the basic symmetry-breaking problems such as coloring
or maximal independent set,
3. those that can be viewed as instances of Lovász local lemma.
Improvements to Theorem 2.1: Can we improve Theorem 2.1? The conjecture of Chang and Pettie
[CP19] (Problem 2.14) suggests that in the local lemma regime, we may get rid of the polynomial gap between
the lower and upper bounds. According to our current knowledge, there could be a local problem with
deterministic and randomized round complexities tdpnq, trpnq for any tdpnq “ Ωplog nq, tdpnq “ rOplog4 nq,
trpnq “ Ωplog log nq, trpnq “ rOplog4 log nq, and tdpnq “ Optrp2nqq, where the last constraint follows from
Theorem 2.20.
On the other hand, it is known [Bal+18] that the (extremely narrow) regime between Ωplog log˚ nq and
Oplog˚ nq is densely populated by certain (artificial) local problems.
32

--- Page 33 ---
2.4.1
Sequential local complexities
Let us now discuss how sequential local complexities fit into the picture painted by Theorem 2.1. We will
first observe that the first two classes from our classification in Theorem 2.1, i.e., Op1q and Oplog˚ nq round
complexities, are equal to the class of problems solvable with the sequential local complexity is Op1q.
Theorem 2.24. On bounded degree graphs, local problems with round complexity Oplog˚ nq are exactly those
whose sequential local complexity is Op1q.
Proof sketch. On one hand, consider any local problem with constant sequential local complexity. We can
use Theorem 2.5 to simulate it with a distributed local algorithm in Oplog˚ nq rounds.
On the other hand, consider any local problem Π with local checkability r solvable in Oplog˚ nq round
complexity. Recall that the proof of Theorem 2.22 says that Π can in fact be solved with a local algorithm A
of round complexity t “ Op1q on any graph G if we are provided a proper coloring of a suitable power graph
G2pt`rq. Recall that p∆` 1q-coloring has sequential local complexity Op1q, meaning that we can construct
a sequential local algorithm of constant complexity for Π.
Next, we will show how our distributed speedup theorems imply speedups in the sequential world.
Theorem 2.25. Let A be a sequential local algorithm solving a local problem Π on bounded degree graphs.
Assume that either
1. A is deterministic and its sequential local complexity is oplog log nq,
2. or A is randomized and its sequential local complexity is oplog log log nq.
Then, there is a distributed local algorithm A1 that solves Π in Oplog˚ nq round complexity.
Proof. If A is a deterministic sequential algorithm of local complexity tpnq “ oplog log nq, we can simulate it
with a distributed local algorithm via Theorem 2.5. We get a deterministic algorithm with local complexity
∆Optpnqq ` Optpnq log˚ nq “ logop1q n “ oplog nq. Such an algorithm is then sped up to Oplog˚ nq complexity
using Theorem 2.22.
Similarly, if A is randomized sequential algorithm of local complexity oplog log log nq, Theorem 2.5 implies
that we get a randomized distributed local algorithm with logop1q log n “ oplog log nq round complexity. Such
an algorithm can then be derandomized by Theorem 2.21 into a deterministic algorithm of local complexity
oplog nq which is in turn sped up to Oplog˚ nq using Theorem 2.22.
Finally, we sketch how one can construct very fast sequential local algorithms for instances of the local
lemma.
Theorem 2.26. Let Π be a C-relaxed Lovász local lemma for sufficiently large C. Then, its deterministic se-
quential local complexity is rOplog4 log nq and its randomized sequential local complexity is rOplog4 log log nq35,
on bounded degree graphs.
Proof Sketch. To prove the first part of the theorem, we consider the randomized distributed local algorithm
for local lemma from Theorem 2.12. We turn it into a deterministic sequential local algorithm of the same
complexity by the derandomization result of Theorem 1.7.
To prove the second part of the theorem, we notice that our randomized distributed local algorithm from
Theorem 2.12 can certainly be implemented in the model of randomized sequential local algorithms. Recall
that the algorithm reduces an instance of the local lemma to instances on graphs of size Oplog nq, as proven
in Theorem 2.11. Then, the best deterministic algorithm is applied to those instances to finish the job.
While Theorem 2.11 is stated as reducing from C-relaxed local lemma with some large C to local lemma
with condition p ď 1{p3∆q, we can generalize it to show that starting with a very large C1, we can reduce
an instance of C1-relaxed local lemma to C-relaxed local lemma for C that is still arbitrarily large.
This allows us to run the deterministic sequential algorithm with complexity rOplog4 log nq constructed in
the first part of the proof instead of using the deterministic Oppoly log nq-round algorithm from Theorem 2.10.
The final randomized sequential local complexity is thus rOplog4 log log nq.
35It is an interesting exercise to open up the proof that the randomized sequential local complexity of local lemma is
Θppoly log log log nq and try to think of theorems we have seen so far that do not go into that proof.
33

--- Page 34 ---
We note that for problems like sinkless orientation for which an Oplog log nq-round randomized algorithm
is known [GHK18], the proofs of above Theorems 2.25 and 2.26 imply tight bounds of Θplog log nq and
Θplog log log nq deterministic and randomized sequential local complexity on bounded degree graphs. In the
case of sinkless orientation, the same bounds are also known even on unbounded degree graphs [GHK18]. If
the conjecture of Chang and Pettie [CP19] (Problem 2.14) is true, then there is no gap between Theorems 2.25
and 2.26.
We also note that Theorems 2.25 and 2.26 show that while one can turn randomized distributed local
algorithms into sequential deterministic ones via Theorem 1.7, it is not possible to turn randomized sequential
local algorithms into deterministic sequential local ones, without loss in their local complexity.
Putting everything together, we get the following refined classification theorem that also includes sequen-
tial local complexities.
Theorem 2.27 (Refined classification of local problems). Let us fix any ∆and any class of graphs G of
degree at most ∆that is closed under taking subgraphs and adding isolated nodes. Let tpnq be a function
such that for any node u in some graph in G we have |Bpu, tpnqq| “ opnq.
Then, any local problem with randomized round complexity at most tpnq has one of the following three
complexities.
1. Order-invariant regime: The problem has Op1q deterministic (or randomized) round complexity and
sequential local complexity.
2. Symmetry-breaking regime: The deterministic and randomized round complexity of the problem lies
between Ωplog log˚ nq and Oplog˚ nq (both the deterministic and the randomized complexity is the same
function). Moreover, the sequential local complexity is Op1q.
3. Lovász-local-lemma regime: The problem has the following complexities:
(a) deterministic round complexity is between Ωplog nq and rOplog4 nq,
(b) randomized round complexity and deterministic sequential local complexity is between Ωplog log nq
and rOplog4 log nq,
(c) randomized sequential local complexity is between Ωplog log log nq and rOplog4 log log nq.
Moreover, if any graph from the class satisfies that for any node u, we have |Bpu, rq| “ 2Opr0.249q, then there
are no local problems in the third class of problems.
The last part of the theorem follows by applying Theorem 2.22: We know that every local problem in
the local-lemma regime can be solved with a deterministic local algorithm of round complexity rOplog4 nq;
since 2p r
Oplog4 nqq
0.249
“ opnq, the speedup to Oplog˚ nq complexity can be applied. If the conjecture of Chang
and Pettie [CP19] (Problem 2.14) is true, we can get rid of the polynomial slack in the local-lemma regime
complexities and the whole local-lemma class of problems is then empty for the class of subexponential
growth graphs (see Section 2.4.2).
Problem 2.28. Can local problem solvable with deterministic sequential local complexity oplog nq be sped up
to poly log log n deterministic sequential complexity (i.e., to the local-lemma regime)? What about problems
with randomized sequential local complexity oplog nq?
2.4.2
Classification of Local Problems for Concrete Graph Classes
This section compiles results from a long line of work trying to extend the classification of local problems on
bounded-degree graphs, i.e., Theorem 2.1, to more specific graph classes. For some simple graph classes, we
now have an almost complete understanding of the local complexity classes that go even beyond the log n
local complexity threshold.
Locally checkable labeling problems: The theorems below are proven for the so-called locally checkable
labeling problems. These are local problems that additionally allow one of the finitely many input colors
on each node of the input graph. For example, a list coloring is an example of a locally checkable labeling
problem.
34

--- Page 35 ---
Definition 2.29. A locally checkable labeling problem (LCL) Π is formally a quintuple pSin, Sout, r, ∆, Pq.
Here, Sin is the finite set of input labels, Sout is the finite set of output labels, and P is the set of allowed
neighborhoods: Each neighborhood has maximum degree ∆, radius r, and each node is labeled with a label
from Sin and Sout. Given an input graph of degree at most ∆and any input coloring of its nodes with Sin,
the task is to find an output coloring by colors from Sout so that the r-hop neighborhood of each node is in
P.
We did not have to distinguish between our definition of a local problem from Definition 1.1 and the
locally checkable labelings since, in the general graph classes like the class of all graphs or all bounded-degree
graphs, it is straightforward to encode input labels as a part of the input graph. We thus chose the simpler
definition that also allowed us to talk about local problems even outside of the setup of bounded-degree
graphs. In the following theorems, especially for very restrictive classes like paths or grids, the difference
between the two definitions matters, since the possibility of allowing inputs may substantially enlarge the
number of possible local problems.
In the following theorems, we will always implicitly assume that they are for solvable locally checkable
labelings, i.e., for problems where the solution is always guaranteed to exist. Otherwise, the problem does
not have a well-defined local complexity class.
Computational aspect: We note that an additional dimension for all classification results below is the
computational complexity of the classification problem, where the input is a description of locally checkable
labeling, and the output is which class it belongs to. On the one hand, it is known that the classification
problem is decidable on paths, albeit PSPACE-hard [Bal+19a]. On the other hand, the classification problem
is undecidable even for grids [Bra+17]. The decidability on trees is open; see Problem 2.34. We will not
discuss this dimension in the following theorem statements for brevity.
Additional remarks: We list the concrete classification theorems below.
Unless stated otherwise, the
deterministic and the randomized round complexity of the problem is always the same. We are always citing
papers proving results specific to the given graph class, for example, general speedup and slowdown theorems
of Chang and Pettie [CP19] and Chang, Kopelowitz, and Pettie [CKP19] are as a rule of thumb always an
important part of the proof. Also, not all the papers we cite prove a part of the given theorem. Some of
them only provide building blocks, analyze the computational complexity of the classification, etc.
List of known classifications: Let us now list known classification theorems on concrete graph classes.
Theorem 2.30 (Classification of local problems on paths [Bra+17; Bal+19a]). Any solvable locally checkable
labeling problem on oriented or unoriented paths with inputs has one of the following round complexities:
1. Op1q,
2. Θplog˚ nq,
3. Θpnq.
Theorem 2.31 (Classification of local problems on grids [NS95; Bra+17; CKP19; GRB22]). Any solvable
locally checkable labeling problem on d-dimensional oriented grids36 has one of the following local complexities:
1. Op1q,
2. Θplog˚ nq,
3. Θpn1{dq.
We note that on unoriented grids, the full classification is not known [GRB22].
Theorem 2.32 (Classification of local problems on bounded-degree rooted regular trees [Bal+21b; Bal+22a]).
Any solvable locally checkable labeling problem on bounded-degree rooted regular trees37 has one of the fol-
lowing round complexities:
36The edges of the input grid are consistently oriented.
37Edges are oriented such that every vertex has at most one ingoing edge.
35

--- Page 36 ---
1. Op1q,
2. Θplog˚ nq,
3. Θplog nq,
4. Θpn1{kq for some k P N.
Theorem 2.33 (Classification of local problems on bounded-degree trees [MR89; CP19; Bal+18; Cha20;
Bal+20b; GRB22; Bal+22a; Bal+20a]). Any solvable locally checkable labeling problem on trees has one of
the following local complexities:
1. Op1q,
2. Θplog˚ nq,
3. Θplog log nq randomized, Θplog nq deterministic,
4. Θplog nq (both randomized and deterministic),
5. Θpn1{kq for some k P N.
Problem 2.34. Given an input locally checkable labeling problem on bounded-degree trees, is it decidable
which class in Theorem 2.33 it belongs to?
More Classifications: It is an intriguing question of how far these classifications can be extended, see e.g.
the recent work extending the theory to minor-closed classes [Cha24] or extending the theory to unbounded-
degree graphs [LPS23].
Another interesting class is the class of subexponential growth graphs, i.e., the class of bounded degree
graphs where for every ε ą 0 we can find r such that |Bpu, rq| ď p1 ` εqr 38. In this class of graphs, we
can apply Theorem 2.22 to speed up deterministic algorithms of complexity Oplog nq (instead of oplog nq)
to Oplog˚ nq. If the conjecture of [CP19] (Problem 2.14) is true, this has an interesting corollary: the local
lemma regime from the classification theorem of Theorem 2.1 would then not be present in this class of
graphs and there would only two classes of local problems there (see Theorem 2.27). This leads to the
following special case of Problem 2.14:
Problem 2.35. Is there a C such that all instances of the C-relaxed Lovász local lemma can be solved with
round complexity Θplog˚ nq on any class of graphs of subexponential growth?
Some implications of a positive answer to this problem are known [Csó+22; BD23].
3
Applications
While the previous two sections, Sections 1 and 2, discussed the general theory of local algorithms, the
following section considers various popular models of distributed, parallel, or sublinear algorithms, as well
as the field of descriptive combinatorics, and briefly discusses how techniques from local algorithms can help
there, discussing a few cherry-picked examples per section. These sections are heavily influenced by the
author’s particular interests; a different author would choose different applications.
3.1
Distributed Computing (CONGEST)
The CONGEST model [Pel00] is a model of distributed computing that is extremely tightly connected to
local algorithms39 Starting from the definition of a local algorithm as a message-passing protocol between
nodes in a graph, the CONGEST model adds an additional requirement that each message is supposed to
38Formally, this is a family of classes, with one class for each possible dependency r “ rpεq.
39Local algorithms are often referred to as “distributed algorithms in the LOCAL model of distributed computing”.
36

--- Page 37 ---
be small. In particular, it should fit into Oplog nq bits. For example, a node can send its unique identifier in
one round.
Many local algorithms in the literature are in fact stated as CONGEST algorithms since a number of
local algorithms are readily implemented in the CONGEST model. However, not all of them. For example,
the problem of counting for each node the number of triangles that contain it is a trivial problem for local
algorithms but a very complex problem in the CONGEST model, where it requires polynomially many
rounds [CPZ19; CS19]. The general derandomization technique of Ghaffari, Harris, and Kuhn [GHK18]
from Theorem 1.8 is also not directly applicable to the CONGEST model, since computing conditional
expectations in a neighborhood of a node requires collecting a lot of information from that neighborhood.
However, the general approach is still helpful, and it was used to derandomize concrete problems like maximal
independent set [CPS17a] or ∆` 1-coloring [BKM20].
It is an interesting question for which classes of graphs the definitions of local and CONGEST algorithms
coincide for local problems. It is known that this is the case for local problems on trees [Bal+21c].
3.2
Local Computation Algorithms and the Volume Model
The model of local computation algorithms [Rub+11; Alo+12], often denoted as LCA, is a model of sublinear
algorithms closely related to the local model. We will first explain its variant, known as the Volume model
by Rosenbaum and Suomela [RS20]. This model is very similar to local algorithms, but we measure the
volume instead of the radius. A volume algorithm run at a node u starts with a set S0 “ tuu and in the
i-th step, the algorithm can pick a node ui P Si and an arbitrary index 1 ď j ď d where d is the degree of
ui. Then, it learns the identifier of the j-th neighbor v of ui. We then set Si`1 “ Si Y tvu. The volume
complexity of the algorithm is the number of queries it makes until it decides to finish and output the label
for u.
In particular, we note that for graphs of maximum degree ∆, any tpnq-round local algorithm can be
turned into a volume algorithm of complexity p2∆qtpnq as the volume algorithm at u can simply query all
the nodes in the tpnq-hop neighborhood of u [PR07].
A local computational algorithm may have several definitions. The stateless local computation algorithm
is defined as follows: we start with the definition of the volume model and add the additional requirement
that the nodes start with unique identifiers from the range rns, even for randomized algorithms. In each
query, the algorithm can additionally ask for the node with the identifier j for any 1 ď j ď n. The node ui
with identifier j is then added to the set of already seen nodes Si. That is, the algorithm can use additional
global queries that are, however, “blind”.
It is unclear whether global queries can help with solutions to local problems. We know that they do not
help for very fast randomized local computation algorithms [Göö+16].
Problem 3.1. Is there a local problem that distinguishes (either randomized or deterministic) Local compu-
tation algorithms and Volume models with respect to a natural class of graphs?
As an example problem considered in the LCA model, there is a long line of work on local computation
algorithms for maximal independent set and related problems [NO08; YYI09; Ona+12; Beh22; Rub+11;
Alo+12; LRY15; Gha16; RV16; GU19; Gha22] culminating with the randomized algorithm of Ghaffari
[Gha22] with volume complexity polyp∆log nq.
For constant degree graphs, we can try to prove classification results similar to the classification of local
problem complexities from Theorem 2.1. We have some understanding of the volume complexities of the
three important local complexity classes from Theorem 2.1:
Theorem 3.2 ([PR07; EMR14; RS20; GRB22; BGR21]). In the class of bounded-degree graphs, each local
problem satisfies the following:
1. If its round complexity is Op1q (order-invariant regime), then its randomized/deterministic volume
complexity is Op1q.
2. If its randomized/deterministic round complexity is ωp1q and Oplog˚ nq (symmetry-breaking regime),
its randomized/deterministic volume complexity is Θplog˚ nq.
37

--- Page 38 ---
3. If its randomized local complexity is ωplog˚ nq but oplog nq (Lovász local lemma regime), its randomized
volume complexity is between Ωp?log nq and Oplog nq.
We note that as far as we know, all local problems in the local-lemma regime have randomized volume
complexity of Θplog nq. In particular, sinkless orientation has this randomized volume complexity [BGR21].
Problem 3.3 (See Conjecture 1.3 in [BGR21]). Is it true on bounded degree graphs that local problems from
the local-lemma regime have randomized volume complexity Θplog nq?
We also note that in the model of deterministic volume complexity where the identifiers come from expo-
nential, instead of polynomial range, we can prove that only the volume complexities Op1q, Θplog˚ nq, Θpnq
are possible [BGR21]. The same could be the case also for the standard, polynomial-range, identifiers.
Problem 3.4. Are there any local problems such that their deterministic volume complexity (with polynomial-
sized identifiers) on bounded degree graphs is ωplog˚ nq but opnq?
Equivalently, we could have asked whether there is a local problem whose deterministic volume complexity
is different for polynomial-sized and exponential-sized identifiers.
3.3
PRAM
PRAM is a classical model of parallel algorithms studied extensively in the past 40 years [JáJ92]. It simplifies
the complexity of practical parallel computing by assuming a simple model of a machine with multiple
processors sharing a common memory. There are two complexity measures: work, i.e., the total number of
instructions made by all processors together throughout the execution, and depth, i.e., the number of rounds
necessary to finish the computation in the case that the machine is equipped with as many processors as the
algorithm requires.
Many techniques developed for distributed and local algorithms are useful in the design of parallel algo-
rithms. As an example application for a local problem, Ghaffari and Haeupler [GH21] develop a randomized
algorithm for maximal independent set on the so-called EREW variant of the PRAM model with the optimal
depth Oplog nq and Opm log2 nq work, building on top of the local maximal independent set algorithm of
Ghaffari [Gha16].
As another example application for a non-local problem, we note that one can generalize deterministic
local algorithms for network decompositions discussed in Section 1.5 to get various clustering results for
weighted undirected graphs like the following one.
Theorem 3.5 (Deterministic low-diameter clustering [Roz+22a]). Let G be a graph and w its nonnegative
weights. Then, there is a parallel algorithm with rOpm`nq work and rOp1q depth such that, given a parameter
R ą 0, it splits vertices of G into clusters such that
1. Each cluster has weighted diameter rOpRq,
2. The total weight of edges that cross between different clusters is at most
1
R
ř
ePEpGq wpeq.
Variants of this clustering result can be used for the design of deterministic parallel algorithms for the
approximate shortest path problem or various metric embedding problems [Roz+22b; Roz+22a].
3.4
Massively Parallel Computing (MPC)
The final parallel model we discuss is the model of Massively parallel computing (MPC) [KSV10], the
theoretical model behind the popular programming framework MapReduce and its variants.
While the
previous PRAM model focuses on the total work done by processors and ignores the cost of communication,
the MPC model ignores the work done by processors and focuses on the communication cost.
Concretely, let us explain the so-called low-memory regime of MPC: At the beginning of any graph
algorithm, the edges of the input graph are split into many machines, each capable of storing Opnεq bits in
its memory. In one round, each machine can perform an arbitrary computation on its edges, and then it
sends arbitrary information to any of its neighbors (the total information sent and received per machine is
Opnεq). We measure the number of rounds until the solution is computed.
38

--- Page 39 ---
Chang, Fischer, Ghaffari, Uitto, and Zheng [Cha+19a] constructed a randomized massively parallel
algorithm for ∆`1-coloring that works in Oplog log log nq rounds by simulating the fastest randomized local
algorithm for coloring of round complexity poly log log n (see Section 3) with exponential speedup. This result
is complemented by the work of Ghaffari, Kuhn, and Uitto [GKU19] that showed that this result cannot be
improved, conditioned on a certain conjecture. Notice how understanding where the three logarithms are
coming from requires an extensive understanding of coloring with local algorithms: The way we arrive at
this complexity is that, first, starting with the trivial constant-round sequential local algorithm for coloring,
we turn it into a deterministic distributed poly log n-round local algorithm using the general translation of
Theorem 1.4. Next, this algorithm can be turned into an exponentially faster randomized algorithm using
the shattering technique [CLP18]. Finally, this randomized algorithm is simulated, again with exponential
speedup, in the massively parallel model.
There is also a line of work aiming to extend the classification of local problems to the massively parallel
algorithms model, though the complexity landscape there is currently much less understood [Bal+22b].
3.5
Descriptive Combinatorics
Descriptive combinatorics [Mik90; MU17; LAO17; DF92; MU16; Gab00; ASS99; Mar16; CM17; CGP24;
Csó+22; Ber23a] is an area at the intersection of combinatorics, measure theory, and set theory (see e.g. the
surveys [KM16; Pik21; Ber22b]). It studies graphs that arise when one manipulates uncountably-infinitely
large mathematical objects equipped with measure.
The main object of interest is a measurable graph.
Instead of a formal definition, let us discuss a particular example.
An example of a measurable graph: Consider a circle, i.e., a set of points of distance 1 from the origin
in the plane R2. A rotation of this circle by 1 radian counterclockwise induces a graph G0: We can draw
an oriented edge from each point v on the circle to the point v1 such that the rotation maps v to v1. This
graph has uncountably many connected components, each of which is a doubly-infinite oriented path: this is
because 1 is an irrational multiple of 2π and thus if we start “jumping” from v around the cycle with jumps
of length 1, we never return to v. Moreover, the standard Lebesgue measure on the circle is telling us which
subsets of vertices of G0 we are “allowed to talk about”. The graph G0, together with the measure on top of
it, is an example of a measurable graph.
Given a local problem Π, we can now ask whether it can be solved on a particular measurable graph.
For example, consider the following problem: Color each vertex of G0 with one of c colors such that the
coloring is proper and each set of vertices of the same color is measurable. It is a folklore fact that this type
of coloring is not possible with c “ 2 colors, but it is possible with c “ 3 colors (this is a special case of the
following Theorem 3.6).
Formal connection between the two worlds: There is a close connection between local algorithms
and descriptive combinatorics. Although this was to some extent understood earlier (see Elek and Lippner
[EL10], Lovász [Lov12, Chapter 23.3]), it was only a breakthrough paper of Bernshteyn [Ber23a] that first
realized the full power of the connection. Bernshteyn was able to prove general theorems of the type “if a
local problem Π can be solved with a local algorithm of round complexity Oplog˚ nq, then any measurable
graph admits a Borel solution to Π”.
As we did not define the terms “measurable graph” or “Borel solution” precisely, we will next only state
perhaps the simplest concrete example manifesting the connection, and we point an interested reader to the
recent survey of Bernshteyn [Ber22b] that covers this very exciting and recent topic in depth.
Theorem 3.6 ([GR21]). Let Π be any local problem (without inputs). Then, the following two statements
are equivalent:
1. There exists an opnq-round local algorithm solving Π on sufficiently large oriented cycles.
2. One can label each vertex of G0 with a label of Π such that all vertices satisfy the constraints of Π, and
for each label ℓ, the set of vertices with that label is Lebesgue-measurable40.
By now, we know of several more results of this type, both for general bounded-degree graphs [Ber23a;
Ber23b] and for special cases like trees [Bra+21] and grids [Gao+18; GR23].
40One can replace “Lebesgue measurable” with “a union of finitely many intervals” and the theorem still holds.
39

--- Page 40 ---
Transfer of techniques: Many recent results in the area of descriptive combinatorics are adopting tech-
niques from local algorithms that are, by now, familiar to readers of this text: network decomposition [BY23],
Lovász local lemma [Ber23a; Ber23b; Csó+22; BW23; BY23], derandomizations [Ber23b; GR23], ID graphs
[Bra+22; Bra+21], and others.
This connection also led to some progress in the area of local algorithms.
For example, Bernshteyn
[Ber22a] used ideas from a measurable Vizing theorem of Grebík and Pikhurko [GP20] to construct a fast
local algorithm for p∆`1q-edge coloring problem. Brandt, Chang, Grebík, Grunau, Rozhoň, and Vidnyánszky
[Bra+22] adapted a lower bound of Marks [Mar16] to give a different (and similarly simple) lower bound for
sinkless orientation from Theorem 2.15.
3.6
Other Models
There are many more models of local/distributed/parallel/sublinear computation that are, in one way or
another, related to local algorithms. In many of these models, it not only makes sense to try to solve concrete
problems but often, one can also hope that the theory of local algorithms, such as the classification of the
local problems on bounded-degree graphs, can be extended similarly to, e.g., Theorem 3.2.
Uniform algorithms: One favorite model of the author is the model of uniform local complexity.
In
this model, a randomized local algorithm does not know the size of the input graph, n. It simply looks at
larger and larger neighborhoods of a given vertex, until it decides that it has seen enough to compute the
output label at the node. This model was independently studied by local algorithms community [KSV12]
and community of probabilists [HSW17; Hol17; Spi20] where it is known as finitary factors of i.i.d.
In the oplog nq-local-complexity regime, uniform algorithms can be seen as a more powerful version of
classical local algorithms. This is because there are certain local problems such that their solution requires
a few nodes to see the whole graph, while most of the nodes can output their solution after seeing their
Op1q-radius neighborhood [GR23]. On the other hand, local problems solvable by uniform local algorithms
still often admit measurable solutions defined in descriptive combinatorics [GR21; GR23; Bra+22]. Thus,
uniform local algorithms can be seen as interpolating between the extremely clean picture painted by the
classification of oplog nq-round algorithms (Theorem 2.1), and the much less well-understood complexity
classes coming from descriptive combinatorics.
The connection between classical local algorithms and uniform ones would be much cleaner if the following
problem was resolved (see [Bra+22]):
Problem 3.7. Is there a C and a uniform randomized local algorithm on bounded degree graphs for C-relaxed
Lovász local lemma such that after poly log logp1{εq rounds, at least 1´ε fraction of nodes know the solution?
Other models: There are many more models of locality studied in the literature.
Let us list a sam-
ple of them.
The list includes the averaged local complexity [Feu17; BT19; CGP20; Bal+23a] (closely
connected to uniform algorithms), online local model [Akb+23; Cha+23; Akb+24], dynamic local model
[Akb+23; Akb+24], local mending model [MSV23], supported local model [SS13; Kor+21], quantum local
model [GKM09; LNR19; Coi+22; Akb+24], awake (energy) complexity [Cha+19b; Cha+20; CGP20; GP22;
GP23], local certification [GS11; FHK12; Fra+13; Feu21], finitely dependent colorings [HL+15; Hol23], or
computable combinatorics [QW22].
Final Remarks
This text aims to present the area of local algorithms in a way that highlights what the author sees as its
key aspect: Unlike typical subareas of computer science and discrete mathematics that are usually unified
by a set of useful techniques and important results, the area of local algorithms extends beyond this norm.
We have a clean theory of the model of local algorithms that leads to a clear complexity-theoretical picture.
We also understand that local algorithms have applications to a number of other models studied by the
broader algorithmic community. In this sense, local complexity is similar to much more established fields
like communication complexity. The author believes that the theory has the potential for diverse extensions
and applications and encourages the reader to identify and explore the next one.
40

--- Page 41 ---
References
[Akb+24]
Amirreza Akbari, Xavier Coiteux-Roy, Francesco d’Amore, François Le Gall, Henrik Lievonen,
Darya Melnyk, Augusto Modanese, Shreyas Pai, Marc-Olivier Renou, Václav Rozhoň, et al.
“Online Locality Meets Distributed Quantum Computing”. In: arXiv preprint arXiv:2403.01903
(2024).
[Akb+23]
Amirreza Akbari, Navid Eslami, Henrik Lievonen, Darya Melnyk, Joona Särkijärvi, and Jukka
Suomela. “Locality in Online, Dynamic, Sequential, and Distributed Graph Algorithms”. In:
50th International Colloquium on Automata, Languages, and Programming (ICALP 2023). Ed.
by Kousha Etessami, Uriel Feige, and Gabriele Puppis. Vol. 261. Leibniz International Pro-
ceedings in Informatics (LIPIcs). Dagstuhl, Germany: Schloss Dagstuhl – Leibniz-Zentrum für
Informatik, 2023, 10:1–10:20. isbn: 978-3-95977-278-5. doi: 10.4230/LIPIcs.ICALP.2023.10.
url: https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ICALP.2023.10.
[ASS99]
Alexander S. Kechris, Sławomir Solecki, and Stevo Todorčević. “Borel chromatic numbers.” In:
Adv. Math. 141.1 (1999), pp. 1–44.
[ABI86]
Noga Alon, Laszlo Babai, and Alon Itai. “A Fast and Simple Randomized Parallel Algorithm
for the Maximal Independent Set Problem”. In: Journal of Algorithms 7.4 (1986), pp. 567–583.
[Alo+12]
Noga Alon, Ronitt Rubinfeld, Shai Vardi, and Ning Xie. “Space-efficient local computation
algorithms”. In: Proceedings of the twenty-third annual ACM-SIAM symposium on Discrete
Algorithms. SIAM. 2012, pp. 1132–1139.
[AB09]
Sanjeev Arora and Boaz Barak. Computational complexity: a modern approach. Cambridge
University Press, 2009.
[Awe+89]
Baruch Awerbuch, Andrew V. Goldberg, Michael Luby, and Serge A. Plotkin. “Network Decom-
position and Locality in Distributed Computation”. In: Proc. 30th IEEE Symp. on Foundations
of Computer Science (FOCS). 1989, pp. 364–369.
[Bal+19a]
Alkida Balliu, Sebastian Brandt, Yi-Jun Chang, Dennis Olivetti, Mikaël Rabie, and Jukka
Suomela. “The Distributed Complexity of Locally Checkable Problems on Paths is Decidable”.
In: Proceedings of the 2019 ACM Symposium on Principles of Distributed Computing. PODC
’19. Toronto ON, Canada: Association for Computing Machinery, 2019, pp. 262–271. isbn:
9781450362177.
[Bal+22a]
Alkida Balliu, Sebastian Brandt, Yi-Jun Chang, Dennis Olivetti, Jan Studený, and Jukka
Suomela. “Efficient Classification of Locally Checkable Problems in Regular Trees”. In: 36th
International Symposium on Distributed Computing. 2022.
[Bal+20a]
Alkida Balliu, Sebastian Brandt, Yuval Efron, Juho Hirvonen, Yannic Maus, Dennis Olivetti,
and Jukka Suomela. “Classification of Distributed Binary Labeling Problems”. In: 34th Interna-
tional Symposium on Distributed Computing (DISC 2020). Schloss Dagstuhl-Leibniz-Zentrum
für Informatik. 2020.
[Bal+22b]
Alkida Balliu, Sebastian Brandt, Manuela Fischer, Rustam Latypov, Yannic Maus, Dennis
Olivetti, and Jara Uitto. “Exponential Speedup over Locality in MPC with Optimal Memory.”
In: 36th International Symposium on Distributed Computing: DISC 2022. Schloss Dagstuhl-
Leibniz-Zentrum für Informatik. 2022, pp. 9–1.
[Bal+19b]
Alkida Balliu, Sebastian Brandt, Juho Hirvonen, Dennis Olivetti, Mikaël Rabie, and Jukka
Suomela. “Lower bounds for maximal matchings and maximal independent sets”. In: Proc. Foun-
dations of Computer Science (FOCS). 2019.
[Bal+22c]
Alkida Balliu, Sebastian Brandt, Fabian Kuhn, and Dennis Olivetti. “Distributed ∆-coloring
plays hide-and-seek”. In: Proceedings of the 54th Annual ACM SIGACT Symposium on Theory
of Computing. 2022, pp. 464–477.
[Bal+21a]
Alkida Balliu, Sebastian Brandt, Fabian Kuhn, and Dennis Olivetti. “Improved distributed
lower bounds for MIS and bounded (out-) degree dominating sets in trees”. In: Proceedings of
the 2021 ACM Symposium on Principles of Distributed Computing. 2021, pp. 283–293.
41

--- Page 42 ---
[Bal+23a]
Alkida Balliu, Sebastian Brandt, Fabian Kuhn, Dennis Olivetti, and Gustav Schmid. “On the
Node-Averaged Complexity of Locally Checkable Problems on Trees”. In: 37th International
Symposium on Distributed Computing. 2023.
[BBO20]
Alkida Balliu, Sebastian Brandt, and Dennis Olivetti. “Distributed Lower Bounds for Ruling
Sets”. In: 61st IEEE Annual Symposium on Foundations of Computer Science, FOCS 2020,
Durham, NC, USA, November 16-19, 2020. 2020, pp. 365–376. doi: 10.1109/FOCS46700.
2020.00042. url: https://doi.org/10.1109/FOCS46700.2020.00042.
[Bal+21b]
Alkida Balliu, Sebastian Brandt, Dennis Olivetti, Jan Studený, Jukka Suomela, and Aleksandr
Tereshchenko. “Locally checkable problems in rooted trees”. In: Proceedings of the 2021 ACM
Symposium on Principles of Distributed Computing. 2021, pp. 263–272.
[Bal+20b]
Alkida Balliu, Sebastian Brandt, Dennis Olivetti, and Jukka Suomela. “Almost global problems
in the LOCAL model”. In: Distributed Computing (2020), pp. 1–23.
[Bal+20c]
Alkida Balliu, Sebastian Brandt, Dennis Olivetti, and Jukka Suomela. “How Much Does Ran-
domness Help with Locally Checkable Problems?” In: Proceedings of the 39th Symposium on
Principles of Distributed Computing. PODC ’20. Virtual Event, Italy: Association for Comput-
ing Machinery, 2020, pp. 299–308. isbn: 9781450375825.
[Bal+21c]
Alkida Balliu, Keren Censor-Hillel, Yannic Maus, Dennis Olivetti, and Jukka Suomela. “Locally
Checkable Labelings with Small Messages”. In: 35th International Symposium on Distributed
Computing. 2021.
[Bal+18]
Alkida Balliu, Juho Hirvonen, Janne H Korhonen, Tuomo Lempiäinen, Dennis Olivetti, and
Jukka Suomela. “New classes of distributed time complexity”. In: Proceedings of the 50th Annual
ACM SIGACT Symposium on Theory of Computing. 2018, pp. 1307–1318.
[Bal+23b]
Alkida Balliu, Janne H Korhonen, Fabian Kuhn, Henrik Lievonen, Dennis Olivetti, Shreyas Pai,
Ami Paz, Joel Rybicki, Stefan Schmid, Jan Studený, et al. “Sinkless Orientation Made Simple”.
In: Symposium on Simplicity in Algorithms (SOSA). SIAM. 2023, pp. 175–191.
[BKM20]
Philipp Bamberger, Fabian Kuhn, and Yannic Maus. “Efficient Deterministic Distributed Col-
oring with Small Bandwidth”. In: Proc. Principles of Distributed Computing (PODC). 2020, to
appear, arXiv:1912.02814.
[BE09]
Leonid Barenboim and Michael Elkin. “Distributed (delta+1)-coloring in linear (in delta) time”.
In: Proceedings of the 41st Annual ACM Symposium on Theory of Computing, STOC 2009,
Bethesda, MD, USA, May 31 - June 2, 2009. Ed. by Michael Mitzenmacher. ACM, 2009,
pp. 111–120. doi: 10.1145/1536414.1536432. url: https://doi.org/10.1145/1536414.
1536432.
[BE13]
Leonid Barenboim and Michael Elkin. Distributed Graph Coloring: Fundamentals and Recent
Developments. Morgan & Claypool Publishers, 2013.
[BEK15]
Leonid Barenboim, Michael Elkin, and Fabian Kuhn. “Distributed p∆` 1q-Coloring in Linear
(in ∆) Time”. In: SIAM Journal on Computing 43.1 (2015), pp. 72–95.
[Bar+16]
Leonid Barenboim, Michael Elkin, Seth Pettie, and Johannes Schneider. “The Locality of Dis-
tributed Symmetry Breaking”. In: Journal of the ACM 63 (3 2016), 20:1–20:45.
[BT19]
Leonid Barenboim and Yaniv Tzur. “Distributed symmetry-breaking with improved vertex-
averaged complexity”. In: 20th International Conference on Distributed Computing and Net-
working, ICDCN 2019. Association for Computing Machinery. 2019, pp. 31–40.
[Bec91]
József Beck. “An algorithmic approach to the Lovász local lemma. I”. In: Random Structures &
Algorithms 2.4 (1991), pp. 343–365.
[Beh22]
Soheil Behnezhad. “Time-optimal sublinear algorithms for matching and vertex cover”. In: 2021
IEEE 62nd Annual Symposium on Foundations of Computer Science (FOCS). IEEE. 2022,
pp. 873–884.
[Ber22a]
Anton Bernshteyn. “A fast distributed algorithm for (∆+ 1)-edge-coloring”. In: Journal of Com-
binatorial Theory, Series B 152 (2022), pp. 319–352.
42

--- Page 43 ---
[Ber22b]
Anton Bernshteyn. “Descriptive combinatorics and distributed algorithms”. In: NOTICES OF
THE AMERICAN MATHEMATICAL SOCIETY 69.9 (2022).
[Ber23a]
Anton Bernshteyn. “Distributed algorithms, the Lovász Local Lemma, and descriptive combi-
natorics”. In: Inventiones mathematicae 233.2 (2023), pp. 495–542.
[Ber23b]
Anton Bernshteyn. “Probabilistic constructions in continuous combinatorics and a bridge to
distributed algorithms”. In: Advances in Mathematics 415 (2023), p. 108895.
[BD23]
Anton Bernshteyn and Abhishek Dhawan. “Borel Vizing’s Theorem for Graphs of Subexponen-
tial Growth”. In: arXiv e-prints (2023), arXiv–2307.
[BW23]
Anton Bernshteyn and Felix Weilacher. “Borel versions of the Local Lemma and LOCAL algo-
rithms for graphs of finite asymptotic separation index”. In: arXiv preprint arXiv:2308.14941
(2023).
[BY23]
Anton Bernshteyn and Jing Yu. “Coarse embeddings into grids and asymptotic dimension for
Borel graphs of polynomial growth”. In: arXiv preprint arXiv:2302.04727 (2023).
[Bra+16]
S. Brandt, O. Fischer, J. Hirvonen, B. Keller, T. Lempiäinen, J. Rybicki, J. Suomela, and J.
Uitto. “A lower bound for the distributed Lovász local lemma”. In: Proc. 48th ACM Symp. on
Theory of Computing (STOC). 2016, pp. 479–488.
[Bra19]
Sebastian Brandt. “An automatic speedup theorem for distributed problems”. In: Proceedings
of the 2019 ACM Symposium on Principles of Distributed Computing. 2019, pp. 379–388.
[Bra+22]
Sebastian Brandt, Yi-Jun Chang, Jan Grebík, Christoph Grunau, Václav Rozhoň, and Zoltán
Vidnyánszky. “Local Problems on Trees from the Perspectives of Distributed Algorithms, Fini-
tary Factors, and Descriptive Combinatorics”. In: 13th Innovations in Theoretical Computer
Science Conference (ITCS 2022). Schloss Dagstuhl-Leibniz-Zentrum für Informatik. 2022.
[Bra+21]
Sebastian Brandt, Yi-Jun Chang, Jan Grebík, Christoph Grunau, Václav Rozhoň, and Zoltán
Vidnyánszky. “On homomorphism graphs”. In: arXiv preprint arXiv:2111.03683 (2021).
[BGR20]
Sebastian Brandt, Christoph Grunau, and Václav Rozhoň. “Generalizing the Sharp Threshold
Phenomenon for the Distributed Complexity of the Lovász Local Lemma”. In: Proceedings of
the 39th Symposium on Principles of Distributed Computing. 2020, pp. 329–338.
[BGR21]
Sebastian Brandt, Christoph Grunau, and Václav Rozhoň. “The randomized local computa-
tion complexity of the Lovász local lemma”. In: Proceedings of the 2021 ACM Symposium on
Principles of Distributed Computing. 2021, pp. 307–317.
[Bra+17]
Sebastian Brandt, Juho Hirvonen, Janne H. Korhonen, Tuomo Lempiäinen, Patric R.J. Östergård,
Christopher Purcell, Joel Rybicki, Jukka Suomela, and Przemysław Uznański. “LCL Problems
on Grids”. In: Proceedings of the ACM Symposium on Principles of Distributed Computing.
PODC ’17. Washington, DC, USA: Association for Computing Machinery, 2017, pp. 101–110.
isbn: 9781450349925.
[BMU19]
Sebastian Brandt, Yannic Maus, and Jara Uitto. “A sharp threshold phenomenon for the dis-
tributed complexity of the lovász local lemma”. In: Proceedings of the 2019 ACM Symposium
on Principles of Distributed Computing. 2019, pp. 389–398.
[BO20]
Sebastian Brandt and Dennis Olivetti. “Truly tight-in-δ bounds for bipartite maximal matching
and variants”. In: Proceedings of the 39th Symposium on Principles of Distributed Computing.
2020, pp. 69–78.
[CPS17a]
Keren Censor-Hillel, Merav Parter, and Gregory Schwartzman. “Derandomizing Local Dis-
tributed Algorithms under Bandwidth Restrictions”. In: 31st International Symposium on Dis-
tributed Computing (DISC 2017). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik. 2017.
[Cha20]
Yi-Jun Chang. “The Complexity Landscape of Distributed Locally Checkable Problems on
Trees”. In: 34th International Symposium on Distributed Computing (DISC 2020). Ed. by Hagit
Attiya. Vol. 179. Leibniz International Proceedings in Informatics (LIPIcs). Dagstuhl, Germany:
Schloss Dagstuhl–Leibniz-Zentrum für Informatik, 2020, 18:1–18:17. isbn: 978-3-95977-168-9.
doi: 10.4230/LIPIcs.DISC.2020.18. url: https://drops.dagstuhl.de/opus/volltexte/
2020/13096.
43

--- Page 44 ---
[Cha24]
Yi-Jun Chang. “The Distributed Complexity of Locally Checkable Labeling Problems Beyond
Paths and Trees”. In: 15th Innovations in Theoretical Computer Science Conference (ITCS
2024). Schloss-Dagstuhl-Leibniz Zentrum für Informatik. 2024.
[Cha+20]
Yi-Jun Chang, Varsha Dani, Thomas P Hayes, and Seth Pettie. “The energy complexity of
BFS in radio networks”. In: Proceedings of the 39th Symposium on Principles of Distributed
Computing. 2020, pp. 273–282.
[Cha+19a]
Yi-Jun Chang, Manuela Fischer, Mohsen Ghaffari, Jara Uitto, and Yufan Zheng. “The Complex-
ity of (∆+ 1) Coloring in Congested Clique, Massively Parallel Computation, and Centralized
Local Computation”. In: Proceedings of the 2019 ACM Symposium on Principles of Distributed
Computing. ACM. 2019, pp. 471–480.
[CG21]
Yi-Jun Chang and Mohsen Ghaffari. “Strong-Diameter Network Decomposition”. In: Proceedings
of the 2021 ACM Symposium on Principles of Distributed Computing. PODC’21. Virtual Event,
Italy: Association for Computing Machinery, 2021, pp. 273–281. isbn: 9781450385480.
[CKP19]
Yi-Jun Chang, Tsvi Kopelowitz, and Seth Pettie. “An Exponential Separation between Ran-
domized and Deterministic Complexity in the LOCAL Model”. In: SIAM Journal on Computing
48.1 (2019), pp. 122–143.
[Cha+19b]
Yi-Jun Chang, Tsvi Kopelowitz, Seth Pettie, Ruosong Wang, and Wei Zhan. “Exponential
separations in the energy complexity of leader election”. In: ACM Transactions on Algorithms
(TALG) 15.4 (2019), pp. 1–31.
[CLP18]
Yi-Jun Chang, Wenzheng Li, and Seth. Pettie. “An Optimal Distributed p∆` 1q-Coloring
Algorithm?” In: Proc. 50th ACM Symp. on Theory of Computing (STOC). 2018.
[Cha+23]
Yi-Jun Chang, Gopinath Mishra, Hung Thuan Nguyen, Mingyang Yang, and Yu-Cheng Yeh.
“A Tight Lower Bound for 3-Coloring Grids in the Online-LOCAL Model”. In: arXiv preprint
arXiv:2312.01384 (2023).
[CP19]
Yi-Jun Chang and Seth Pettie. “A Time Hierarchy Theorem for the LOCAL Model”. In: SIAM
Journal on Computing 48.1 (2019), pp. 33–69.
[CPZ19]
Yi-Jun Chang, Seth Pettie, and Hengjie Zhang. “Distributed triangle detection via expander
decomposition”. In: Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete
Algorithms. SIAM. 2019, pp. 821–840.
[CS19]
Yi-Jun Chang and Thatchaphol Saranurak. “Improved distributed expander decomposition and
nearly optimal triangle enumeration”. In: Proceedings of the 2019 ACM Symposium on Princi-
ples of Distributed Computing. 2019, pp. 66–73.
[CGP20]
Soumyottam Chatterjee, Robert Gmyr, and Gopal Pandurangan. “Sleeping is efficient: Mis
in o (1)-rounds node-averaged awake complexity”. In: Proceedings of the 39th Symposium on
Principles of Distributed Computing. 2020, pp. 99–108.
[CPS17b]
Kai-Min Chung, Seth Pettie, and Hsin-Hao Su. “Distributed algorithms for the Lovász local
lemma and graph coloring”. In: Distributed Computing 30.4 (2017), pp. 261–280.
[Coi+22]
Xavier Coiteux-Roy, Francesco d’Amore, Rishikesh Gajjala, Fabian Kuhn, François Le Gall,
Henrik Lievonen, Augusto Modanese, Marc-Olivier Renou, Gustav Schmid, and Jukka Suomela.
“No distributed quantum advantage for approximate graph coloring.” In: Quantum Information
and Computation 22.15&16 (2022), pp. 1261–1279.
[CV86]
Richard Cole and Uzi Vishkin. “Deterministic Coin Tossing with Applications to Optimal Par-
allel List Ranking”. In: Information and Control 70.1 (1986), pp. 32–53.
[CGP24]
Clinton T Conley, Jan Grebík, and Oleg Pikhurko. “Divisibility of spheres with measurable
pieces”. In: L’Enseignement Mathématique (2024).
[CM17]
Clinton T. Conley and Benjamin D. Miller. “Measure reducibility of countable Borel equivalence
relations”. In: Ann. of Math. (2) 185.2 (2017), pp. 347–402. issn: 0003-486X.
44

--- Page 45 ---
[Csó+22]
Endre Csóka, Łukasz Grabowski, András Máthé, Oleg Pikhurko, and Konstantinos Tyros.
“Moser-Tardos Algorithm with small number of random bits”. In: arXiv preprint arXiv:2203.05888
(2022).
[DF92]
Randall Dougherty and Matthew Foreman. “Banach-Tarski paradox using pieces with the prop-
erty of Baire”. In: Proc. Nat. Acad. Sci. U.S.A. 89.22 (1992), pp. 10726–10728. issn: 0027-8424.
[EL10]
Gábor Elek and Gábor Lippner. “Borel oracles. An analytical approach to constant-time algo-
rithms”. In: Proceedings of the American Mathematical Society 138.8 (2010), pp. 2939–2947.
[EFF82]
Paul Erdös, Peter Frankl, and Zoltán Füredi. “Families of finite sets in which no set is covered
by the union of two others”. In: Journal of Combinatorial Theory, Series A 33.2 (1982), pp. 158–
166.
[EL75]
Paul Erdős and László Lovász. “Problems and results on 3-chromatic hypergraphs and some
related questions”. In: Infinite and finite sets 10.2 (1975), pp. 609–627.
[EMR14]
Guy Even, Moti Medina, and Dana Ron. “Deterministic stateless centralized local algorithms
for bounded degree graphs”. In: European Symposium on Algorithms. Springer. 2014, pp. 394–
405.
[Fao+23]
Salwa Faour, Mohsen Ghaffari, Christoph Grunau, Fabian Kuhn, and Václav Rozhoň. “Local
distributed rounding: Generalized to mis, matching, set cover, and beyond”. In: Proceedings
of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA). SIAM. 2023,
pp. 4409–4447.
[Feu17]
Laurent Feuilloley. “How long it takes for an ordinary node with an ordinary ID to output?” In:
International Colloquium on Structural Information and Communication Complexity. Springer.
2017, pp. 263–282.
[Feu21]
Laurent Feuilloley. “Introduction to local certification”. In: Discrete Mathematics & Theoretical
Computer Science 23.Distributed Computing and Networking (2021).
[FG17]
Manuela Fischer and Mohsen Ghaffari. “Sublogarithmic Distributed Algorithms for Lovász Lo-
cal Lemma, and the Complexity Hierarchy”. In: 31 International Symposium on Distributed
Computing. 2017.
[FGK17]
Manuela Fischer, Mohsen Ghaffari, and Fabian Kuhn. “Deterministic Distributed Edge-Coloring
via Hypergraph Maximal Matching”. In: Proc. 58th IEEE Symp. on Foundations of Computer
Science (FOCS). 2017.
[Fra+13]
Pierre Fraigniaud, Mika Göös, Amos Korman, and Jukka Suomela. “What Can Be Decided
Locally without Identifiers?” In: Proceedings of the 2013 ACM Symposium on Principles of
Distributed Computing. PODC ’13. Montréal, Québec, Canada: Association for Computing Ma-
chinery, 2013, pp. 157–165. isbn: 9781450320658.
[FHK12]
Pierre Fraigniaud, Magnús M Halldórsson, and Amos Korman. “On the impact of identifiers on
local decision”. In: International Conference On Principles Of Distributed Systems. Springer.
2012, pp. 224–238.
[Gab00]
Damien Gaboriau. “Coût des relations d’équivalence et des groupes”. In: Invent. Math. 139.1
(2000), pp. 41–98. issn: 0020-9910.
[Gao+18]
Su Gao, Steve Jackson, Edward Krohne, and Brandon Seward. “Continuous combinatorics of
abelian group actions”. In: arXiv preprint arXiv:1803.03872 (2018).
[Gav+09]
Cyril Gavoille, Ralf Klasing, Adrian Kosowski, Łukasz Kuszner, and Alfredo Navarra. “On the
complexity of distributed graph coloring with local minimality constraints”. In: Networks: An
International Journal 54.1 (2009), pp. 12–19.
[GKM09]
Cyril Gavoille, Adrian Kosowski, and Marcin Markiewicz. “What Can Be Observed Locally?
Round-Based Models for Quantum Distributed Computing”. In: Proceedings of the 23rd Inter-
national Conference on Distributed Computing. DISC’09. Elche, Spain: Springer-Verlag, 2009,
pp. 243–257. isbn: 3642043542.
45

--- Page 46 ---
[Gha16]
Mohsen Ghaffari. “An improved distributed algorithm for maximal independent set”. In: Proc.
ACM-SIAM Symp. on Discrete Algorithms (SODA). 2016, pp. 270–277.
[Gha22]
Mohsen Ghaffari. “Local computation of maximal independent set”. In: 2022 IEEE 63rd Annual
Symposium on Foundations of Computer Science (FOCS). IEEE. 2022, pp. 438–449.
[GG23]
Mohsen Ghaffari and Christoph Grunau. “Faster Deterministic Distributed MIS and Approxi-
mate Matching”. In: Proceedings of the 55th Annual ACM Symposium on Theory of Computing.
2023, pp. 1777–1790.
[GG24]
Mohsen Ghaffari and Christoph Grunau. “Near-Optimal Deterministic Network Decomposition
and Ruling Set, and Improved MIS”. In: Proc. 65th IEEE Symp. on Foundations of Computer
Science (FOCS). 2024.
[Gha+23]
Mohsen Ghaffari, Christoph Grunau, Bernhard Haeupler, Saeed Ilchi, and Václav Rozhoň.
“Improved distributed network decomposition, hitting sets, and spanners, via derandomization”.
In: Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA).
SIAM. 2023, pp. 2532–2566.
[GGR21]
Mohsen Ghaffari, Christoph Grunau, and Václav Rozhoň. “Improved Deterministic Network
Decomposition”. In: Proc. of the 32nd ACM-SIAM Symp. on Discrete Algorithms (SODA). USA:
Society for Industrial and Applied Mathematics, 2021, pp. 2904–2923. isbn: 9781611976465.
[GH21]
Mohsen Ghaffari and Bernhard Haeupler. “A time-optimal randomized parallel algorithm for
mis”. In: Proceedings of the 2021 ACM-SIAM Symposium on Discrete Algorithms (SODA).
SIAM. 2021, pp. 2892–2903.
[GHK18]
Mohsen Ghaffari, David Harris, and Fabian Kuhn. “On derandomizing local distributed algo-
rithms”. In: Proc. Foundations of Computer Science (FOCS). 2018, pp. 662–673.
[GK22]
Mohsen Ghaffari and Fabian Kuhn. “Deterministic distributed vertex coloring: Simpler, faster,
and without network decomposition”. In: 2021 IEEE 62nd Annual Symposium on Foundations
of Computer Science (FOCS). IEEE. 2022, pp. 1009–1020.
[GKM17]
Mohsen Ghaffari, Fabian Kuhn, and Yannic Maus. “On the Complexity of Local Distributed
Graph Problems”. In: Proc. 49th ACM Symp. on Theory of Computing (STOC). 2017, pp. 784–
797.
[GKU19]
Mohsen Ghaffari, Fabian Kuhn, and Jara Uitto. “Conditional Hardness Results for Massively
Parallel Computation from Distributed Lower Bounds”. In: Proc. Foundations of Computer
Science (FOCS). 2019.
[GP22]
Mohsen Ghaffari and Julian Portmann. “Average Awake Complexity of MIS and Matching”.
In: Proceedings of the 34th ACM Symposium on Parallelism in Algorithms and Architectures.
SPAA ’22. Philadelphia, PA, USA: Association for Computing Machinery, 2022, pp. 45–55.
isbn: 9781450391467.
[GP23]
Mohsen Ghaffari and Julian Portmann. “Distributed MIS with Low Energy and Time Complex-
ities”. In: Proceedings of the 2023 ACM Symposium on Principles of Distributed Computing.
PODC ’23. Orlando, FL, USA: Association for Computing Machinery, 2023, pp. 146–156.
[GU19]
Mohsen Ghaffari and Jara Uitto. “Sparsifying distributed algorithms with ramifications in mas-
sively parallel computation and centralized local computation”. In: Proceedings of the Thirtieth
Annual ACM-SIAM Symposium on Discrete Algorithms. SIAM. 2019, pp. 1636–1653.
[Gha20]
Ghaffari, Mohsen. Distributed Graph Algorithms. Lecture notes. 2020. url: https://disco.
ethz.ch/courses/fs20/podc/lecturenotes/DGA.pdf.
[GPS88]
Andrew V. Goldberg, Sergey A. Plotkin, and Gregory E. Shannon. “Parallel Symmetry-Breaking
in Sparse Graphs”. In: SIAM Journal on Discrete Mathematics 1.4 (1988), pp. 434–446.
[Göö+16]
Mika Göös, Juho Hirvonen, Reut Levi, Moti Medina, and Jukka Suomela. “Non-local probes do
not help with many graph problems”. In: Distributed Computing: 30th International Symposium,
DISC 2016, Paris, France, September 27-29, 2016. Proceedings 30. Springer. 2016, pp. 201–214.
46

--- Page 47 ---
[GS11]
Mika Göös and Jukka Suomela. “Locally Checkable Proofs”. In: Proc. 30th Symp. on Principles
of Distributed Computing (PODC). 2011, pp. 159–168.
[GRS91]
Ronald L Graham, Bruce L Rothschild, and Joel H Spencer. Ramsey theory. Vol. 20. John
Wiley & Sons, 1991.
[GP20]
Jan Grebík and Oleg Pikhurko. “Measurable versions of Vizing’s theorem”. In: Advances in
Mathematics 374 (2020), p. 107378.
[GR21]
Jan Grebík and Václav Rozhoň. “Classification of local problems on paths from the perspective
of descriptive combinatorics”. In: Extended Abstracts EuroComb 2021: European Conference on
Combinatorics, Graph Theory and Applications. Springer. 2021, pp. 553–559.
[GR23]
Jan Grebík and Václav Rozhoň. “Local problems on grids from the perspective of distributed
algorithms, finitary factors, and descriptive combinatorics”. In: Advances in Mathematics 431
(2023), p. 109241.
[GRB22]
Christoph Grunau, Václav Rozhoň, and Sebastian Brandt. “The landscape of distributed com-
plexities on trees and beyond”. In: Proceedings of the 2022 ACM Symposium on Principles of
Distributed Computing. 2022, pp. 37–47.
[HKP01]
M. Hańćkowiak, M. Karoński, and A. Panconesi. “On the Distributed Complexity of Computing
Maximal Matchings”. In: SIAM Journal on Discrete Math. 15.1 (2001), pp. 41–57.
[Har19]
David G Harris. “Distributed local approximation algorithms for maximum matching in graphs
and hypergraphs”. In: 2019 IEEE 60th Annual Symposium on Foundations of Computer Science
(FOCS). IEEE. 2019, pp. 700–724.
[HS20]
Juho Hirvonen and Jukka Suomela. “Distributed Algorithms”. In: Textbook, Aalto University
(2020).
[HL+15]
Alexander Holroyd, Thomas Liggett, et al. “Symmetric 1-dependent colorings of the integers”.
In: Electronic Communications in Probability 20 (2015).
[Hol23]
Alexander E Holroyd. “Symmetrization for finitely dependent colouring”. In: arXiv preprint
arXiv:2305.13980 (2023).
[Hol17]
Alexander E. Holroyd. “One-dependent coloring by finitary factors”. In: Annales de l’Institut
Henri Poincaré, Probabilités et Statistiques 53.2 (2017), pp. 753–765.
[HSW17]
Alexander E. Holroyd, Oded Schramm, and David B. Wilson. “Finitary coloring”. In: Ann.
Probab. 45.5 (Sept. 2017), pp. 2867–2898. url: https://doi.org/10.1214/16-AOP1127.
[JáJ92]
Joseph JáJá. An introduction to parallel algorithms. Addison Wesley Longman Publishing Co.,
Inc., 1992.
[KSV10]
Howard Karloff, Siddharth Suri, and Sergei Vassilvitskii. “A model of computation for MapRe-
duce”. In: Proceedings of the twenty-first annual ACM-SIAM symposium on Discrete Algorithms.
SIAM. 2010, pp. 938–948.
[KM16]
Alexander S Kechris and Andrew S Marks. “Descriptive graph combinatorics”. In: preprint
2020.9 (2016).
[KSS81]
Daniel J. Kleitman, J Shearer, and Dean Sturtevant. “Intersections of k-element sets”. In: Com-
binatorica 1.4 (1981), pp. 381–384.
[Kor+21]
Janne H. Korhonen, Ami Paz, Joel Rybicki, Stefan Schmid, and Jukka Suomela. “Brief An-
nouncement: Sinkless Orientation Is Hard Also in the Supported LOCAL Model”. In: 35th In-
ternational Symposium on Distributed Computing (DISC 2021). Ed. by Seth Gilbert. Vol. 209.
Leibniz International Proceedings in Informatics (LIPIcs). Dagstuhl, Germany: Schloss Dagstuhl
– Leibniz-Zentrum für Informatik, 2021, 58:1–58:4. isbn: 978-3-95977-210-5. doi: 10.4230/
LIPIcs.DISC.2021.58. url: https://drops.dagstuhl.de/opus/volltexte/2021/14860.
[KSV12]
Amos Korman, Jean-Sébastien Sereni, and Laurent Viennot. “Toward more localized local algo-
rithms: removing assumptions concerning global knowledge”. In: Distributed Computing 26.5-6
(Sept. 2012), pp. 289–308. issn: 1432-0452. doi: 10.1007/s00446-012-0174-8. url: http:
//dx.doi.org/10.1007/s00446-012-0174-8.
47

--- Page 48 ---
[Kuh09]
Fabian Kuhn. “Local Weak Coloring Algorithms and Implications on Deterministic Symmetry
Breaking”. In: Proc. 21st ACM Symp. on Parallelism in Algorithms and Architectures (SPAA).
2009.
[KMW16]
Fabian Kuhn, Thomas Moscibroda, and Roger Wattenhofer. “Local Computation: Lower and
Upper Bounds”. In: Journal of the ACM 63.2 (2016).
[LNR19]
François Le Gall, Harumichi Nishimura, and Ansis Rosmanis. “Quantum Advantage for the
LOCAL Model in Distributed Computing”. In: 36th International Symposium on Theoretical
Aspects of Computer Science. 2019.
[LRY15]
Reut Levi, Ronitt Rubinfeld, and Anak Yodpinyanee. “Local computation algorithms for graphs
of non-constant degrees”. In: Proceedings of the 27th ACM symposium on Parallelism in Algo-
rithms and Architectures. 2015, pp. 59–61.
[LPS23]
Henrik Lievonen, Timothé Picavet, and Jukka Suomela. “Distributed Binary Labeling Problems
in High-Degree Graphs”. In: arXiv preprint arXiv:2312.12243 (2023).
[Lin92]
Nati Linial. “Locality in Distributed Graph Algorithms”. In: SIAM Journal on Computing 21.1
(1992), pp. 193–201.
[LS93]
Nati Linial and Michael Saks. “Low Diameter Graph Decompositions”. In: Combinatorica 13.4
(1993), pp. 441–454.
[Lov12]
László Lovász. Large networks and graph limits. Vol. 60. American Mathematical Soc., 2012.
[Lub86]
Michael Luby. “A Simple Parallel Algorithm for the Maximal Independent Set Problem”. In:
SIAM Journal on Computing 15 (1986), pp. 1036–1053.
[LAO17]
Lukasz Grabowski, András Máthé, and Oleg Pikhurko. “Measurable circle squaring.” In: Ann.
of Math. 185.2 (2017), pp. 671–710.
[MU16]
Andrew Marks and Spencer Unger. “Baire measurable paradoxical decompositions via match-
ings”. In: Advances in Mathematics 289 (2016), pp. 397–410.
[Mar16]
Andrew S Marks. “A determinacy approach to Borel combinatorics”. In: Journal of the American
Mathematical Society 29.2 (2016), pp. 579–600.
[MU17]
Andrew S Marks and Spencer T Unger. “Borel circle squaring”. In: Annals of Mathematics 186.2
(2017), pp. 581–605.
[Mau]
Y. Maus. personal communication.
[MSV23]
Darya Melnyk, Jukka Suomela, and Neven Villani. “Mending Partial Solutions with Few Changes”.
In: 26th International Conference on Principles of Distributed Systems. 2023.
[Mik90]
Miklós Laczkovich. “Equidecomposability and discrepancy; a solution of Tarski’s circle-squaring
problem.” In: J. Reine Angew. Math. 404 (1990), pp. 77–117.
[MPX13]
Gary L Miller, Richard Peng, and Shen Chen Xu. “Parallel graph decompositions using random
shifts”. In: Proceedings of the twenty-fifth annual ACM symposium on Parallelism in algorithms
and architectures. 2013, pp. 196–203.
[MR89]
Gary L. Miller and John H. Reif. “Parallel Tree Contraction–Part I: Fundamentals”. In: Advances
in Computing Research 5 (1989), pp. 47–72.
[MT10]
Robin A Moser and Gábor Tardos. “A constructive proof of the general Lovász local lemma”.
In: Journal of the ACM (JACM) 57.2 (2010), pp. 1–15.
[Nao91]
Moni Naor. “A lower bound on probabilistic algorithms for distributive ring coloring”. In: SIAM
Journal on Discrete Mathematics 4.3 (1991), pp. 409–412.
[NS95]
Moni Naor and Larry Stockmeyer. “What Can Be Computed Locally?” In: SIAM Journal on
Computing 24.6 (1995), pp. 1259–1277.
[NO08]
Huy N. Nguyen and Krzysztof Onak. “Constant-Time Approximation Algorithms via Local
Improvements”. In: 2008 49th Annual IEEE Symposium on Foundations of Computer Science.
2008, pp. 327–336. doi: 10.1109/FOCS.2008.81.
48

--- Page 49 ---
[Ona+12]
Krzysztof Onak, Dana Ron, Michal Rosen, and Ronitt Rubinfeld. “A near-optimal sublinear-
time algorithm for approximating the minimum vertex cover size”. In: Proceedings of the twenty-
third annual ACM-SIAM symposium on Discrete Algorithms. SIAM. 2012, pp. 1123–1131.
[PS92]
Alessandro Panconesi and Aravind Srinivasan. “Improved distributed algorithms for coloring
and network decomposition problems”. In: Proc. 24th ACM Symp. on Theory of Computing
(STOC). 1992, pp. 581–592.
[PR07]
Michal Parnas and Dana Ron. “Approximating the minimum vertex cover in sublinear time
and a connection to distributed algorithms”. In: Theoretical Computer Science 381.1-3 (2007),
pp. 183–196.
[Pel00]
David Peleg. Distributed Computing: A Locality-Sensitive Approach. SIAM, 2000.
[Pik21]
Oleg Pikhurko. Borel Combinatorics of Locally Finite Graphs. 2021. arXiv: 2009.09113 [math.CO].
[QW22]
Long Qian and Felix Weilacher. “Descriptive Combinatorics, Computable Combinatorics, and
ASI Algorithms”. In: arXiv preprint arXiv:2206.08426 (2022).
[RV16]
Omer Reingold and Shai Vardi. “New techniques and tighter bounds for local computation
algorithms”. In: Journal of Computer and System Sciences 82.7 (2016), pp. 1180–1200.
[RS20]
Will Rosenbaum and Jukka Suomela. “Seeing Far vs. Seeing Wide: Volume Complexity of Local
Graph Problems”. In: Proceedings of the 39th Symposium on Principles of Distributed Comput-
ing. PODC ’20. Virtual Event, Italy: Association for Computing Machinery, 2020, pp. 89–98.
isbn: 9781450375825.
[Roz+22a]
Václav Rozhoň, Michael Elkin, Christoph Grunau, and Bernhard Haeupler. “Deterministic low-
diameter decompositions for weighted graphs and distributed and parallel applications”. In:
2022 IEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS). IEEE. 2022,
pp. 1114–1121.
[RG20]
Václav Rozhoň and Mohsen Ghaffari. “Polylogarithmic-time deterministic network decompo-
sition and distributed derandomization”. In: Proceedings of the 52nd Annual ACM SIGACT
Symposium on Theory of Computing. 2020, pp. 350–363.
[Roz+22b]
Václav Rozhoň, Christoph Grunau, Bernhard Haeupler, Goran Zuzic, and Jason Li. “Undi-
rected (1+eps)-Shortest Paths via Minor-Aggregates: Near-Optimal Deterministic Parallel and
Distributed Algorithms”. In: Proceedings of the 54th Annual ACM SIGACT Symposium on
Theory of Computing. STOC 2022. Rome, Italy: Association for Computing Machinery, 2022,
pp. 478–487. isbn: 9781450392648.
[RHG23]
Václav Rozhoň, Bernhard Haeupler, and Christoph Grunau. “A Simple Deterministic Dis-
tributed Low-Diameter Clustering”. In: Symposium on Simplicity in Algorithms (SOSA). SIAM.
2023, pp. 166–174.
[Rub+11]
Ronitt Rubinfeld, Gil Tamir, Shai Vardi, and Ning Xie. “Fast local computation algorithms”.
In: arXiv preprint arXiv:1104.1377 (2011).
[RS15]
Joel Rybicki and Jukka Suomela. “Exact bounds for distributed graph colouring”. In: Interna-
tional Colloquium on Structural Information and Communication Complexity. Springer. 2015,
pp. 46–60.
[SS13]
Stefan Schmid and Jukka Suomela. “Exploiting Locality in Distributed SDN Control”. In: Pro-
ceedings of the Second ACM SIGCOMM Workshop on Hot Topics in Software Defined Network-
ing. HotSDN ’13. Hong Kong, China: Association for Computing Machinery, 2013, pp. 121–126.
isbn: 9781450321785.
[Spi20]
Yinon Spinka. “Finitely dependent processes are finitary”. In: Ann. Probab. 48.4 (2020), pp. 2088–
2117.
[Suo13]
Jukka Suomela. “Survey of local algorithms”. In: ACM Computing Surveys 45.2 (2013).
[Suo20]
Jukka Suomela. “Using Round Elimination to Understand Locality”. In: SIGACT News 51.3
(Sept. 2020), pp. 63–81. issn: 0163-5700.
49

--- Page 50 ---
[Suo23]
Suomela, Jukka. Open problems related to locality in distributed graph algorithms. 2023. url:
https://jukkasuomela.fi/open/.
[YYI09]
Yuichi Yoshida, Masaki Yamamoto, and Hiro Ito. “An improved constant-time approximation
algorithm for maximum matchings”. In: Proceedings of the forty-first annual ACM symposium
on Theory of computing. 2009, pp. 225–234.
50


=== quantum.pdf ===

--- Page 1 ---
What Can Be Observed Locally?⋆
Round-Based Models for Quantum Distributed Computing
Cyril Gavoille1, Adrian Kosowski1,2, and Marcin Markiewicz3
1 LaBRI - University of Bordeaux
2 Dept of Algorithms and System Modeling, Gda´nsk University of Technology
3 Institute of Theoretical Physics and Astrophysics, University of Gda´nsk
Abstract. We consider the question of locality in distributed comput-
ing in the context of quantum information. Speciﬁcally, we focus on the
round complexity of quantum distributed algorithms, with no bounds
imposed on local computational power or on the bit size of messages.
Linial’s LOCAL model of a distributed system is augmented through
two types of quantum extensions: (1) initialization of the system in a
quantum entangled state, and/or (2) application of quantum communi-
cation channels. For both types of extensions, we discuss proof-of-concept
examples of distributed problems whose round complexity is in fact re-
duced through genuinely quantum eﬀects. Nevertheless, we show that
even such quantum variants of the LOCAL model have non-trivial lim-
itations, captured by a very simple (purely probabilistic) notion which
we call “physical locality” (ϕ-LOCAL). While this is strictly weaker
than the “computational locality” of the classical LOCAL model, it
nevertheless leads to a generic view-based analysis technique for con-
structing lower bounds on round complexity. It turns out that the best
currently known lower time bounds for many distributed combinatorial
optimization problems, such as Maximal Independent Set, bounds cannot
be broken by applying quantum processing, in any conceivable way.
1
Introduction
The introduction of computational models based on quantum computing, start-
ing from the works of Deutsch in the 1980’s [11], has led to the advent of a new
branch of complexity theory. Many studies have for instance focused on the com-
plexity class BQP of problems solvable on a quantum computer in polynomial
time with bounded error probability, and its relation to the classical complex-
ity classes. One of the best known algorithmic results in this respect is Shor’s
polynomial-time method of integer factorization [37] based on the Quantum
Fourier Transform, which has recently been partially tested in an experimental
set-up for very small values of problem input. Nevertheless, application of quan-
tum information in centralized computing scenarios still proves extremely costly
and is riddled with technological diﬃculties resulting from quantum decoherence
⋆Supported by the ANR project “ALADDIN”, by the INRIA ´equipe-project
“C´EPAGE”, and by the KBN Grant 4 T11C 047 25.
I. Keidar (Ed.): DISC 2009, LNCS 5805, pp. 243–257, 2009.
c
⃝Springer-Verlag Berlin Heidelberg 2009

--- Page 2 ---
244
C. Gavoille, A. Kosowski, and M. Markiewicz
eﬀects. On the other hand, in an even wider time-frame, properties of quantum-
mechanical systems have proven to be of interest from the perspective of game
theory [4,13,2], information theory [31,22,3], and distributed systems [4,9].
A major line of study (which we brieﬂy look at in the related work section)
concerns the application of quantum eﬀects to reduce communication complex-
ity, i.e., to decrease the number of communication bits required to solve a speciﬁc
task performed within a system graph with several distributed agents. The in-
ﬂuence of quantum information on the computing power of distributed systems
with node anonymity and distributed systems in the presence of faults has also
been studied.
This paper focuses on a diﬀerent aspect of quantum distributed computing:
we do not impose any bounds on the size of communicated messages, but assume
that the system operates in synchronous rounds, and ask to what extent quantum
eﬀects can reduce the number of rounds required to solve combinatorial optimi-
sation problems. The starting point for considerations is the well-established
LOCAL model a.k.a. Linial’s Free model [25,26]. We provide a comparison of
the “computational power” of the quantum and non-quantum models, formalis-
ing the notion of locality in quantum distributed computing, and showing how
it essentially diﬀers from the understanding of locality in the LOCAL model.
1.1
Related Work
One of the most intensively studied problems related to multi-agent quantum sce-
narios, when expressed in the language of distributed computing, is roughly try-
ing to address the question: Can quantum eﬀects be used to enhance distributed
computations with messages of bounded size, i.e., in settings inspired by the
CONGEST distributed model? (See [35] for an introduction to the CONGEST
model.) The quantum variant of CONGEST , widely studied in physics, is known
as the Local Operations and Classical Communication (LOCC) model. It ex-
ploits the key quantum-mechanical concept of an entangled state (see e.g. [31]).
This is achieved by altering the initialization phase of the system to allow for a
starting state entangled among all the processors, which are locally given quan-
tum computation capabilities; however, communication between processors is
still restricted to the exchange of classical information, only. This application
of pre-entanglement has been shown to decrease the number of communication
bits required to solve certain distributed problems with output collected from
one node, and consequently, to decrease the number of required communication
rounds when message sizes are bounded. The ﬁrst proof-of-concept example was
provided in [6], where the computation of a speciﬁc function of input data dis-
tributed among three parties was shown to require at least 3 communicated bits
in the classical case, but only 2 communicated bits if the system is initialized in
a speciﬁc quantum entangled state. Many related results and reﬁnements of this
scenario are surveyed in e.g. [7,39].
Other works on the subject have focused on characterising the physical evo-
lution of states attainable in the LOCC model [30,32,8], while other authors
have dealt with the combinatorial complexity of distributing the entangled state

--- Page 3 ---
What Can Be Observed Locally?
245
over the whole system in the initialization phase [38]. Other modiﬁcations of
the model attempt to show that a denser coding of information in transmit-
ted messages is possible when using quantum channels, as compared to classical
communication links (see e.g. [5,36]).
Very recently, some authors have begun to study the impact of quantum eﬀects
on fundamental concepts of the theory of distributed computing. An overview of
this line of research is contained in the recent survey paper [9]. The advantages of
applying quantum communication in games against a dynamic adversary are dis-
played in [1], where it is shown that a constant number of computational rounds
is suﬃcient to solve the quantum Byzantine agreement problem for an n-node
system with less than n/3 faulty nodes in such a dynamic setting; corresponding
classical algorithms require Ω(√n) rounds. Another especially interesting result
is that the leader election problem can be solved in distributed systems with
quantum links, but no pre-entanglement [40,23]. Some authors have also claimed
that problems related to leader election [33,12] and distributed consensus [12,21]
can be solved in distributed systems aided by quantum pre-entanglement.
1.2
Outline of the Paper
In Subsection 1.3 we brieﬂy outline the LOCAL model and its extensions,
obtained by modifying the initialization of the system set-up and/or adding
quantum communication capabilities on the edges. Whereas this discussion is
self-contained, we also provide a formal mathematical deﬁnition of the cor-
responding notions in an extended version of the paper [19]. Subsection 1.4
introduces some notation used when comparing computational models.
In Section 2 we compare the computational power of models based on the
proposed extensions of LOCAL. In particular, we prove that adding quantum
extensions to the LOCAL model decreases the round complexity of certain dis-
tributed problems. This is achieved through simple proof-of-concept examples.
Most importantly, in Section 3 we introduce a probabilistic framework for
proving lower bounds on the distributed time complexity of computational prob-
lems in any quantum (or other unconventional) models based on LOCAL. This
is directly applied to obtain such lower bounds for many combinatorial optimiza-
tion problems, including Maximal Independent Set, Greedy Graph Coloring, and
problems of spanner construction. As a side eﬀect, the simple concept of “physi-
cal locality” formulated in this section, leads to the deﬁnition of a computational
model we call ϕ-LOCAL, which appears to be of independent interest.
Finally, in Section 4 we make an attempt to clarify issues with some of the
related work on quantum distributed computing as surveyed by [9]. Making
use of the framework of computational models deﬁned in the previous sections,
we explain why certain claims, saying that problems such as Leader Election
or Distributed Consensus beneﬁt from the application of quantum processing,
should be approached with caution.
Section 5 contains some concluding remarks and suggests directions of future
studies.

--- Page 4 ---
246
C. Gavoille, A. Kosowski, and M. Markiewicz
1.3
Preliminaries: Description of Computation Models
The LOCAL Model. The LOCAL model has been the subject of intensive
study in the last 20 years, starting from the seminal works [25,29]. It is assumed
that the distributed system consists of a set of processors V (with |V | = n) and
operates in a sequence of synchronous rounds, each of which involves unbounded
computations on the local state variables of the processors, and a subsequent ex-
change of messages of arbitrary size between pairs of processors which are con-
nected by links (except for round 0, which involves local computations, only).
Nodes can identify their neighbours using integer labels assigned successively
to communication ports. The local computation procedures encoded in all pro-
cessors are necessarily the same, and initially all local state variables have the
same value for all processors, except for one distinguished local variable x(v) of
each processor v which encodes input data. The input of a problem is deﬁned
in the form of a labeled graph Gx, where G = (V, E) is the system graph, while
x : V →N is an assignment of labels to processors. The output of the algorithm
is given in the form of a vector of local variables y : V →N, and the algorithm
is assumed to terminate once all variables y(v) are deﬁnitely ﬁxed. Herein we
assume that faults do not appear on processors and links, that local computa-
tion procedures may be randomized (with processors having access to their own
generators of random variables), and that the input labels x need not in general
be distinct for all processors.
In our considerations, it is convenient to assume that the set of processors
V is given before the input is deﬁned. This is used for convenience of notation,
and neither aﬀects the model, nor the anonymity of nodes in the considered
problems.
Extensions of System Initialization (+S and +E). In the LOCAL model, it
is assumed that the initial set-up of all the processors is identical. This assump-
tion can be relaxed by allowing the processors to obtain some information from
a central helper, but only before the start of the distributed process (i.e., inde-
pendently of the input Gx). The initialization procedure is an integral part of
the algorithm used for solving the distributed problem. Several diﬀerent forms of
initialization can be naturally deﬁned; for clarity of discussion, we consider only
two extensions of the model: the +S extension (for Separable state), which allows
for the most general form of initialization possible in a classical computational
setting, and the more powerful +E extension (for Entangled state), which allows
for the most general form of initialization available in a quantum distributed
system.
The +S extension. We say that a computational model is equipped with the +S
extension if the following modiﬁcations are introduced:
– For any computational problem, the computational procedure consists of
the distributed algorithm applied by all the processors during the rounds
of computation, and an additional (randomized) procedure executed in a
centralized way in the initialization phase. The result of the initialization

--- Page 5 ---
What Can Be Observed Locally?
247
procedure is an assignment h : V →N of helper variables to the set of
processors. The helper variables are independent1 of the input Gx.
– For each processor v ∈V , at the start of round 0, its input label x(v) is
augmented by the value h(v), stored in a helper register of the local memory.
It is straightforward to show that the above formulation has two equivalent char-
acterizations. From a computational perspective, we may equivalently say that
for each processor v, the helper initialization value h(v) encodes: (1) a unique
identiﬁer of v from the range {1, . . . , n}, (2) the value of n, (3) the value of a
random number, chosen from an arbitrarily large range, and shared by all pro-
cessors. All further helper information is unnecessary, since it can be computed
by the processors in round 0 of the distributed computations (simulation of the
centralized assignment of further helper information can be simulated based on
random bits and starting information which is common to all processors).
Alternatively, we may say that through the randomized initialization, accord-
ing to some probability distribution we choose some deterministic initialization
of the set of states of individual processors. This intuition precisely corresponds
to the notion of a state with uncertainty in classical statistical physics, referred
to in quantum-mechanical discussions as a (mixed) separable state of the sys-
tem. It is obviously true to say that whenever a problem is solved in a model
with the +S extension, it may beneﬁt solely from the modiﬁcation of the system
initialization, and not from the laws of quantum mechanics.
The +E extension. Unlike in classical physics, in quantum mechanics not every
initialization of the system has to follow the above pattern. Consider a scenario in
which we centrally create an initial global state of the whole system of processors,
and spatially distribute “parts” of it to the individual processors (for example,
by sharing out among the nodes a set of quantum-correlated photons). Then,
each of the processors can perform operations on the “part” of the state assigned
to its spatial location; by a loose analogy to processing of classical information,
this is sometimes referred to as each processor “manipulating its own quantum
bits (qubits)”. Given a general initial state of the system, the outcome of such
a physical process, as determined by the processors, may display correlations
which cannot be described using any classical probabilistic framework. Initial
states which can be lead to display such properties are called non-separable, or
entangled states. Quantum entanglement is without doubt one of the predom-
inant topics studied in quantum-mechanical literature of the last decades; we
refer the interested reader to e.g. [31] for an extensive introduction to the topic.
We say that a computational model is equipped with the +E extension if all
processors are equipped with helper quantum information registers h, and the
computational procedure used to solve a problem sets in the initialization phase
in a centralized way some chosen, possibly entangled, quantum state over the
set of quantum information registers h of all processors, in a way independent
of the input graph Gx.
1 Helper variables that do depend on the inputs are referred to in the literature as
Oracles [16,15]. Such extensions are not discussed in this paper.

--- Page 6 ---
248
C. Gavoille, A. Kosowski, and M. Markiewicz
Extension of Communication Capabilities (+Q). Whereas the application
of local quantum operations in each processor does not increase the power of the
LOCAL model as such, the situation changes when the processors can interact
with each other using quantum communication channels. Intuitively, such chan-
nels allow for the distribution of an entangled state by a processor over several
of its neighbours in one communication round; such an eﬀect cannot be achieved
using classical communication links.
We say that a computational model is equipped with the +Q extension if all
communication links between processors in the system graph are replaced by
quantum communication channels.
Models with the Extensions. Modiﬁcations to the initialization and commu-
nication capabilities of the system are completely independent of each other. For
initialization, we can apply no extension, use a separable state (+S), or an en-
tangled state (+E). For communication, we can apply no extension, or use quan-
tum channels (+Q). Hence, we obtain 6 possible models (LOCAL, LOCAL+S,
LOCAL+E, LOCAL+Q, LOCAL+Q+S, LOCAL+Q+E), which are discussed in
the following section. (Some of these models collapse onto each other.)
1.4
Notation for Comparing the Power of Computational Models
In order to compare the computational power of diﬀerent models, we introduce
two basic notions: that of the problem being solved, and of an outcome of the
computational process.
Deﬁnition 1. A problem P is a mapping Gx →{yi}, which assigns to each
input graph Gx a set of permissable output vectors yi : V →N.
Instead of explicitly saying that we are interested in ﬁnding eﬃcient (possibly
randomized) distributed algorithms for solving problems within the considered
computational models, we characterize the behavior of such procedures through
the probability distribution of output vectors which they may lead to, known as
an outcome. In fact, such a probability distribution is necessarily well deﬁned,
whereas formally describing the computational process may be diﬃcult in some
unconventional settings (see e.g. the ϕ-LOCAL model in Section 3).
Deﬁnition 2. An outcome O is a mapping Gx →{(yi, pi)}, which assigns to
each input graph Gx a normalized discrete probability distribution {pi}, such
that: ∀i pi > 0 and 
i pi = 1, with pi representing the probability of obtaining
yi : V →N as the output vector of the distributed system.
Deﬁnition 3. For any outcome O in a computational model M which is a variant
of LOCAL, we will write O ∈M[t] if within model M there exists a distributed
procedure which yields outcome O after at most t rounds of computation.
We will say that an outcome O is a solution to problem P with probability p if
for all Gx, we have: 
{(yi,pi)∈O(Gx) : yi∈P(Gx)} pi ≥p. When p = 1, we will
simply call O a solution to P (with certainty).

--- Page 7 ---
What Can Be Observed Locally?
249
By a slight abuse of notation, for a problem P we will write P ∈M[t] (re-
spectively, P ∈M[t, p]) if there exists an outcome O ∈M[t] which is a solution
to problem P (respectively, a solution to problem P with probability p).
For two computational models M1, M2, we say that M1 is not more powerful
than M2 (denoted M1 ⊆M2) if for every problem P, for all t ∈N and p > 0,
P ∈M1[t, p]
=⇒
P ∈M2[t, p]. The relation ⊆induces a partial order
of models which is naturally extended to say that M1 and M2 are equivalent
(M1 = M2), or that M1 is less powerful than M2 (M1 ⊊M2).
It can easily be proved that M1 ⊆M2 if and only if for every outcome O, for
all t ∈N, O ∈M1[t] =⇒O ∈M2[t]. Such an outcome-based characterisation
of models is occasionally more intuitive, since it is not explicitly parameterised
by probability p.
In all further considerations, when proving that M1 ⊊M2, we will do so in
a stronger, deterministic sense, by showing that there exist a problem P and
t ∈N such that P ∈M2[t] and P /∈M1[t].
2
Hierarchy of Quantum Models
The most natural variants of LOCAL which are based on the extensions proposed
in the previous subsection are the classical model with separable initialization
(LOCAL+S), and quantum models with pre-entanglement at initialization, quan-
tum channels, or both (LOCAL+E, LOCAL+Q, and LOCAL+Q+E, respectively).
The strengths of the models can obviously be ordered as follows: LOCAL ⊆
LOCAL+Q ⊆LOCAL+Q+S ⊆LOCAL+Q+E, and LOCAL ⊆LOCAL+S ⊆
LOCAL+E ⊆LOCAL+Q+E. We now proceed to show that, whereas LOCAL+E =
LOCAL+Q+E, all the remaining inclusions are in fact strict. The hierarchy of the
most important models is shown in Fig. 1.
Proposition 1. LOCAL ⊊LOCAL+S. Moreover, there exists a problem P
such that P ∈LOCAL+S[0] and P ̸∈LOCAL[t] for all t ∈N.
Proof. Any problem, which can be solved when given unique node identiﬁers
from the range {1, . . . , n} is clearly in LOCAL+S[0]. On the other hand, there
are many examples of such problems which are not in LOCAL (or require Ω(n)
rounds assuming that the system graph is connected and node labels are unique),
most trivially the problem P of assigning unique node identiﬁers from the range
{1, . . ., n} to all nodes.
⊓⊔
More interestingly, one can show that LOCAL+S beneﬁts due to the fact that
helper variables h(v) can encode a value which is set in a randomized way.
Consider as a simple example a problem P′ whose input is a graph G = (V, E),
of suﬃciently large order n, with input labels of the nodes encoding unique node
identiﬁers {1, . . . , n} and the value of n; moreover, G is restricted to be the
complete graph Kn minus exactly one edge. The goal is to select an edge of the
graph, i.e., output y must be such that for some two nodes u, v ∈V , with {u, v} ∈
E, we have y(u) = y(v) = 1, and for all other w ∈V we have y(w) = 0. Even

--- Page 8 ---
250
C. Gavoille, A. Kosowski, and M. Markiewicz
Fig. 1. Hierarchy of computational extensions to the LOCAL model. See Section 3 for
a deﬁnition of the ϕ-LOCAL model, and Section 1.3 or the extended version [19] for
deﬁnitions of all other models.
with the knowledge of node identiﬁers and n, in the LOCAL model the problem
cannot be solved with high probability without communication, i.e., within 0
rounds: we have P′ /∈LOCAL[0, e−1] (the proof is technical and postponed to
the extended version [19]). On the other hand, within the LOCAL+S model this
problem admits a solution in 0 rounds with probability arbitrarily close to 1 for
suﬃciently large n. Similar arguments can be applied to display the diﬀerence
between the models for more advanced problems which simulate collaborative
mobile agent scenarios, in particular variants of the cops-and-robbers problems
in graphs.
We now point out the diﬀerence in power between the classical and quantum
models. The proofs proceed by rephrasing one of the best established results of
quantum interferometry, ﬁrst introduced in the context of the so called Bell’s
Theorem without inequalities, for a 3-particle quantum entangled state (cf. [20]
for the original paper or [34] for a contemporary exposition). We use its more
algorithmic modulo-4 sum formulation, similar to that found in [41].
Theorem 1. LOCAL+S ⊊LOCAL+E. Moreover, there exists a problem P
such that P ∈LOCAL+E[0] and P ̸∈LOCAL+S[t] for all t ∈N.
Proof. Let P be a problem deﬁned on a system with 3 nodes. Let the input graph
be empty, and assume that input labels x = (x1, x2, x3) ∈{0, 1}3 of respective
nodes satisfy the condition x1 + x2 + x3 ∈{0, 2}. An output y = (y1, y2, y3) ∈
{0, 1}3 is considered valid for input x if and only if 2(y1+y2+y3) ≡(x1+x2+x3)
mod 4. This problem is not in LOCAL+S, since ﬁnding a solution with certainty
would imply that there exist three deterministic functions Y1, Y2, Y3 : {0, 1} →
{0, 1}, such that for any input vector (x1, x2, x3) satisfying the constraints of
the problem, (Y1(x1), Y2(x2), Y3(x3)) is a valid output vector. It is immediate to
show that this is impossible.
The situation is diﬀerent when the system operates in the LOCAL+E model
starts in an entangled state. The procedure required to obtain a valid solution
is described in detail in [20]. In brief, in the initialization phase we share out
to each of the processors one of 3 entangled qubits, carried e.g. by photons,

--- Page 9 ---
What Can Be Observed Locally?
251
which are in the entangled tripartite state known as the GHZ state (namely
1
√
2(|000⟩+ |111⟩) in Dirac’s notation for pure states). Each of the processors
then performs a simple transformation on “its own” qubit, in a way dependent
only on the processor’s input xi. Finally, a measurement is performed, and it
can be shown that the probability distribution of obtained output vectors (the
outcome) is that stated in Table 1. Since all of the outputs are accepted as valid
for the considered problem P, this implies that P ∈LOCAL+E[0].
⊓⊔
Table 1. An outcome O which is a solution (with certainty) to the modulo-4 sum
problem on the 3-node empty graph, and belongs to LOCAL+E[0] (see Theorem 1)
Input
Probability
Output
(x1, x2, x3)
pi
(yi
1, yi
2, yi
3)
(0, 0, 0)
1/4
(0, 0, 0)
1/4
(0, 1, 1)
1/4
(1, 0, 1)
1/4
(1, 1, 0)
Input
Probability
Output
(x1, x2, x3)
pi
(yi
1, yi
2, yi
3)
(0, 1, 1)
or (1, 0, 1)
or (1, 1, 0)
1/4
(1, 1, 1)
1/4
(1, 0, 0)
1/4
(0, 1, 0)
1/4
(0, 0, 1)
Proposition 2. LOCAL ⊊LOCAL+Q. Moreover, for any t > 0, there exists a
problem P such that P ∈LOCAL+Q[t] and P ̸∈LOCAL[2t −1].
Proof (sketch). The proof proceeds by a modiﬁcation of the argument from The-
orem 1. This time, we consider a system on n = 3k+1 nodes, and an input graph
with the topology of a uniformly subdivided star with a central node of degree 3.
The modiﬁed problem P′ consists in solving the problem from Theorem 1, when
the three input and output values are put on the three leaves of the star. Within
LOCAL, this problem requires 2k rounds to solve, whereas within LOCAL+Q,
k rounds are suﬃcient.
⊓⊔
Whereas the time distinction between LOCAL+S and LOCAL+E given by
Theorem 1 is remarkable (since it considers the feasibility of solving problems,
or when discussing connected graphs, a speed-up from Ω(n) to 0 communication
rounds), the situation is less clear between LOCAL+Q and LOCAL. Although a
speed-up factor of 2 as expressed by Proposition 2 looks like a natural limit, the
authors know of no conclusive arguments to show that it cannot be increased
further.
Finally, following the argumentation of [9], we observe that LOCAL+E =
LOCAL+Q+E, or in other words that, given access to pre-entanglement, it is
possible to simulate quantum links by means of classical ones. The eﬀect used
to achieve this is known as quantum teleportation [34]; by carefully choosing
an entangled state over the whole system, it can be applied even when the
communicating nodes do not yet know their neighbors’ unique identiﬁers. The
amount of pre-entanglement provided at initialization must be suﬃcient to allow
for communication throughout all the rounds of the algorithm.

--- Page 10 ---
252
C. Gavoille, A. Kosowski, and M. Markiewicz
To complete a discussion of Fig. 1, we point out that LOCAL+Q is incom-
parable with LOCAL+S. This is because the problem discussed in the proof of
Proposition 1 belongs to LOCAL+S, but not to LOCAL+Q, and the problem
discussed in the proof of Proposition 2 belongs to LOCAL+Q[1], but not to
LOCAL+S[1].
The LOCAL+Q+S model has been left out from discussion, since it appears
to be of little signiﬁcance. By considering the same problems as before, we have
LOCAL+Q+S ⊊LOCAL+Q+E = LOCAL+E, so LOCAL+Q+S could be placed
directly to the left of LOCAL+E in Fig. 1.
3
Lower Time Bounds Based on Physical Locality
(ϕ-LOCAL)
Proving lower bounds on the power of quantum models is problematic. This
results, in particular, from the fact that there does not exist as yet an easy-to-use
classiﬁcation of entangled states, or of quantum operations (completely positive
maps) which can be performed to transform one quantum state into another.
However, in the context of distributed computing, it is possible to consider a
more general framework of physical locality, leading to the ϕ-LOCAL model
we deﬁne hereafter, which in turn can be used to bound the power of quantum
models.
Within the classical LOCAL model, we can say that the output of any pro-
cessor v after t rounds has to be computed based on the input data which can
be collected from the input graph Gx by performing an exploration up to a
depth of t, starting from node v; we call this the distance-t local view denoted
by Vt(Gx, v). This leads to a simple characterisation of the LOCAL model in
terms of valid outcomes (see the extended version [19] for a formalization).
In order to allow for quantum extensions to local, the assumption of classical
computability needs to be relaxed, while at the same time retaining in some
form the assumption of locality. Given a round-based model with interactions
between nearest neighbors only, the physical understanding of locality is as fol-
lows: Locality is violated if and only if, based on the available output data, we can
conclusively verify that after t rounds some subset S of processors was aﬀected
by input data initially localized outside its view Vt(Gx, S) := 
v∈S Vt(Gx, v).
Using the above intuition, we now formalize this notion to obtain what we
call the ϕ-LOCAL model, i.e., the weakest possible distributed model which still
preserves physical locality. Given an output distribution {(yi, pi)} acting on V ,
for any subset of vertices S ⊆V we deﬁne its marginal distribution on set S,
{(yi, pi)}[S], as the unique distribution {(yj, pj)} acting on S which satisﬁes
the condition pj = 
{i : yj=yi[S]} pi, where yi[S] is the restriction of output
yi : V →N to nodes from subset S ⊆V .
Deﬁnition 4. An outcome Gx →{(yi, pi)} belongs to ϕ-LOCAL[t] if for all sub-
sets S ⊆V , for any pair of inputs G(a)
x , G(b)
x
such that Vt(G(a)
x , S) = Vt(G(b)
x , S),
the output distributions corresponding to these inputs have identical marginal dis-
tributions on set S, i.e., {(yi(a), pi(a))}[S] = {(yi(b), pi(b))}[S].

--- Page 11 ---
What Can Be Observed Locally?
253
Quantum relaxations of the LOCAL model, whether obtained through applica-
tion of pre-entanglement, quantum channels, or both, lie in terms of strength “in
between” the LOCAL and ϕ-LOCAL model. This is expressed by the following
theorem, whose proof is provided in the extended version of the paper [19].
Theorem 2. LOCAL+Q+E ⊆ϕ-LOCAL.
The theorem captures the property of locality of nearest-neighbor interactions
in quantum mechanics, and it does not rely in any way on any other physical
concepts, such as causality or speed of information in the theory of relativity.
Although it is not clear whether the containment in the above theorem is strict
(we leave this as an open question), the ϕ-LOCAL model is still suﬃciently
constrained to preserve many important lower time bounds known from the
LOCAL model, which are based on arguments of indistinguishability of local
views of a node for diﬀerent inputs. In particular, by careful analysis, it is easy
to prove the following statements for the ϕ-LOCAL model.
– The problem of ﬁnding a maximal independent set in the system graph
requires Ω(

log n
log log n) rounds to solve [24].
– The problem of ﬁnding a locally minimal (greedy) coloring of the system
graph requires Ω(
log n
log log n) rounds to solve [18,17].
– The problem of ﬁnding a connected subgraph with O(n1+1/k) edges requires
Ω(k) rounds to solve [10,14].
The matter is less clear in the case of the (Δ + 1)-coloring problem. The proof
of the famous lower bound of 1
2 log∗n −O(1) rounds [26] (and its extension to
randomized algorithms [28]) does not appear to generalize from the LOCAL
model to the ϕ-LOCAL model; we are unaware of any (even constant) bound on
the number of rounds required to ﬁnd a solution to (Δ+1)-coloring in ϕ-LOCAL.
Some indication that the technique of coloring neighborhood graphs, used by
Linial, may not apply in ϕ-LOCAL, is that this technique can likewise be used
to show a lower bound of
 n
2

−1 rounds on the time required for 2-coloring the
cycle Cn, where n is even. However, in ϕ-LOCAL the same problem admits a
solution in fewer rounds.
Theorem 3. The problem of 2-coloring the even cycle Cn (given unique node la-
bels x) belongs to ϕ-LOCAL[⌈n−2
4 ⌉], but does not belong to ϕ-LOCAL[⌈n−2
4 ⌉−1].
Proof (sketch). For the lower bound, consider the local view of two nodes u, v
which still have disjoint views after ⌈n−2
4 ⌉−1 rounds. There are at least two
nodes which belong to neither the view of u nor the view of v; hence, u and v
cannot distinguish whether they are at an even or at an odd distance from each
other in the cycle. This directly leads to the lower bound, since the deﬁnition
condition of ϕ-LOCAL can be shown to be violated for S = {u, v}.
The upper bound is generated by on outcome O of the 2-coloring problem,
given as follows: each of the 2 legal 2-colorings of Cn is used as the output with
probability 1
2. Such an outcome O belongs to ϕ-LOCAL[⌈n−2
4 ⌉]. This can be
easily veriﬁed, since for any subset S ⊆V we either have that S consists of

--- Page 12 ---
254
C. Gavoille, A. Kosowski, and M. Markiewicz
exactly two antipodal nodes of Cn, or the view V⌈n−2
4
⌉(Cnx, S) is simply an arc
of the cycle.
⊓⊔
It would be interesting to ﬁnd a constructive quantum procedure for ﬁnding a
2-coloring of Cn in ⌈n−2
4 ⌉rounds. In particular, we have that 2-coloring of C6
belongs to ϕ-LOCAL[1], does not belong to LOCAL+S[1], and do not know if
it belongs to LOCAL+E[1].
4
Simple Problems in a Quantum Setting
In this section, we have a look at some of the related work on quantum dis-
tributed problems, as outlined in the survey [9]. Whereas the discussion in this
section relies on the results and notation from the preceding sections, it can also
be translated into the (not always precisely described) computational models
studied in the considered related work.
Two problems which have been used to exhibit the diﬀerence between quan-
tum models and non-quantum models are LeaderElection, where the goal is for
exactly one node of the system graph to output a value of 1 whereas all other
nodes output 0, and a problem which we will call BitPicking, where the goal is
for all nodes to return the same output value, either 0 or 1. These discussions
include the concept of fairness, which in the terminology of this paper means
that we are asking not about the problems as such, but about obtaining speciﬁc
(fair) outcomes. More precisely, we will say that FairLeaderElection is the out-
come which puts a uniform probability distribution on the n distinct outputs
valid for LeaderElection (i.e., on all possible leaders), and FairBitPicking is the
outcome which puts a uniform probability distribution on the 2 distinct outputs
valid for BitPicking (i.e., picking 0 or 1).
The focus of [33,12,21] is to show that FairBitPicking and FairLeaderElection
belong to LOCAL+E[0] (even with some additional restrictions on the amount
of allowed pre-entanglement), whereas they do not belong to LOCAL[0]. This
statement is correct, however, this eﬀect is due to the modiﬁcation of initializa-
tion of the system, and not to quantum mechanics. In fact, we can make the
following obvious statement.
Proposition 3. FairBitPicking and FairLeaderElection belong to the non-quantum
class LOCAL+S[0]. Moreover, they can be solved with only one bit of helper infor-
mation per node, at initialization.
Finally, we relate to the recent claims that the DistributedConsensus can be solved
in a quantum setting without communication. Whereas these claims result from
a misunderstanding of the deﬁnition [27] of DistributedConsensus, we point out
that such a result is impossible in any quantum model, since it is even impos-
sible in ϕ-LOCAL (a short proof is provided in the extended version of the
paper [19]). We recall that in DistributedConsensus, given an assignment of input
labels (x1, . . . , xn) to particular processors, the goal is to obtain an output vector
(y, . . . , y), such that y ∈{x1, . . . , xn}.
Proposition 4. DistributedConsensus /∈ϕ-LOCAL[0].

--- Page 13 ---
What Can Be Observed Locally?
255
5
Conclusions and Future Work
We have pointed out that the computational power of quantum variants of the
LOCAL model is strictly greater than that of the classical LOCAL model, or
that of the LOCAL model equipped with helper information such as a pool of
shared random bits. It remains to be seen whether a diﬀerence can be observed
for any problems of practical signiﬁcance. It is potentially possible that certain
combinatorial optimization problems may beneﬁt from quantum extensions to
the LOCAL model. However, we can say that the “view-based” limitations of
the LOCAL model still hold in quantum models. So, one speciﬁc question which
remains open is whether the (Δ+1)-Coloring problem can be solved in a constant
number of rounds in any of the relaxed variants of LOCAL.
Finally, we can ask about a characterization of the limitations of quantum
computability, the most natural question being to establish whether the con-
tainment LOCAL+E ⊆ϕ-LOCAL is strict. As a matter of fact, further studies
of the ϕ-LOCAL model, which can be seen as the weakest distributed local
model, capturing veriﬁability rather than computability of outcomes, appear to
be of interest in their own right.
Acknowledgment. We gratefully thank Pierre Fraigniaud and Zvi Lotker for their
preliminary discussions on the EPR eﬀect and its applicability to Distributed
Computing. We thank Robert Alicki and Wladyslaw Adam Majewski for helpful
discussions concerning quantum dynamic maps, and Marek ˙Zukowski for several
references on quantum information.
References
1. Ben-Or, M., Hassidim, A.: Fast quantum byzantine agreement. In: 37th Annual
ACM Symposium on Theory of Computing (STOC), pp. 481–485. ACM Press,
New York (2005)
2. Benjamin, S.C., Hayden, P.M.: Multiplayer quantum games. Physical Review
A 64(3), 030301 (2001)
3. Bennett, C.H., Shor, P.W.: Quantum information theory. IEEE Transactions on
Information Theory 44, 2724–2742 (1998)
4. Broadbent, A., Tapp, A.: Can quantum mechanics help distributed computing?
ACM SIGACT News - Distributed Computing Column 39(3), 67–76 (2008)
5. Buhrman, H., Cleve, R., Wigderson, A.: Quantum vs. classical communication
and computation. In: 30th Annual ACM Symposium on the Theory of Computing
(STOC), pp. 63–68 (1998)
6. Cleve, R., Buhrman, H.: Substituting quantum entanglement for communication.
Physical Review A 56(2), 1201–1204 (1997)
7. de Wolf, R.: Quantum communication and complexity. Theoretical Computer Sci-
ence 287(1), 337–353 (2002)
8. den Nest, M.V., D¨ur, W., Vidal, G., Briegel, H.: Classical simulation versus uni-
versality in measurement-based quantum computation. Physical Review A 75(1),
012337 (2007)
9. Denchev, V.S., Pandurangan, G.: Distributed quantum computing: A new fron-
tier in distributed systems or science ﬁction? ACM SIGACT News - Distributed
Computing Column 39(3), 77–95 (2008)

--- Page 14 ---
256
C. Gavoille, A. Kosowski, and M. Markiewicz
10. Derbel, B., Gavoille, C., Peleg, D., Viennot, L.: On the locality of distributed
sparse spanner construction. In: 27th Annual ACM Symposium on Principles of
Distributed Computing (PODC), pp. 273–282. ACM Press, New York (2008)
11. Deutsch, D.: Quantum theory, the Church-Turing principle and the universal quan-
tum computer. Proceedings of the Royal Society of London A400, 97–117 (1985)
12. D’Hondt, E., Panangaden, P.: The computational power of the W and GHZ states.
Quantum Information and Computation 6(2), 173–183 (2006)
13. Eisert, J., Wilkens, M., Lewenstein, M.: Quantum games and quantum strategies.
Physical Review Letters 83(11), 3077–3080 (1999)
14. Elkin, M.: A near-optimal fully dynamic distributed algorithm for maintaining
sparse spanners. In: 26th Annual ACM Symposium on Principles of Distributed
Computing (PODC), pp. 195–204. ACM Press, New York (2007)
15. Fraigniaud, P., Gavoille, C., Ilcinkas, D., Pelc, A.: Distributed computing with ad-
vice: Information sensitivity of graph coloring. In: Arge, L., Cachin, C., Jurdzi´nski,
T., Tarlecki, A. (eds.) ICALP 2007. LNCS, vol. 4596, pp. 231–242. Springer, Hei-
delberg (2007)
16. Fraigniaud, P., Ilcinkas, D., Pelc, A.: Oracle size: a new measure of diﬃculty for
communication tasks. In: 25th Annual ACM Symposium on Principles of Dis-
tributed Computing (PODC), pp. 179–187. ACM Press, New York (2006)
17. Gavoille, C., Klasing, R., Kosowski, A., Kuszner, L., Navarra, A.: On the complex-
ity of distributed graph coloring with local minimality constraints. Networks (to
appear, 2009)
18. Gavoille, C., Klasing, R., Kosowski, A., Navarra, A.: Brief announcement: On the
complexity of distributed greedy coloring. In: Pelc, A. (ed.) DISC 2007. LNCS,
vol. 4731, pp. 482–484. Springer, Heidelberg (2007)
19. Gavoille, C., Kosowski, A., Markiewicz, M.: What can be observed locally? Round-
based models for quantum distributed computing. Technical report, arXiv: quant-
ph/0903.1133 (2009)
20. Greenberger, D.M., Horne, M.A., Zeilinger, A.: Going beyond Bell’s Theorem. In:
Bell’s Theorem, Quantum Theory, and Conceptions of the Universe, pp. 69–72.
Kluwer, Dordrecht (1989)
21. Helm, L.: Brief announcement: Quantum distributed consensus. In: 27th Annual
ACM Symposium on Principles of Distributed Computing (PODC), p. 445. ACM
Press, New York (2008)
22. Jaeger, G.: Quantum Information. An Overview. Springer, Heidelberg (2007)
23. Kobayashi, H., Matsumoto, K., Tani, S.: Fast exact quantum leader election on
anonymous rings. In: 8th Asian Conference on Quantum Information Science
(AQIS), August 2008, pp. 157–158 (2008)
24. Kuhn, F., Moscibroda, T., Wattenhofer, R.: What cannot be computed locally!
In. In: 23rd Annual ACM Symposium on Principles of Distributed Computing
(PODC), pp. 300–309. ACM Press, New York (2004)
25. Linial, N.: Distributive graph algorithms - Global solutions from local data. In:
28th Annual IEEE Symposium on Foundations of Computer Science (FOCS), pp.
331–335. IEEE Computer Society Press, Los Alamitos (1987)
26. Linial, N.: Locality in distributed graphs algorithms. SIAM Journal on Comput-
ing 21(1), 193–201 (1992)
27. Lynch, N.: Distributed Algorithms. Morgan Kaufmann Publishers, San Francisco
(1997)
28. Naor, M.: A lower bound on probabilistic algorithms for distributive ring coloring.
SIAM Journal on Discrete Mathematics 4(3), 409–412 (1991)

--- Page 15 ---
What Can Be Observed Locally?
257
29. Naor, M., Stockmeyer, L.: What can be computed locally. SIAM Journal on Com-
puting 24(6), 1259–1277 (1995)
30. Nielsen, M.: Conditions for a class of entanglement transformations. Physical Re-
view Letters 83(2), 436–439 (1999)
31. Nielsen, M., Chuang, I.: Quantum Computation and Quantum Information. Cam-
bridge University Press, Cambridge (2000)
32. Owari, M., Matsumoto, K., Murao, M.: Entanglement convertibility for inﬁnite-
dimensional pure bipartite states. Physical Review A 70(5), 1–4 (2004)
33. Pal, S.P., Singh, S.K., Kumar, S.: Multi-partite quantum entanglement versus ran-
domization: Fair and unbiased leader election in networks. Technical report, arXiv:
quant-ph/0306195v1 (June 2003)
34. Pan, J.-W., Chen, Z.-B., ˙Zukowski, M., Weinfurter, H., Zeilinger, A.: Multi-photon
entanglement and interferometry. Technical report, arXiv: quant-ph/0805.2853v1
(May 2008)
35. Peleg, D.: Proximity-preserving labeling schemes and their applications. In: Wid-
mayer, P., Neyer, G., Eidenbenz, S. (eds.) WG 1999. LNCS, vol. 1665, pp. 30–41.
Springer, Heidelberg (1999)
36. Raz, R.: Exponential separation of quantum and classical communication complex-
ity. In: 31st Annual ACM Symposium on the Theory of Computing (STOC), pp.
358–367 (1999)
37. Shor, P.W.: Polynomial-time algorithms for prime factorization and discrete log-
arithms on a quantum computer. SIAM Journal on Computing 26(5), 1484–1509
(1997)
38. Singh, S.K., Kumar, S., Pal, S.P.: Characterizing the combinatorics of dis-
tributed EPR pairs for multi-partite entanglement. Technical report, arXiv: quant-
ph/0306049v2 (January 2004)
39. Ta-Shma, A.: Classical versus quantum communication complexity. SIGACT
News 30(3), 25–34 (1999)
40. Tani, S., Kobayashi, H., Matsumoto, K.: Exact quantum algorithms for the leader
election problem. In: Diekert, V., Durand, B. (eds.) STACS 2005. LNCS, vol. 3404,
pp. 581–592. Springer, Heidelberg (2005)
41. ˙Zukowski, M.: On Bell’s Theorem, quantum communication, and entanglement
detection. In: Foundations of Probability and Physics 5 (August 2008)


=== round-0006/verifier.feedback.md ===
High-level assessment. Your pivot to a finite, stationary single-block feasibility test (MIQCP/QCQP) that encodes (i) perfect properness on the interior edges; (ii) shift-consistency (stationarity); and (iii) exact pair-independence at separation 2r+1 is sound and well-motivated. For r = 2, the 6-block (length L = 2r+2 = 6) formulation captures exactly the pair-independence constraint at lag 5 that any product-state 2-round output must satisfy (Theorem 2 in output.md). The corrected two-point formula for the no-self-loop 3-state chain is correct and useful: it certifies that the chain cannot satisfy lag-5 independence and thus cannot witness feasibility at value 1 once independence is enforced.

Rigor checks and minor corrections.
- Stationarity via a single 6-block distribution: Your shift-consistency constraints M1(α) = M2(α) for all α ∈ Σ^5 are exactly the Kolmogorov (sliding-window) consistency needed to define a stationary order-5 process with the prescribed 6-block marginals. We add a formal extension lemma to output.md to justify this rigorously and to make your modeling auditable.
- Pair-independence at lag 5: For r = 2, N_r({i}) and N_r({i+5}) are disjoint on the cycle/line, so independence of X_i and X_{i+5} holds in the product-state regime (Theorem 2). Imposing p(a,b) = m(a)m(b) for the (1,6) coordinates in the 6-block is therefore necessary. Because the 6-block is common across all interior positions by stationarity, this enforces independence at lag 5 globally.
- Properness constraints: Requiring t(ζ) = 0 whenever ζ_j = ζ_{j+1} for some j = 1,…,5 is exactly what “objective = 1” within the window means; this is the correct way to encode perfect properness as feasibility.
- Color symmetry: Your caution is correct—global color-permutation symmetrization can destroy unconditional independence across distant sets. We add a remark in output.md to flag this explicitly.

Scope and sufficiency. The 6-block test enforces only a subset of the independence that the product-state model guarantees; it is still necessary, hence any infeasibility is decisive. If 6-block is feasible, moving to a 7-block to add lag-6 independence (and, if needed, both lag-5 and lag-6 together) is the right escalation. Triple independence (e.g., positions 1,6,11) is also valid in the product-state regime and would require an 11-block; keep this as a later knob if simpler pair constraints do not already yield infeasibility.

Value triage. The main contributions this round are: (1) a clean, sound MIQCP formulation at L=6 for r=2; (2) clear abandonment of unsound linearizations; (3) corrections to the chain’s correlation formula. These are meaningful steps, though not yet a contradiction or bound. We capture the modeling in notes and add two rigorous structural results to output.md: (i) an extension lemma from shift-consistent L-block marginals to a stationary process; (ii) a single-block necessary-conditions proposition for product-state outputs (general r), plus a corollary tying MIQCP infeasibility to a constant-error lower bound via our amplification template.

Concrete next steps (actionable):
1) Implement the L = 6 MIQCP as stated; use BARON/Couenne/SCIP-NLP. Archive the exact model and solver logs. If infeasible, we immediately obtain a constant-error bound (Corollary below) and can proceed to quantify ε by maximizing the properness probability under the same constraints.
2) If feasible, tighten progressively: (a) move to L = 7 and enforce both lag-5 and lag-6 independence; (b) if still feasible, consider L = 8–9 adding additional necessary constraints (e.g., independence of a far pair internal to the larger window), or jump to triple independence at L = 11.
3) In parallel, add an optimization variant: maximize the probability of the “all 5 interior edges proper” event under the same constraints to get an explicit q < 1 if infeasible at value 1 fails. Nonconvex solvers can still handle this scale.
4) Exploratory combinatorics: analyze the increment process S_t = X_{t+1} − X_t (mod 3) with S_t ∈ {±1}; independence at lag 5 forces conditions on the 5-step sum of S’s mod 3. This may yield an analytic contradiction without computation, or suggest extra necessary constraints to add to the MIQCP.
5) Keep color-symmetry out of the model unless you separately prove it preserves the independence equalities you enforce.

We append the formal single-block reduction and Kolmogorov/Markov extension lemmas to output.md so the MIQCP pipeline is fully justified and citable.

=== notes.md ===
Scope and goal
We seek lower bounds for 2–3 round quantum LOCAL algorithms that 3-color an n-cycle. We separate two resource regimes: (i) no initial shared entanglement (initial product state across vertices), and (ii) arbitrary initial shared entanglement. Our strategy follows and extends Le Gall–Rosmanis (LGR, 2022): reduce to a line-segment optimization under r-local non-signaling constraints, then lift to cycles. Two technical pillars are (A) light-cone localization of measurements in r rounds (implying r-non-signaling), and (B) independence across well-separated regions when the initial state is a product.

Key corrections/new facts
- Independence threshold is 2r, not r, in the two-way model without entanglement. After reversing r communication layers, any measurement on a block depends only on the block’s r-neighborhood. Thus independence of multiple blocks requires their r-neighborhoods to be disjoint, i.e., pairwise distances > 2r. Counterexample to “> r” for r = 1: on a path 0–1–2, one round suffices for node 1 to broadcast a private random bit to nodes 0 and 2, correlating their outputs at distance 2.
- Non-signaling beyond r holds with or without shared entanglement: the marginal on a set S depends only on the initial state on N_r(S). This follows from Heisenberg-picture localization of effects under depth-r local circuits/channels.

Amplification templates
- No entanglement (product initial state): If there exists k and q < 1 such that every r-non-signaling distribution on a length-k segment makes the segment proper with probability at most q, then on cycles C_n the success probability is at most q^{⌊n/(k+2r)⌋}. Partition C_n into ⌊n/(k+2r)⌋ disjoint windows of length k separated by gaps of size 2r; window events are independent by the 2r-separation lemma; ring proper implies all windows are proper.
- With entanglement allowed: For any fixed window W of length k, ring proper implies W is proper. The distribution on W (restricted to placements with r-buffers inside W) is feasible for the r-non-signaling LP, hence P[ring proper] ≤ P[W proper] ≤ q. There is no improvement from packing without independence; the optimal general bound is the n-independent constant q.

LP plan for r = 2, 3
- Variables: probabilities over colorings on r-gapped placements (collections of frames) inside [1..k]. Placements include cores and r-buffers fully contained in [1..k].
- Constraints: non-signaling equalities enforcing that the marginal distribution on a given core is independent of the surrounding placement context as long as r-buffers are intact (equalities of marginals across placements that agree on the core).
- Objective: maximize P[all k − 1 edges inside [1..k] are properly 3-colored].
- Symmetries: quotient by S3 color permutations; translations (and reflections, if used). It is safe (as a relaxation) to enforce only a generating set of non-signaling constraints; for the final certificate, include all placements that respect the segment.
- Execution: sweep k ≈ 10–16 for r = 2 (then smaller k for r = 3), solve numerically, and extract dual certificates for any instance with optimum < 1.

What remains to be computed
- A concrete (r, k, q) with q < 1 via the LP. Once obtained, immediately plug into the amplification templates above. Note the stride is k + 2r (not k + r) in the independence-based exponential bound.

Reference counterexample (to avoid regression)
- Two-way, r = 1, no entanglement: path 0–1–2. Node 1 samples b ∈ {0,1}, sends b to 0 and 2, both output b. Outputs at distance 2 are perfectly correlated; independence beyond r = 1 fails. Independence holds only when r-neighborhoods are disjoint (distance > 2r).
Additional clarifications and refinements

1) Interior placement invariance: correct assumptions and a counterexample
- Valid regimes. For an r-round uniform LOCAL algorithm on a cycle C_n, invariance of interior placements (i.e., equality of core marginals for all gap-r placements whose r-buffers lie within a window W) holds under either of the following assumptions:
  (a) No shared entanglement and identical local initial states (product initial state ⊗_v ρ, with the same ρ at every vertex).
  (b) Shared entanglement is allowed, but the global initial state ρ_0 is invariant under the automorphisms of C_n (rotations and reflections). Uniformity of the local channels across vertices is also required.
- Why. In the Heisenberg picture, the effect for a core event depends only on the union of r-neighborhoods of the cores. Two interior placements of the same frame family induce isomorphic unions; the corresponding effects are related by a permutation of registers. If ρ_0 is invariant under that permutation (true in (a) and (b)), the probabilities coincide.
- Necessity of the symmetry assumption with entanglement. Without (b), the statement can fail. Counterexample (r = 0): prepare EPR pairs on disjoint edges (1,2), (3,4), … around the cycle, and have each vertex measure Z and output a color that is a function of its bit. Then the joint distribution on two adjacent cores depends on whether the placement coincides with a paired edge (correlated) or straddles a pair boundary (independent). Hence, equality across placements fails.

2) Segment LP (precise, and what it models)
- Alphabet Σ = {1,2,3}. Fix r ≥ 1 and k ≥ 1. Let a frame family F = ({{s_1}}, …, {{s_t}}), each {{s_j}} a contiguous core of length s_j.
- An r-gapped placement ω of F inside [1..k] is a t-tuple of start positions (ω_1,…,ω_t) such that the r-buffers [[ω_j − r .. ω_j + s_j − 1 + r]] are subsets of [1..k] and pairwise disjoint. The cores are C_j = [[ω_j .. ω_j + s_j − 1]].
- Variables: p_ψ for ψ ∈ Σ^k, with p_ψ ≥ 0 and ∑_ψ p_ψ = 1.
- Objective: maximize ∑_ψ p_ψ · 1{ψ has no equal-color adjacencies on edges (i, i+1), i = 1..k−1}.
- Constraints (interior placement invariance): For every family F and every core assignment ζ = (ζ_1,…,ζ_t), the marginal probability ∑_{ψ: ∀j ψ|_{C_j} = ζ_j} p_ψ is the same for all gap-r placements ω of F (whose r-buffers lie in [1..k]).
- Soundness: These constraints are necessary for distributions induced by r-round uniform algorithms in regimes (1a) or (1b). Dropping some equalities yields a relaxation (weaker constraints and thus a larger feasible set); any optimum < 1 for a relaxation implies the true optimum < 1 as well.

3) Monotonicity in segment length
Let q(r,k) denote the LP optimum at parameters (r,k) as above. Then q(r,k+1) ≤ q(r,k). Proof idea: Any feasible distribution on Σ^{k+1} marginalizes to a feasible distribution on Σ^k (equalities on interior placements survive marginalization), and 1{proper on k+1} ≤ 1{proper on first k} pointwise.

4) Why a point mass on a proper coloring violates the constraints
Under the single-core placement-invariance constraints, the distribution of s-blocks (e.g., s ∈ {1,2}) must be identical for all interior positions. A point mass on a single proper ψ has position-dependent s-blocks unless ψ is constant (impossible if ψ is proper). Hence a Dirac mass cannot be feasible—this is a useful solver sanity check.

5) Amplification stride and regimes
- No entanglement (product initial state): independence requires gaps of size 2r (not r). The exponential amplification stride is k + 2r. This is tight in general (see r = 1 path 0–1–2 counterexample).
- With entanglement: constant-error bounds via the LP above are valid if the initial shared state is automorphism-invariant; without that symmetry, the placement-equality constraints need not hold (cf. the counterexample in item 1).

6) Computational plan (r = 2)
- Variables: p_ψ, ψ ∈ Σ^k. For k = 10, |Σ^k| = 59,049; for k = 12, |Σ^k| = 531,441.
- Symmetry/useful reductions: quotient by S_3 (color permutations) and reflection; treat translation of placements via equality constraints.
- Constraints to start with: all single-core families with s ∈ {1,2,3}; then add two-core families (1,1), (2,1), (2,2) at several separations, over all interior placements.
- Certification: if optimum < 1, extract a dual certificate (constraint multipliers) that verifies the bound.
Important correction: geometry-aware interior placement invariance
- The equalities we enforce must respect automorphism classes of placements. Two placements of t cores are guaranteed to have equal core marginals only if they are related by a cycle automorphism (rotation; reflection only if the model is reflection-invariant). Equating placements with different inter-core distances is not justified by light-cone localization plus uniformity.
- Minimal counterexample (r = 0, entangled, rotation-invariant): let ρ0 be the 1/2-mixture of the two perfect matchings of EPR pairs around the cycle. Adjacent vertices have Z-correlations (EPR half the time); vertices at distance 2 are uncorrelated. Thus, two singleton cores at distance 1 vs distance 2 have different joint marginals, defeating geometry-agnostic equality constraints.
- Fix: Parameterize multi-core constraints by geometry (core lengths s = (s1,…,st) and inter-core gaps δ = (δ1,…,δt−1), where δj is the number of vertices between cores j and j+1). Require equality only across translations inside [1..k] (and optionally reflections) for the same (s, δ), with the additional admissibility condition δj ≥ 2r ensuring disjoint r-buffers.

Monotonicity in r (new)
- Let q(r,k) be the (revised, geometry-aware) LP optimum. Then q(r+1,k) ≥ q(r,k). Reason: when r increases, fewer placements are admissible, so fewer equalities are enforced; the feasible region enlarges and the optimum cannot decrease.

Extreme-point structure (new)
- The feasible set is a nonempty polytope in R^{3^k} (uniform distribution is feasible), defined by linear equalities (geometry-aware invariance), nonnegativity, and normalization. Hence an optimal distribution exists and can be taken at an extreme point (basic feasible solution). This supports sparse-support searches and dual-certificate extraction.

Amplification reminders (unchanged)
- No entanglement: independence requires gaps of size 2r, so the exponential stride is k+2r. The r = 1 path 0–1–2 counterexample shows smaller gaps are insufficient.
- With entanglement: constant-error bounds require automorphism-invariant initial states (or an admissible public random rotation to enforce it). Without that symmetry, interior-placement equalities need not hold.

Computation plan (r = 2), updated to geometry-aware constraints
- Variables: p_ψ, ψ ∈ Σ^k. Quotient by S3 color permutations; do not assume reflection unless explicitly imposed.
- Constraints (progressive):
  • Single-core: s ∈ {1,2,3}, equality across all interior translations.
  • Two-core: (s1,s2) ∈ {(1,1),(2,1),(2,2)}, at several admissible separations δ ≥ 2r; enforce equality across translations for each fixed δ.
  • If needed, add t = 3 families similarly.
- Certification: For any q < 1, extract a dual and archive (r,k), the (s,δ) list, the dual vector, and the inequality certifying ∑_ψ p_ψ·1{proper} ≤ q.

Transfer-matrix/Markov cross-check
- Restricting to stationary Markov chains (order d) is a subset of the LP-feasible set; maximizing properness yields a lower bound on q(r,k), useful for catching modeling/solver errors but not a certifying upper bound.

Pitfalls and checks
- Do not equate placements with different δ. Keep separate runs with and without reflection constraints. Validate symmetry reductions on small k against the full (unreduced) LP.
- Ensure all placements counted in constraints have r-buffers fully inside [1..k].
Critical correction: the segment LP (Definition 6) is too weak for two-way
- New fact. For every r ≥ 1 and k ≥ 1, the LP optimum q(r,k) in Definition 6 equals 1. A feasible witness achieving objective 1 is given by the order-1 Markov chain on Σ={1,2,3} with stationary distribution u≡1/3 and transition matrix P with P(i,i)=0 and P(i,j)=1/2 for j≠i. Let p_k be the law of (X_1,…,X_k) with X_1∼u and X_{t+1}|X_t∼P. Then p_k assigns probability 1 to internally proper strings, and because (X_t) is strictly stationary, all core marginals for any fixed geometry (s,δ) are invariant under interior translations, hence all Definition 6 constraints hold. If reflection constraints are included, the chain remains feasible because it is reversible under u.
- Implication. The current LP cannot certify any nontrivial bound q<1 in the two-way model (with or without entanglement). Corollary 10 remains formally valid but is vacuous with this LP (it upper-bounds by 1).

Why the witness satisfies the geometry-aware equalities (minimal checks)
- Single core (t=1). For any s and any interior position i, the s-block (X_i,…,X_{i+s−1}) has the stationary s-block law; translation of i within the window preserves the law.
- Two cores (t=2). For s=(s1,s2) and gap δ≥2r, the joint law of the two blocks depends only on δ (and s1,s2); by strict stationarity, translating the placement within [1..k] does not change this joint law.
- Three cores (t=3). Similarly, for s=(s1,s2,s3) and gaps δ=(δ1,δ2) with δj≥2r, the joint law of the three blocks depends only on the inter-core separations, not on absolute position; interior translations preserve it.

Consequences for modeling and plan (forked)
- Track A (product-state, no entanglement): Independence across regions whose r-neighborhoods are disjoint (>2r separation) must be used. This is nonlinear (factorization). Two practical approaches:
  1) Lifted linear relaxation (Sherali–Adams style): Introduce auxiliary variables for joint marginals on small tuples of cores; enforce linear consistency across overlaps and interior-translation equalities; add necessary linear bounds implied by independence (e.g., Fréchet inequalities for all pairs). This excludes some spurious correlated witnesses (including the Markov chain) and may already force q<1 for small r,k.
  2) Nonlinear exact factorization: Add constraints P(A∩B)=P(A)P(B) for cylinder events A,B supported on disjoint r-buffers. Solve the resulting bilinear system for r=2 and k≤12 using algebraic/MIP methods. Any infeasibility at value 1 yields the desired q(r,k)<1.
- Track B (entanglement allowed): The segment LP cannot help. Pursue ring-level methods: (i) tailor LGR-style experiments for two-way r=2 to derive linear identities that cannot hold simultaneously under properness; (ii) indistinguishability/φ-LOCAL arguments to prove uniform ε(r)>0 constant-error lower bounds for fixed small r. Start at r=2.

Near-term to-dos
- Archive a formal statement and proof that q(r,k)=1 (now added to output.md) to prevent regressions.
- Implement Track A level-1/2 lift and a small exact factorization instance for r=2, k≤12, and test whether q<1 emerges. Extract and store any dual certificates (linear inequalities) obtained.
- Begin a concrete r=2 indistinguishability construction: enumerate r-views on the cycle; design two globally incompatible templates sharing those r-views on a positive fraction of positions; quantify a constant contradiction via averaging.
Addendum: independence-linearization, color symmetry, and corrected chain correlation

1) Pair independence at large separations and its linearization
- In the product-state regime (no shared entanglement), independence across sets whose r-neighborhoods are disjoint (distance > 2r) implies, for single-site cores at positions i and j with |i − j| ≥ 2r + 1:
  P[X_i = a, X_j = b] = P[X_i = a] · P[X_j = b] for all colors a, b.
- This yields, for the equality event:
  P_equal(i, j) := P[X_i = X_j] = ∑_{a∈{1,2,3}} P[X_i = a] P[X_j = a].
- If, in addition, the single-site marginals are uniform, i.e., P[X_u = a] = 1/3 for all a and all interior positions u, then P_equal(i, j) = 1/3. This is the proposed linear identity I1(δ) for δ ≥ 2r + 1.
- Caution (soundness): Enforcing uniform marginals (color symmetry) is harmless for the base LP (geometry-aware placement equalities), but combining it with independence-derived constraints needs justification. A global random color-permutation used only for symmetrization can introduce correlations across far-apart sets (breaking unconditional independence). Therefore, unless we prove that restricting to color-symmetric algorithms is w.l.o.g. even under independence constraints, using I1(δ) as a necessary linear condition is not sound. As a safe alternative, either (i) keep the exact (nonlinear) independence equalities, or (ii) prove the w.l.o.g. color-symmetry claim for the product-state model.

2) Corrected two-point correlation for the stationary “no self-loop” 3-state chain
Let (X_t) be the stationary order-1 Markov chain on {1,2,3} with transition matrix P(i,i) = 0 and P(i,j) = 1/2 for j ≠ i and stationary distribution u ≡ 1/3. Then, for d ≥ 1,
  P[X_t = X_{t+d}] = 1/3 + (2/3) (−1/2)^d.
This follows from the spectral decomposition of P (eigenvalues 1, −1/2, −1/2). In particular, P[X_t = X_{t+1}] = 0 and P[X_t = X_{t+2}] = 1/2. Consequently, for any finite d ≥ 1, this chain violates the identity P_equal(d) = 1/3.

3) Track A (product-state) implementation notes
- Sound feasibility test at objective 1 should include exact (nonlinear) pair independence for δ ∈ {2r+1, 2r+2}, along with placement equalities by geometry. For r = 2 and k ∈ {10, 11, 12}, this should be within reach of a MIP/CP-SAT solver. An infeasibility certificate at value 1 would be decisive.
- If you pursue the linearized I1(δ) route, first prove rigorously that restricting to color-symmetric strategies is w.l.o.g. with independence preserved in the relevant sense (i.e., that the resulting distribution still satisfies the imposed independence equalities). Otherwise, any certificate obtained may not upper-bound the true product-state optimum.

4) Track B (entanglement allowed) clarifications
- r-view equivalence lemma to formalize: If two experiments induce the same distribution over the Heisenberg-evolved effects for the queried event at depth r (as random placements on the cycle), then every r-LOCAL strategy yields equal expectations for the two experiments. Your weight-solving LP should enforce exact equality of the induced multiset of r-view isomorphism types (including gap size if it is part of the view definition).
- Separation on proper colorings must be uniform over all proper colorings (for n beyond some threshold). The parity-oscillation intuition is valid for the stationary chain or the uniform measure over proper colorings, but not for each fixed coloring; e.g., the 2-color alternating pattern has P_equal(d) ∈ {0,1} depending on parity. Therefore, after finding (D1, D2) with equal r-views, compute the minimum separation over all proper colorings (e.g., by transfer-matrix enumeration) and certify a positive gap.

5) Practical next steps
- Product-state: implement the exact pair-independence feasibility test at value 1 for r = 2, k ≤ 12. If infeasible, record the specific contradiction (solver proof log) and the list of constraints used. If feasible, extend δ or add three-core geometry constraints.
- Entanglement allowed: enumerate r = 2 pair-view types up to distance 10–12; solve for two mixtures with equal view distributions; compute the minimum separation over proper colorings and report whether a uniform ε > 0 is achieved.
Stationary single-block MIQCP for r = 2 (product-state, two-way)

- Block length L = 2r + 2 = 6. Alphabet Σ = {1,2,3}. Variables t(ζ) for ζ ∈ Σ^6.
- Linear constraints:
  • Nonnegativity and normalization: t(ζ) ≥ 0; ∑_ζ t(ζ) = 1.
  • Shift-consistency (stationarity of length-5 marginals): For all α ∈ Σ^5, M_1(α) := ∑_{ζ: ζ_1..ζ_5 = α} t(ζ) equals M_2(α) := ∑_{ζ: ζ_2..ζ_6 = α} t(ζ).
  • Perfect properness on interior edges: For j = 1,…,5 and a ∈ Σ, ∑_{ζ: ζ_j = ζ_{j+1} = a} t(ζ) = 0.
- Nonlinear (bilinear) independence at lag 5:
  • m(a) := ∑_{ζ: ζ_1 = a} t(ζ), p(a,b) := ∑_{ζ: ζ_1 = a, ζ_6 = b} t(ζ).
  • Enforce p(a,b) = m(a) m(b) for all a,b ∈ Σ (equivalently, ∑_{ζ: ζ_1=a, ζ_6=b} t(ζ) = (∑_{ζ: ζ_1=a} t(ζ))(∑_{ζ: ζ_1=b} t(ζ))).

Soundness rationale (concise): For a uniform r-round algorithm on a cycle with product initial state (identical local states), the output process is strictly stationary. Independence at separation 2r+1 follows from Theorem 2. If, on a sufficiently long segment, the interior 5 edges of a 6-block are proper with probability 1, then the 6-block marginal t assigns zero to any ζ with ζ_j = ζ_{j+1}. Hence any such algorithm induces t feasible for the MIQCP above. Conversely, any t satisfying the linear equalities is extendable to a stationary order-5 process with 6-block marginal t (Kolmogorov/Markov extension), so infeasibility certifies impossibility of perfect interior properness at r = 2 in the product-state regime.

Escalation knobs (if L = 6 is feasible):
- Enforce lag-6 independence by moving to L = 7 and adding ∑_{ζ: ζ_1=a, ζ_7=b} t(ζ) = (∑_{ζ: ζ_1=a} t(ζ))(∑_{ζ: ζ_1=b} t(ζ)). Both lag-5 and lag-6 are necessary in the product-state model.
- For stronger constraints, eventually consider triple independence (e.g., positions 1,6,11) requiring L = 11.

Numerical plan:
- Solvers: BARON, Couenne/Bonmin, SCIP-NLP. Archive model files and solver logs. If infeasible at L = 6, immediately use amplification (stride k + 2r) to conclude a constant-error bound (see Corollary below in output.md). If feasible, switch to an optimization variant to upper-bound the maximum properness probability (< 1) numerically.

Cautions reiterated:
- Do not impose color symmetry when independence constraints are active; a global color-permutation randomization can destroy unconditional independence across distant sets.
- The Markov-chain witness p_equal(d) = 1/3 + (2/3)(−1/2)^d shows why the base (linear) segment LP is vacuous but is excluded as soon as any lag-5 independence is enforced.

Analytic angle (optional):
- Let S_t = X_{t+1} − X_t (mod 3) ∈ {±1}. Properness forces S_t ∈ {±1} a.s. Independence at lag 5 forces constraints on the distribution of ∑_{j=0}^4 S_{t+j} (mod 3). An explicit contradiction along these lines would bypass computation and is worth exploring in parallel.

=== output.md ===
Main theorems proved in this file
- Light-cone localization and r-non-signaling for r-round LOCAL algorithms (with or without initial entanglement).
- Independence beyond 2r for two-way r-round LOCAL algorithms with product initial states (no shared entanglement).
- Exponential amplification without entanglement given a segment-level bound q(r,k) < 1.
- Automorphism-covariant interior placement invariance within fixed geometry classes.
- Segment LP with geometry-aware interior invariance; structural lemmas: monotonicity in k, monotonicity in r, extreme-point optimality.
- Constant-error bound with entanglement under automorphism invariance.

Preliminaries
Let G = (V, E) be a graph (cycles are of primary interest). An r-round quantum LOCAL algorithm consists of r synchronous layers of local channels acting on vertex/edge registers, followed by local measurements at the vertices that output colors in {1,2,3}. Each round is modeled as a product of CPTP maps localized on vertices/edges (purifiable to local unitaries by Stinespring dilation). For S ⊆ V, let N_r(S) = {v ∈ V : dist(v, S) ≤ r} denote the r-neighborhood of S.

Theorem 1 (Light-cone localization and r-non-signaling)
Fix an r-round quantum LOCAL algorithm. Let S ⊆ V, and let M_S be any POVM element that depends only on the final local measurements in S. Then there exists a positive operator X_S supported only on the registers associated with N_r(S) (and ancillas therein) such that, for every initial global state ρ (possibly entangled), the probability of M_S is Tr[ρ X_S]. Consequently, if two initial states ρ and ρ′ agree on N_r(S), then the output marginal on S is the same under ρ and ρ′.

Proof sketch (standard): Purify to a depth-r circuit of local unitaries. In the Heisenberg picture, conjugating M_S backward through each round enlarges its support by at most one graph hop. After r rounds, the evolved effect X_S is supported on N_r(S). For any ρ, P[M_S] = Tr[ρ X_S]. If ρ and ρ′ coincide on N_r(S), then Tr[ρ X_S] = Tr[ρ′ X_S].

Theorem 2 (Independence beyond 2r without initial entanglement)
Assume the initial state is a product across vertices, ρ = ⊗_{v∈V} ρ_v. Let S_1, …, S_m ⊆ V have pairwise disjoint r-neighborhoods (equivalently, dist(S_i, S_j) > 2r for i ≠ j). For each i, let M_{S_i} be any event depending only on measurements in S_i, and let X_{S_i} be its Heisenberg-evolved effect from Theorem 1. Then the random outcomes on S_1, …, S_m are mutually independent; in particular,
Tr[ρ X_{S_1} ⋯ X_{S_m}] = ∏_{i=1}^m Tr[ρ_{N_r(S_i)} X_{S_i}].

Proof: Each X_{S_i} acts only on N_r(S_i); these supports are disjoint, and ρ factors across them. The trace of the product factors, which is precisely independence.

Corollary 3 (Exponential amplification without entanglement)
Let r ≥ 1. Fix k ≥ 1 and suppose there exists q < 1 such that, for every distribution on a length-k path segment that satisfies the LP constraints in Definition 6 (below), the probability the segment is internally proper is at most q. Then, for any r-round two-way quantum LOCAL algorithm on the n-cycle with product initial state, the success probability satisfies
P_success(C_n) ≤ q^{⌊n / (k + 2r)⌋}.

Proof: Partition the cycle into m = ⌊n / (k + 2r)⌋ disjoint windows of length k separated by gaps of size 2r. If the cycle is proper, each window is internally proper. Let E_i be “window i is internally proper,” and X_i its Heisenberg-evolved effect. Supports N_r(W_i) are disjoint, so E_i are independent by Theorem 2. By the segment-level bound, P[E_i] ≤ q. Hence P_success(C_n) ≤ ∏_i P[E_i] ≤ q^m.

Remark 4 (Necessity of the 2r separation)
For r = 1 on a path 0–1–2, one round suffices for node 1 to correlate nodes 0 and 2 (e.g., by broadcasting a private random bit), so outputs at distance 2 need not be independent. Thus 2r is tight in general.

Lemma 5 (Automorphism-covariant interior placement invariance for fixed geometries)
Fix an r-round uniform quantum LOCAL algorithm on a cycle C_n, with initial global state ρ_0. Let W ⊆ C_n be any contiguous window of length k. Consider t cores with lengths s = (s_1,…,s_t), and let δ = (δ_1,…,δ_{t−1}) be nonnegative integers encoding the inter-core gaps (δ_j is the number of vertices strictly between core j and core j+1). Let ω and ω′ be two r-gapped placements of (s, δ) inside W (i.e., all r-buffers lie in W and δ_j ≥ 2r). Assume ρ_0 is invariant under the rotations of C_n (reflections as well if the model is reflection-invariant). Then, for every core assignment ζ, the probability that the outputs on the cores equal ζ is the same for ω and ω′.

Proof: Let U_ω ⊆ W and U_{ω′} ⊆ W be the unions of the r-neighborhoods of the cores. Because ω and ω′ have the same geometry (s, δ), there exists a rotation (and possibly a reflection) π of C_n mapping U_ω to U_{ω′} and carrying each core in ω to the corresponding core in ω′. By Theorem 1, there exist positive operators X_ω and X_{ω′} supported on U_ω and U_{ω′} giving the core-event probabilities as Tr[ρ_0 X_ω] and Tr[ρ_0 X_{ω′}]. Uniformity implies covariance under π: X_{ω′} = U_π X_ω U_π^†. Since ρ_0 is invariant under π, Tr[ρ_0 X_{ω′}] = Tr[ρ_0 X_ω].

Definition 6 (Segment LP with geometry-aware interior invariance)
Fix Σ = {1,2,3}, r ≥ 1, k ≥ 1. A geometry is a pair (s, δ) with s = (s_1,…,s_t) positive integers and δ = (δ_1,…,δ_{t−1}) nonnegative integers. An r-gapped placement ω of (s, δ) inside [1..k] is a t-tuple of start positions (ω_1 < ⋯ < ω_t) such that each core C_j = [ω_j .. ω_j + s_j − 1] has its r-buffer C_j^{(+r)} = [ω_j − r .. ω_j + s_j − 1 + r] contained in [1..k], these r-buffers are pairwise disjoint, and ω_{j+1} = ω_j + s_j + δ_j. The variables are p_ψ for ψ ∈ Σ^k, with p_ψ ≥ 0 and ∑_ψ p_ψ = 1. The objective is to maximize ∑_ψ p_ψ · 1{ψ has no equal-color adjacencies on edges (i,i+1), i = 1..k−1}. The constraints enforce interior placement invariance within fixed geometries: for every geometry (s, δ), every core assignment ζ, and every two r-gapped placements ω, ω′ of (s, δ) inside [1..k], the marginal ∑_{ψ: ∀j ψ|_{C_j(ω)} = ζ_j} p_ψ equals ∑_{ψ: ∀j ψ|_{C_j(ω′)} = ζ_j} p_ψ. Denote the optimum by q(r,k).

Remark 6.1 (Soundness regimes and symmetry)
These equality constraints are necessary for r-round uniform algorithms under either of the following assumptions: (i) product initial states with identical local marginals (⊗_v ρ; rotation-invariant), or (ii) arbitrary shared entanglement provided the initial global state is invariant under the rotations of the cycle (reflections as well if the model is reflection-invariant). Without such symmetry in the initial state, the constraints need not hold across placements, even within the same window.

Lemma 7 (Monotonicity in k)
For all r ≥ 1 and k ≥ 1, q(r,k+1) ≤ q(r,k).

Proof: Let p be feasible for (r,k+1). Its marginal p′ on the first k coordinates satisfies all geometry-aware invariance constraints for (r,k): any placement inside [1..k] remains a placement inside [1..k+1], and equalities are preserved under marginalization. Moreover 1{proper on k+1} ≤ 1{proper on first k} pointwise, hence ∑_ψ p_ψ·1{proper on k+1} ≤ ∑_{ψ′} p′_{ψ′}·1{proper on k}. Taking suprema over feasible p proves the claim.

Lemma 8 (Monotonicity in r)
For all r ≥ 1 and k ≥ 1, q(r+1,k) ≥ q(r,k).

Proof: As r increases to r+1, the set of admissible placements (and hence the set of equality constraints) for any geometry (s, δ) weakens: some placements cease to be admissible because r-buffers no longer fit or become non-disjoint. Therefore the feasible set enlarges, and the supremum cannot decrease.

Lemma 9 (Extreme-point optimality)
For each fixed (r,k), the feasible region of Definition 6 is a nonempty polytope in R^{3^k} defined by linear equalities, nonnegativity, and normalization. Hence an optimal solution exists and can be taken at an extreme point (basic feasible solution).

Proof: Nonemptiness follows from the uniform distribution p_ψ = 3^{-k}, which satisfies all equality constraints. Boundedness follows from nonnegativity and normalization. Linear programming theory guarantees that a maximum exists and is achieved at an extreme point of the polytope.

Corollary 10 (Constant-error bound with entanglement under automorphism invariance)
Let r ≥ 1 and k ≥ 1, and let q(r,k) be as in Definition 6. Consider any r-round uniform quantum LOCAL algorithm on C_n whose initial global state is invariant under the rotations of the cycle. Then, for all n ≥ k, the success probability obeys P_success(C_n) ≤ q(r,k).

Proof: Fix any contiguous window W ⊆ C_n of length k. If the cycle is properly colored, then W is internally proper. By Lemma 5, the distribution on W (restricted to events supported on geometry-aware r-buffered placements) satisfies the invariance constraints of Definition 6. Therefore it is feasible for the LP, and the probability that W is internally proper is at most q(r,k). Since {cycle proper} ⊆ {W proper}, P_success(C_n) ≤ q(r,k). (Necessity of the symmetry assumption is illustrated by the EPR counterexample in the notes.)
Proposition 11 (Trivialization of the segment LP under Definition 6)
For every r ≥ 1 and k ≥ 1, the optimum q(r,k) in Definition 6 satisfies q(r,k) = 1.

Proof.
Let Σ = {1,2,3}. Consider the order-1 Markov chain (X_t) with stationary distribution u(i) = 1/3 for i∈Σ and transition matrix P with P(i,i)=0 and P(i,j)=1/2 for j≠i. For k ≥ 1, define a distribution p on Σ^k by drawing (X_1,…,X_k) according to X_1 ∼ u and X_{t+1} | X_t ∼ P.

(i) Objective value. Because P(i,i)=0, adjacent colors are never equal: P[X_t = X_{t+1}] = 0 for all t. Therefore p assigns probability 1 to the event “ψ has no equal-color adjacencies on edges (t,t+1), t=1..k−1,” and the objective equals 1.

(ii) Feasibility (geometry-aware interior invariance). Since u is stationary for P, the process (X_t) is strictly stationary. Fix any geometry (s,δ) and two r-gapped placements ω, ω′ of (s,δ) inside [1..k]. Let C(ω) ⊆ {1,…,k} be the ordered list of core indices of ω (similarly C(ω′)). Because ω and ω′ have the same (s,δ), there exists an integer shift τ such that C(ω′) = C(ω) + τ (coordinatewise). Strict stationarity implies that the joint law of (X_i)_{i∈C(ω)} equals the joint law of (X_{i+τ})_{i∈C(ω)} = (X_j)_{j∈C(ω′)}. Hence for every core assignment ζ, the marginal probability that the cores equal ζ is the same for ω and ω′. Nonnegativity and normalization of p are immediate. Thus p is feasible with objective value 1, and so q(r,k) ≥ 1. Since the objective is at most 1 for all feasible p, q(r,k)=1.

Corollary 12 (No segment-LP constant-error bound in two-way under Definition 6)
Under Definition 6, the segment LP cannot certify any nontrivial bound for two-way algorithms: for all r,k we have q(r,k)=1. Consequently, Corollary 10 specializes to the trivial inequality P_success(C_n) ≤ 1 in the entanglement-allowed regime and gives no constant-error lower bound.

Remark 12.1 (Scope). Proposition 11 does not contradict the soundness of the constraints in Definition 6 for actual r-round algorithms under the symmetry assumptions of Remark 6.1; it shows that these constraints alone are insufficient. To obtain nontrivial upper bounds in the product-state regime, independence across sets with disjoint r-neighborhoods (>2r separation) must be incorporated, which is nonlinear (factorization). In the entanglement-allowed regime, no such independence holds, so segment-based linear constraints of this form cannot lead to q<1.
New results appended

Proposition 13 (Pair-equality identity at large separation in the product-state regime)
Assume no initial entanglement (product initial state). Let r ≥ 1, and let i, j be two vertices in a path segment whose r-neighborhoods are disjoint (equivalently, |i − j| ≥ 2r + 1). Then, for any r-round two-way LOCAL algorithm, the equality probability satisfies
  P[X_i = X_j] = ∑_{a∈{1,2,3}} P[X_i = a] · P[X_j = a].
In particular, if the single-site marginals at i and j are uniform (P[X_i = a] = P[X_j = a] = 1/3 for all a), then P[X_i = X_j] = 1/3.

Proof.
By Theorem 2 in this file, the outcomes on {i} and {j} are independent because their r-neighborhoods are disjoint. Hence, for any a, b,
  P[X_i = a, X_j = b] = P[X_i = a] P[X_j = b].
Summing over a = b gives the displayed identity. If the marginals are uniform, the sum is 3 · (1/3) · (1/3) = 1/3.

Lemma 14 (Two-point correlation for the 3-state no-self-loop chain)
Let Σ = {1,2,3}. Consider the stationary order-1 Markov chain (X_t) with stationary distribution u(i) = 1/3 and transition probabilities P(i,i) = 0, P(i,j) = 1/2 for j ≠ i. Then for all integers d ≥ 1,
  P[X_t = X_{t+d}] = 1/3 + (2/3)(−1/2)^d.

Proof.
The transition matrix P has eigenvalues 1 and −1/2 (with multiplicity 2). Diagonalizing P gives, for i ≠ j,
  P^d(i,i) = 1/3 + (2/3)(−1/2)^d,   P^d(i,j) = 1/3 − (1/3)(−1/2)^d.
Under the stationary initial law u, we have
  P[X_t = X_{t+d}] = ∑_{i} u(i) P^d(i,i) = (1/3) · 3 · [1/3 + (2/3)(−1/2)^d] = 1/3 + (2/3)(−1/2)^d.
This equals 0 at d = 1 and tends monotonically to 1/3 in absolute value with rate (1/2)^d.

Corollary 15 (Markov-chain witness violates the pair-equality identity)
For the chain in Lemma 14 and every d ≥ 1,
  P[X_t = X_{t+d}] ≠ 1/3.
Therefore, for any r ≥ 1 and any δ ≥ 2r + 1, the Markov-chain distributions used in Proposition 11 cannot satisfy the pair-equality identity of Proposition 13 at separation δ (in particular, they cannot satisfy the specialized form P_equal = 1/3 under uniform single-site marginals).

Remark.
Proposition 13 provides a sound linear identity (after imposing uniform marginals) that must be satisfied by any product-state strategy at separations ≥ 2r + 1. Lemma 14 certifies that the order-1 Markov-chain witness (which trivializes the base LP) is excluded as soon as these independence-driven identities are enforced.
Proposition 16 (Single-block reduction for product-state outputs, general r)
Fix r ≥ 1 and alphabet Σ = {1,2,3}. Let L := 2r + 2. Consider a uniform r-round LOCAL algorithm on a cycle C_n with product initial state ⊗_{v∈V} ρ (identical local marginals). Let (X_t)_{t∈ℤ/nℤ} be the output colors. Define t ∈ Δ(Σ^L) to be the common distribution of any contiguous L-block (X_i,…,X_{i+L−1}); by rotation invariance this is well defined. Then t satisfies:
(i) Nonnegativity and normalization: t(ζ) ≥ 0 and ∑_ζ t(ζ) = 1.
(ii) Shift-consistency: For all α ∈ Σ^{L−1}, letting M_1(α) = ∑_{ζ: ζ_1..ζ_{L−1}=α} t(ζ) and M_2(α) = ∑_{ζ: ζ_2..ζ_L=α} t(ζ), we have M_1(α) = M_2(α).
(iii) Perfect properness on the L − 1 interior edges, whenever it holds in the algorithm: If the algorithm achieves P[ζ_j ≠ ζ_{j+1} for all j = 1,…,L−1] = 1 on contiguous L-blocks, then t(ζ) = 0 for every ζ with ζ_j = ζ_{j+1} for some j ∈ {1,…,L−1}.
(iv) Lag-(2r+1) pair-independence at the block ends: Let m(a) = ∑_{ζ: ζ_1=a} t(ζ) and p(a,b) = ∑_{ζ: ζ_1=a, ζ_L=b} t(ζ). Then, for all a,b ∈ Σ, p(a,b) = m(a) m(b).

Proof.
- (i) is immediate.
- (ii) Rotation invariance (strict stationarity) of (X_t) implies the (L−1)-block marginals are equal when shifted by one, i.e., M_1(α) = M_2(α).
- (iii) If P[ζ_j ≠ ζ_{j+1} for all j] = 1 on contiguous L-blocks, then for each fixed j, P[ζ_j = ζ_{j+1}] = 0, which means ∑_{ζ: ζ_j = ζ_{j+1}} t(ζ) = 0. Hence t has support only on internally proper words.
- (iv) For any i, the r-neighborhoods of {i} and {i + (2r+1)} are disjoint. By Theorem 2 (independence beyond 2r in the product-state regime), X_i and X_{i + (2r+1)} are independent. Therefore, for all a,b, P[X_i=a, X_{i+(2r+1)}=b] = P[X_i=a] P[X_{i+(2r+1)}=b]. Identifying t’s (1,L) marginal with this pair law (by stationarity) gives p(a,b) = m(a)m(b).

Remark 16.1 (Color symmetry is not w.l.o.g. under independence constraints)
Averaging a feasible strategy by a random global color permutation can destroy unconditional independence across distant sets. Hence one should not impose color-symmetry constraints in models that also enforce independence equalities, unless admissibility is proved separately.

Lemma 17 (Kolmogorov/Markov extension from shift-consistent L-block marginals)
Let L ≥ 2 and Σ finite. Suppose t ∈ Δ(Σ^L) satisfies nonnegativity, normalization, and the shift-consistency equalities M_1(α) = M_2(α) for all α ∈ Σ^{L−1}. Then there exists a strictly stationary process (X_t)_{t∈ℤ} on Σ whose L-block marginal equals t. Moreover, the process can be taken to be a stationary Markov chain of order L−1 on the state space Σ^{L−1}.

Proof.
Define weights on (L−1)-blocks by μ(α) := M_1(α) = M_2(α). For any pair of (L−1)-blocks α,β that overlap on L−2 symbols (i.e., α_2..α_{L−1} = β_1..β_{L−2}), define a transition probability K(α→β) by
  K(α→β) := t(ζ) / μ(α),
where ζ ∈ Σ^L is the unique concatenation with ζ_1..ζ_{L−1} = α, ζ_2..ζ_L = β. If μ(α) = 0, leave K(α→·) arbitrary (those states are transient). Shift-consistency implies ∑_{β} K(α→β) = 1 and stationarity of μ: ∑_{α} μ(α) K(α→β) = μ(β). Hence μ is a stationary distribution for the order-(L−1) Markov chain on Σ^{L−1} with kernel K. Let (Y_t) be this chain at stationarity and set X_t := (Y_t)_{L−1} (the last symbol). One checks directly that (X_t,…,X_{t+L−1}) has law t for every t, yielding a strictly stationary process with the desired L-block marginal.

Corollary 18 (Implication of MIQCP infeasibility for r = 2)
Let r = 2 and L = 6. Consider the MIQCP that seeks t ∈ Δ(Σ^6) satisfying the linear constraints of Proposition 16 (i)–(iii) and the bilinear lag-5 independence equalities (iv). If this MIQCP is infeasible, then no uniform 2-round LOCAL algorithm with product initial state can achieve P[all 5 interior edges of a contiguous 6-block are proper] = 1 on the cycle. Consequently, there exists q < 1 and k ≥ 6 such that the success probability on C_n obeys P_success(C_n) ≤ q^{⌊n/(k+2r)⌋} by Corollary 3 (exponential amplification without entanglement).

Proof.
If an algorithm achieved perfect interior properness with probability 1 on contiguous 6-blocks, Proposition 16 would produce a feasible t, contradicting infeasibility. The amplification claim then follows from Corollary 3 once any finite k and q < 1 are certified (e.g., by optimizing the same constraints or by extending the infeasibility to a slightly larger window that yields an explicit q).



Current round tag: Round 0007 — 2025-08-27T19:01:44.345889Z
Return ONLY valid JSON with a single field:
{ "progress_md": "<your progress notes for this round>" }

Read output.md. If you spot gaps, errors, or missing justifications in output.md, point them out clearly inside progress_md.
