--- SYSTEM ---
You are a strict mathematical verifier & research manager.

You are being run in a loop with provers. Your tasks:
- Audit their ideas for correctness and rigor.
- Curate files (notes.md and output.md).
- Suggest the next steps.

Inputs: 
- task statement
- outputs of provers
- notes.md (summary so far)
- output.md (rigorously proven results so far)

Guidelines:
- notes.md: should be a readable running log of interesting work. Prefer appending. Replace only if old notes are clearly misleading. Remember -- notes should be self-contained and should make sense even without seeing outputs of past provers. 
- output.md:  Think twice before you add something to this file. Everything here should be rigorous, almost publication-ready. It should contain only fully proven theorems that are clearly an interesting step towards the solution (or the solution itself). The beginning of the file is a clear list of interesting theorems you can prove, together with a discussion about why it is relevant. From the statement of the theorem it has to be clear that this constitutes nontrivial progress towards solution. The rest of the file contains a fully rigorous list of the proofs of the theorems. Keep only proven theorems with clear proofs. If a statement in that file is flawed / unprecise and you cannot fix it on the spot, remove it from output.md and instead add it to notes.md with explanation.
- Be careful with the booleans `new_notes_append` and `new_outputs_append`: default is True (append). Use False only when deliberately rewriting everything.

Tasks:
1) Audit rigor: identify unjustified steps, false statements, missing lemmas; produce minimal counterexamples.
2) Triage value: separate genuine progress from noise.
3) Guide next steps: propose what provers should try next.

**Return strictly JSON**:
{
  "feedback_md": "Detailed critique of prover outputs (≥200 words). Include concrete next-step suggestions. The next round of provers may not see last round outputs; ensure all valuable info is stored in notes.",
  "new_notes_md": "Markdown (KaTeX allowed). Usually appended to notes.",
  "new_notes_append": "True|False",
  "new_outputs_md": "Markdown (KaTeX allowed). Usually appended to output.md.",
  "new_outputs_append": "True|False",
  "verdict": "success|partial success|nothing so far"
}

**Verdict definitions**:
- **success**: Something that one could publish, even if it is not the full solution (e.g., significant theorem, key lemma, novel technique, partial solution with clear path forward)
- **partial success**: Something worthy enough to write into output.md (e.g., correct but preliminary results, useful technical lemmas, validated approaches that advance understanding)
- **nothing so far**: No meaningful mathematical progress or only exploratory work


--- USER ---
You receive multiple prover reports. Evaluate correctness, value, and pick promising directions. Update notes.md (append/replace) with useful ideas and update output.md (append/replace) ONLY with rigorously verified results.

Prover reports (JSON):
[{"prover_id": "01", "progress_md": "## Recap of curated results and scope\n- We have a clean per-k bound (Theorem 1 in output.md) via the anchor s(k):=min{s\u2264k: OPT_s \u2264 2\u00b7OPT_k}, translating \u201ceffective oversampling\u201d into the MRS bi-criteria guarantee with a factor-2 slack.\n- We have a per-plateau average bound (Theorem 2) using only the logarithmic branch of MRS and a Stirling inequality, plus a global decomposition across plateaus (Corollary 3).\n\n## Small fixes/clarifications for output.md\n- Monotonicity justification: In Theorem 2\u2019s proof, replacing (s(k),\u0394(k)) by (m,k\u2212m) is valid because the MRS two-branch bound f(s,\u0394):=min{2+1/(2e)+ln(2s/\u0394), 1+s/(e(\u0394\u22121))} is nondecreasing in s and nonincreasing in \u0394 for \u0394\u22652; the log-branch is also nonincreasing in \u0394 for \u0394\u22651. Thus f(s(k),\u0394(k)) \u2264 f(m,k\u2212m). This monotonicity could be stated explicitly for completeness.\n- Endpoint constant: The \u0394=0 contribution can be bounded by C_fix(ln m + 2)/L, so A2 can be set to C_fix and the implicit O(1) made explicit as +2. This may help downstream constant accounting.\n- Range note: On [k0,2k0), any plateau start m\u2265k0 and length L\u22642k0\u2212m\u2264m. This observation is useful when invoking the \u201clarge-\u0394 branch\u201d below: since \u0394\u2264L\u22121\u2264m\u22121, the second branch never yields values below 1+1/e.\n\n## Lemma A (Monotonicity of the MRS bi-criteria bound)\nStatement. Let f(s,\u0394):=min{ 2+1/(2e)+ln(2s/\u0394), 1+s/(e(\u0394\u22121)) } defined for integers s\u22651, \u0394\u22651 (interpret the second term only for \u0394\u22652). Then for fixed s, f is nonincreasing in \u0394; for fixed \u0394\u22652, f is nondecreasing in s.\nWhy useful here. This formally justifies the substitution s(k)\u2264m and \u0394(k)\u2265k\u2212m in Theorem 2.\nSketch. Each branch is coordinate-wise monotone: ln(2s/\u0394) increases in s and decreases in \u0394; s/(e(\u0394\u22121)) increases in s and decreases in \u0394 for \u0394\u22652. The pointwise minimum of functions with the same monotonicity preserves these directions.\n\n## Proposition B (Two-branch per-plateau averaging with a tunable split)\nSetup. On a 2-plateau I=[m,m+L) (L\u22652), for \u0394:=k\u2212m\u2208{1,\u2026,L\u22121}, we have the per-k bound (Theorem 1, with s(k)\u2264m, \u0394(k)\u2265\u0394):\nE_++[ALG_{m+\u0394}/OPT_{m+\u0394}] \u2264 2\u00b7C_bi\u00b7min{ a + ln(2m/\u0394), 1 + m/(e(\u0394\u22121)) }, where a:=2 + 1/(2e).\nFor any integer \u03c4 with 1\u2264\u03c4\u2264L\u22121,\n(1/(L\u22121)) \u03a3_{\u0394=1}^{L\u22121} min{ a + ln(2m/\u0394), 1 + m/(e(\u0394\u22121)) }\n\u2264 a + (\u03c4/(L\u22121))\u00b7ln(2m/\u03c4) + ((L\u22121\u2212\u03c4)/(L\u22121)) + (m/(e(L\u22121)))\u00b7(H_{L\u22122} \u2212 H_{\u03c4\u22121}),\nwhere H_r is the r-th harmonic number, H_0:=0.\nProof idea. Split the sum at \u03c4: for \u0394\u2264\u03c4 use the logarithmic branch and upper bound ln(2m/\u0394) by ln(2m/\u03c4); for \u0394\u2265\u03c4+1 use the 1+m/(e(\u0394\u22121)) branch and sum the 1/(\u0394\u22121)-tail by H_{L\u22122}\u2212H_{\u03c4\u22121}.\n\n- Consequence 1 (recovering Theorem 2): Choosing \u03c4=L\u22121 (where the \u201clarge-\u0394\u201d branch is unused) yields the Stirling-based bound used in Theorem 2: average \u2264 a + 1 + ln(2m/(L\u22121)).\n- Consequence 2 (benefit when L is a constant fraction of m): Since L\u2264m on [k0,2k0), set \u03c4=\u230ac\u00b7L\u230b with c\u2208(0,1) fixed. Then H_{L\u22122}\u2212H_{\u03c4\u22121} \u2264 ln((L\u22121)/(cL\u22121)) + O(1/L) = ln(1/c) + O(1/L). The right-hand side becomes\n  a + c\u00b7ln(2m/(cL)) + (1\u2212c) + (m/(e(L\u22121)))\u00b7(ln(1/c)+o(1)).\n  If L\u2265\u03b1 m (\u03b1\u2208(0,1]), then m/(L\u22121)\u22641/\u03b1 and ln(2m/(cL)) \u2264 ln(2/(c\u03b1)), giving an explicit O(1) bound in terms of \u03b1 (see Corollary C below).\n\n## Corollary C (Explicit constants on long plateaus)\nIf L\u2265\u03b1 m for some \u03b1\u2208(0,1], then for k uniform over I and algorithmic randomness,\nE[ALG_k/OPT_k] \u2264 2\u00b7C_bi\u00b7( a + 1 + ln(2/\u03b1) ) + (C_fix(ln m + 2))/L.\nTaking C_bi=C_fix=5, this simplifies to\nE[ALG_k/OPT_k] \u2264 10\u00b7(3 + 1/(2e) + ln(2/\u03b1)) + 5(ln m + 2)/L.\nIn particular, if \u03b1 is an absolute constant, the plateau-average is an absolute constant (e.g., for \u03b1=1, the leading term is \u2264 10\u00b7(3 + 1/(2e) + ln 2) \u2248 38.8).\nProof. Apply Proposition B with \u03c4=L\u22121 (or any fixed fraction of L) and the observation m/(L\u22121)\u22641/\u03b1, ln(2m/(L\u22121)) \u2264 ln(2/\u03b1) + ln(L/(L\u22121)) \u2264 ln(2/\u03b1) + O(1/L). Add the \u0394=0 endpoint term.\n\n## Corollary D (Quantile-in-\u0394 guarantee on a plateau)\nFix any \u03b7\u2208(0,1). On I=[m,m+L) with L\u22652, for all \u0394\u2265\u03b7(L\u22121), the large-\u0394 branch yields\nE_++[ALG_{m+\u0394}/OPT_{m+\u0394}] \u2264 2\u00b7C_bi\u00b7(1 + m/(e\u00b7\u03b7(L\u22121))).\nTherefore, for at least a (1\u2212\u03b7) fraction of k\u2208I, we have the bound above. If moreover L\u2265\u03b1 m, this becomes \u2264 2\u00b7C_bi\u00b7(1 + 1/(e\u03b1\u03b7)). For C_bi=5 and, say, \u03b7=0.01, \u03b1=1, this gives an explicit 1%\u2011quantile bound \u2264 10\u00b7(1 + 100/e) \u2248 10\u00b7(1 + 36.8) \u2248 378.\nWhy useful. This provides a rigorous \u201cwith probability \u2265 1\u2212\u03b7 over k uniform on the plateau\u201d guarantee using the second branch. It is numerically loose but constant when L is a constant fraction of m.\n\n## Suggested curation items\n- Add Lemma A explicitly to output.md to justify the monotonic substitutions.\n- Add Proposition B (two-branch split) and Corollary C (explicit constants for L\u2265\u03b1 m). These strengthen Theorem 2 in regimes with long plateaus by giving explicit constants that do not grow with k0 (beyond a negligible L^{-1} endpoint term).\n- Optionally add Corollary D (quantile-in-\u0394 within a plateau) as a step toward the \u201cprobability \u2265 0.01\u201d formulation in the task.\n\n## Examples and sanity checks\n- Long dyadic plateau: If OPT halves only once across [k0,2k0), then L\u2248m (\u03b1\u22481). Corollary C gives an O(1) plateau-average; Theorem 2 also gives O(1); Corollary D yields an explicit 1% bound \u2264 ~378 (with C_bi=5), improvable by tightening constants.\n- Short-plateau regime: If all plateaus have L_j=1, Corollary 3 indicates the global average can be \u0398(log k0). Proposition B reverts to the Theorem 2 bound with \u03c4=L\u22121.\n\n## Toward a high-probability \u201cheavy-coverage\u201d lemma (progress)\nGoal. Under strong scale separation (e.g., OPT_{k1} \u2265 k^C\u00b7OPT_k for large C), show that the first k1 steps select one center in each of the k1 heavy optimal clusters without collision with probability \u2265 1\u2212k^{-\u03a9(1)}.\nIncremental step (testable sub-claim). Let H_t be the set of heavy clusters still uncovered at step t\u2264k1, and U_t(heavy) their uncovered cost. Then using Corollary 4.5 of MRS (supermartingale eH_t(P) per cluster) and linearity, we can define eH_t(heavy):=\u03a3_{P\u2208H_t} eH_t(P), which is a supermartingale dominating H_t(heavy). If the total \u201clight\u201d mass satisfies H_t(light)+U_t(light) \u2264 OPT_k \u00b7 polylog k and OPT_{k1} \u2265 k^C\u00b7OPT_k, then for all t\u2264k1,\n  E[ 1 \u2212 U_{t}(heavy)/(U_t(heavy)+H_t(all)) ] \u2264 k^{-\u03a9(1)}.\nInterpretation. The term in brackets is the one-step miss probability within heavy clusters. Summing over t or using a multiplicative Chernoff-type bound for time-inhomogeneous trials suggests a k^{-\u03a9(1)} bound on any miss among heavy clusters. Formalizing this requires quantifying the drift of eH_t(heavy) and the coupling between heavy and light processes; this is the next technical hurdle.\nNext steps: (i) pin down a concrete scale-separation threshold (C) and a light-mass bound that make the miss probability summably small; (ii) formalize a stopping-time argument over the first k1 steps, applying optional stopping to eH_t(heavy) and bounding the cumulative collision probability.\n\n## Next concrete actions\n1) Curate Lemma A (monotonicity) and Proposition B (two-branch plateau averaging) into output.md, with explicit constants (e.g., C_bi=C_fix=5) to yield numerically interpretable bounds (Corollary C and D).\n2) For the \u201c0.01 probability\u201d goal, record Corollary D as a per-plateau quantile bound. Then state a global condition: if at least 1% of k lie in plateaus with L\u2265\u03b1 m, we get an explicit constant bound for those k.\n3) Tighten constants in Corollary C by optimizing the split \u03c4 in Proposition B (solve for \u03c4 minimizing the RHS or pick \u03c4\u2248(m/e)\u2227(L\u22121) to balance branches). Provide a closed-form upper bound using ln and 1/\u03c4 estimates.\n4) Continue the heavy-coverage program: attempt to bound the expected number of heavy-collisions via a martingale or potential argument and convert to a high-probability bound via Freedman/Azuma inequalities adapted to bounded differences in eH_t(heavy).\n5) Optional: instantiate Theorem 2\u2019s constants numerically: A0=10\u00b7(2+1/(2e))\u224821.84, A1=10, A2=C_fix\u22485, replacing O(1) by +2 in the endpoint term, to facilitate downstream aggregation and \u201cback-of-envelope\u201d guarantees.\n"}, {"prover_id": "02", "progress_md": "## Overview and focus of this round\nI concentrate on strengthening the per-plateau averaging step by using both branches of the Makarychev\u2013Reddy\u2013Shan (MRS) bi-criteria bound, and extracting explicit, checkable corollaries for (i) improved plateau-average bounds across regimes, and (ii) \u201cprobability \u2265 0.01\u201d guarantees under a simple structural condition. I also isolate a monotonicity lemma needed implicitly in output.md, and outline a concrete micro-lemma toward the conjectural high-probability \u201cheavy-coverage\u201d statement.\n\n## Small gaps and clarifications in output.md\n- Monotonicity of the MRS bound in (s,\u0394): The proof of Theorem 2 relies on replacing (s(k),\u0394(k)) by (m,\u0394) on a factor-2 plateau. It would help to add a one-line justification: both branches f_A(s,\u0394)=2+1/(2e)+ln(2s/\u0394) and f_B(s,\u0394)=1+s/(e(\u0394\u22121)) are nondecreasing in s and nonincreasing in \u0394 for s\u22651, \u0394\u22651, hence min{f_A,f_B} shares the same monotonicity. Therefore s(k)\u2264m and \u0394(k)\u2265\u0394 imply min{f_A(s(k),\u0394(k)),f_B(s(k),\u0394(k))} \u2264 min{f_A(m,\u0394),f_B(m,\u0394)}.\n- \u0394=1 in the \u201clarge-\u0394\u201d branch: The MRS branch f_B(s,\u0394) is only defined for \u0394\u22652 (since \u0394\u22121 appears in the denominator). When averaging across \u0394\u2208{1,\u2026,L\u22121}, the \u0394=1 term must be taken from f_A. The derivation below handles this explicitly.\n- Constants: Theorem 2\u2019s A0,A1,A2 are stated as absolute constants depending on C_bi,C_fix, which is fine. The refined statements below keep constants explicit and isolate a clean dependence on L and m.\n\n## Refinement: Hybrid plateau averaging using both MRS branches\nSetup: On a factor-2 plateau I=[m,m+L) with L\u22653, for k=m+\u0394 (\u0394\u2208{1,\u2026,L\u22121}), Theorem 1 and monotonicity give\nE_++[ALG_k/OPT_k] \u2264 2\u00b7C_bi \u00b7 min{ 2+1/(2e)+ln(2m/\u0394), 1 + m/(e(\u0394\u22121)) } for \u0394\u22652,\nand for \u0394=1 the RHS is 2\u00b7C_bi\u00b7(2+1/(2e)+ln(2m)). The \u0394=0 endpoint has probability 1/L and contributes \u2264 C_fix(ln m + O(1))/L.\n\nUpper-bounding the average of the min by the min of per-branch averages (plus the \u0394=1 and \u0394=0 adjustments) yields the following explicit bound.\n\nLemma (Hybrid plateau average, L\u22653). For k uniform in I,\nE_{k\u2208I} E_++[ALG_k/OPT_k] \u2264 2\u00b7C_bi\u00b7min{ A\u0304, B\u0304 } + C_fix\u00b7(ln m + O(1))/L,\nwhere\n- A\u0304 = (L\u22121)^{-1} \u03a3_{\u0394=1}^{L\u22121} [ 2 + 1/(2e) + ln(2m/\u0394) ]\n      = 2 + 1/(2e) + ln(2m) \u2212 ln((L\u22121)!)/(L\u22121)\n      \u2264 3 + 1/(2e) + ln(2m/(L\u22121))  (using ln(n!) \u2265 n ln n \u2212 n + 1),\n- B\u0304 = (L\u22121)^{-1} [ (2 + 1/(2e) + ln(2m)) + \u03a3_{\u0394=2}^{L\u22121} (1 + m/(e(\u0394\u22121)) ) ]\n      = 1 + (1/(L\u22121))(2 + 1/(2e) + ln(2m)) + (m/(e(L\u22121)))\u00b7H_{L\u22122}\n      \u2264 1 + (1/(L\u22121))(2 + 1/(2e) + ln(2m)) + (m/(e(L\u22121)))(ln(L\u22122)+1).\nProof idea: For each \u0394\u22652, min{A(\u0394),B(\u0394)} \u2264 B(\u0394); for \u0394=1, use A(1). Average and apply Stirling\u2019s lower bound and H_{q} \u2264 ln q + 1.\n\nClean corollary (two-regime consolidation). There exist absolute constants K0,K1,K2 such that for L\u22653,\nE_{k\u2208I} E_++[ALG_k/OPT_k] \u2264 K0 + K1\u00b7min{ ln^+(2m/(L\u22121)), (m ln L)/L } + K2\u00b7(ln m)/L.\nWhy useful: This improves Theorem 2 by adapting to two regimes. When L\u2248m, the logarithmic branch (first term in the min) gives O(1). When L\u226bm ln L, the \u201clarge-\u0394\u201d branch yields O(1) via (m ln L)/L \u226a1. The extra (ln m)/L is negligible on long plateaus.\n\nCheckable specializations:\n- If L \u2265 m/\u03b1 with any fixed \u03b1>0, the logarithmic branch gives E[ALG/OPT] \u2264 O(1) (recovers Theorem 2\u2019s phenomenon explicitly).\n- If L \u2265 C\u00b7m\u00b7ln L (e.g., L \u2265 C m ln m), then the large-\u0394 branch gives E[ALG/OPT] \u2264 O(1), a complementary regime where oversampling is rare but long ranges make most \u0394 large.\n\n## Quantile (probability) guarantee on a plateau\nFor any threshold T\u2208{2,\u2026,L\u22121}, for all \u0394\u2265T we have the per-instance bound\nE_++[ALG_{m+\u0394}/OPT_{m+\u0394}] \u2264 2\u00b7C_bi\u00b7(1 + m/(e(T\u22121))). Thus, for k uniform on I,\nP_k[ E_++[ALG_k/OPT_k] \u2264 2\u00b7C_bi\u00b7(1 + m/(e(T\u22121))) ] \u2265 (L\u2212T+1)/(L\u22121).\nChoosing T = \u2308c\u00b7m\u2309 with any constant c>0, if L \u2265 (1+\u03b5)\u00b7c\u00b7m then at least an \u03b5/(1+\u03b5) fraction of k in I enjoys a constant expected ratio (\u2264 2\u00b7C_bi\u00b7(1+1/(e c))).\nTurning this into a joint probability (k and seeding): For any plateau with such parameters, by Markov\u2019s inequality,\nP_{k,++}[ ALG_k/OPT_k \u2264 200\u00b7C_bi ] \u2265 (L\u2212T+1)/(L\u22121) \u00b7 0.99.\nIn particular, if a single plateau satisfies L \u2265 101\u00b7m, then with probability at least \u2248 0.98 over k uniform in that plateau (hence \u2265 (L/2k0)\u00b70.98 globally), we get a 200\u00b7C_bi-approximation. This yields a direct \u201c\u22650.01-probability\u201d guarantee whenever that plateau occupies at least \u2248 2% of [k0,2k0).\n\n## Global decomposition with hybrid averaging\nLet I_j=[m_j,m_j+L_j) be the factor-2 plateaus covering [k0,2k0) with lengths L_j. The hybrid bound yields\nE_{k\u223cU([k0,2k0))} E_++[ALG_k/OPT_k]\n\u2264 (1/k0) \u03a3_{j: L_j\u22653} L_j [ K0 + K1\u00b7min{ ln^+(2m_j/(L_j\u22121)), (m_j ln L_j)/L_j } ]\n   + (1/k0) \u03a3_{j: L_j\u22652} K2\u00b7ln m_j + (1/k0) \u03a3_{j: L_j\u2208{1,2}} C_fix\u00b7(ln m_j + O(1)).\nThis strictly strengthens Corollary 3 by allowing the (m_j ln L_j)/L_j regime to kick in when L_j is large relative to m_j.\n\n## Toward a high-probability \u201cheavy coverage\u201d step: a micro-lemma\nLet P_H be k1 optimal clusters (\u201cheavy\u201d), P_L the rest. Suppose \u03a3_{P\u2208P_H} OPT1(P) \u2265 R\u00b7\u03a3_{Q\u2208P_L} OPT1(Q) with R\u2265k^C for a large constant C. Let U_t(H) be uncovered heavy cost at step t, and H_t(*) the covered cost proxy from MRS (Cor. 4.5): E[eH_{t+1}(*) | C_t] \u2264 eH_t(*).\nClaim (expected collision bound, sketch). In the first k1 steps,\nE[# times we sample a point from an already-covered heavy cluster] \u2264 O(1/R) \u00b7 k1.\nIdea: At any t before all heavy clusters are covered, the probability to hit a covered heavy cluster is \u2264 (covered-heavy-cost)/(U_t(H) + rest). By Lemma 4.1 and Cor. 4.5, covered-heavy-cost is at most a 5\u00d7 sum of OPT1 over covered heavy clusters in expectation, while U_t(H) remains a constant fraction of \u03a3_{P\u2208P_H} OPT1(P) until the last few heavy clusters are hit. Summing these probabilities over t yields the O(k1/R) bound. A rigorous proof needs a stopping-time argument that tracks U_t(H) via the supermartingale eH_t and a conditioning on the first time the number of uncovered heavy clusters drops to a given value.\nWhy useful here: This is a concrete, checkable step toward showing that under strong scale separation, k-means++ covers each heavy cluster before collision with high probability, enabling an O(log(1/\u03b5)) tail via bi-criteria on the light remainder.\n\n## Lower-bound direction (status)\nA robust \u03a9(log k0) instance under random-k smoothing likely requires \u0394(k)=1 for a 1\u2212o(1) fraction of k\u2208[k0,2k0). A candidate is a nested family of nearly orthogonal tiny-variance simplices placed at carefully chosen radii so that OPT(k\u22121) \u2248 (1+\u0398(1/ln k0))\u00b7OPT(k) for most k in the range. I propose to formalize a discrete schedule of radii ensuring each additional center yields only a multiplicative \u2248(1\u22121/(c ln k0)) drop in OPT, yielding only microscopic plateaus; verifying this rigorously is the next step for a lower bound.\n\n## Next steps (concrete and verifiable)\n1) Incorporate the Hybrid plateau average lemma into output.md as an explicit theorem, with all constants tracked and a short proof (as above), and add the monotonicity one-liner.\n2) Add a short corollary: On a plateau with L \u2265 c\u00b7m, at least a 1\u22121/c fraction of k achieves E_++[ALG/OPT] \u2264 2\u00b7C_bi\u00b7(1+1/(e c)). Then translate by Markov into a 0.01-probability global statement under a simple mass condition on such plateaus.\n3) Begin formalizing the expected-collision micro-lemma under the scale separation ratio R, with a precise supermartingale/optional stopping argument (using eH_t from MRS). The goal is an explicit bound of the form P[\u2265 one heavy collision] \u2264 R^{\u2212\u03a9(1)}.\n4) Explore the refined global bound numerically on synthetic OPT(\u00b7) profiles to validate the improvement from the (m ln L)/L term and identify worst-case patterns.\n\n## Why this is incremental progress\n- Provides a strictly stronger plateau-average bound using both MRS branches, with explicit constants and steps that are easy to verify.\n- Extracts a practical quantile guarantee (for the \u201c\u22650.01 probability\u201d variant) under a simple plateau-length condition.\n- Identifies and justifies an implicit monotonicity used in output.md.\n- Advances the heavy-coverage program by isolating a concrete expected-collision estimate to be proved next."}]

Current notes.md:
Problem and notation
- X ⊂ R^d finite dataset; cost(C) = ∑_{x∈X} min_{c∈C} ||x−c||^2.
- OPT_k := min_{|C|=k} cost(C), nonincreasing in k.
- ALG_k := cost of k-means++ after k centers; E_++[·] denotes expectation over its randomness.
- We study E_{k∼U({k0,…,2k0−1})} E_++[ ALG_k / OPT_k ].

Key external input (Makarychev–Reddy–Shan 2020)
- There is an absolute constant C_bi (quoted as 5 in MRS) such that for any r≥1, Δ≥1,
  E_++[cost after r+Δ centers] ≤ C_bi · min{ 2 + 1/(2e) + ln(2r/Δ), 1 + r/(e(Δ−1)) } · OPT_r.
- For Δ=0 (fixed-k), there is an absolute constant C_fix (also ≲5 in MRS) with E_++[ALG_k] ≤ C_fix · (ln k + O(1)) · OPT_k.

Per-k oversampling bound (robust to s-misalignment)
- For any k, define s(k) := min{ s∈{1,…,k} : OPT_s ≤ 2·OPT_k }. Let Δ(k)=k−s(k).
- If Δ(k)≥1, then
  E_++[ALG_k] ≤ 2·C_bi · min{ 2 + 1/(2e) + ln(2 s(k)/Δ(k)), 1 + s(k)/(e(Δ(k)−1)) } · OPT_k.
- If Δ(k)=0, fall back to E_++[ALG_k] ≤ C_fix · (ln k + O(1)) · OPT_k.
Note: On any factor-2 plateau I=[m,m+L) (i.e., OPT_k∈(OPT_m/2,OPT_m] for k∈I), we have s(k)≤m and Δ(k)≥k−m; since the MRS bound is monotone in (s,Δ), replacing (s(k),Δ(k)) by (m,k−m) yields a valid upper bound.

Per-plateau averaging and Stirling control
- For a factor-2 plateau I=[m,m+L), L≥2, uniform k over I gives
  E_{k,++}[ALG_k/OPT_k] ≤ 2·C_bi · (2 + 1/(2e) + (1/(L−1))∑_{Δ=1}^{L−1} ln(2m/Δ)) + (C_fix(ln m + O(1)))/L.
- Using ln(n!) ≥ n ln n − n + 1 (n≥1),
  (1/(L−1))∑_{Δ=1}^{L−1} ln(2m/Δ) = ln(2m) − ln((L−1)!)/(L−1) ≤ 1 + ln(2m/(L−1)).
- Hence E_{k,++}[ALG_k/OPT_k] ≤ const + const·ln^+(2m/(L−1)) + O((ln m)/L), where ln^+(x)=max{ln x,0} and all const’s are absolute.

Decomposition over [k0,2k0)
- Partition [k0,2k0) into maximal factor-2 plateaus I_j=[m_j, m_j+L_j). For L_j≥2, the per-plateau average is bounded as above. For L_j=1, the single k in I_j contributes ≤ C_fix(ln m_j + O(1)). Averaging with weights L_j/k0 yields a global bound explicitly in terms of {(m_j,L_j)}; in the worst case many L_j=1 plateaus can force Θ(log k0).

Consequences and regimes
- Long plateaus: If some I=[m,m+L) satisfies L ≥ m/polylog(k0), then E_{k∈I,++}[ALG/OPT] = O(log log k0). If a constant fraction of [k0,2k0) is covered by such plateaus, the global average is O(log log k0).
- Worst case without structure: If many plateaus are short (e.g., L_j=1), the global average can be Θ(log k0), aligning with classic worst-case fixed-k behavior.

Open directions
- Structural conditions on OPT(·) implying many long plateaus (e.g., bounded discrete derivative decay, quasiconvexity/regularity of k·OPT_k) to get unconditional O(log log k0).
- Heavy-coverage lemma (conjectural): under strong scale separation OPT_{k1} ≫ OPT_k, show k-means++ hits all k1 heavy clusters w.h.p. before collisions, then apply bi-criteria on the remaining part.
- Lower bounds: Construct instances with Δ(k)=1 for a 1−o(1) fraction of k in [k0,2k0), giving an Ω(log k0) average and clarifying optimality of random-k smoothing.


Current output.md (if any):
Theorems curated in this file depend on the following standard notation and external input.
- For a finite dataset X⊂R^d, write OPT_k for the optimal k-means cost with k centers, and ALG_k for the cost produced by k-means++ after k centers; E_++[·] is expectation over the algorithm’s randomness.
- External input (Makarychev–Reddy–Shan, 2020): There exists an absolute constant C_bi such that for all integers r≥1 and Δ≥1,
  E_++[cost after r+Δ centers] ≤ C_bi · min{ 2 + 1/(2e) + ln(2r/Δ), 1 + r/(e(Δ−1)) } · OPT_r.
  There is also an absolute constant C_fix with E_++[ALG_k] ≤ C_fix·(ln k + O(1))·OPT_k for all k (the fixed-k bound). We treat C_bi and C_fix as absolute numerical constants.

Theorem 1 (Per-k oversampling bound via a 2-approximate anchor).
Fix k≥1 and define
  s(k) := min{ s∈{1,…,k} : OPT_s ≤ 2·OPT_k },    Δ(k) := k − s(k).
Then:
- If Δ(k) ≥ 1, we have
  E_++[ALG_k] ≤ 2·C_bi · min{ 2 + 1/(2e) + ln(2 s(k)/Δ(k)), 1 + s(k)/(e(Δ(k)−1)) } · OPT_k.
- If Δ(k) = 0, we have E_++[ALG_k] ≤ C_fix·(ln k + O(1))·OPT_k.
Proof.
For Δ(k)≥1, apply the MRS bi-criteria inequality with r = s(k) and Δ = k−s(k):
  E_++[ALG_k] = E_++[cost after s(k)+Δ(k) centers]
  ≤ C_bi · min{ 2 + 1/(2e) + ln(2 s(k)/Δ(k)), 1 + s(k)/(e(Δ(k)−1)) } · OPT_{s(k)}.
By definition of s(k), OPT_{s(k)} ≤ 2·OPT_k, giving the stated bound. For Δ(k)=0 the fixed-k bound yields the second claim. ∎

Theorem 2 (Averaging over a factor-2 plateau).
Let I = {m, m+1, …, m+L−1} with L≥2 and assume OPT_k ∈ (OPT_m/2, OPT_m] for all k∈I. Then for k uniform in I and over the k-means++ randomness,
  E_{k∈I} E_++[ ALG_k / OPT_k ] ≤ A0 + A1 · ln^+( 2m/(L−1) ) + (A2 · ln m)/L,
where ln^+(x) := max{ln x,0} and A0,A1,A2 are absolute constants depending only on C_bi,C_fix.
Proof.
Average the bound from Theorem 1 over k∈I. For Δ:=k−m≥1, we may upper bound s(k) by m and lower bound Δ(k) by Δ (since s(k)≤m and Δ(k)≥Δ on a factor-2 plateau), and use only the logarithmic branch of MRS to get
  E_++[ALG_{m+Δ}/OPT_{m+Δ}] ≤ 2·C_bi · ( 2 + 1/(2e) + ln(2m/Δ) ).
Averaging Δ from 1 to L−1 gives
  (1/(L−1))∑_{Δ=1}^{L−1} ln(2m/Δ) = ln(2m) − ln((L−1)!)/(L−1) ≤ 1 + ln(2m/(L−1)),
where we used ln(n!) ≥ n ln n − n + 1 for n=L−1≥1. Multiplying by (L−1)/L and adding the Δ=0 endpoint contribution C_fix(ln m + O(1))/L yields the claim with suitable absolute constants A0,A1,A2. Replacing ln by ln^+ only weakens the bound. ∎

Corollary 3 (Decomposition across [k0,2k0)).
Partition the integer interval [k0,2k0) into maximal factor-2 plateaus I_j = [m_j, m_j+L_j), j=1,…,J, so OPT_k ∈ (OPT_{m_j}/2, OPT_{m_j}] for k∈I_j, and ∑_j L_j = k0. Then, for k uniform on [k0,2k0),
  E_k E_++[ ALG_k / OPT_k ]
  ≤ (1/k0) ∑_{j : L_j≥2} L_j [ A0 + A1 · ln^+( 2 m_j/(L_j−1) ) ]
    + (1/k0) ∑_{j : L_j≥2} A2 · ln m_j
    + (1/k0) ∑_{j : L_j=1} C_fix · (ln m_j + O(1)).
In particular, if a constant fraction of [k0,2k0) is covered by plateaus satisfying L_j ≥ m_j / polylog(k0), then the contribution of those plateaus is O(log log k0), and the remaining fraction must be controlled separately; in the worst case with many L_j=1 plateaus the global average can be Θ(log k0).
Proof.
Average the bound of Theorem 2 over plateaus with weights L_j/k0, and handle L_j=1 plateaus by the fixed-k bound. ∎

