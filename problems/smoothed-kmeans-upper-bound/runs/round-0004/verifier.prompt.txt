--- SYSTEM ---
You are a strict mathematical verifier & research manager.

You are being run in a loop with provers. Your tasks:
- Audit their ideas for correctness and rigor.
- Curate files (notes.md and output.md).
- Suggest the next steps.

Inputs: 
- task statement
- outputs of provers
- notes.md (summary so far)
- output.md (rigorously proven results so far)

Guidelines:
- notes.md: should be a readable running log of interesting work. Prefer appending. Replace only if old notes are clearly misleading. Remember -- notes should be self-contained and should make sense even without seeing outputs of past provers. 
- output.md:  Think twice before you add something to this file. Everything here should be rigorous, almost publication-ready. It should contain only fully proven theorems that are clearly an interesting step towards the solution (or the solution itself). The beginning of the file is a clear list of interesting theorems you can prove, together with a discussion about why it is relevant. From the statement of the theorem it has to be clear that this constitutes nontrivial progress towards solution. The rest of the file contains a fully rigorous list of the proofs of the theorems. Keep only proven theorems with clear proofs. If a statement in that file is flawed / unprecise and you cannot fix it on the spot, remove it from output.md and instead add it to notes.md with explanation.
- Be careful with the booleans `new_notes_append` and `new_outputs_append`: default is True (append). Use False only when deliberately rewriting everything.

Tasks:
1) Audit rigor: identify unjustified steps, false statements, missing lemmas; produce minimal counterexamples.
2) Triage value: separate genuine progress from noise.
3) Guide next steps: propose what provers should try next.

**Return strictly JSON**:
{
  "feedback_md": "Detailed critique of prover outputs (≥200 words). Include concrete next-step suggestions. The next round of provers may not see last round outputs; ensure all valuable info is stored in notes.",
  "new_notes_md": "Markdown (KaTeX allowed). Usually appended to notes.",
  "new_notes_append": "True|False",
  "new_outputs_md": "Markdown (KaTeX allowed). Usually appended to output.md.",
  "new_outputs_append": "True|False",
  "verdict": "success|partial success|nothing so far"
}

**Verdict definitions**:
- **success**: Something that one could publish, even if it is not the full solution (e.g., significant theorem, key lemma, novel technique, partial solution with clear path forward)
- **partial success**: Something worthy enough to write into output.md (e.g., correct but preliminary results, useful technical lemmas, validated approaches that advance understanding)
- **nothing so far**: No meaningful mathematical progress or only exploratory work


--- USER ---
You receive multiple prover reports. Evaluate correctness, value, and pick promising directions. Update notes.md (append/replace) with useful ideas and update output.md (append/replace) ONLY with rigorously verified results.

Prover reports (JSON):
[{"prover_id": "01", "progress_md": "Overview and audit of output.md\n- The curated file now contains: (i) the per-k anchor bound (Theorem 1), (ii) per-plateau averaging (Theorem 2), (iii) the monotonicity lemma, (iv) a tunable \u03c4-split (Theorem 3), (v) the hybrid extremes (Corollary 4), (vi) long-plateau constants (Corollary 5), (vii) a quantile-in-\u0394 lemma (Corollary 6), (viii) the min-of-extremes bound (Corollary 7), (ix) an upper envelope (Corollary 8), and (x) a plateau-level and globally mixed probability statement (Corollary 9). The remark \u201cL \u2264 m on [k0,2k0)\u201d is present with the correct implication m/(L\u22121) \u2265 1.\n- I see no correctness issues that require retraction. Constants are not yet fully optimized but are kept symbolic, which is fine for now.\n\nNew refinement: an improved \u201cthird branch\u201d via choosing \u03c4 \u2248 m/ln L\nWhy useful here. Corollary 8 gives the envelope K0 + K1\u00b7min{ ln^+(2m/(L\u22121)), (m ln L)/L } + K2\u00b7(ln m)/L. The (m ln L)/L term is sometimes loose. By an explicit choice \u03c4 := \u230am/ln L\u230b in Theorem 3 (when admissible), we can replace (m ln L)/L by (m (1 + ln ln L))/L, which is strictly smaller for L\u2265e^e, tightening intermediate regimes.\n\nStatement (proposed Corollary: \u03c4 = \u230am/ln L\u230b branch).\n- Setting \u03c4* := min{ L\u22121, \u230am/ln L\u230b } in Theorem 3, for L\u22653 and m\u2265L, there exist absolute constants K0,K1,K2 (depending only on C_bi,C_fix) such that\n  E_{k\u2208I} E_++[ALG_k/OPT_k]\n  \u2264 K0 + K1\u00b7(m/L)\u00b7(1 + ln ln L) + K2\u00b7(ln m)/L.\n- In particular, when \u03c4* = \u230am/ln L\u230b \u2264 L\u22121 (i.e., m \u2264 (L\u22121) ln L), one can take\n  E_{k\u2208I} E_++[ALG_k/OPT_k]\n  \u2264 2 C_bi\u00b7[ 1 + (m/((L\u22121) ln L))\u00b7(a+1+ln(4 ln L)) + (m/(e(L\u22121)))\u00b7(1 + ln ln L) ] + (C_fix\u00b7(ln m + 2))/L,\n  with a := 2 + 1/(2e).\n\nProof sketch (fully checkable from Theorem 3).\n- Start from Theorem 3 with general \u03c4. Put \u03c4 := \u230am/ln L\u230b. We use the following bounds for L\u22653 and m\u2265L:\n  1) \u03c4 \u2265 m/ln L \u2212 1 \u21d2 2m/\u03c4 \u2264 4 ln L \u21d2 ln(2m/\u03c4) \u2264 ln(4 ln L).\n  2) \u03c4/(L\u22121) \u2264 (m/ln L)/(L\u22121) \u2264 m/(L ln L).\n  3) H_{L\u22122} \u2212 H_{\u03c4\u22121} \u2264 ln((L\u22122)/(\u03c4\u22121)) + 1 \u2264 ln(L/\u03c4) + 1 \u2264 ln( (L ln L)/m ) + 1 \u2264 1 + ln ln L, since L \u2264 m.\n- Plugging into Theorem 3\u2019s RHS:\n  (\u03c4/(L\u22121))(a + 1 + ln(2m/\u03c4)) \u2264 (m/(L ln L))(a+1+ln(4 ln L));\n  ((L\u22121\u2212\u03c4)/(L\u22121)) \u2264 1;\n  (m/(e(L\u22121)))(H_{L\u22122} \u2212 H_{\u03c4\u22121}) \u2264 (m/(e(L\u22121)))(1 + ln ln L).\n- Add the \u0394=0 endpoint term C_fix(ln m + O(1))/L. Absorb additive constants into K0 and account for L\u22121 \u2248 L (since L\u22653) to get the displayed form.\n- If \u03c4* = L\u22121 (i.e., m > (L\u22121) ln L), we revert to the pure-log branch in Corollary 4.\n\nConsequences and regime comparison\n- Min-of-three envelope. Taken together with Corollary 7, we can use a min of three branches: (i) pure-log: ln^+(2m/(L\u22121)), (ii) hybrid (\u03c4=1): (m ln L)/L, (iii) the new \u03c4=\u230am/ln L\u230b: (m (1 + ln ln L))/L. This uniformly strengthens Corollary 8 by allowing the improved middle regime.\n- Where it helps: When L is moderately large relative to m (e.g., L \u2265 m^\u03b3 with \u03b3\u2208(0,1)), both hybrid branches yield O(1). The improvement is most visible for intermediate L where the previous envelope gave O((m ln L)/L) but ln ln L \u226a ln L, so the new bound is smaller by a factor \u2248 ln L / ln ln L.\n- Checkable example. Let L = m/\u221aln m (so L \u2264 m and L\u22653 for m large). Then\n  \u2022 Pure-log: ln(2m/(L\u22121)) \u2248 ln(2\u221aln m) = O(ln ln m).\n  \u2022 Old hybrid: (m ln L)/L \u2248 (m ln(m/\u221aln m))/(m/\u221aln m) \u2248 \u221aln m \u00b7 (ln m \u2212 (1/2) ln ln m) = \u0398(\u221aln m \u00b7 ln m) [very loose].\n  \u2022 New branch: (m (1 + ln ln L))/L \u2248 \u221aln m \u00b7 (1 + ln(ln m \u2212 (1/2) ln ln m)) = \u0398(\u221aln m \u00b7 ln ln m).\n  Hence min{\u00b7} now picks the O(ln ln m) pure-log branch anyway, but the new branch dramatically tightens the hybrid alternative and will be advantageous in other intermediate regimes (e.g., L = m / polylog m).\n\nGlobal aggregation (plateau-wise min-of-three)\n- Using the decomposition of Corollary 3, we can strengthen Corollary 8 as follows. There exist absolute constants K0,K1,K2 such that for the covering plateaus I_j=[m_j,m_j+L_j),\n  E_{k\u223cU([k0,2k0))} E_++[ALG_k/OPT_k]\n  \u2264 (1/k0) \u2211_j L_j [ K0 + K1\u00b7min{ ln^+(2m_j/(L_j\u22121)), (m_j ln L_j)/L_j, (m_j (1 + ln ln L_j))/L_j } ]\n    + (K2/k0) \u2211_j ln m_j.\n- This follows by taking, for each plateau, the minimum over the three explicit instantiations \u03c4=L\u22121, \u03c4=1, \u03c4=\u230am_j/ln L_j\u230b, and summing with weights L_j/k0.\n\nProbability-\u22650.01 guarantees (clarification)\n- Corollary 9 provides the plateau-level and globally mixed guarantees via (\u03b7,c). A simple instantiation for \u201c\u22650.01 probability\u201d: If a single plateau I occupies a \u03b3\u22650.02 fraction of [k0,2k0) and satisfies L \u2265 \u03b1 m, then choosing \u03b7=0.5 and c=2 gives\n  P[ ALG_k/OPT_k \u2264 2\u00b7B_I ] \u2265 \u03b3\u00b7(0.5\u2212O(1/L))\u00b70.5 \u2265 0.01 for all sufficiently large L,\n  with B_I \u2264 2\u00b7C_bi (1 + 1/(\u03b1 e \u03b7)) + o(1). This is numerically loose but completely explicit. Tuning (\u03b7,c) can improve constants as desired.\n\nSmall technical lemmas and clarifications (ready-to-curate)\n- Stirling floor correction in the \u03c4=\u230am/ln L\u230b branch: Using \u03c4 \u2265 m/ln L \u2212 1 and m \u2265 L \u2265 3, the inequality 2m/\u03c4 \u2264 4 ln L holds (since m/ln L \u2265 L/ln L \u2265 3/ln 3 > 2, hence m/ln L \u2212 1 \u2265 (1/2)\u00b7m/ln L), justifying ln(2m/\u03c4) \u2264 ln(4 ln L) cleanly.\n- Harmonic tail control: H_{L\u22122} \u2212 H_{\u03c4\u22121} \u2264 ln(L/\u03c4) + 1 works uniformly for L\u22653, \u03c4\u22651; with \u03c4=\u230am/ln L\u230b and L \u2264 m, this gives \u2264 1 + ln ln L.\n\nHeavy-coverage program: a precise, checkable sub-lemma (pathwise bound)\n- Pathwise covered-heavy control. For any set H of heavy optimal clusters, define eH_t(P) as in MRS. Then pathwise we have H_t(P) \u2264 eH_t(P) \u2264 5\u00b7OPT1(P) for every heavy P and every t (the first inequality is by definition of eH, the second is Lemma 4.1 applied at first hit). Hence\n  H_t(H_cov) \u2264 5\u00b7\u2211_{P\u2208H} OPT1(P) deterministically for all t.\n- Conditional per-step collision probability bound. At step t conditioned on filtration F_t,\n  P[\u201csample from a covered heavy cluster\u201d | F_t] = H_t(H_cov) / cost_t(X)\n  \u2264 5\u00b7(\u2211_{P\u2208H} OPT1(P)) / cost_t(X).\n- This converts the heavy-collision question into lower bounding cost_t(X) (denominator) by a function of the current uncovered-heavy mass U_t(H) (plus possibly light mass). Under a quantitative \u201cdominance/persistence\u201d hypothesis of the form cost_t(X) \u2265 \u03b2\u00b7U_t(H) for all t before heavy coverage completes (\u03b2\u22651), we immediately get\n  P[collision in heavy at step t | F_t] \u2264 5\u00b7(\u2211_H OPT1(P)) / (\u03b2\u00b7U_t(H)).\n  Summing only over steps in which a heavy pick occurs and using U_t(H) \u2265 \u2211_{P\u2208H_uncovered} OPT1(P), we find that the expected number of heavy collisions before covering all heavy clusters is bounded by a telescoping potential argument akin to a variable-probability coupon collector. This is a concrete, checkable path: it remains to prove the \u03b2-persistence from a scale-separation condition (e.g., OPT_{k1} \u2265 k^C\u00b7OPT_k) via the eH_t supermartingale and to carry out the summation rigorously (I will do this next).\n\nExamples and sanity checks\n- Dyadic plateau (one long plateau): L\u2248m. All three branches give O(1) (pure-log dominates), consistent with Corollary 5.\n- Geometric intermediate L: If L = m / polylog m, then the pure-log branch gives O(log log m); the new \u03c4=\u230am/ln L\u230b branch gives O( (m/L)\u00b7ln ln L ) = O( polylog(m)\u00b7ln ln m ), which is larger; hence the min will pick the pure-log branch, as desired.\n- Short plateaus L=O(1): All hybrid branches devolve to O(m/L), while pure-log gives O(ln m). Min therefore selects O(ln m), matching known worst cases.\n\nGaps and open tasks (clearly identified)\n- output.md currently presents the min-of-two envelope (Corollary 8). The improved \u03c4=\u230am/ln L\u230b branch is not yet recorded; adding it would strengthen the per-plateau bound in some regimes.\n- The heavy-coverage argument remains conditional. The pathwise bound H_t(H_cov) \u2264 5\u2211_H OPT1(P) is now explicit and correct. The key missing piece is to prove a denominator persistence bound cost_t(X) \u2265 \u03b2\u00b7U_t(H) (or a comparable lower bound) from a scale-separation assumption; I will attempt this via the eH_t supermartingale and a careful analysis of how sampling outside H affects U_t(H).\n- Lower bound under random-k smoothing: still open; designing an instance with many short plateaus across the entire window requires careful OPT(\u00b7) control. This remains an item for a separate development.\n\nConcrete next steps (verifiable)\n1) Curate the new \u03c4=\u230am/ln L\u230b corollary into output.md (as a third explicit instantiation of Theorem 3) and add the \u201cmin-of-three\u201d per-plateau envelope and its global aggregation counterpart. All inequalities are elementary and already itemized above.\n2) Provide explicit numerical constants K0,K1,K2 when C_bi=C_fix=5 for the new branch, e.g., K0\u224840, K1\u224810, K2\u22485 (to be checked and tightened in write-up).\n3) For the probability-\u22650.01 variant, add a short remark instantiating Corollary 9 with (\u03b7,c) tuned to hit 1% under a simple plateau mass condition (as outlined above), giving a concrete constant.\n4) Heavy-coverage: formalize \u201c\u03b2-persistence from scale separation\u201d and sum conditional collision probabilities over heavy draws until coverage; aim for an explicit bound on expected heavy collisions (e.g., polynomially small in k under scale separation), then lift to high probability via Freedman\u2013Azuma.\n5) Explore, even empirically, OPT profiles where the new \u03c4=\u230am/ln L\u230b branch strictly improves the previous envelope, to guide any further analytical tightening (e.g., replacing ln(4 ln L) by ln ln(2m) in some ranges).\n"}, {"prover_id": "02", "progress_md": "### Quick audit of output.md (this round)\n- The min-of-extremes bound (Corollary 7) and the derived upper envelope (Corollary 8) look correct and rigorously supported by Theorem 3 and H_q \u2264 ln q + 1. The \u201cplateau length within [k0,2k0)\u201d Remark is now correctly stated with m/(L\u22121) \u2265 1.\n- The probability corollary (Corollary 9) is also correct in its methodology (quantile-in-\u0394 + Markov). It cleanly separates the plateau-level and global mixing statements.\n- Missing but useful: a rigorously stated \u201cbalanced-split\u201d instantiation of Theorem 3 with \u03c4=\u230aL/2\u230b (with safe constants) that can improve constants in some intermediate regimes, and an explicit instantiation of constants in Corollary 8 when C_bi=C_fix=5 to facilitate downstream aggregation.\n\n### New, checkable refinements (to be curated)\n\n1) Balanced-split corollary with safe constants (intermediate regime)\n- Statement (new). In the setting of Theorem 3 with L\u22653 and \u03c4:=\u230aL/2\u230b, for k uniform on I and ++ randomness,\n  E[ALG/OPT] \u2264 2 C_bi [ (2/3)(a + 1 + ln(4m/(L\u22121))) + 1/2 + (m/(e(L\u22121)))(ln 3 + 1) ] + (C_fix(ln m + O(1)))/L,\n  where a=2+1/(2e).\n- Proof sketch (fully checkable): Start from Theorem 3, choose \u03c4=\u230aL/2\u230b. Use the uniform bounds valid for all L\u22653: \u03c4/(L\u22121) \u2264 2/3; (L\u22121\u2212\u03c4)/(L\u22121) \u2264 1/2; H_{L\u22122}\u2212H_{\u03c4\u22121} \u2264 ln 3 + 1; and ln(2m/\u03c4) \u2264 ln(4m/(L\u22121)). Substitute these into Theorem 3 and simplify. This yields a rigorous bound that can outperform both extremes in some midrange regimes (large L but not a fixed fraction of m), at the expense of slightly bigger constants on the logarithmic term.\n- Why useful: Strengthens Corollary 7 by adding a third, explicitly computable candidate bound in the min, sometimes improving over the pure-log extreme when L is moderately large, and over the \u03c4=1 extreme when m/(L\u22121) is not too big.\n\n2) Explicit constants for the upper-envelope (Corollary 8) when C_bi=C_fix=5\n- Claim (explicit instantiation). With C_bi=C_fix=5 and L\u22652,\n  E_{k\u2208I} E_++[ALG/OPT] \u2264 35 + 10\u00b7min{ ln^+(2m/(L\u22121)), (m ln L)/L } + 5\u00b7(ln m)/L.\n- Justification: From Corollary 7, the logarithmic extreme gives 2\u00b7C_bi\u00b7(a+1) \u2264 2\u00b75\u00b7(2+1/(2e)+1) \u2264 32 (more carefully: 10\u00b7(3+1/(2e)) \u2248 31.83), we round up to 35 to absorb O(1/L) terms and endpoint constants. The coefficient in front of ln^+(2m/(L\u22121)) is 2\u00b7C_bi=10. The hybrid extreme contributes a (m ln L)/(e(L\u22121)) term with factor 2\u00b7C_bi/e \u2264 10/e \u2248 3.68; we upper-envelope it by 10 for simplicity, safe since L\u22121\u2248L for L\u22652. The endpoint \u0394=0 term adds \u2264 C_fix(ln m + 2)/L = 5(ln m + 2)/L, which we cover by 5\u00b7(ln m)/L after absorbing constants into the 35. This produces a fully explicit, conservative version of Corollary 8 ready for aggregation.\n- Use: Facilitates clean global inequalities without carrying symbolic constants; helpful when deriving numeric probability thresholds from Corollary 9.\n\n3) Plateau-level 1% guarantee: explicit instantiation\n- From Corollary 9, choosing \u03b7=0.99 and c=100, on a single plateau I=[m,m+L) we get\n  P_{k\u223cU(I),++}[ ALG/OPT \u2264 100\u00b7B_I ] \u2265 (1\u22120.99\u2212O(1/L))\u00b70.99 \u2248 0.01 \u2212 O(1/L),\n  with B_I = 2\u00b7C_bi\u00b7(1 + m/(e(T\u22121))) and T=\u23080.99(L\u22121)\u2309+1. If L \u2265 \u03b1 m, then B_I \u2264 2\u00b7C_bi\u00b7(1 + 1/(\u03b1 e \u00b7 0.99)) \u2264 10\u00b7(1 + 1.02/\u03b1e). For \u03b1=1 and C_bi=5, this gives B_I \u2272 10\u00b7(1+0.376) \u2248 13.76, hence ALG/OPT \u2264 1376 with probability \u2265 1% for k uniform on that plateau. If the plateau occupies a \u03b3-fraction of [k0,2k0), the global (k,++) probability is \u2265 \u03b3 times this quantity.\n- Why useful: A ready-to-use \u201c0.01-probability\u201d bound with explicit constants under the simple condition L \u2265 \u03b1 m on one plateau covering a nonnegligible fraction \u03b3 of the window.\n\n### Special-case heavy-coverage under metric separation (progress toward Subsec. 2)\n- Motivation. The conjectural \u201cheavy coverage\u201d lemma under scale separation is difficult to prove in full generality due to possible reductions of U_t(H) by centers sampled outside heavy clusters. As an incremental step, we formalize and prove a special-case lemma under explicit metric separation, making the dominance/persistence condition verifiable.\n- Setup. Let H be the set of k1 optimal clusters (heavy), and L the rest. For each heavy cluster P\u2208H, let diam2(P):=max_{x\u2208P}||x\u2212\u00b5_P||^2, and impose the separation condition: for some \u03bb\u226510,\n  dist(\u00b5_P, y) \u2265 \u03bb \u00b7 sqrt(diam2(P)) for all P\u2208H and all y\u2209P.\n  This enforces that points outside P are at least \u03bb radii away from its centroid. Let k=k1+k2 and run k-means++ for k\u2032=k1+(1+\u03b5)k2 steps.\n- Lemma (special-case heavy coverage). Under the above separation with \u03bb\u226510,\n  (i) For any step t before covering all k1 heavy clusters, conditioned on the filtration, the probability that the next sample falls in an uncovered heavy cluster is at least 1 \u2212 O(1/\u03bb^2).\n  (ii) Consequently, with probability \u2265 1 \u2212 k1\u00b7O(1/\u03bb^2), k-means++ selects one center in each heavy cluster within the first k1 selections that hit heavy clusters (i.e., before any heavy collision).\n  (iii) Conditioned on (ii), the remaining k\u2032\u2212k1 steps oversample the light part by a factor (1+\u03b5), hence by MRS Theorem 5.1, the final cost is \u2264 5\u00b7O(ln(1/\u03b5))\u00b7OPT_k.\n- Proof sketch (checkable constants): For (i), before covering P\u2208H, every x\u2208P has D(x)^2 \u2265 ||x\u2212\u00b5_P||^2 (no heavy center chosen), while for any y\u2209P, D(y) \u2265 dist(y,\u00b5_P)\u2212||x\u2212\u00b5_P|| \u2265 (\u03bb\u22121)\u00b7sqrt(diam2(P)) by triangle inequality. Summing over all uncovered heavy clusters and using that OPT1(P)=\u2211_{x\u2208P}||x\u2212\u00b5_P||^2, we get that the D^2-mass of uncovered heavy points is at least \u2211_{P\u2208H_uncovered} OPT1(P), while the mass outside these heavy clusters is at most a 1/(\u03bb\u22121)^2 fraction per point relative to diameters; aggregating, the uncovered-heavy mass dominates by a factor 1\u2212O(1/\u03bb^2). Thus the next D^2-sample lands in uncovered heavy with probability \u2265 1 \u2212 O(1/\u03bb^2). Summing the collision probabilities over the k1 heavy hits yields (ii). Part (iii) follows from the bi-criteria bound (MRS Theorem 5.1). A short writeup can fix constants (e.g., replacing O(1/\u03bb^2) by \u2264 5/\u03bb^2) by carefully bounding the total outside mass in terms of \u2211_{P\u2208H} OPT1(P).\n- Why useful: Proves the desired phenomenon (coverage before collisions and O(ln(1/\u03b5)) tail) in a clean geometric regime; provides a stepping stone toward deriving persistence from purely scale-separation conditions.\n\n### Lower-bound direction: toward robustness under random-k smoothing\n- Goal. Construct a dataset X for which \u0394(k)=k\u2212s(k)=1 for a 1\u2212o(1) fraction of k\u2208[k0,2k0), implying that the plateau calculus cannot improve beyond \u0398(log k0) unconditionally.\n- Candidate blueprint (adapting MRS App. C.2):\n  - Use one \u201cheavy\u201d simplex (many points) centered at the origin with extremely small edge length (so OPT1(heavy) \u2248 1 after scaling) and many \u201clight\u201d singleton clusters placed on coordinate axes at radii r_j chosen so that adding a center primarily \u201cunlocks\u201d one light cluster at a time with a small multiplicative drop in OPT.\n  - Calibrate radii r_j so that OPT(k\u22121)/OPT(k)=1+\u0398(1/ln k0) for most k in [k0,2k0), making the OPT sequence nearly flat and ensuring s(k)=k\u22121 typically.\n- Next, compute E_{k,++}[ALG/OPT] over this window using Arthur\u2013Vassilvitskii\u2019s lower-bound technique (the \u201cmisses\u201d process), to target a matching \u03a9(log k0) expectation.\n- Concrete next steps: (i) write the exact OPT_k for this family; (ii) verify the discrete derivative control across the window; (iii) adapt the MRS miss-counting lower bound to average over k.\n\n### Examples and sanity checks\n- Long dyadic plateau: With OPT halving only once on [k0,2k0), L\u2248m. Using the explicit constants above, E_{k\u2208I}E_++[ALG/OPT] \u2264 35 + 10 ln 2 + o(1) \u2248 41.9.\n- Intermediate L (balanced split advantage): Take L=m/\u221aln m. The balanced-split bound gives a term (m/(e(L\u22121)))(ln 3+1) \u2248 O(\u221aln m), whereas the pure-log extreme gives 10 ln(2\u221aln m) = O(ln ln m). In this regime, the logarithmic extreme remains asymptotically better; the \u03c4=\u230aL/2\u230b bound, however, can numerically improve constants when m/(L\u22121) is small but L not a constant fraction of m.\n\n### Obstacles and gaps\n- Unconditional improvement: Without structural constraints on OPT(\u00b7), the plateau calculus still allows \u0398(log k0) worst-case averages (e.g., when all L_j=1). No universal O(log log k0) upper bound is currently proven.\n- Heavy-coverage beyond metric separation: Deriving a persistence bound U_t(H) \u2273 \u03a3_H purely from OPT-scale separation remains open. The special-case lemma addresses geometric separation but not the general case.\n\n### Next steps (actionable)\n1) Add the balanced-split corollary (with \u03c4=\u230aL/2\u230b) and its proof (with safe constants) to output.md; note it as an optional third candidate in the min.\n2) Record the explicit-constants version of Corollary 8 for C_bi=C_fix=5 to support numerical corollaries and global aggregation.\n3) Write a short, fully rigorous proof of the special-case heavy-coverage lemma under metric separation (choose concrete constants, e.g., \u03bb\u226520 to make probabilities crisp), and add it as a separate lemma with an application corollary (O(ln(1/\u03b5)) under oversampling of light part).\n4) Begin formalizing the random-k lower bound: fix a radii schedule {r_j}, prove \u0394(k)=1 for \u2265 0.9k0 values in [k0,2k0), and compute the averaged \u03a9(log k0) lower bound via the miss-counting framework.\n5) Explore whether mild regularity assumptions on OPT(\u00b7) (e.g., lower bounds on plateau lengths at dyadic scales) can be derived from general geometric principles to yield unconditional O(log log k0) bounds via Corollary 8.\n"}]

Current notes.md:
Problem and notation
- X ⊂ R^d finite dataset; cost(C) = ∑_{x∈X} min_{c∈C} ||x−c||^2.
- OPT_k := min_{|C|=k} cost(C), nonincreasing in k.
- ALG_k := cost of k-means++ after k centers; E_++[·] denotes expectation over its randomness.
- We study E_{k∼U({k0,…,2k0−1})} E_++[ ALG_k / OPT_k ].

Key external input (Makarychev–Reddy–Shan 2020)
- There is an absolute constant C_bi (quoted as 5 in MRS) such that for any r≥1, Δ≥1,
  E_++[cost after r+Δ centers] ≤ C_bi · min{ 2 + 1/(2e) + ln(2r/Δ), 1 + r/(e(Δ−1)) } · OPT_r.
- For Δ=0 (fixed-k), there is an absolute constant C_fix (also ≲5 in MRS) with E_++[ALG_k] ≤ C_fix · (ln k + O(1)) · OPT_k.

Per-k oversampling bound (robust to s-misalignment)
- For any k, define s(k) := min{ s∈{1,…,k} : OPT_s ≤ 2·OPT_k }. Let Δ(k)=k−s(k).
- If Δ(k)≥1, then
  E_++[ALG_k] ≤ 2·C_bi · min{ 2 + 1/(2e) + ln(2 s(k)/Δ(k)), 1 + s(k)/(e(Δ(k)−1)) } · OPT_k.
- If Δ(k)=0, fall back to E_++[ALG_k] ≤ C_fix · (ln k + O(1)) · OPT_k.
Note: On any factor-2 plateau I=[m,m+L) (i.e., OPT_k∈(OPT_m/2,OPT_m] for k∈I), we have s(k)≤m and Δ(k)≥k−m; since the MRS bound is monotone in (s,Δ), replacing (s(k),Δ(k)) by (m,k−m) yields a valid upper bound.

Per-plateau averaging and Stirling control
- For a factor-2 plateau I=[m,m+L), L≥2, uniform k over I gives
  E_{k,++}[ALG_k/OPT_k] ≤ 2·C_bi · (2 + 1/(2e) + (1/(L−1))∑_{Δ=1}^{L−1} ln(2m/Δ)) + (C_fix(ln m + O(1)))/L.
- Using ln(n!) ≥ n ln n − n + 1 (n≥1),
  (1/(L−1))∑_{Δ=1}^{L−1} ln(2m/Δ) = ln(2m) − ln((L−1)!)/(L−1) ≤ 1 + ln(2m/(L−1)).
- Hence E_{k,++}[ALG_k/OPT_k] ≤ const + const·ln^+(2m/(L−1)) + O((ln m)/L), where ln^+(x)=max{ln x,0} and all const’s are absolute.

Decomposition over [k0,2k0)
- Partition [k0,2k0) into maximal factor-2 plateaus I_j=[m_j, m_j+L_j). For L_j≥2, the per-plateau average is bounded as above. For L_j=1, the single k in I_j contributes ≤ C_fix(ln m_j + O(1)). Averaging with weights L_j/k0 yields a global bound explicitly in terms of {(m_j,L_j)}; in the worst case many L_j=1 plateaus can force Θ(log k0).

Consequences and regimes
- Long plateaus: If some I=[m,m+L) satisfies L ≥ m/polylog(k0), then E_{k∈I,++}[ALG/OPT] = O(log log k0). If a constant fraction of [k0,2k0) is covered by such plateaus, the global average is O(log log k0).
- Worst case without structure: If many plateaus are short (e.g., L_j=1), the global average can be Θ(log k0), aligning with classic worst-case fixed-k behavior.

Open directions
- Structural conditions on OPT(·) implying many long plateaus (e.g., bounded discrete derivative decay, quasiconvexity/regularity of k·OPT_k) to get unconditional O(log log k0).
- Heavy-coverage lemma (conjectural): under strong scale separation OPT_{k1} ≫ OPT_k, show k-means++ hits all k1 heavy clusters w.h.p. before collisions, then apply bi-criteria on the remaining part.
- Lower bounds: Construct instances with Δ(k)=1 for a 1−o(1) fraction of k in [k0,2k0), giving an Ω(log k0) average and clarifying optimality of random-k smoothing.
Refinements and corrections for plateau averaging and monotonicity

- Monotonicity of the MRS bi-criteria bound. Define for integers s≥1 and Δ≥1 (interpreting the second branch only for Δ≥2):
  f(s,Δ) := min{ a + ln(2s/Δ), 1 + s/(e(Δ−1)) }, where a := 2 + 1/(2e).
  Then f is nondecreasing in s and nonincreasing in Δ. Consequently, on any factor-2 plateau I=[m,m+L) and for k=m+Δ with Δ≥1, the per-k bound from Theorem 1 satisfies
  f(s(k),Δ(k)) ≤ f(m,Δ), so we may safely replace (s(k),Δ(k)) by (m,Δ) in upper bounds.

- Correct τ-split averaging (fixing Proposition B). On a factor-2 plateau I=[m,m+L) with L≥2, for any integer τ∈{1,…,L−1}:
  (1/(L−1)) ∑_{Δ=1}^{L−1} min{ a+ln(2m/Δ), 1 + m/(e(Δ−1)) } (with the second term read only for Δ≥2)
  ≤ (τ/(L−1)) [ a + 1 + ln(2m/τ) ]
    + ((L−1−τ)/(L−1))
    + (m/(e(L−1))) · (H_{L−2} − H_{τ−1}).
  Proof sketch: Split the sum at τ and use Stirling ln(τ!) ≥ τ ln τ − τ + 1 to bound ∑_{Δ≤τ} ln(2m/Δ) ≤ τ(1+ln(2m/τ)). For the tail, sum 1/(Δ−1) as H_{L−2}−H_{τ−1}. This corrects two issues in earlier drafts: (i) the constant a must be multiplied by τ/(L−1), and (ii) ln(2m/Δ) cannot be upper bounded by ln(2m/τ) when Δ≤τ.

- Hybrid extremes recovered from the τ-split:
  • Choosing τ=L−1 gives the pure-logarithmic average a+1+ln(2m/(L−1)).
  • Choosing τ=1 gives the “hybrid extreme” 1 + (a+ln(2m))/(L−1) + (m/(e(L−1))) H_{L−2}.
  Hence we may take the minimum of these two regimes for a tighter bound, plateau by plateau.

- Long-plateau corollary. If L≥α m with α∈(0,1], then a+1+ln(2m/(L−1)) ≤ a+1+ln(2/α)+O(1/L), so the plateau-average is O(1) up to the endpoint term of order (ln m)/L.

- Quantile-in-Δ bound (careful threshold). For any η∈(0,1), let T := max{2, ⌈η(L−1)⌉+1}. Then, for all Δ≥T, by the large-Δ branch
  E_++[ALG_{m+Δ}/OPT_{m+Δ}] ≤ 2·C_bi·(1 + m/(e(T−1))).
  The fraction of k∈I with Δ≥T is (L−T+1)/L = 1 − η − O(1/L). This yields a rigorous “with probability ≥ 1−η−O(1/L) over k uniform on the plateau” expected-ratio bound; Markov then converts it into a constant-factor joint (k,++) probability if desired.

- Global decomposition improvement. Using the τ-split per plateau and optimizing τ as a function of (m,L) leads to a refined global bound that, informally, scales like
  K0 + K1 · min{ ln^+(2m/(L−1)), (m ln L)/L } + K2 · (ln m)/L,
  up to absolute constants K0,K1,K2. Formalizing this from Theorem 3 is a next step.

Open directions and next steps
- Optimize τ in the τ-split bound and write a clean, closed-form per-plateau bound. Then aggregate over plateaus to strengthen Corollary 3.
- Probability guarantees: phrase clean conditions under which at least a 1% measure of k (in [k0,2k0) or on a specific plateau) yields a constant expected ratio, and apply Markov to obtain joint (k,++) probability.
- Heavy-coverage: formalize the supermartingale for heavy uncovered mass (precise citation from MRS), bound expected heavy-collisions by O(k1/R), and lift to high probability via Freedman/Azuma with a stopping time.
- Lower bounds: construct OPT(·) with OPT_{k−1}/OPT_k ≈ 1 − Θ(1/ln k0) for most k to force Δ(k)=1 on a 1−o(1) fraction of the window, yielding an Ω(log k0) average.
Additions and clarifications

- Geometric constraint on plateau length within the window. If a factor-2 plateau I=[m,m+L) is contained in [k0,2k0), then L ≤ 2k0−m ≤ m. In particular, for L≥2 we have m/(L−1) ≥ 1. This prevents sign errors when simplifying expressions involving m/(L−1).

- Min-of-extremes and an upper envelope. From Theorem 3 and Corollary 4 we can (and will) use the minimum of the two extreme instantiations τ=L−1 (pure log) and τ=1 (hybrid extreme). Using H_q ≤ ln q + 1, this yields a clean per-plateau upper envelope of the form
  E_{k∈I} E_++[ALG_k/OPT_k] ≤ K0 + K1 · min{ ln^+(2m/(L−1)), (m ln L)/L } + K2 · (ln m)/L,
for absolute constants K0,K1,K2 depending only on C_bi,C_fix. This is the regime split we will use in global aggregation: the log term dominates when L≪m, while the (m ln L)/L term is O(1) when L is a constant fraction of m.

- Safe balanced-split (τ=⌊L/2⌋) template (optional). The following uniform bounds hold for L≥3 and τ=⌊L/2⌋:
  • τ/(L−1) ≤ 2/3 and (L−1−τ)/(L−1) ≤ 1/2.
  • ln(2m/τ) ≤ ln(4m/(L−1)).
  • H_{L−2} − H_{τ−1} ≤ ln 3 + 1 (with small-L cases checked directly).
Plugging these into Theorem 3 yields the rigorous estimate
  E_{k∈I} E_++[ALG_k/OPT_k]
  ≤ 2C_bi [ (2/3)(a + 1 + ln(4m/(L−1))) + 1/2 + (m/(e(L−1)))(ln 3 + 1) ]
    + (C_fix(\ln m + O(1)))/L.
This improves the (m ln L)/L term to a pure (m/L) term at the expense of a larger coefficient on the logarithmic piece. It may be tighter than the min-of-extremes envelope in intermediate regimes. If used, constants must be kept as above (1/2 is not a safe coefficient for τ/(L−1) when L is even).

- Probability ≥ 1% guarantees under a long-plateau condition. From Corollary 6: fix η∈(0,1) and define T := max{2, ⌈η(L−1)⌉+1}. For at least a (1−η−O(1/L)) fraction of k∈I we have
  E_++[ALG_k/OPT_k] ≤ 2C_bi (1 + m/(e(T−1))).
By Markov, for any c≥1,
  P_{++}[ ALG_k/OPT_k ≤ c · 2C_bi (1 + m/(e(T−1))) ] ≥ 1 − 1/c
for each such k. Therefore, jointly over k uniform on I and ++ randomness,
  P[ ALG_k/OPT_k ≤ c · 2C_bi (1 + m/(e(T−1))) ] ≥ (1−η−O(1/L))(1−1/c).
If L ≥ α m, then m/(T−1) ≤ 1/(α η) up to 1+O(1/L) factors, giving an explicit constant bound. If the plateau covers a γ-fraction of [k0,2k0), the global probability is ≥ γ times the RHS. Example: with C_bi=5, α=1, η=0.99, c=100, we get a ≥1% guarantee with a factor ≤ 100·2·5·(1 + 1/(0.99 e)).

- Heavy-coverage program (caveats and plan). Any per-step “collision within heavy” probability bound must be stated conditionally on the current filtration F_t: under D^2 sampling,
  P[collision in H at step t | F_t] = cost_t(covered H) / cost_t(all).
Avoid ratio-of-expectations. A plausible route is to bound cost_t(covered H) in terms of the uncovered heavy mass U_t(H) via the MRS eH_t supermartingale (in expectation and eventually with concentration), while lower bounding cost_t(all) by U_t(H) + U_t(L). To obtain a β-persistence-type condition from scale separation, quantify the expected reduction of U_t(H) when sampling outside H and show it is o(U_t(H)) under strong separation (e.g., OPT_{k1} ≥ k^C · OPT_k). With these in place, the expected number of heavy collisions can be bounded by summing the conditional probabilities until all heavy clusters are hit, and then lifted to high probability by Freedman/Azuma.

- Lower bounds. To show random-k smoothing cannot beat Θ(log k0) in general, aim for an instance where Δ(k)=1 for a 1−o(1) fraction of k in [k0,2k0). Concretely, calibrate radii so OPT_{k−1}/OPT_k ≈ 1 + Θ(1/ln k0) across most of the window, ensuring s(k)=k−1 on most k. Then adapt Arthur–Vassilvitskii’s lower-bound calculation to the averaged setting.


Current output.md (if any):
Theorems curated in this file depend on the following standard notation and external input.
- For a finite dataset X⊂R^d, write OPT_k for the optimal k-means cost with k centers, and ALG_k for the cost produced by k-means++ after k centers; E_++[·] is expectation over the algorithm’s randomness.
- External input (Makarychev–Reddy–Shan, 2020): There exists an absolute constant C_bi such that for all integers r≥1 and Δ≥1,
  E_++[cost after r+Δ centers] ≤ C_bi · min{ 2 + 1/(2e) + ln(2r/Δ), 1 + r/(e(Δ−1)) } · OPT_r.
  There is also an absolute constant C_fix with E_++[ALG_k] ≤ C_fix·(ln k + O(1))·OPT_k for all k (the fixed-k bound). We treat C_bi and C_fix as absolute numerical constants.

Theorem 1 (Per-k oversampling bound via a 2-approximate anchor).
Fix k≥1 and define
  s(k) := min{ s∈{1,…,k} : OPT_s ≤ 2·OPT_k },    Δ(k) := k − s(k).
Then:
- If Δ(k) ≥ 1, we have
  E_++[ALG_k] ≤ 2·C_bi · min{ 2 + 1/(2e) + ln(2 s(k)/Δ(k)), 1 + s(k)/(e(Δ(k)−1)) } · OPT_k.
- If Δ(k) = 0, we have E_++[ALG_k] ≤ C_fix·(ln k + O(1))·OPT_k.
Proof.
For Δ(k)≥1, apply the MRS bi-criteria inequality with r = s(k) and Δ = k−s(k):
  E_++[ALG_k] = E_++[cost after s(k)+Δ(k) centers]
  ≤ C_bi · min{ 2 + 1/(2e) + ln(2 s(k)/Δ(k)), 1 + s(k)/(e(Δ(k)−1)) } · OPT_{s(k)}.
By definition of s(k), OPT_{s(k)} ≤ 2·OPT_k, giving the stated bound. For Δ(k)=0 the fixed-k bound yields the second claim. ∎

Theorem 2 (Averaging over a factor-2 plateau).
Let I = {m, m+1, …, m+L−1} with L≥2 and assume OPT_k ∈ (OPT_m/2, OPT_m] for all k∈I. Then for k uniform in I and over the k-means++ randomness,
  E_{k∈I} E_++[ ALG_k / OPT_k ] ≤ A0 + A1 · ln^+( 2m/(L−1) ) + (A2 · ln m)/L,
where ln^+(x) := max{ln x,0} and A0,A1,A2 are absolute constants depending only on C_bi,C_fix.
Proof.
Average the bound from Theorem 1 over k∈I. For Δ:=k−m≥1, we may upper bound s(k) by m and lower bound Δ(k) by Δ (since s(k)≤m and Δ(k)≥Δ on a factor-2 plateau), and use only the logarithmic branch of MRS to get
  E_++[ALG_{m+Δ}/OPT_{m+Δ}] ≤ 2·C_bi · ( 2 + 1/(2e) + ln(2m/Δ) ).
Averaging Δ from 1 to L−1 gives
  (1/(L−1))∑_{Δ=1}^{L−1} ln(2m/Δ) = ln(2m) − ln((L−1)!)/(L−1) ≤ 1 + ln(2m/(L−1)),
where we used ln(n!) ≥ n ln n − n + 1 for n=L−1≥1. Multiplying by (L−1)/L and adding the Δ=0 endpoint contribution C_fix(ln m + O(1))/L yields the claim with suitable absolute constants A0,A1,A2. Replacing ln by ln^+ only weakens the bound. ∎

Corollary 3 (Decomposition across [k0,2k0)).
Partition the integer interval [k0,2k0) into maximal factor-2 plateaus I_j = [m_j, m_j+L_j), j=1,…,J, so OPT_k ∈ (OPT_{m_j}/2, OPT_{m_j}] for k∈I_j, and ∑_j L_j = k0. Then, for k uniform on [k0,2k0),
  E_k E_++[ ALG_k / OPT_k ]
  ≤ (1/k0) ∑_{j : L_j≥2} L_j [ A0 + A1 · ln^+( 2 m_j/(L_j−1) ) ]
    + (1/k0) ∑_{j : L_j≥2} A2 · ln m_j
    + (1/k0) ∑_{j : L_j=1} C_fix · (ln m_j + O(1)).
In particular, if a constant fraction of [k0,2k0) is covered by plateaus satisfying L_j ≥ m_j / polylog(k0), then the contribution of those plateaus is O(log log k0), and the remaining fraction must be controlled separately; in the worst case with many L_j=1 plateaus the global average can be Θ(log k0).
Proof.
Average the bound of Theorem 2 over plateaus with weights L_j/k0, and handle L_j=1 plateaus by the fixed-k bound. ∎
Lemma (Monotonicity of the MRS bi-criteria bound).
Let a := 2 + 1/(2e), and for integers s≥1, Δ≥1 define
  F(s,Δ) := min{ a + ln(2s/Δ), 1 + s/(e(Δ−1)) },
where the second term is interpreted only for Δ≥2 (or taken as +∞ for Δ=1). Then:
- For fixed Δ, F is nondecreasing in s.
- For fixed s, F is nonincreasing in Δ (for all Δ≥1 in the above interpretation).
Proof.
For Δ≥2, both functions s ↦ a + ln(2s/Δ) and s ↦ 1 + s/(e(Δ−1)) are nondecreasing in s, hence their pointwise minimum is nondecreasing. For Δ≥2, both functions Δ ↦ a + ln(2s/Δ) and Δ ↦ 1 + s/(e(Δ−1)) are nonincreasing in Δ, hence the minimum is nonincreasing. For the transition from Δ=1 to Δ=2, note that F(s,1) = a + ln(2s) ≥ a + ln(s) ≥ a + ln(2s/2) ≥ F(s,2), since the logarithmic branch decreases with Δ and adding the second branch at Δ=2 can only decrease the minimum. Thus F is nonincreasing in Δ for all Δ≥1. ∎

Theorem 3 (Plateau averaging with a tunable split of the two MRS branches).
Let I = {m, m+1, …, m+L−1} be a factor-2 plateau (i.e., OPT_k ∈ (OPT_m/2, OPT_m] for k∈I) with L≥2. For any integer τ with 1≤τ≤L−1, for k uniform on I and over k-means++ randomness we have
  E_{k∈I} E_++[ ALG_k / OPT_k ]
  ≤ 2·C_bi · [ (τ/(L−1)) · ( a + 1 + ln(2m/τ) )
                + ((L−1−τ)/(L−1))
                + (m/(e(L−1))) · ( H_{L−2} − H_{τ−1} ) ]
    + (C_fix · (ln m + O(1)))/L,
where H_r denotes the r-th harmonic number (H_0:=0).
Proof.
Fix k=m+Δ with Δ∈{1,…,L−1}. By Theorem 1, and Lemma (monotonicity),
  E_++[ALG_{m+Δ}/OPT_{m+Δ}] ≤ 2·C_bi · min{ a + ln(2m/Δ), 1 + m/(e(Δ−1)) },
with the second branch applicable for Δ≥2. Averaging Δ uniformly over {1,…,L−1}, split the sum at τ:
  (1/(L−1)) ∑_{Δ=1}^{L−1} min{…}
  ≤ (1/(L−1)) ∑_{Δ=1}^{τ} [ a + ln(2m/Δ) ]
    + (1/(L−1)) ∑_{Δ=τ+1}^{L−1} [ 1 + m/(e(Δ−1)) ].
For the first sum, use ∑_{Δ=1}^{τ} ln(2m/Δ) = τ ln(2m) − ln(τ!) ≤ τ[1 + ln(2m/τ)] by ln(τ!) ≥ τ ln τ − τ. For the second, ∑_{Δ=τ+1}^{L−1} 1 = L−1−τ and ∑_{Δ=τ+1}^{L−1} 1/(Δ−1) = H_{L−2} − H_{τ−1}. This yields the displayed bound. Finally, incorporate the Δ=0 endpoint k=m which has probability 1/L and contributes at most C_fix·(ln m + O(1))/L by the fixed-k bound. ∎

Corollary 4 (Hybrid extremes recovered; strengthening Theorem 2).
In the setting of Theorem 3:
- Choosing τ = L−1 gives
  E_{k∈I} E_++[ ALG_k / OPT_k ] ≤ 2·C_bi · ( a + 1 + ln(2m/(L−1)) ) + (C_fix · (ln m + O(1)))/L.
  This recovers Theorem 2 (up to constant reparameterization by a and the explicit +1 from Stirling).
- Choosing τ = 1 gives
  E_{k∈I} E_++[ ALG_k / OPT_k ] ≤ 2·C_bi · ( 1 + (a+ln(2m))/(L−1) + (m/(e(L−1))) · H_{L−2} )
    + (C_fix · (ln m + O(1)))/L.
Using H_q ≤ ln q + 1, this yields a complementary regime where the bound scales like 1 + O((ln m)/L) + O((m ln L)/L).
Proof.
Both bounds are immediate from Theorem 3 with the specified τ and the inequality H_q ≤ ln q + 1 for q≥1. ∎

Corollary 5 (Explicit constants on long plateaus).
If L ≥ α m for some fixed α∈(0,1], then for k uniform on I,
  E_{k∈I} E_++[ ALG_k / OPT_k ]
  ≤ 2·C_bi · ( a + 1 + ln(2/α) ) + (C_fix · (ln m + O(1)))/L.
Proof.
Apply Corollary 4 with τ=L−1 and use ln(2m/(L−1)) ≤ ln(2/α) + O(1/L). The endpoint term is unchanged. ∎

Corollary 6 (Quantile-in-Δ guarantee on a plateau).
Fix η∈(0,1) and let T := max{2, ⌈η(L−1)⌉+1}. Then for all Δ∈{T,…,L−1},
  E_++[ ALG_{m+Δ} / OPT_{m+Δ} ] ≤ 2·C_bi · ( 1 + m/( e (T−1) ) ).
Consequently, for k uniform on I, the fraction of k for which the above inequality holds is at least (L−T+1)/L = 1 − η − O(1/L).
Proof.
For Δ≥T, the large-Δ branch gives 1 + m/(e(Δ−1)) ≤ 1 + m/(e(T−1)). Combine with Theorem 1 and monotonicity, and note that the set {k: Δ(k)≥T} has size L−T+1 among the L indices in I. ∎
Remark (Plateau length within [k0,2k0)).
Let I = [m,m+L) be a factor-2 plateau contained in [k0,2k0). Then L ≤ 2k0 − m ≤ m. In particular, for L≥2 we have m/(L−1) ≥ 1.
Proof.
Since m+L−1 ≤ 2k0−1, we have L ≤ 2k0−m. As m ≥ k0, it follows that 2k0−m ≤ m. The final claim is immediate. ∎

Corollary 7 (Min-of-extremes plateau bound).
In the setting of Theorem 3 with L≥2, for k uniform on I and the k-means++ randomness,
  E_{k∈I} E_++[ ALG_k / OPT_k ]
  ≤ min{ B_log, B_hyb } + (C_fix · (ln m + O(1)))/L,
where
  B_log := 2·C_bi · ( a + 1 + ln^+( 2m/(L−1) ) ),
  B_hyb := 2·C_bi · ( 1 + (a+\ln(2m))/(L−1) + (m/(e(L−1))) · H_{L−2} ),
and a := 2 + 1/(2e), H_q denotes the q-th harmonic number with H_0:=0, and ln^+(x):=max{ln x,0}.
Proof.
Take τ=L−1 and τ=1 in Theorem 3 to obtain the two bounds (cf. Corollary 4). Replacing ln by ln^+ only increases the RHS. Taking the minimum preserves validity. ∎

Corollary 8 (Upper envelope from the min-of-extremes).
In the setting of Corollary 7, there exist absolute constants K0,K1,K2 (depending only on C_bi and C_fix) such that
  E_{k∈I} E_++[ ALG_k / OPT_k ]
  ≤ K0 + K1 · min{ ln^+( 2m/(L−1) ), (m ln L)/L } + K2 · (\ln m)/L.
Proof.
From Corollary 7 with the logarithmic extreme,
  E ≤ 2·C_bi·(a+1) + 2·C_bi·ln^+(2m/(L−1)) + (C_fix·(\ln m + O(1)))/L.
From the hybrid extreme and H_{L−2} ≤ ln(L−2)+1 ≤ ln L + 1,
  E ≤ 2·C_bi·\Big( 1 + (a+\ln(2m))/(L−1) + (m/(e(L−1))) (\ln L + 1) \Big)
    + (C_fix·(\ln m + O(1)))/L.
Absorb constants into K0 and the terms (ln m)/(L−1), (m/(L−1)) into K2·(\ln m)/L and K1·(m ln L)/L, respectively, using L−1≈L up to absolute factors for L≥2. Taking the minimum of the two displays yields the claim. ∎

Corollary 9 (Plateau-level probability guarantee via quantiles and Markov; global mixing).
Let I=[m,m+L) be a factor-2 plateau with L≥2 and fix η∈(0,1). Define T := max{2, ⌈η(L−1)⌉+1}. Then for at least a (1−η−O(1/L)) fraction of k∈I we have
  E_++[ ALG_k / OPT_k ] ≤ B_I := 2·C_bi · ( 1 + m/( e (T−1) ) ).
Consequently, for any c≥1,
  P_{k\sim U(I),\,++}\big[ ALG_k/OPT_k ≤ c · B_I \big] ≥ (1−η−O(1/L)) · (1 − 1/c).
If, moreover, L ≥ α m for some α∈(0,1], then B_I ≤ 2·C_bi · (1 + 1/(α e η)) + O(1/L). If a plateau I covers a γ-fraction of [k0,2k0) (i.e., L/k0 ≥ γ), then for k uniform on [k0,2k0) and the ++ randomness,
  P\big[ ALG_k/OPT_k ≤ c · B_I \big] ≥ γ · (1−η−O(1/L)) · (1 − 1/c).
Proof.
The first assertion is Corollary 6: a (1−η−O(1/L)) fraction of k satisfy the displayed per-k bound with Δ≥T, hence with E_++ bounded by B_I. For any such k, Markov’s inequality gives P_{++}[ALG_k/OPT_k ≤ c·B_I] ≥ 1−1/c. Averaging uniformly over k on I yields the claim. If L ≥ α m, then T−1 ≥ η(L−1) ≥ η(α m−1), which implies m/(T−1) ≤ 1/(α η) + O(1/L). The global bound follows by restricting to k in I, which occurs with probability ≥ γ. ∎

