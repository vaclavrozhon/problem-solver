--- SYSTEM ---
You are a research **summarizer**. Summarize this *last round only* for a human log.

Include:
- 3–7 bullet **Highlights** (facts learned, reductions, counterexamples, partial bounds).
- 1–3 **Open questions / TODOs** for the next round.
- 1–3 **Citations to files** you relied on (e.g. round files or papers by name).

**Return strictly JSON**:
{
  "summary_md": "Readable summary of the round (≤200 words)",
  "highlights": [],
  "next_questions": []
}

--- USER ---
=== prover-01.out.json (progress_md) ===
Headlines
- Model identification: each step is a parallel adjacent block transposition, i.e., the class PBT in Jelínek–Opler–Pekárek (arXiv:2311.08727). So we study the PBT-sorting time of the specific input π = bit-reversal on n = 2^d.
- Known bounds from 2311.08727: wstp(PBT; n) = O(log^2 n); lower bound Ω(log n) for any proper class. The tight bound for PBT (and layered L) is explicitly left open; proving Ω(log^2 n) for the bit-reversal input would improve the general lower bound for PBT.
- Proposed potential Φ(A) = Σ_j D_j(A), with D_j(A) := |log_2 B_j(A) − (d − j)|, where B_j(A) is the number of monochromatic runs under coloring by bit j. For the bit-reversal input A_0, Σ_j D_j(A_0) = Θ(d^2) = Θ(log^2 n). Goal: per step drop ΔΦ = O(1).

New rigor (small lemmas), why useful, and proofs/sketches
1) Equivalence to PBT (why useful: aligns our model with the literature and its O(log^2 n) upper bound, and frames the task as a special-case lower bound within their class hierarchy).
- In one step we partition into consecutive intervals and swap disjoint adjacent pairs of intervals in parallel. This is precisely a composition with an element of the class PBT (parallel block transpositions), namely a permutation obtained as a sum of rotations on the interval decomposition. Therefore “our model” = sorting by PBT.

2) Exact values B_j at the endpoints (why useful: calibrates the potential function).
- For n=2^d and the bit-reversal input A_0, B_j(A_0) = 2^{j+1} (j=0,…,d−1). For the fully sorted order A_⋆, B_j(A_⋆) = 2^{d−j}. Thus D_j(A_0) = |(j+1) − (d−j)| = |2j+1−d| and
  Σ_{j=0}^{d−1} D_j(A_0) = Θ(d^2) = Θ(log^2 n).

3) Per-level “additive” change bound via local boundary accounting (why useful: bounds how much B_j can move in one step in terms of which array boundaries are affected).
- Fix j. Let T_j(A) ⊆ {1,…,n−1} be the set of indices i where the j-color changes between positions i and i+1; so |T_j(A)| = B_j(A) − 1.
- One step picks disjoint adjacent interval pairs (L_k, R_k). For each matched pair there are exactly three index positions whose adjacent pair changes: the boundary before L_k, the boundary between L_k and R_k, and the boundary after R_k. All other internal adjacencies remain unchanged.
- Hence the symmetric difference T_j(A) Δ T_j(A′) is contained in the set S_step of indices altered by this step, with |S_step| ≤ 3·(# matched pairs). Consequently, for every j we have |B_j(A′) − B_j(A)| ≤ |T_j(A′) Δ T_j(A)| ≤ 3·(# pairs).
- Remark: this by itself is too coarse for our Ω(log^2 n) goal, because the number of pairs can be Θ(n) in a step. It does, however, isolate that only the 3-per-pair boundary changes can affect B_j.

4) Per-level “useful boundary” refinement (why useful: ties the change in B_j to current j-run structure, not to the raw number of pairs).
Claim 4.1. For fixed j, a matched pair can change B_j only if at least one of its three altered indices is either (i) itself in T_j(A), or (ii) adjacent to a run boundary in the following sense: the altered index shares one of its incident positions with a j-run boundary in A.
- Rationale. If both positions adjacent to an altered index belong to the same j-run and neither end of the index abuts a j-run boundary in A, then the two items at that index (pre- and post-step) both come from the same j-run; in particular they have the same j-color both before and after, so the indicator “i ∈ T_j(·)” cannot flip at that index.
- Consequence. Let U_j(A) be the set of indices that are in T_j(A) or adjacent to an element of T_j(A). Then |U_j(A)| ≤ 3·|T_j(A)| = 3(B_j(A) − 1). The number of indices at which T_j-membership can possibly change in one step is ≤ |U_j(A)|. Therefore
  |B_j(A′) − B_j(A)| ≤ |T_j(A′) Δ T_j(A)| ≤ |U_j(A)| ≤ 3(B_j(A) − 1).
- Corollary 4.2 (per-level constant-factor cap). For any A→A′ in one step and any j,
  B_j(A′) ≤ 4·B_j(A) and B_j(A) ≤ 4·B_j(A′). Equivalently, |log_2 B_j| changes by at most 2 per step.
Proof. From the inequality above, B_j(A′) ≤ B_j(A) + 3(B_j(A) − 1) ≤ 4B_j(A). Apply the same inequality to the inverse step (also a PBT step) to get the reverse inequality.
- Comment. The factor 4 is certainly improvable; I suspect factor 2 holds, but a clean proof that avoids overcounting “double-adjacent” alterations requires a tight charging scheme. Even factor 4 already implies |Δ log_2 B_j| ≤ 2.

5) Alignment scarcity of cut positions across bit-levels (why useful: a quantitative cross-level restriction for the bit-reversal input A_0).
Lemma 5.1 (dyadic alignment bound). For the bit-reversal input A_0, let G_j ⊆ {1,…,n−1} denote the set of j-run boundary indices (so |G_j| = B_j(A_0) − 1 = 2^{j+1} − 1). For any set S of partition cut positions (i.e., indices where we place interval boundaries in a step),
  Σ_{j=0}^{d−1} |S ∩ G_j| = Σ_{i∈S} (1 + v_2(i)) ≤ |S|(1 + ⌊log_2(n−1)⌋).
- Proof. In A_0 the j-run boundaries are the indices i divisible by 2^{d−j−1}. Equivalently, i ∈ G_j iff d−j−1 ≤ v_2(i), where v_2(i) is the 2-adic valuation. Thus for a fixed i, the set {j: i ∈ G_j} has size 1+v_2(i). Summing over S and using v_2(i) ≤ ⌊log_2 i⌋ ≤ ⌊log_2(n−1)⌋ gives the bound.
- Intuition: a single cut index can be simultaneously “useful” for only O(log n) bit-levels; hence even very fine partitions cannot align with all bit-level boundaries at once at linear density.

Small examples and sanity checks
- n=8, A_0 = [0,4,2,6,1,5,3,7]. B_0=2, B_1=4, B_2=8. If we partition into singletons and match (1,2), (3,4), (5,6), (7,8), the three indices that change per matched pair are exactly the three boundaries around each pair; but for j=0 only the central boundary near the 0/1 split can be “useful”. Empirically B_0 cannot jump from 2 to Θ(n) in one step; more generally, the useful-boundary lemma predicts |ΔB_0| ≤ 3(B_0−1) = 3.
- For j = d−1 (MSB) at A_0, B_{d−1} = 2^d = n. Then |ΔB_{d−1}| ≤ 3(n−1) is trivially true; the interesting regime is small j where B_j is small. There, Lemma 4.1 caps the number of useful indices by O(B_j), consistent with the block-coalescence intuition.

Why these are not yet enough for Ω(log^2 n)
- The “per-level constant factor cap” (even with factor 2) alone only yields that each D_j can decrease by O(1) per step; summing over all levels gives ΔΦ = O(d) per step, implying only Ω(d) steps. To reach Ω(d^2) we need to argue that only O(1) levels can enjoy constant-factor progress in the same step (a cross-level scarcity lemma).
- A naive “capacity” counting using Σ_j B_j(A_0) = Θ(n) and the observation that a matched pair of size L influences ≈ L/ℓ_j boundaries at level j (where ℓ_j = 2^{d−j−1} is the j-run length in A_0) suggests that simultaneously reducing B_j by a constant factor across many j is not obviously impossible: Σ_j (L/ℓ_j) = O(L), and Σ_j B_j(A_0) = Θ(n). So simple one-dimensional capacity arguments do not create a missing log factor.
- The alignment lemma (Lemma 5.1) shows a single cut index hits O(log n) levels, but a partition has |S| ≈ n cuts in the extreme, and |S|·log n is still big enough to interact with all levels in principle. So we need a stronger statement than mere counting of aligned cuts; we must quantify how many aligned cuts are actually needed to produce constant-factor changes in B_j and show that a single partition cannot simultaneously supply that demand for many j.

Obstacles and gaps (explicit)
- The factor-2 per-level cap is plausible but not yet proved cleanly; I gave a rigorous factor-4 cap (Corollary 4.2). Improving this constant strengthens the per-level bound but does not yet give Ω(log^2 n).
- The key missing piece is a robust cross-level scarcity theorem. The naive union bound over cuts (Lemma 5.1) is insufficient—the capacity vs. demand calculation doesn’t produce an extra log. We need a structural reason why the same set of disjoint adjacent block swaps cannot simultaneously realize the “good pairings” of runs required for constant-factor reduction at many distinct bit-levels.
- There is no output.md provided; thus far there is no curated, rigorously proved result beyond the baseline Ω(log n). Our Lemma 3–5 fill some pieces but do not yet imply Ω(log^2 n).

Ideas for next steps (testable subgoals)
- Strengthen the per-level cap: Aim to prove B_j(A′) ≤ 2·B_j(A) and B_j(A) ≤ 2·B_j(A′) in one step for every j. Strategy: refine the “useful boundary” charging so that every index whose membership toggles is charged to a unique j-run boundary in A or in A′, and each boundary receives O(1) charge. This would give |Δ log_2 B_j| ≤ 1 per step.
- Quantify “demand” to get constant-factor progress at a fixed j: Formalize that reducing B_j by a factor of 1−ε requires selecting cuts that microscopically pair (most of) adjacent j-runs in an alternating fashion. Prove that such a pairing demands Ω(B_j) central cuts specifically at the j-run boundaries (not just adjacency to them) and also constraints on which of those cuts are matched. This could lift the per-level demand from mere Θ(B_j) “touched indices” to Θ(B_j) “central matched boundaries,” which then interacts more tightly across levels via disjointness of pairs.
- Cross-level conflict via disjointness: For A_0 the sets of j-run boundaries form a family of dyadic arithmetic progressions. Try to show that if you match central boundaries to reduce B_j substantially, those same matched pairs necessarily misalign with the central boundaries needed to reduce B_k for |k−j| large; i.e., central boundaries for different j’s largely do not coincide and cannot all be matched at once due to disjointness of pairs. Precise goal: For any partition+matching M, let C_j(M) be the number of matched central boundaries that lie in G_j. Prove Σ_j C_j(M)/B_j ≤ O(1) (or at least O(log n)). This would imply that only O(1) (or O(log n)) levels can see constant-factor progress in a single step.
- Computational probe (n=16,32): Enumerate partitions+matchings from A_0 (up to symmetries), compute all B_j before/after, and record which levels see ≥2× change. This can guide a conjecture on an absolute bound for the number of such levels per step.
- Alternative potentials: Explore weighted potentials that penalize “simultaneous progress across many j” more severely, e.g., Φ_α(A) = Σ_j α^{|2j+1−d|}·|log_2 B_j(A) − (d−j)| for α>1, and try to prove a per-step drop independent of d. This would hinge on relating the weights to the dyadic structure of G_j.
- Connection to known open problem: If we can show the desired cross-level scarcity for the specific A_0, it already yields Ω(log^2 n) for bit-reversal under PBT and strictly improves the general lower bound for the class. Even a weaker statement like “in any step, at most O(1) levels with |2j+1−d| ≥ c·d see constant-factor progress” would imply a near-Ω(log^2 n) bound.

Summary
- Formalized that our model is exactly PBT.
- Established a clean per-step per-level bound: |ΔB_j| ≤ 3(B_j−1) ⇒ a constant-factor cap B_j′/B_j ≤ 4 (factor likely improvable to 2). This justifies that |Δ log B_j| is O(1) per level per step.
- Proved an “alignment scarcity” lemma (Lemma 5.1) for A_0: a cut position can be aligned with at most O(log n) levels j. This is a building block towards a cross-level scarcity theorem, but by itself not sufficient.
- Identified the main obstacle: converting alignment scarcity and disjointness of matched pairs into a sharp bound on how many levels can make constant-factor progress in the same step.
- Outlined concrete next steps: (i) tighten the per-level cap to factor 2; (ii) quantify per-level demand in terms of central matched boundaries; (iii) prove a cross-level trade-off Σ_j C_j(M)/B_j ≤ O(1); (iv) run small-n experiments to test these phenomena.


=== prover-02.out.json (progress_md) ===
Ideas and setup
- Model recap. One step picks a partition of the array into consecutive intervals and swaps some disjoint adjacent interval-pairs in parallel. This exactly matches one-step permutations in the class PBT (parallel block transpositions) as in Jelínek–Opler–Pekárek (JOP): partition into B1 B2 … B2k (allowing empty blocks formally, but we never need them) and swap each (B2i−1,B2i).
- Significance. JOP show wstp(PBT;n) = O(log^2 n) but only Ω(log n) lower bounds are known. Proving Ω(log^2 n) for bit-reversal in our model would imply Θ(log^2 n) worst-case in PBT and address an open direction (their Problem 8.1 for L and PBT).
- Strategy. Track, for each bit level j, the number B_j(A) of monochromatic runs when elements are colored by bit j. For bit-reversal input A0 (n=2^d): B_j(A0)=2^{j+1}. For the sorted order A⋆: B_j(A⋆)=n/2^j=2^{d−j}. The potential Φ(A)=∑_{j=0}^{d−1} D_j(A) with D_j(A)=|log_2 B_j(A)−log_2 B_j(A⋆)| satisfies Φ(A0)=Θ(d^2) and Φ(A⋆)=0. Goal: per-step drop of Φ is O(1) to force Ω(d^2) steps.

Claim 1 (per-level constant-factor cap)
- Statement. Fix j. In any single step A→A′, the run-count B_j can change by at most a constant multiplicative factor: there exists an absolute c such that B_j(A′) ∈ [B_j(A)/c, c·B_j(A)]. In particular, we can take c=7.
- Why useful here. It prevents a step from massively improving a single level j.
- Proof sketch (rigorous local counting). Let R_j(A) be the set of j-run boundaries (edges between adjacent items where bit j flips), so B_j(A)=|R_j(A)|+1. In a step, only adjacencies at three kinds of edges per swapped pair can change: the left outer boundary, the inner boundary between the two swapped intervals, and the right outer boundary. Hence if m pairs are swapped, at most 3m adjacency edges can change in total. However, only pairs that actually intersect the j-run boundary set can affect B_j: if a pair lies entirely within a single j-monochromatic run, all three affected adjacencies are between same colors, so B_j is unchanged. Let Q_j be the set of swapped pairs whose union intersects R_j(A). By disjointness, each boundary in R_j(A) lies in the union of at most one swapped pair, so |Q_j| ≤ |R_j(A)| = B_j(A)−1. For each such pair, at most O(1) of the three changed adjacencies can flip the “is boundary” status. Therefore |B_j(A′)−B_j(A)| ≤ C·|Q_j| ≤ C(B_j(A)−1) for some absolute C (one can take C=6 by a brute-force case check along the three edges). This implies B_j(A′) ≤ (1+C) B_j(A) and symmetrically B_j(A) ≤ (1+C) B_j(A′), hence the factor cap with c=1+C ≤ 7.
- Sanity check on toy cases. For j=0 with initial 00…011…1, only the unique 0|1 boundary can be in Q_j, hence B_0 can increase or decrease by O(1) in one step, matching the known “merging needs Ω(log n)” folklore.

Edge-to-level charging (a quantitative cross-level accounting tool)
- Setup. Let S be the set of adjacency edges whose status (same-color vs different-color at level j) changes in a step. For a fixed j, the change Δ_j := |B_j(A′)−B_j(A)| is O(|S ∩ E_j|), where E_j is the set of j-run boundary gridlines (the edges periodically spaced by L_j=2^{d−1−j}).
- Observation (valuation count). For an edge position e∈{1,…,n−1}, define ν_2(e) as the exponent of the highest power of 2 dividing e. The edge e belongs to E_j if and only if L_j divides e, i.e., j ≤ d−1−ν_2(e). Thus the number of levels j at which e is a j-grid boundary equals ν_2(e)+1. The harmonic identity ∑_{e=1}^{n−1} (ν_2(e)+1) = Θ(n) implies that “on average” an edge participates in O(1) levels.
- Consequence (weighted bound). For any nonnegative weights w_j, we have ∑_j w_j·Δ_j ≤ C·∑_{e∈S} ∑_{j: e∈E_j} w_j. Choosing w_j = 2^{−(j+1)} gives ∑_j 2^{−(j+1)}·Δ_j ≤ C′·|S| because ∑_{j: e∈E_j} 2^{−(j+1)} ≤ 1 for every e. More generally, for w_j = 2^{−(j+1)}/(j+1) we get ∑_j w_j·Δ_j ≤ C′′·|S| (up to an extra O(log log n) factor if one tightens constants). These bounds are robust and will be useful for potentials that weight levels by 2^{−j} (or slightly heavier penalties near extremes).
- Why useful here. This provides a cross-level scarcity principle: many changed adjacencies cannot produce “large” relative progress on many levels simultaneously, once progress is normalized appropriately by the density of j-boundaries.

Scale-sensitive refinement via pair sizes
- Additional structure. Let each swapped pair p consist of two adjacent intervals of total length s(p). At level j, every j-run has length L_j=2^{d−1−j}. One pair p can affect at most O(min{1, s(p)/L_j}) distinct j-boundaries: the three adjacency changes are confined to O(1) blocks of length s(p), which intersect O(s(p)/L_j) of the L_j-spaced grid edges.
- Lemma (deterministic). For all j, Δ_j ≤ C·∑_{p} min{1, s(p)/L_j}. Consequently, using B_j(A0)=2^{j+1} and L_j=2^{d−1−j}, we get for the bit-reversal input A0: Δ_j / B_j(A0) ≤ (C/n)·∑_{p} min{s(p), L_j}.
- Summing in j and swapping sums yields: ∑_j Δ_j / B_j(A0) ≤ (C/n)·∑_{p} ∑_{t=0}^{d−1} min{s(p), 2^t} = (C/n)·∑_{p} O(s(p)·log(1+s(p))). Since ∑_{p} s(p) ≤ n in every step, the RHS is O(log n) per step. This recovers an Ω(log n) lower bound by a “fractional progress” argument and quantifies that a step cannot make constant-fraction progress on many levels at once unless it spends large total size in pairs.
- Why useful here. This pins down quantitatively how pair sizes limit multi-level progress. It suggests going beyond additive counting toward scale-weighted potentials.

Toward an Ω(log^2 n) (or near) bound: a proposed program
- Lemma 1 is now clean and rigorous. The remaining challenge is a cross-level bound strong enough to cap the drop of Φ(A)=∑_j |log B_j(A)−log B_j(A⋆)| by O(1) per step. The above tools give only O(log n) so far, recovering Ω(log n).
- Heuristic strengthening. To achieve a constant-factor change in B_j, one needs Θ(B_j) changed adjacencies at level j (since each changes B_j by O(1)). By the “size lemma” above, generating Θ(B_j) changes at level j requires ∑_{p} min{1, s(p)/L_j} = Ω(1), i.e., the total s(p) across pairs must be Ω(L_j). Doing this for T different levels j in one step requires Ω(∑_{t=1}^T L_{j_t}) total size budget, but ∑_{p} s(p) ≤ n. For the dyadic sequence L_j=2^{d−1−j}, the sum over a set of T distinct levels is at least ≈ 2^{d−T} if clustered, but if spread out evenly across O(d) levels, ∑ L_j ≈ Θ(n). This suggests that making constant-factor progress on ω(1) distinct levels at once quickly exhausts the size budget, hinting that only O(1) levels can enjoy a constant-factor change per step (a formal version of speculative Lemma 2).
- Formal target (to prove next). There exists an absolute c>0 such that in any step, the set J of levels j for which B_j changes by a factor ≥2 satisfies |J| ≤ c. Outline approach: assign to each pair p a unique “home level” h(p) so that (i) p can contribute at most O(1) to constant-factor progress for levels ̸= h(p), and (ii) the sum of s(p)/L_{h(p)} over all p is O(1). A natural home level is the unique j with L_j ∈ [s(p)/2, 2 s(p)]. Packing disjoint pairs implies ∑ s(p) ≤ n, hence ∑ s(p)/L_{h(p)} ≤ O(1). Use the size lemma to argue that constant-factor progress at level j requires total contribution Ω(1) from pairs with h(p)=j. Thus at most O(1) such levels exist per step.
- If established, combining with the per-level factor cap (Lemma 1) implies that Φ can decrease by at most O(1) per step: each of the O(1) “active” levels can shrink |log B_j − log B_j⋆| by O(1), all other levels shrink by at most a constant fraction of a fraction, summing to O(1) overall. This would yield the desired Ω(log^2 n) lower bound.

Toy special case (to aim for as an intermediate milestone)
- Restricted steps: equal-scale partitions. Suppose every step uses a partition into intervals whose lengths are within a factor 2 of a common L (and swaps a matching on these). Then: a pair has size s≈L. The size lemma gives Δ_j ≤ C·m·min{1, L/L_j}. Since m≤n/L, we have Δ_j ≤ C·(n/L)·min{1, L/L_j} ≤ C·min{n/L, n/L_j}. For j with L_j ≪ L, Δ_j ≤ C·(n/L_j), a tiny fraction of B_j(A0)=2^{j+1} unless L≈L_j. For j with L_j≈L, Δ_j ≤ C·(n/L) gives at best constant-fraction progress. Only O(1) neighboring j have L_j within factor 2 of L. Hence per step, only O(1) levels can change by a constant factor. This toy case supports Lemma 2 in a simplified setting and could be made rigorous.

Small examples and checks
- n=8 (d=3), A0=[0,4,2,6,1,5,3,7]. Compute B_j(A0)=(2,4,8) for j=0,1,2; B_j(A⋆)=(8,4,2). Any step alters at most three adjacencies per pair; a pair not intersecting the unique B_0 boundary is irrelevant to B_0; at most one pair is relevant, so B_0 changes by O(1) factor. For B_1, the four boundaries are at positions multiples of 2; disjointness similarly limits pairs that can affect many of them at once unless s(p)≈2. This matches the scale-sensitive picture.

Connections to literature (JOP and gaps)
- Our model coincides (one-step-wise) with PBT. JOP prove O(log^2 n) upper bounds (also for L), and Ω(log n) lower bounds in general via counting. They leave open closing the gap to Ω(log^2 n). Our Lemma 1 aligns with their “boundary locality” arguments; the key remaining step is Lemma 2 (cross-level scarcity). The size-based accounting we developed above is a promising path; formalizing the “home level” charging to show only O(1) levels can change by factor ≥2 per step would settle the lower bound.

Next steps (concrete, testable)
1) Formalize and prove the size lemma: Δ_j ≤ C·∑_p min{1, s(p)/L_j}, including an exact constant C and a careful accounting of the three changed adjacencies per pair. This is local and checkable.
2) Prove Lemma 1 rigorously with an explicit constant c (I gave c=7 via a union bound; tightening to c=3 or c=5 is likely with a refined boundary case analysis). Write the proof cleanly so the verifier can include it in output.md.
3) Prove the toy special-case Lemma 2 for equal-scale partitions, giving an Ω(log^2 n) lower bound for that restricted algorithm class. This creates a baseline “special case” lower bound.
4) Develop the “home level” charging in full generality: for each pair p, define h(p) with L_{h(p)}≈s(p). Show that to achieve a factor-2 change at level j, the sum over p with h(p)=j of min{1, s(p)/L_j} must be Ω(1). Since ∑_p s(p)/L_{h(p)} ≤ O(1), only O(1) levels can have such progress.
5) If step 4 succeeds, deduce per-step Φ drop ≤ O(1) (each active level reduces D_j by O(1); inactive ones by at most a small fraction), hence Ω(log^2 n).
6) Computational aid on small n (n=16,32): enumerate random partitions and measure how many levels j see a ≥2× change in B_j in a single step; record empirical maximum; this can guide constants and refine the “active level” definition.

Gaps or issues in current outputs
- There is no output.md provided; hence no prior rigorous lemmas to cross-check. The present round delivers Lemma 1 in a form ready to be curated and a precise statement of the “size lemma” with a clear proof plan. The main open gap remains the core cross-level scarcity (Lemma 2), for which I outlined two routes: the equal-scale special case (feasible) and the general “home level” charging (harder but promising).


=== Verifier (summary_md) ===

=== Verifier (verdict) ===
success

