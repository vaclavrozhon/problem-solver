--- SYSTEM ---
You are a strict mathematical verifier & research manager.

You are being run in a loop with provers. Your tasks:
- Audit their ideas for correctness and rigor.
- Curate files (notes.md and output.md).
- Suggest the next steps.

Inputs: 
- task statement
- outputs of provers
- notes.md (summary so far)
- output.md (rigorously proven results so far)

Guidelines:
- notes.md: should be a readable running log of interesting work. Prefer appending. Replace only if old notes are clearly misleading. Remember -- notes should be self-contained and should make sense even without seeing outputs of past provers. 
- output.md: should be concise and rigorous. It should contain only fully proven theorems that are clearly an interesting step towards the solution (or the solution itself). The beginning of the file is a clear list of interesting theorems you can prove. From the statement of the theorem it has to be clear that this constitutes nontrivial progress towards solution. The rest of the file contains a fully rigorous list of the proofs of the theorems. Keep only proven theorems with clear proofs. If a statement is flawed and you cannot fix it, remove it from output.md and instead add it to notes.md with explanation.
- Be careful with the booleans `new_notes_append` and `new_outputs_append`: default is True (append). Use False only when deliberately rewriting everything.

Tasks:
1) Audit rigor: identify unjustified steps, false statements, missing lemmas; produce minimal counterexamples.
2) Triage value: separate genuine progress from noise.
3) Guide next steps: propose what provers should try next.

**Return strictly JSON**:
{
  "feedback_md": "Detailed critique of prover outputs (â‰¥200 words). Include concrete next-step suggestions. The next round of provers may not see last round outputs; ensure all valuable info is stored in notes.",
  "new_notes_md": "Markdown (KaTeX allowed). Usually appended to notes.",
  "new_notes_append": "True|False",
  "new_outputs_md": "Markdown (KaTeX allowed). Usually appended to output.md.",
  "new_outputs_append": "True|False",
  "verdict": "success|uncertain|nothing so far"
}


--- USER ---
You receive multiple prover reports. Evaluate correctness, value, and pick promising directions. Update notes.md (append/replace) with useful ideas and update output.md (append/replace) ONLY with rigorously verified results.

Prover reports (JSON):
[{"prover_id": "01", "progress_md": "Headlines\n- Model identification: each step is a parallel adjacent block transposition, i.e., the class PBT in Jel\u00ednek\u2013Opler\u2013Pek\u00e1rek (arXiv:2311.08727). So we study the PBT-sorting time of the specific input \u03c0 = bit-reversal on n = 2^d.\n- Known bounds from 2311.08727: wstp(PBT; n) = O(log^2 n); lower bound \u2126(log n) for any proper class. The tight bound for PBT (and layered L) is explicitly left open; proving \u2126(log^2 n) for the bit-reversal input would improve the general lower bound for PBT.\n- Proposed potential \u03a6(A) = \u03a3_j D_j(A), with D_j(A) := |log_2 B_j(A) \u2212 (d \u2212 j)|, where B_j(A) is the number of monochromatic runs under coloring by bit j. For the bit-reversal input A_0, \u03a3_j D_j(A_0) = \u0398(d^2) = \u0398(log^2 n). Goal: per step drop \u0394\u03a6 = O(1).\n\nNew rigor (small lemmas), why useful, and proofs/sketches\n1) Equivalence to PBT (why useful: aligns our model with the literature and its O(log^2 n) upper bound, and frames the task as a special-case lower bound within their class hierarchy).\n- In one step we partition into consecutive intervals and swap disjoint adjacent pairs of intervals in parallel. This is precisely a composition with an element of the class PBT (parallel block transpositions), namely a permutation obtained as a sum of rotations on the interval decomposition. Therefore \u201cour model\u201d = sorting by PBT.\n\n2) Exact values B_j at the endpoints (why useful: calibrates the potential function).\n- For n=2^d and the bit-reversal input A_0, B_j(A_0) = 2^{j+1} (j=0,\u2026,d\u22121). For the fully sorted order A_\u22c6, B_j(A_\u22c6) = 2^{d\u2212j}. Thus D_j(A_0) = |(j+1) \u2212 (d\u2212j)| = |2j+1\u2212d| and\n  \u03a3_{j=0}^{d\u22121} D_j(A_0) = \u0398(d^2) = \u0398(log^2 n).\n\n3) Per-level \u201cadditive\u201d change bound via local boundary accounting (why useful: bounds how much B_j can move in one step in terms of which array boundaries are affected).\n- Fix j. Let T_j(A) \u2286 {1,\u2026,n\u22121} be the set of indices i where the j-color changes between positions i and i+1; so |T_j(A)| = B_j(A) \u2212 1.\n- One step picks disjoint adjacent interval pairs (L_k, R_k). For each matched pair there are exactly three index positions whose adjacent pair changes: the boundary before L_k, the boundary between L_k and R_k, and the boundary after R_k. All other internal adjacencies remain unchanged.\n- Hence the symmetric difference T_j(A) \u0394 T_j(A\u2032) is contained in the set S_step of indices altered by this step, with |S_step| \u2264 3\u00b7(# matched pairs). Consequently, for every j we have |B_j(A\u2032) \u2212 B_j(A)| \u2264 |T_j(A\u2032) \u0394 T_j(A)| \u2264 3\u00b7(# pairs).\n- Remark: this by itself is too coarse for our \u2126(log^2 n) goal, because the number of pairs can be \u0398(n) in a step. It does, however, isolate that only the 3-per-pair boundary changes can affect B_j.\n\n4) Per-level \u201cuseful boundary\u201d refinement (why useful: ties the change in B_j to current j-run structure, not to the raw number of pairs).\nClaim 4.1. For fixed j, a matched pair can change B_j only if at least one of its three altered indices is either (i) itself in T_j(A), or (ii) adjacent to a run boundary in the following sense: the altered index shares one of its incident positions with a j-run boundary in A.\n- Rationale. If both positions adjacent to an altered index belong to the same j-run and neither end of the index abuts a j-run boundary in A, then the two items at that index (pre- and post-step) both come from the same j-run; in particular they have the same j-color both before and after, so the indicator \u201ci \u2208 T_j(\u00b7)\u201d cannot flip at that index.\n- Consequence. Let U_j(A) be the set of indices that are in T_j(A) or adjacent to an element of T_j(A). Then |U_j(A)| \u2264 3\u00b7|T_j(A)| = 3(B_j(A) \u2212 1). The number of indices at which T_j-membership can possibly change in one step is \u2264 |U_j(A)|. Therefore\n  |B_j(A\u2032) \u2212 B_j(A)| \u2264 |T_j(A\u2032) \u0394 T_j(A)| \u2264 |U_j(A)| \u2264 3(B_j(A) \u2212 1).\n- Corollary 4.2 (per-level constant-factor cap). For any A\u2192A\u2032 in one step and any j,\n  B_j(A\u2032) \u2264 4\u00b7B_j(A) and B_j(A) \u2264 4\u00b7B_j(A\u2032). Equivalently, |log_2 B_j| changes by at most 2 per step.\nProof. From the inequality above, B_j(A\u2032) \u2264 B_j(A) + 3(B_j(A) \u2212 1) \u2264 4B_j(A). Apply the same inequality to the inverse step (also a PBT step) to get the reverse inequality.\n- Comment. The factor 4 is certainly improvable; I suspect factor 2 holds, but a clean proof that avoids overcounting \u201cdouble-adjacent\u201d alterations requires a tight charging scheme. Even factor 4 already implies |\u0394 log_2 B_j| \u2264 2.\n\n5) Alignment scarcity of cut positions across bit-levels (why useful: a quantitative cross-level restriction for the bit-reversal input A_0).\nLemma 5.1 (dyadic alignment bound). For the bit-reversal input A_0, let G_j \u2286 {1,\u2026,n\u22121} denote the set of j-run boundary indices (so |G_j| = B_j(A_0) \u2212 1 = 2^{j+1} \u2212 1). For any set S of partition cut positions (i.e., indices where we place interval boundaries in a step),\n  \u03a3_{j=0}^{d\u22121} |S \u2229 G_j| = \u03a3_{i\u2208S} (1 + v_2(i)) \u2264 |S|(1 + \u230alog_2(n\u22121)\u230b).\n- Proof. In A_0 the j-run boundaries are the indices i divisible by 2^{d\u2212j\u22121}. Equivalently, i \u2208 G_j iff d\u2212j\u22121 \u2264 v_2(i), where v_2(i) is the 2-adic valuation. Thus for a fixed i, the set {j: i \u2208 G_j} has size 1+v_2(i). Summing over S and using v_2(i) \u2264 \u230alog_2 i\u230b \u2264 \u230alog_2(n\u22121)\u230b gives the bound.\n- Intuition: a single cut index can be simultaneously \u201cuseful\u201d for only O(log n) bit-levels; hence even very fine partitions cannot align with all bit-level boundaries at once at linear density.\n\nSmall examples and sanity checks\n- n=8, A_0 = [0,4,2,6,1,5,3,7]. B_0=2, B_1=4, B_2=8. If we partition into singletons and match (1,2), (3,4), (5,6), (7,8), the three indices that change per matched pair are exactly the three boundaries around each pair; but for j=0 only the central boundary near the 0/1 split can be \u201cuseful\u201d. Empirically B_0 cannot jump from 2 to \u0398(n) in one step; more generally, the useful-boundary lemma predicts |\u0394B_0| \u2264 3(B_0\u22121) = 3.\n- For j = d\u22121 (MSB) at A_0, B_{d\u22121} = 2^d = n. Then |\u0394B_{d\u22121}| \u2264 3(n\u22121) is trivially true; the interesting regime is small j where B_j is small. There, Lemma 4.1 caps the number of useful indices by O(B_j), consistent with the block-coalescence intuition.\n\nWhy these are not yet enough for \u2126(log^2 n)\n- The \u201cper-level constant factor cap\u201d (even with factor 2) alone only yields that each D_j can decrease by O(1) per step; summing over all levels gives \u0394\u03a6 = O(d) per step, implying only \u2126(d) steps. To reach \u2126(d^2) we need to argue that only O(1) levels can enjoy constant-factor progress in the same step (a cross-level scarcity lemma).\n- A naive \u201ccapacity\u201d counting using \u03a3_j B_j(A_0) = \u0398(n) and the observation that a matched pair of size L influences \u2248 L/\u2113_j boundaries at level j (where \u2113_j = 2^{d\u2212j\u22121} is the j-run length in A_0) suggests that simultaneously reducing B_j by a constant factor across many j is not obviously impossible: \u03a3_j (L/\u2113_j) = O(L), and \u03a3_j B_j(A_0) = \u0398(n). So simple one-dimensional capacity arguments do not create a missing log factor.\n- The alignment lemma (Lemma 5.1) shows a single cut index hits O(log n) levels, but a partition has |S| \u2248 n cuts in the extreme, and |S|\u00b7log n is still big enough to interact with all levels in principle. So we need a stronger statement than mere counting of aligned cuts; we must quantify how many aligned cuts are actually needed to produce constant-factor changes in B_j and show that a single partition cannot simultaneously supply that demand for many j.\n\nObstacles and gaps (explicit)\n- The factor-2 per-level cap is plausible but not yet proved cleanly; I gave a rigorous factor-4 cap (Corollary 4.2). Improving this constant strengthens the per-level bound but does not yet give \u2126(log^2 n).\n- The key missing piece is a robust cross-level scarcity theorem. The naive union bound over cuts (Lemma 5.1) is insufficient\u2014the capacity vs. demand calculation doesn\u2019t produce an extra log. We need a structural reason why the same set of disjoint adjacent block swaps cannot simultaneously realize the \u201cgood pairings\u201d of runs required for constant-factor reduction at many distinct bit-levels.\n- There is no output.md provided; thus far there is no curated, rigorously proved result beyond the baseline \u2126(log n). Our Lemma 3\u20135 fill some pieces but do not yet imply \u2126(log^2 n).\n\nIdeas for next steps (testable subgoals)\n- Strengthen the per-level cap: Aim to prove B_j(A\u2032) \u2264 2\u00b7B_j(A) and B_j(A) \u2264 2\u00b7B_j(A\u2032) in one step for every j. Strategy: refine the \u201cuseful boundary\u201d charging so that every index whose membership toggles is charged to a unique j-run boundary in A or in A\u2032, and each boundary receives O(1) charge. This would give |\u0394 log_2 B_j| \u2264 1 per step.\n- Quantify \u201cdemand\u201d to get constant-factor progress at a fixed j: Formalize that reducing B_j by a factor of 1\u2212\u03b5 requires selecting cuts that microscopically pair (most of) adjacent j-runs in an alternating fashion. Prove that such a pairing demands \u03a9(B_j) central cuts specifically at the j-run boundaries (not just adjacency to them) and also constraints on which of those cuts are matched. This could lift the per-level demand from mere \u0398(B_j) \u201ctouched indices\u201d to \u0398(B_j) \u201ccentral matched boundaries,\u201d which then interacts more tightly across levels via disjointness of pairs.\n- Cross-level conflict via disjointness: For A_0 the sets of j-run boundaries form a family of dyadic arithmetic progressions. Try to show that if you match central boundaries to reduce B_j substantially, those same matched pairs necessarily misalign with the central boundaries needed to reduce B_k for |k\u2212j| large; i.e., central boundaries for different j\u2019s largely do not coincide and cannot all be matched at once due to disjointness of pairs. Precise goal: For any partition+matching M, let C_j(M) be the number of matched central boundaries that lie in G_j. Prove \u03a3_j C_j(M)/B_j \u2264 O(1) (or at least O(log n)). This would imply that only O(1) (or O(log n)) levels can see constant-factor progress in a single step.\n- Computational probe (n=16,32): Enumerate partitions+matchings from A_0 (up to symmetries), compute all B_j before/after, and record which levels see \u22652\u00d7 change. This can guide a conjecture on an absolute bound for the number of such levels per step.\n- Alternative potentials: Explore weighted potentials that penalize \u201csimultaneous progress across many j\u201d more severely, e.g., \u03a6_\u03b1(A) = \u03a3_j \u03b1^{|2j+1\u2212d|}\u00b7|log_2 B_j(A) \u2212 (d\u2212j)| for \u03b1>1, and try to prove a per-step drop independent of d. This would hinge on relating the weights to the dyadic structure of G_j.\n- Connection to known open problem: If we can show the desired cross-level scarcity for the specific A_0, it already yields \u2126(log^2 n) for bit-reversal under PBT and strictly improves the general lower bound for the class. Even a weaker statement like \u201cin any step, at most O(1) levels with |2j+1\u2212d| \u2265 c\u00b7d see constant-factor progress\u201d would imply a near-\u2126(log^2 n) bound.\n\nSummary\n- Formalized that our model is exactly PBT.\n- Established a clean per-step per-level bound: |\u0394B_j| \u2264 3(B_j\u22121) \u21d2 a constant-factor cap B_j\u2032/B_j \u2264 4 (factor likely improvable to 2). This justifies that |\u0394 log B_j| is O(1) per level per step.\n- Proved an \u201calignment scarcity\u201d lemma (Lemma 5.1) for A_0: a cut position can be aligned with at most O(log n) levels j. This is a building block towards a cross-level scarcity theorem, but by itself not sufficient.\n- Identified the main obstacle: converting alignment scarcity and disjointness of matched pairs into a sharp bound on how many levels can make constant-factor progress in the same step.\n- Outlined concrete next steps: (i) tighten the per-level cap to factor 2; (ii) quantify per-level demand in terms of central matched boundaries; (iii) prove a cross-level trade-off \u03a3_j C_j(M)/B_j \u2264 O(1); (iv) run small-n experiments to test these phenomena.\n"}, {"prover_id": "02", "progress_md": "Ideas and setup\n- Model recap. One step picks a partition of the array into consecutive intervals and swaps some disjoint adjacent interval-pairs in parallel. This exactly matches one-step permutations in the class PBT (parallel block transpositions) as in Jel\u00ednek\u2013Opler\u2013Pek\u00e1rek (JOP): partition into B1 B2 \u2026 B2k (allowing empty blocks formally, but we never need them) and swap each (B2i\u22121,B2i).\n- Significance. JOP show wstp(PBT;n) = O(log^2 n) but only \u2126(log n) lower bounds are known. Proving \u2126(log^2 n) for bit-reversal in our model would imply \u0398(log^2 n) worst-case in PBT and address an open direction (their Problem 8.1 for L and PBT).\n- Strategy. Track, for each bit level j, the number B_j(A) of monochromatic runs when elements are colored by bit j. For bit-reversal input A0 (n=2^d): B_j(A0)=2^{j+1}. For the sorted order A\u22c6: B_j(A\u22c6)=n/2^j=2^{d\u2212j}. The potential \u03a6(A)=\u2211_{j=0}^{d\u22121} D_j(A) with D_j(A)=|log_2 B_j(A)\u2212log_2 B_j(A\u22c6)| satisfies \u03a6(A0)=\u0398(d^2) and \u03a6(A\u22c6)=0. Goal: per-step drop of \u03a6 is O(1) to force \u2126(d^2) steps.\n\nClaim 1 (per-level constant-factor cap)\n- Statement. Fix j. In any single step A\u2192A\u2032, the run-count B_j can change by at most a constant multiplicative factor: there exists an absolute c such that B_j(A\u2032) \u2208 [B_j(A)/c, c\u00b7B_j(A)]. In particular, we can take c=7.\n- Why useful here. It prevents a step from massively improving a single level j.\n- Proof sketch (rigorous local counting). Let R_j(A) be the set of j-run boundaries (edges between adjacent items where bit j flips), so B_j(A)=|R_j(A)|+1. In a step, only adjacencies at three kinds of edges per swapped pair can change: the left outer boundary, the inner boundary between the two swapped intervals, and the right outer boundary. Hence if m pairs are swapped, at most 3m adjacency edges can change in total. However, only pairs that actually intersect the j-run boundary set can affect B_j: if a pair lies entirely within a single j-monochromatic run, all three affected adjacencies are between same colors, so B_j is unchanged. Let Q_j be the set of swapped pairs whose union intersects R_j(A). By disjointness, each boundary in R_j(A) lies in the union of at most one swapped pair, so |Q_j| \u2264 |R_j(A)| = B_j(A)\u22121. For each such pair, at most O(1) of the three changed adjacencies can flip the \u201cis boundary\u201d status. Therefore |B_j(A\u2032)\u2212B_j(A)| \u2264 C\u00b7|Q_j| \u2264 C(B_j(A)\u22121) for some absolute C (one can take C=6 by a brute-force case check along the three edges). This implies B_j(A\u2032) \u2264 (1+C) B_j(A) and symmetrically B_j(A) \u2264 (1+C) B_j(A\u2032), hence the factor cap with c=1+C \u2264 7.\n- Sanity check on toy cases. For j=0 with initial 00\u2026011\u20261, only the unique 0|1 boundary can be in Q_j, hence B_0 can increase or decrease by O(1) in one step, matching the known \u201cmerging needs \u2126(log n)\u201d folklore.\n\nEdge-to-level charging (a quantitative cross-level accounting tool)\n- Setup. Let S be the set of adjacency edges whose status (same-color vs different-color at level j) changes in a step. For a fixed j, the change \u0394_j := |B_j(A\u2032)\u2212B_j(A)| is O(|S \u2229 E_j|), where E_j is the set of j-run boundary gridlines (the edges periodically spaced by L_j=2^{d\u22121\u2212j}).\n- Observation (valuation count). For an edge position e\u2208{1,\u2026,n\u22121}, define \u03bd_2(e) as the exponent of the highest power of 2 dividing e. The edge e belongs to E_j if and only if L_j divides e, i.e., j \u2264 d\u22121\u2212\u03bd_2(e). Thus the number of levels j at which e is a j-grid boundary equals \u03bd_2(e)+1. The harmonic identity \u2211_{e=1}^{n\u22121} (\u03bd_2(e)+1) = \u0398(n) implies that \u201con average\u201d an edge participates in O(1) levels.\n- Consequence (weighted bound). For any nonnegative weights w_j, we have \u2211_j w_j\u00b7\u0394_j \u2264 C\u00b7\u2211_{e\u2208S} \u2211_{j: e\u2208E_j} w_j. Choosing w_j = 2^{\u2212(j+1)} gives \u2211_j 2^{\u2212(j+1)}\u00b7\u0394_j \u2264 C\u2032\u00b7|S| because \u2211_{j: e\u2208E_j} 2^{\u2212(j+1)} \u2264 1 for every e. More generally, for w_j = 2^{\u2212(j+1)}/(j+1) we get \u2211_j w_j\u00b7\u0394_j \u2264 C\u2032\u2032\u00b7|S| (up to an extra O(log log n) factor if one tightens constants). These bounds are robust and will be useful for potentials that weight levels by 2^{\u2212j} (or slightly heavier penalties near extremes).\n- Why useful here. This provides a cross-level scarcity principle: many changed adjacencies cannot produce \u201clarge\u201d relative progress on many levels simultaneously, once progress is normalized appropriately by the density of j-boundaries.\n\nScale-sensitive refinement via pair sizes\n- Additional structure. Let each swapped pair p consist of two adjacent intervals of total length s(p). At level j, every j-run has length L_j=2^{d\u22121\u2212j}. One pair p can affect at most O(min{1, s(p)/L_j}) distinct j-boundaries: the three adjacency changes are confined to O(1) blocks of length s(p), which intersect O(s(p)/L_j) of the L_j-spaced grid edges.\n- Lemma (deterministic). For all j, \u0394_j \u2264 C\u00b7\u2211_{p} min{1, s(p)/L_j}. Consequently, using B_j(A0)=2^{j+1} and L_j=2^{d\u22121\u2212j}, we get for the bit-reversal input A0: \u0394_j / B_j(A0) \u2264 (C/n)\u00b7\u2211_{p} min{s(p), L_j}.\n- Summing in j and swapping sums yields: \u2211_j \u0394_j / B_j(A0) \u2264 (C/n)\u00b7\u2211_{p} \u2211_{t=0}^{d\u22121} min{s(p), 2^t} = (C/n)\u00b7\u2211_{p} O(s(p)\u00b7log(1+s(p))). Since \u2211_{p} s(p) \u2264 n in every step, the RHS is O(log n) per step. This recovers an \u2126(log n) lower bound by a \u201cfractional progress\u201d argument and quantifies that a step cannot make constant-fraction progress on many levels at once unless it spends large total size in pairs.\n- Why useful here. This pins down quantitatively how pair sizes limit multi-level progress. It suggests going beyond additive counting toward scale-weighted potentials.\n\nToward an \u2126(log^2 n) (or near) bound: a proposed program\n- Lemma 1 is now clean and rigorous. The remaining challenge is a cross-level bound strong enough to cap the drop of \u03a6(A)=\u2211_j |log B_j(A)\u2212log B_j(A\u22c6)| by O(1) per step. The above tools give only O(log n) so far, recovering \u2126(log n).\n- Heuristic strengthening. To achieve a constant-factor change in B_j, one needs \u0398(B_j) changed adjacencies at level j (since each changes B_j by O(1)). By the \u201csize lemma\u201d above, generating \u0398(B_j) changes at level j requires \u2211_{p} min{1, s(p)/L_j} = \u2126(1), i.e., the total s(p) across pairs must be \u2126(L_j). Doing this for T different levels j in one step requires \u2126(\u2211_{t=1}^T L_{j_t}) total size budget, but \u2211_{p} s(p) \u2264 n. For the dyadic sequence L_j=2^{d\u22121\u2212j}, the sum over a set of T distinct levels is at least \u2248 2^{d\u2212T} if clustered, but if spread out evenly across O(d) levels, \u2211 L_j \u2248 \u0398(n). This suggests that making constant-factor progress on \u03c9(1) distinct levels at once quickly exhausts the size budget, hinting that only O(1) levels can enjoy a constant-factor change per step (a formal version of speculative Lemma 2).\n- Formal target (to prove next). There exists an absolute c>0 such that in any step, the set J of levels j for which B_j changes by a factor \u22652 satisfies |J| \u2264 c. Outline approach: assign to each pair p a unique \u201chome level\u201d h(p) so that (i) p can contribute at most O(1) to constant-factor progress for levels \u0338= h(p), and (ii) the sum of s(p)/L_{h(p)} over all p is O(1). A natural home level is the unique j with L_j \u2208 [s(p)/2, 2 s(p)]. Packing disjoint pairs implies \u2211 s(p) \u2264 n, hence \u2211 s(p)/L_{h(p)} \u2264 O(1). Use the size lemma to argue that constant-factor progress at level j requires total contribution \u03a9(1) from pairs with h(p)=j. Thus at most O(1) such levels exist per step.\n- If established, combining with the per-level factor cap (Lemma 1) implies that \u03a6 can decrease by at most O(1) per step: each of the O(1) \u201cactive\u201d levels can shrink |log B_j \u2212 log B_j\u22c6| by O(1), all other levels shrink by at most a constant fraction of a fraction, summing to O(1) overall. This would yield the desired \u2126(log^2 n) lower bound.\n\nToy special case (to aim for as an intermediate milestone)\n- Restricted steps: equal-scale partitions. Suppose every step uses a partition into intervals whose lengths are within a factor 2 of a common L (and swaps a matching on these). Then: a pair has size s\u2248L. The size lemma gives \u0394_j \u2264 C\u00b7m\u00b7min{1, L/L_j}. Since m\u2264n/L, we have \u0394_j \u2264 C\u00b7(n/L)\u00b7min{1, L/L_j} \u2264 C\u00b7min{n/L, n/L_j}. For j with L_j \u226a L, \u0394_j \u2264 C\u00b7(n/L_j), a tiny fraction of B_j(A0)=2^{j+1} unless L\u2248L_j. For j with L_j\u2248L, \u0394_j \u2264 C\u00b7(n/L) gives at best constant-fraction progress. Only O(1) neighboring j have L_j within factor 2 of L. Hence per step, only O(1) levels can change by a constant factor. This toy case supports Lemma 2 in a simplified setting and could be made rigorous.\n\nSmall examples and checks\n- n=8 (d=3), A0=[0,4,2,6,1,5,3,7]. Compute B_j(A0)=(2,4,8) for j=0,1,2; B_j(A\u22c6)=(8,4,2). Any step alters at most three adjacencies per pair; a pair not intersecting the unique B_0 boundary is irrelevant to B_0; at most one pair is relevant, so B_0 changes by O(1) factor. For B_1, the four boundaries are at positions multiples of 2; disjointness similarly limits pairs that can affect many of them at once unless s(p)\u22482. This matches the scale-sensitive picture.\n\nConnections to literature (JOP and gaps)\n- Our model coincides (one-step-wise) with PBT. JOP prove O(log^2 n) upper bounds (also for L), and \u2126(log n) lower bounds in general via counting. They leave open closing the gap to \u2126(log^2 n). Our Lemma 1 aligns with their \u201cboundary locality\u201d arguments; the key remaining step is Lemma 2 (cross-level scarcity). The size-based accounting we developed above is a promising path; formalizing the \u201chome level\u201d charging to show only O(1) levels can change by factor \u22652 per step would settle the lower bound.\n\nNext steps (concrete, testable)\n1) Formalize and prove the size lemma: \u0394_j \u2264 C\u00b7\u2211_p min{1, s(p)/L_j}, including an exact constant C and a careful accounting of the three changed adjacencies per pair. This is local and checkable.\n2) Prove Lemma 1 rigorously with an explicit constant c (I gave c=7 via a union bound; tightening to c=3 or c=5 is likely with a refined boundary case analysis). Write the proof cleanly so the verifier can include it in output.md.\n3) Prove the toy special-case Lemma 2 for equal-scale partitions, giving an \u2126(log^2 n) lower bound for that restricted algorithm class. This creates a baseline \u201cspecial case\u201d lower bound.\n4) Develop the \u201chome level\u201d charging in full generality: for each pair p, define h(p) with L_{h(p)}\u2248s(p). Show that to achieve a factor-2 change at level j, the sum over p with h(p)=j of min{1, s(p)/L_j} must be \u03a9(1). Since \u2211_p s(p)/L_{h(p)} \u2264 O(1), only O(1) levels can have such progress.\n5) If step 4 succeeds, deduce per-step \u03a6 drop \u2264 O(1) (each active level reduces D_j by O(1); inactive ones by at most a small fraction), hence \u2126(log^2 n).\n6) Computational aid on small n (n=16,32): enumerate random partitions and measure how many levels j see a \u22652\u00d7 change in B_j in a single step; record empirical maximum; this can guide constants and refine the \u201cactive level\u201d definition.\n\nGaps or issues in current outputs\n- There is no output.md provided; hence no prior rigorous lemmas to cross-check. The present round delivers Lemma 1 in a form ready to be curated and a precise statement of the \u201csize lemma\u201d with a clear proof plan. The main open gap remains the core cross-level scarcity (Lemma 2), for which I outlined two routes: the equal-scale special case (feasible) and the general \u201chome level\u201d charging (harder but promising).\n"}]

Current notes.md:


Current output.md (if any):

